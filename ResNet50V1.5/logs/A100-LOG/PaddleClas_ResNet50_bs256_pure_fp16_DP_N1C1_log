A new field (seed) detected!
A new field (fuse_elewise_add_act_ops) detected!
A new field (enable_addto) detected!
[2023/08/02 20:50:25] ppcls INFO: 
===========================================================
==        PaddleClas is powered by PaddlePaddle !        ==
===========================================================
==                                                       ==
==   For more info please go to the following website.   ==
==                                                       ==
==       https://github.com/PaddlePaddle/PaddleClas      ==
===========================================================

[2023/08/02 20:50:25] ppcls INFO: Global : 
[2023/08/02 20:50:25] ppcls INFO:     checkpoints : None
[2023/08/02 20:50:25] ppcls INFO:     pretrained_model : None
[2023/08/02 20:50:25] ppcls INFO:     output_dir : ./output/
[2023/08/02 20:50:25] ppcls INFO:     device : gpu
[2023/08/02 20:50:25] ppcls INFO:     save_interval : 1
[2023/08/02 20:50:25] ppcls INFO:     eval_during_train : False
[2023/08/02 20:50:25] ppcls INFO:     eval_interval : 1
[2023/08/02 20:50:25] ppcls INFO:     epochs : 1
[2023/08/02 20:50:25] ppcls INFO:     print_batch_step : 10
[2023/08/02 20:50:25] ppcls INFO:     use_visualdl : False
[2023/08/02 20:50:25] ppcls INFO:     image_channel : 4
[2023/08/02 20:50:25] ppcls INFO:     image_shape : [4, 224, 224]
[2023/08/02 20:50:25] ppcls INFO:     save_inference_dir : ./inference
[2023/08/02 20:50:25] ppcls INFO:     to_static : False
[2023/08/02 20:50:25] ppcls INFO:     use_dali : True
[2023/08/02 20:50:25] ppcls INFO:     seed : 1234
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: AMP : 
[2023/08/02 20:50:25] ppcls INFO:     use_amp : True
[2023/08/02 20:50:25] ppcls INFO:     use_fp16_test : False
[2023/08/02 20:50:25] ppcls INFO:     scale_loss : 128.0
[2023/08/02 20:50:25] ppcls INFO:     use_dynamic_loss_scaling : True
[2023/08/02 20:50:25] ppcls INFO:     use_promote : False
[2023/08/02 20:50:25] ppcls INFO:     level : O2
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: Arch : 
[2023/08/02 20:50:25] ppcls INFO:     name : ResNet50
[2023/08/02 20:50:25] ppcls INFO:     class_num : 1000
[2023/08/02 20:50:25] ppcls INFO:     input_image_channel : 4
[2023/08/02 20:50:25] ppcls INFO:     data_format : NHWC
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: Loss : 
[2023/08/02 20:50:25] ppcls INFO:     Train : 
[2023/08/02 20:50:25] ppcls INFO:         CELoss : 
[2023/08/02 20:50:25] ppcls INFO:             weight : 1.0
[2023/08/02 20:50:25] ppcls INFO:     Eval : 
[2023/08/02 20:50:25] ppcls INFO:         CELoss : 
[2023/08/02 20:50:25] ppcls INFO:             weight : 1.0
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: Optimizer : 
[2023/08/02 20:50:25] ppcls INFO:     name : Momentum
[2023/08/02 20:50:25] ppcls INFO:     momentum : 0.9
[2023/08/02 20:50:25] ppcls INFO:     multi_precision : True
[2023/08/02 20:50:25] ppcls INFO:     lr : 
[2023/08/02 20:50:25] ppcls INFO:         name : Piecewise
[2023/08/02 20:50:25] ppcls INFO:         learning_rate : 0.1
[2023/08/02 20:50:25] ppcls INFO:         decay_epochs : [30, 60, 90]
[2023/08/02 20:50:25] ppcls INFO:         values : [0.1, 0.01, 0.001, 0.0001]
[2023/08/02 20:50:25] ppcls INFO:     regularizer : 
[2023/08/02 20:50:25] ppcls INFO:         name : L2
[2023/08/02 20:50:25] ppcls INFO:         coeff : 0.0001
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: DataLoader : 
[2023/08/02 20:50:25] ppcls INFO:     Train : 
[2023/08/02 20:50:25] ppcls INFO:         dataset : 
[2023/08/02 20:50:25] ppcls INFO:             name : ImageNetDataset
[2023/08/02 20:50:25] ppcls INFO:             image_root : ./dataset/ILSVRC2012/
[2023/08/02 20:50:25] ppcls INFO:             cls_label_path : ./dataset/ILSVRC2012/train_list.txt
[2023/08/02 20:50:25] ppcls INFO:             transform_ops : 
[2023/08/02 20:50:25] ppcls INFO:                 DecodeImage : 
[2023/08/02 20:50:25] ppcls INFO:                     to_rgb : True
[2023/08/02 20:50:25] ppcls INFO:                     channel_first : False
[2023/08/02 20:50:25] ppcls INFO:                 RandCropImage : 
[2023/08/02 20:50:25] ppcls INFO:                     size : 224
[2023/08/02 20:50:25] ppcls INFO:                 RandFlipImage : 
[2023/08/02 20:50:25] ppcls INFO:                     flip_code : 1
[2023/08/02 20:50:25] ppcls INFO:                 NormalizeImage : 
[2023/08/02 20:50:25] ppcls INFO:                     scale : 1.0/255.0
[2023/08/02 20:50:25] ppcls INFO:                     mean : [0.485, 0.456, 0.406]
[2023/08/02 20:50:25] ppcls INFO:                     std : [0.229, 0.224, 0.225]
[2023/08/02 20:50:25] ppcls INFO:                     order : 
[2023/08/02 20:50:25] ppcls INFO:                     output_fp16 : True
[2023/08/02 20:50:25] ppcls INFO:                     channel_num : 4
[2023/08/02 20:50:25] ppcls INFO:         sampler : 
[2023/08/02 20:50:25] ppcls INFO:             name : DistributedBatchSampler
[2023/08/02 20:50:25] ppcls INFO:             batch_size : 256
[2023/08/02 20:50:25] ppcls INFO:             drop_last : False
[2023/08/02 20:50:25] ppcls INFO:             shuffle : True
[2023/08/02 20:50:25] ppcls INFO:         loader : 
[2023/08/02 20:50:25] ppcls INFO:             num_workers : 4
[2023/08/02 20:50:25] ppcls INFO:             use_shared_memory : True
[2023/08/02 20:50:25] ppcls INFO:     Eval : 
[2023/08/02 20:50:25] ppcls INFO:         dataset : 
[2023/08/02 20:50:25] ppcls INFO:             name : ImageNetDataset
[2023/08/02 20:50:25] ppcls INFO:             image_root : ./dataset/ILSVRC2012/
[2023/08/02 20:50:25] ppcls INFO:             cls_label_path : ./dataset/ILSVRC2012/val_list.txt
[2023/08/02 20:50:25] ppcls INFO:             transform_ops : 
[2023/08/02 20:50:25] ppcls INFO:                 DecodeImage : 
[2023/08/02 20:50:25] ppcls INFO:                     to_rgb : True
[2023/08/02 20:50:25] ppcls INFO:                     channel_first : False
[2023/08/02 20:50:25] ppcls INFO:                 ResizeImage : 
[2023/08/02 20:50:25] ppcls INFO:                     resize_short : 256
[2023/08/02 20:50:25] ppcls INFO:                 CropImage : 
[2023/08/02 20:50:25] ppcls INFO:                     size : 224
[2023/08/02 20:50:25] ppcls INFO:                 NormalizeImage : 
[2023/08/02 20:50:25] ppcls INFO:                     scale : 1.0/255.0
[2023/08/02 20:50:25] ppcls INFO:                     mean : [0.485, 0.456, 0.406]
[2023/08/02 20:50:25] ppcls INFO:                     std : [0.229, 0.224, 0.225]
[2023/08/02 20:50:25] ppcls INFO:                     order : 
[2023/08/02 20:50:25] ppcls INFO:                     channel_num : 4
[2023/08/02 20:50:25] ppcls INFO:         sampler : 
[2023/08/02 20:50:25] ppcls INFO:             name : DistributedBatchSampler
[2023/08/02 20:50:25] ppcls INFO:             batch_size : 64
[2023/08/02 20:50:25] ppcls INFO:             drop_last : False
[2023/08/02 20:50:25] ppcls INFO:             shuffle : False
[2023/08/02 20:50:25] ppcls INFO:         loader : 
[2023/08/02 20:50:25] ppcls INFO:             num_workers : 4
[2023/08/02 20:50:25] ppcls INFO:             use_shared_memory : True
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: Infer : 
[2023/08/02 20:50:25] ppcls INFO:     infer_imgs : docs/images/inference_deployment/whl_demo.jpg
[2023/08/02 20:50:25] ppcls INFO:     batch_size : 10
[2023/08/02 20:50:25] ppcls INFO:     transforms : 
[2023/08/02 20:50:25] ppcls INFO:         DecodeImage : 
[2023/08/02 20:50:25] ppcls INFO:             to_rgb : True
[2023/08/02 20:50:25] ppcls INFO:             channel_first : False
[2023/08/02 20:50:25] ppcls INFO:         ResizeImage : 
[2023/08/02 20:50:25] ppcls INFO:             resize_short : 256
[2023/08/02 20:50:25] ppcls INFO:         CropImage : 
[2023/08/02 20:50:25] ppcls INFO:             size : 224
[2023/08/02 20:50:25] ppcls INFO:         NormalizeImage : 
[2023/08/02 20:50:25] ppcls INFO:             scale : 1.0/255.0
[2023/08/02 20:50:25] ppcls INFO:             mean : [0.485, 0.456, 0.406]
[2023/08/02 20:50:25] ppcls INFO:             std : [0.229, 0.224, 0.225]
[2023/08/02 20:50:25] ppcls INFO:             order : 
[2023/08/02 20:50:25] ppcls INFO:             channel_num : 4
[2023/08/02 20:50:25] ppcls INFO:         ToCHWImage : None
[2023/08/02 20:50:25] ppcls INFO:     PostProcess : 
[2023/08/02 20:50:25] ppcls INFO:         name : Topk
[2023/08/02 20:50:25] ppcls INFO:         topk : 5
[2023/08/02 20:50:25] ppcls INFO:         class_id_map_file : ppcls/utils/imagenet1k_label_list.txt
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: Metric : 
[2023/08/02 20:50:25] ppcls INFO:     Train : 
[2023/08/02 20:50:25] ppcls INFO:         TopkAcc : 
[2023/08/02 20:50:25] ppcls INFO:             topk : [1, 5]
[2023/08/02 20:50:25] ppcls INFO:     Eval : 
[2023/08/02 20:50:25] ppcls INFO:         TopkAcc : 
[2023/08/02 20:50:25] ppcls INFO:             topk : [1, 5]
[2023/08/02 20:50:25] ppcls INFO: ------------------------------------------------------------
[2023/08/02 20:50:25] ppcls INFO: fuse_elewise_add_act_ops : True
[2023/08/02 20:50:25] ppcls INFO: enable_addto : True
[2023-08-02 20:50:25,650] [    INFO] distributed_strategy.py:160 - distributed strategy initialized
[2023/08/02 20:50:25] ppcls INFO: DALI fused Operator conversion(Train): [DecodeImage, RandCropImage] -> DecodeRandomResizedCrop: {'device': 'mixed', 'output_type': <DALIImageType.RGB: 0>, 'device_memory_padding': 211025920, 'host_memory_padding': 140544512, 'random_area': [0.08, 1.0], 'random_aspect_ratio': [0.75, 1.3333333333333333], 'num_attempts': 100, 'resize_x': 224, 'resize_y': 224}
[2023/08/02 20:50:25] ppcls INFO: DALI fused Operator conversion(Train): [RandCropImage, RandFlipImage, NormalizeImage] -> CropMirrorNormalize: {'dtype': <DALIDataType.FLOAT16: 8>, 'output_layout': 'CHW', 'crop': (224, 224), 'mean': [123.675, 116.28, 103.53000000000002], 'std': [58.395, 57.120000000000005, 57.375], 'pad_output': True, 'prob': 0.5, 'device': 'gpu'}
[2023/08/02 20:50:25] ppcls INFO: Building DALI Train pipeline with num_shards: 1, num_gpus: 1
[/opt/dali/dali/operators/image/resize/resampling_attr.cc:100] The default behavior for LINEAR interpolation type has been changed to apply an antialiasing filter. If you didn't mean to apply an antialiasing filter, please use `antialias=False`
W0802 20:50:29.596110 15097 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 12.0, Runtime API Version: 11.2
W0802 20:50:29.599541 15097 gpu_resources.cc:149] device: 0, cuDNN Version: 8.1.
[2023/08/02 20:50:29] ppcls WARNING: "init_res" will be deprecated, please use "init_net" instead.
[2023-08-02 20:50:29,963] [    INFO] distributed_strategy.py:160 - distributed strategy initialized
[2023-08-02 20:50:29,963] [ WARNING] fleet.py:1092 - It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
I0802 20:50:30.387931 15097 fuse_pass_base.cc:59] ---  detected 33 subgraphs
I0802 20:50:30.474519 15097 fuse_pass_base.cc:59] ---  detected 33 subgraphs
I0802 20:50:30.866433 15097 fuse_pass_base.cc:59] ---  detected 16 subgraphs
I0802 20:50:30.894554 15097 fuse_pass_base.cc:59] ---  detected 16 subgraphs
I0802 20:50:32.512733 15097 interpretercore.cc:237] New Executor is Running.
[2023/08/02 20:50:32] ppcls WARNING: Only support FP16 evaluation when AMP O2 is enabled.
W0802 20:50:32.989854 15097 gpu_resources.cc:275] WARNING: device:  . The installed Paddle is compiled with CUDNN 8.2, but CUDNN version in your machine is 8.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
I0802 20:50:35.487388 15097 interpreter_util.cc:518] Standalone Executor is Used.
[2023/08/02 20:50:44] ppcls INFO: epoch:0   train step:10   lr: 0.100000, loss:  8.5818 top1:  0.0000 top5:  0.0078 batch_cost: 0.10081 s, reader_cost: 0.04201 s, ips: 2539.34225 samples/sec.
[2023/08/02 20:50:45] ppcls INFO: epoch:0   train step:20   lr: 0.100000, loss:  7.5250 top1:  0.0000 top5:  0.0039 batch_cost: 0.09998 s, reader_cost: 0.04160 s, ips: 2560.53699 samples/sec.
[2023/08/02 20:50:46] ppcls INFO: epoch:0   train step:30   lr: 0.100000, loss:  7.1901 top1:  0.0000 top5:  0.0117 batch_cost: 0.10144 s, reader_cost: 0.04371 s, ips: 2523.72436 samples/sec.
[2023/08/02 20:50:47] ppcls INFO: epoch:0   train step:40   lr: 0.100000, loss:  7.0740 top1:  0.0039 top5:  0.0039 batch_cost: 0.10084 s, reader_cost: 0.04296 s, ips: 2538.75252 samples/sec.
[2023/08/02 20:50:48] ppcls INFO: epoch:0   train step:50   lr: 0.100000, loss:  7.0093 top1:  0.0000 top5:  0.0000 batch_cost: 0.10002 s, reader_cost: 0.04229 s, ips: 2559.50391 samples/sec.
[2023/08/02 20:50:49] ppcls INFO: epoch:0   train step:60   lr: 0.100000, loss:  6.9190 top1:  0.0000 top5:  0.0000 batch_cost: 0.09930 s, reader_cost: 0.04124 s, ips: 2577.96417 samples/sec.
[2023/08/02 20:50:50] ppcls INFO: epoch:0   train step:70   lr: 0.100000, loss:  6.9239 top1:  0.0000 top5:  0.0078 batch_cost: 0.09938 s, reader_cost: 0.04150 s, ips: 2575.85075 samples/sec.
[2023/08/02 20:50:51] ppcls INFO: epoch:0   train step:80   lr: 0.100000, loss:  6.9034 top1:  0.0000 top5:  0.0117 batch_cost: 0.09878 s, reader_cost: 0.04097 s, ips: 2591.53712 samples/sec.
[2023/08/02 20:50:52] ppcls INFO: epoch:0   train step:90   lr: 0.100000, loss:  6.9485 top1:  0.0000 top5:  0.0195 batch_cost: 0.09855 s, reader_cost: 0.04076 s, ips: 2597.77831 samples/sec.
[2023/08/02 20:50:53] ppcls INFO: epoch:0   train step:100  lr: 0.100000, loss:  6.9381 top1:  0.0039 top5:  0.0078 batch_cost: 0.09851 s, reader_cost: 0.04068 s, ips: 2598.74663 samples/sec.
[2023/08/02 20:50:54] ppcls INFO: epoch:0   train step:110  lr: 0.100000, loss:  6.9030 top1:  0.0039 top5: -0.0078 batch_cost: 0.09826 s, reader_cost: 0.04045 s, ips: 2605.22807 samples/sec.
[2023/08/02 20:50:55] ppcls INFO: epoch:0   train step:120  lr: 0.100000, loss:  6.9073 top1:  0.0000 top5: -0.0117 batch_cost: 0.09814 s, reader_cost: 0.04038 s, ips: 2608.46094 samples/sec.
[2023/08/02 20:50:56] ppcls INFO: epoch:0   train step:130  lr: 0.100000, loss:  6.9040 top1:  0.0000 top5: -0.0078 batch_cost: 0.09822 s, reader_cost: 0.04051 s, ips: 2606.37583 samples/sec.
[2023/08/02 20:50:57] ppcls INFO: epoch:0   train step:140  lr: 0.100000, loss:  6.9047 top1:  0.0000 top5:  0.0000 batch_cost: 0.09848 s, reader_cost: 0.04082 s, ips: 2599.61088 samples/sec.
[2023/08/02 20:50:58] ppcls INFO: epoch:0   train step:150  lr: 0.100000, loss:  6.9052 top1:  0.0039 top5:  0.0039 batch_cost: 0.09841 s, reader_cost: 0.04081 s, ips: 2601.27090 samples/sec.
[2023/08/02 20:50:59] ppcls INFO: epoch:0   train step:160  lr: 0.100000, loss:  6.9091 top1:  0.0117 top5:  0.0195 batch_cost: 0.09839 s, reader_cost: 0.04082 s, ips: 2601.95094 samples/sec.
[2023/08/02 20:51:00] ppcls INFO: epoch:0   train step:170  lr: 0.100000, loss:  6.8890 top1:  0.0000 top5: -0.0039 batch_cost: 0.09823 s, reader_cost: 0.04070 s, ips: 2606.24821 samples/sec.
[2023/08/02 20:51:01] ppcls INFO: epoch:0   train step:180  lr: 0.100000, loss:  6.9770 top1:  0.0039 top5:  0.0078 batch_cost: 0.09820 s, reader_cost: 0.04069 s, ips: 2606.81057 samples/sec.
[2023/08/02 20:51:02] ppcls INFO: epoch:0   train step:190  lr: 0.100000, loss:  6.8750 top1:  0.0039 top5: -0.0156 batch_cost: 0.09825 s, reader_cost: 0.04080 s, ips: 2605.66430 samples/sec.
[2023/08/02 20:51:03] ppcls INFO: epoch:0   train step:200  lr: 0.100000, loss:  6.8901 top1:  0.0000 top5: -0.0039 batch_cost: 0.09837 s, reader_cost: 0.04092 s, ips: 2602.39151 samples/sec.
[2023/08/02 20:51:04] ppcls INFO: epoch:0   train step:210  lr: 0.100000, loss:  6.8888 top1:  0.0078 top5: -0.0195 batch_cost: 0.09844 s, reader_cost: 0.04100 s, ips: 2600.48283 samples/sec.
[2023/08/02 20:51:05] ppcls INFO: epoch:0   train step:220  lr: 0.100000, loss:  6.8826 top1:  0.0039 top5:  0.0117 batch_cost: 0.09841 s, reader_cost: 0.04099 s, ips: 2601.37626 samples/sec.
[2023/08/02 20:51:06] ppcls INFO: epoch:0   train step:230  lr: 0.100000, loss:  6.8774 top1:  0.0000 top5: -0.0117 batch_cost: 0.09846 s, reader_cost: 0.04104 s, ips: 2600.05176 samples/sec.
[2023/08/02 20:51:07] ppcls INFO: epoch:0   train step:240  lr: 0.100000, loss:  6.8913 top1:  0.0039 top5:  0.0078 batch_cost: 0.09839 s, reader_cost: 0.04098 s, ips: 2601.96203 samples/sec.
[2023/08/02 20:51:08] ppcls INFO: epoch:0   train step:250  lr: 0.100000, loss:  6.8628 top1:  0.0000 top5:  0.0117 batch_cost: 0.09834 s, reader_cost: 0.04092 s, ips: 2603.20799 samples/sec.
[2023/08/02 20:51:09] ppcls INFO: epoch:0   train step:260  lr: 0.100000, loss:  6.9453 top1:  0.0000 top5:  0.0078 batch_cost: 0.09829 s, reader_cost: 0.04088 s, ips: 2604.48026 samples/sec.
[2023/08/02 20:51:10] ppcls INFO: epoch:0   train step:270  lr: 0.100000, loss:  6.8702 top1:  0.0039 top5:  0.0156 batch_cost: 0.09844 s, reader_cost: 0.04102 s, ips: 2600.44829 samples/sec.
[2023/08/02 20:51:11] ppcls INFO: epoch:0   train step:280  lr: 0.100000, loss:  6.8355 top1:  0.0039 top5:  0.0273 batch_cost: 0.09847 s, reader_cost: 0.04108 s, ips: 2599.69828 samples/sec.
[2023/08/02 20:51:12] ppcls INFO: epoch:0   train step:290  lr: 0.100000, loss:  6.8679 top1:  0.0039 top5:  0.0195 batch_cost: 0.09852 s, reader_cost: 0.04114 s, ips: 2598.48360 samples/sec.
[2023/08/02 20:51:13] ppcls INFO: epoch:0   train step:300  lr: 0.100000, loss:  6.8435 top1:  0.0039 top5: -0.0078 batch_cost: 0.09845 s, reader_cost: 0.04110 s, ips: 2600.23562 samples/sec.
[2023/08/02 20:51:14] ppcls INFO: epoch:0   train step:310  lr: 0.100000, loss:  6.8350 top1:  0.0000 top5: -0.0156 batch_cost: 0.09850 s, reader_cost: 0.04116 s, ips: 2599.01217 samples/sec.
[2023/08/02 20:51:15] ppcls INFO: epoch:0   train step:320  lr: 0.100000, loss:  6.7975 top1:  0.0039 top5:  0.0195 batch_cost: 0.09850 s, reader_cost: 0.04118 s, ips: 2598.97172 samples/sec.
[2023/08/02 20:51:16] ppcls INFO: epoch:0   train step:330  lr: 0.100000, loss:  6.8152 top1:  0.0000 top5: -0.0117 batch_cost: 0.09854 s, reader_cost: 0.04120 s, ips: 2597.82590 samples/sec.
[2023/08/02 20:51:17] ppcls INFO: epoch:0   train step:340  lr: 0.100000, loss:  6.8452 top1:  0.0000 top5:  0.0117 batch_cost: 0.09854 s, reader_cost: 0.04120 s, ips: 2598.05510 samples/sec.
[2023/08/02 20:51:18] ppcls INFO: epoch:0   train step:350  lr: 0.100000, loss:  6.8252 top1:  0.0039 top5: -0.0195 batch_cost: 0.09858 s, reader_cost: 0.04126 s, ips: 2596.98297 samples/sec.
[2023/08/02 20:51:19] ppcls INFO: epoch:0   train step:360  lr: 0.100000, loss:  6.7806 top1:  0.0000 top5: -0.0117 batch_cost: 0.09854 s, reader_cost: 0.04122 s, ips: 2598.04418 samples/sec.
[2023/08/02 20:51:20] ppcls INFO: epoch:0   train step:370  lr: 0.100000, loss:  6.7853 top1:  0.0039 top5:  0.0117 batch_cost: 0.09849 s, reader_cost: 0.04117 s, ips: 2599.29724 samples/sec.
[2023/08/02 20:51:21] ppcls INFO: epoch:0   train step:380  lr: 0.100000, loss:  6.7912 top1:  0.0117 top5:  0.0234 batch_cost: 0.09843 s, reader_cost: 0.04111 s, ips: 2600.89135 samples/sec.
[2023/08/02 20:51:22] ppcls INFO: epoch:0   train step:390  lr: 0.100000, loss:  6.8049 top1:  0.0039 top5: -0.0078 batch_cost: 0.09837 s, reader_cost: 0.04106 s, ips: 2602.43446 samples/sec.
[2023/08/02 20:51:23] ppcls INFO: epoch:0   train step:400  lr: 0.100000, loss:  6.7815 top1:  0.0000 top5:  0.0078 batch_cost: 0.09834 s, reader_cost: 0.04104 s, ips: 2603.13402 samples/sec.
[2023/08/02 20:51:24] ppcls INFO: epoch:0   train step:410  lr: 0.100000, loss:  6.8158 top1:  0.0039 top5: -0.0078 batch_cost: 0.09839 s, reader_cost: 0.04107 s, ips: 2601.91155 samples/sec.
[2023/08/02 20:51:25] ppcls INFO: epoch:0   train step:420  lr: 0.100000, loss:  6.7018 top1:  0.0039 top5:  0.0273 batch_cost: 0.09841 s, reader_cost: 0.04109 s, ips: 2601.24732 samples/sec.
[2023/08/02 20:51:26] ppcls INFO: epoch:0   train step:430  lr: 0.100000, loss:  6.7250 top1:  0.0039 top5: -0.0312 batch_cost: 0.09841 s, reader_cost: 0.04108 s, ips: 2601.38267 samples/sec.
[2023/08/02 20:51:27] ppcls INFO: epoch:0   train step:440  lr: 0.100000, loss:  6.6341 top1:  0.0117 top5: -0.0273 batch_cost: 0.09845 s, reader_cost: 0.04110 s, ips: 2600.17519 samples/sec.
[2023/08/02 20:51:28] ppcls INFO: epoch:0   train step:450  lr: 0.100000, loss:  6.6282 top1:  0.0078 top5: -0.0234 batch_cost: 0.09839 s, reader_cost: 0.04098 s, ips: 2601.90058 samples/sec.
[2023/08/02 20:51:29] ppcls INFO: epoch:0   train step:460  lr: 0.100000, loss:  6.7491 top1:  0.0039 top5:  0.0234 batch_cost: 0.09854 s, reader_cost: 0.04109 s, ips: 2598.01033 samples/sec.
[2023/08/02 20:51:30] ppcls INFO: epoch:0   train step:470  lr: 0.100000, loss:  6.7066 top1:  0.0078 top5:  0.0391 batch_cost: 0.09858 s, reader_cost: 0.04109 s, ips: 2596.92825 samples/sec.
[2023/08/02 20:51:31] ppcls INFO: epoch:0   train step:480  lr: 0.100000, loss:  6.6992 top1:  0.0039 top5:  0.0312 batch_cost: 0.09861 s, reader_cost: 0.04108 s, ips: 2596.09861 samples/sec.
[2023/08/02 20:51:32] ppcls INFO: epoch:0   train step:490  lr: 0.100000, loss:  6.7344 top1:  0.0000 top5: -0.0039 batch_cost: 0.09858 s, reader_cost: 0.04103 s, ips: 2596.91459 samples/sec.
[2023/08/02 20:51:33] ppcls INFO: epoch:0   train step:500  lr: 0.100000, loss:  6.6165 top1:  0.0117 top5: -0.0352 batch_cost: 0.09857 s, reader_cost: 0.04100 s, ips: 2597.01231 samples/sec.
[2023/08/02 20:51:34] ppcls INFO: epoch:0   train step:510  lr: 0.100000, loss:  6.6367 top1:  0.0078 top5: -0.0234 batch_cost: 0.09855 s, reader_cost: 0.04094 s, ips: 2597.73654 samples/sec.
[2023/08/02 20:51:35] ppcls INFO: epoch:0   train step:520  lr: 0.100000, loss:  6.6650 top1:  0.0078 top5:  0.0195 batch_cost: 0.09852 s, reader_cost: 0.04088 s, ips: 2598.41837 samples/sec.
[2023/08/02 20:51:36] ppcls INFO: epoch:0   train step:530  lr: 0.100000, loss:  6.6563 top1:  0.0078 top5: -0.0273 batch_cost: 0.09848 s, reader_cost: 0.04081 s, ips: 2599.46475 samples/sec.
[2023/08/02 20:51:37] ppcls INFO: epoch:0   train step:540  lr: 0.100000, loss:  6.6602 top1:  0.0117 top5:  0.0195 batch_cost: 0.09854 s, reader_cost: 0.04086 s, ips: 2597.81070 samples/sec.
[2023/08/02 20:51:38] ppcls INFO: epoch:0   train step:550  lr: 0.100000, loss:  6.6470 top1:  0.0117 top5: -0.0195 batch_cost: 0.09856 s, reader_cost: 0.04089 s, ips: 2597.29037 samples/sec.
[2023/08/02 20:51:39] ppcls INFO: epoch:0   train step:560  lr: 0.100000, loss:  6.5489 top1:  0.0039 top5: -0.0234 batch_cost: 0.09855 s, reader_cost: 0.04089 s, ips: 2597.58880 samples/sec.
[2023/08/02 20:51:40] ppcls INFO: epoch:0   train step:570  lr: 0.100000, loss:  6.6514 top1:  0.0039 top5: -0.0469 batch_cost: 0.09854 s, reader_cost: 0.04088 s, ips: 2597.94898 samples/sec.
[2023/08/02 20:51:40] ppcls INFO: epoch:0   train step:580  lr: 0.100000, loss:  6.6232 top1:  0.0039 top5:  0.0117 batch_cost: 0.09852 s, reader_cost: 0.04082 s, ips: 2598.58339 samples/sec.
[2023/08/02 20:51:41] ppcls INFO: epoch:0   train step:590  lr: 0.100000, loss:  6.5995 top1:  0.0000 top5: -0.0078 batch_cost: 0.09847 s, reader_cost: 0.04079 s, ips: 2599.87382 samples/sec.
[2023/08/02 20:51:42] ppcls INFO: epoch:0   train step:600  lr: 0.100000, loss:  6.6056 top1:  0.0078 top5:  0.0312 batch_cost: 0.09847 s, reader_cost: 0.04081 s, ips: 2599.84468 samples/sec.
[2023/08/02 20:51:43] ppcls INFO: epoch:0   train step:610  lr: 0.100000, loss:  6.5746 top1:  0.0078 top5: -0.0156 batch_cost: 0.09846 s, reader_cost: 0.04082 s, ips: 2600.15162 samples/sec.
[2023/08/02 20:51:44] ppcls INFO: epoch:0   train step:620  lr: 0.100000, loss:  6.6024 top1:  0.0039 top5:  0.0391 batch_cost: 0.09842 s, reader_cost: 0.04079 s, ips: 2601.13716 samples/sec.
[2023/08/02 20:51:45] ppcls INFO: epoch:0   train step:630  lr: 0.100000, loss:  6.6369 top1:  0.0039 top5:  0.0273 batch_cost: 0.09838 s, reader_cost: 0.04077 s, ips: 2602.21347 samples/sec.
[2023/08/02 20:51:46] ppcls INFO: epoch:0   train step:640  lr: 0.100000, loss:  6.6206 top1:  0.0078 top5:  0.0117 batch_cost: 0.09840 s, reader_cost: 0.04080 s, ips: 2601.52337 samples/sec.
[2023/08/02 20:51:47] ppcls INFO: epoch:0   train step:650  lr: 0.100000, loss:  6.5394 top1:  0.0078 top5:  0.0273 batch_cost: 0.09841 s, reader_cost: 0.04080 s, ips: 2601.40492 samples/sec.
[2023/08/02 20:51:48] ppcls INFO: epoch:0   train step:660  lr: 0.100000, loss:  6.5515 top1:  0.0078 top5:  0.0391 batch_cost: 0.09840 s, reader_cost: 0.04080 s, ips: 2601.50453 samples/sec.
[2023/08/02 20:51:49] ppcls INFO: epoch:0   train step:670  lr: 0.100000, loss:  6.5600 top1:  0.0000 top5: -0.0078 batch_cost: 0.09837 s, reader_cost: 0.04077 s, ips: 2602.40809 samples/sec.
[2023/08/02 20:51:50] ppcls INFO: epoch:0   train step:680  lr: 0.100000, loss:  6.5561 top1:  0.0078 top5:  0.0352 batch_cost: 0.09840 s, reader_cost: 0.04082 s, ips: 2601.57039 samples/sec.
[2023/08/02 20:51:51] ppcls INFO: epoch:0   train step:690  lr: 0.100000, loss:  6.5518 top1:  0.0039 top5: -0.0156 batch_cost: 0.09840 s, reader_cost: 0.04083 s, ips: 2601.52019 samples/sec.
[2023/08/02 20:51:52] ppcls INFO: epoch:0   train step:700  lr: 0.100000, loss:  6.4688 top1:  0.0156 top5:  0.0273 batch_cost: 0.09841 s, reader_cost: 0.04086 s, ips: 2601.32486 samples/sec.
[2023/08/02 20:51:53] ppcls INFO: epoch:0   train step:710  lr: 0.100000, loss:  6.4978 top1:  0.0039 top5: -0.0352 batch_cost: 0.09841 s, reader_cost: 0.04086 s, ips: 2601.46255 samples/sec.
[2023/08/02 20:51:54] ppcls INFO: epoch:0   train step:720  lr: 0.100000, loss:  6.5412 top1:  0.0039 top5: -0.0430 batch_cost: 0.09840 s, reader_cost: 0.04085 s, ips: 2601.70783 samples/sec.
[2023/08/02 20:51:55] ppcls INFO: epoch:0   train step:730  lr: 0.100000, loss:  6.6407 top1:  0.0078 top5:  0.0117 batch_cost: 0.09844 s, reader_cost: 0.04088 s, ips: 2600.66688 samples/sec.
[2023/08/02 20:51:56] ppcls INFO: epoch:0   train step:740  lr: 0.100000, loss:  6.6454 top1:  0.0039 top5: -0.0195 batch_cost: 0.09838 s, reader_cost: 0.04081 s, ips: 2602.22026 samples/sec.
[2023/08/02 20:51:57] ppcls INFO: epoch:0   train step:750  lr: 0.100000, loss:  6.4903 top1:  0.0195 top5: -0.0391 batch_cost: 0.09842 s, reader_cost: 0.04082 s, ips: 2601.21793 samples/sec.
[2023/08/02 20:51:58] ppcls INFO: epoch:0   train step:760  lr: 0.100000, loss:  6.4784 top1:  0.0039 top5: -0.0391 batch_cost: 0.09846 s, reader_cost: 0.04087 s, ips: 2600.03427 samples/sec.
[2023/08/02 20:51:59] ppcls INFO: epoch:0   train step:770  lr: 0.100000, loss:  6.5065 top1:  0.0039 top5:  0.0234 batch_cost: 0.09848 s, reader_cost: 0.04089 s, ips: 2599.57329 samples/sec.
[2023/08/02 20:52:00] ppcls INFO: epoch:0   train step:780  lr: 0.100000, loss:  6.5599 top1:  0.0000 top5: -0.0273 batch_cost: 0.09847 s, reader_cost: 0.04086 s, ips: 2599.80881 samples/sec.
[2023/08/02 20:52:01] ppcls INFO: epoch:0   train step:790  lr: 0.100000, loss:  6.4539 top1:  0.0117 top5: -0.0391 batch_cost: 0.09844 s, reader_cost: 0.04081 s, ips: 2600.68771 samples/sec.
[2023/08/02 20:52:02] ppcls INFO: epoch:0   train step:800  lr: 0.100000, loss:  6.3842 top1:  0.0117 top5:  0.0508 batch_cost: 0.09841 s, reader_cost: 0.04077 s, ips: 2601.43424 samples/sec.
[2023/08/02 20:52:03] ppcls INFO: epoch:0   train step:810  lr: 0.100000, loss:  6.3252 top1:  0.0039 top5: -0.0273 batch_cost: 0.09843 s, reader_cost: 0.04078 s, ips: 2600.81545 samples/sec.
[2023/08/02 20:52:04] ppcls INFO: epoch:0   train step:820  lr: 0.100000, loss:  6.5150 top1:  0.0078 top5: -0.0117 batch_cost: 0.09842 s, reader_cost: 0.04079 s, ips: 2600.96963 samples/sec.
[2023/08/02 20:52:05] ppcls INFO: epoch:0   train step:830  lr: 0.100000, loss:  6.3529 top1:  0.0195 top5:  0.0664 batch_cost: 0.09842 s, reader_cost: 0.04080 s, ips: 2601.09691 samples/sec.
[2023/08/02 20:52:06] ppcls INFO: epoch:0   train step:840  lr: 0.100000, loss:  6.4142 top1:  0.0234 top5:  0.0508 batch_cost: 0.09844 s, reader_cost: 0.04082 s, ips: 2600.68128 samples/sec.
[2023/08/02 20:52:07] ppcls INFO: epoch:0   train step:850  lr: 0.100000, loss:  6.3400 top1:  0.0078 top5: -0.0273 batch_cost: 0.09845 s, reader_cost: 0.04085 s, ips: 2600.23361 samples/sec.
[2023/08/02 20:52:08] ppcls INFO: epoch:0   train step:860  lr: 0.100000, loss:  6.4219 top1:  0.0039 top5: -0.0391 batch_cost: 0.09846 s, reader_cost: 0.04086 s, ips: 2600.14105 samples/sec.
[2023/08/02 20:52:09] ppcls INFO: epoch:0   train step:870  lr: 0.100000, loss:  6.3246 top1:  0.0117 top5: -0.0469 batch_cost: 0.09842 s, reader_cost: 0.04083 s, ips: 2601.15887 samples/sec.
[2023/08/02 20:52:10] ppcls INFO: epoch:0   train step:880  lr: 0.100000, loss:  6.3492 top1:  0.0039 top5:  0.0352 batch_cost: 0.09839 s, reader_cost: 0.04081 s, ips: 2601.81732 samples/sec.
[2023/08/02 20:52:11] ppcls INFO: epoch:0   train step:890  lr: 0.100000, loss:  6.2823 top1:  0.0195 top5: -0.0703 batch_cost: 0.09839 s, reader_cost: 0.04081 s, ips: 2601.95805 samples/sec.
[2023/08/02 20:52:12] ppcls INFO: epoch:0   train step:900  lr: 0.100000, loss:  6.3268 top1:  0.0156 top5: -0.0703 batch_cost: 0.09835 s, reader_cost: 0.04079 s, ips: 2602.81857 samples/sec.
[2023/08/02 20:52:13] ppcls INFO: epoch:0   train step:910  lr: 0.100000, loss:  6.2409 top1:  0.0078 top5:  0.0469 batch_cost: 0.09832 s, reader_cost: 0.04076 s, ips: 2603.61773 samples/sec.
[2023/08/02 20:52:14] ppcls INFO: epoch:0   train step:920  lr: 0.100000, loss:  6.3049 top1:  0.0195 top5:  0.0508 batch_cost: 0.09833 s, reader_cost: 0.04077 s, ips: 2603.55187 samples/sec.
[2023/08/02 20:52:15] ppcls INFO: epoch:0   train step:930  lr: 0.100000, loss:  6.3651 top1:  0.0156 top5: -0.0508 batch_cost: 0.09833 s, reader_cost: 0.04079 s, ips: 2603.51102 samples/sec.
[2023/08/02 20:52:16] ppcls INFO: epoch:0   train step:940  lr: 0.100000, loss:  6.2179 top1:  0.0156 top5: -0.0469 batch_cost: 0.09834 s, reader_cost: 0.04080 s, ips: 2603.19610 samples/sec.
[2023/08/02 20:52:17] ppcls INFO: epoch:0   train step:950  lr: 0.100000, loss:  6.2121 top1:  0.0195 top5: -0.0859 batch_cost: 0.09831 s, reader_cost: 0.04077 s, ips: 2604.11759 samples/sec.
[2023/08/02 20:52:18] ppcls INFO: epoch:0   train step:960  lr: 0.100000, loss:  6.1332 top1:  0.0273 top5:  0.0820 batch_cost: 0.09833 s, reader_cost: 0.04081 s, ips: 2603.54284 samples/sec.
[2023/08/02 20:52:19] ppcls INFO: epoch:0   train step:970  lr: 0.100000, loss:  6.2942 top1:  0.0234 top5:  0.0547 batch_cost: 0.09830 s, reader_cost: 0.04079 s, ips: 2604.15766 samples/sec.
[2023/08/02 20:52:20] ppcls INFO: epoch:0   train step:980  lr: 0.100000, loss:  6.1791 top1:  0.0156 top5:  0.0820 batch_cost: 0.09830 s, reader_cost: 0.04079 s, ips: 2604.32558 samples/sec.
[2023/08/02 20:52:21] ppcls INFO: epoch:0   train step:990  lr: 0.100000, loss:  6.2356 top1:  0.0195 top5:  0.0625 batch_cost: 0.09829 s, reader_cost: 0.04079 s, ips: 2604.59633 samples/sec.
[2023/08/02 20:52:22] ppcls INFO: epoch:0   train step:1000 lr: 0.100000, loss:  6.1725 top1:  0.0117 top5:  0.0625 batch_cost: 0.09832 s, reader_cost: 0.04082 s, ips: 2603.67817 samples/sec.
[2023/08/02 20:52:23] ppcls INFO: epoch:0   train step:1010 lr: 0.100000, loss:  6.0784 top1:  0.0391 top5: -0.0859 batch_cost: 0.09832 s, reader_cost: 0.04082 s, ips: 2603.74510 samples/sec.
[2023/08/02 20:52:24] ppcls INFO: epoch:0   train step:1020 lr: 0.100000, loss:  6.2962 top1:  0.0117 top5:  0.0312 batch_cost: 0.09831 s, reader_cost: 0.04081 s, ips: 2604.03495 samples/sec.
[2023/08/02 20:52:25] ppcls INFO: epoch:0   train step:1030 lr: 0.100000, loss:  6.1553 top1:  0.0234 top5:  0.0820 batch_cost: 0.09832 s, reader_cost: 0.04083 s, ips: 2603.82644 samples/sec.
[2023/08/02 20:52:26] ppcls INFO: epoch:0   train step:1040 lr: 0.100000, loss:  6.0904 top1:  0.0234 top5: -0.0625 batch_cost: 0.09830 s, reader_cost: 0.04082 s, ips: 2604.16905 samples/sec.
[2023/08/02 20:52:27] ppcls INFO: epoch:0   train step:1050 lr: 0.100000, loss:  6.0993 top1:  0.0234 top5: -0.0586 batch_cost: 0.09828 s, reader_cost: 0.04080 s, ips: 2604.73765 samples/sec.
[2023/08/02 20:52:28] ppcls INFO: epoch:0   train step:1060 lr: 0.100000, loss:  6.1163 top1:  0.0352 top5:  0.0898 batch_cost: 0.09826 s, reader_cost: 0.04078 s, ips: 2605.28001 samples/sec.
[2023/08/02 20:52:29] ppcls INFO: epoch:0   train step:1070 lr: 0.100000, loss:  6.0948 top1:  0.0195 top5:  0.0664 batch_cost: 0.09826 s, reader_cost: 0.04079 s, ips: 2605.23976 samples/sec.
[2023/08/02 20:52:30] ppcls INFO: epoch:0   train step:1080 lr: 0.100000, loss:  6.1006 top1:  0.0312 top5:  0.0820 batch_cost: 0.09827 s, reader_cost: 0.04080 s, ips: 2605.03638 samples/sec.
[2023/08/02 20:52:31] ppcls INFO: epoch:0   train step:1090 lr: 0.100000, loss:  6.1220 top1:  0.0195 top5:  0.0664 batch_cost: 0.09828 s, reader_cost: 0.04081 s, ips: 2604.87851 samples/sec.
[2023/08/02 20:52:32] ppcls INFO: epoch:0   train step:1100 lr: 0.100000, loss:  5.9914 top1:  0.0273 top5: -0.0977 batch_cost: 0.09826 s, reader_cost: 0.04079 s, ips: 2605.22872 samples/sec.
[2023/08/02 20:52:32] ppcls INFO: epoch:0   train step:1110 lr: 0.100000, loss:  6.2023 top1:  0.0078 top5: -0.0508 batch_cost: 0.09824 s, reader_cost: 0.04077 s, ips: 2605.94051 samples/sec.
[2023/08/02 20:52:33] ppcls INFO: epoch:0   train step:1120 lr: 0.100000, loss:  5.9777 top1:  0.0195 top5:  0.0938 batch_cost: 0.09823 s, reader_cost: 0.04076 s, ips: 2606.12338 samples/sec.
[2023/08/02 20:52:34] ppcls INFO: epoch:0   train step:1130 lr: 0.100000, loss:  5.9698 top1:  0.0156 top5:  0.0742 batch_cost: 0.09824 s, reader_cost: 0.04077 s, ips: 2605.98362 samples/sec.
[2023/08/02 20:52:35] ppcls INFO: epoch:0   train step:1140 lr: 0.100000, loss:  6.0585 top1:  0.0156 top5:  0.0820 batch_cost: 0.09823 s, reader_cost: 0.04077 s, ips: 2606.13491 samples/sec.
[2023/08/02 20:52:36] ppcls INFO: epoch:0   train step:1150 lr: 0.100000, loss:  5.9468 top1:  0.0312 top5: -0.0781 batch_cost: 0.09824 s, reader_cost: 0.04078 s, ips: 2605.98635 samples/sec.
[2023/08/02 20:52:37] ppcls INFO: epoch:0   train step:1160 lr: 0.100000, loss:  6.1247 top1:  0.0234 top5: -0.0859 batch_cost: 0.09826 s, reader_cost: 0.04080 s, ips: 2605.46133 samples/sec.
[2023/08/02 20:52:38] ppcls INFO: epoch:0   train step:1170 lr: 0.100000, loss:  6.0422 top1:  0.0273 top5:  0.0859 batch_cost: 0.09828 s, reader_cost: 0.04083 s, ips: 2604.89017 samples/sec.
[2023/08/02 20:52:39] ppcls INFO: epoch:0   train step:1180 lr: 0.100000, loss:  6.0245 top1:  0.0312 top5:  0.0859 batch_cost: 0.09829 s, reader_cost: 0.04084 s, ips: 2604.65403 samples/sec.
[2023/08/02 20:52:40] ppcls INFO: epoch:0   train step:1190 lr: 0.100000, loss:  5.9417 top1:  0.0234 top5: -0.0938 batch_cost: 0.09827 s, reader_cost: 0.04083 s, ips: 2605.05780 samples/sec.
[2023/08/02 20:52:41] ppcls INFO: epoch:0   train step:1200 lr: 0.100000, loss:  5.9472 top1:  0.0195 top5: -0.0898 batch_cost: 0.09831 s, reader_cost: 0.04087 s, ips: 2604.00639 samples/sec.
[2023/08/02 20:52:42] ppcls INFO: epoch:0   train step:1210 lr: 0.100000, loss:  5.9459 top1:  0.0156 top5:  0.0898 batch_cost: 0.09829 s, reader_cost: 0.04086 s, ips: 2604.60931 samples/sec.
[2023/08/02 20:52:43] ppcls INFO: epoch:0   train step:1220 lr: 0.100000, loss:  5.9038 top1:  0.0469 top5: -0.1172 batch_cost: 0.09829 s, reader_cost: 0.04086 s, ips: 2604.59710 samples/sec.
[2023/08/02 20:52:44] ppcls INFO: epoch:0   train step:1230 lr: 0.100000, loss:  5.9524 top1:  0.0430 top5: -0.1055 batch_cost: 0.09828 s, reader_cost: 0.04086 s, ips: 2604.70173 samples/sec.
[2023/08/02 20:52:45] ppcls INFO: epoch:0   train step:1240 lr: 0.100000, loss:  5.8740 top1:  0.0430 top5:  0.1133 batch_cost: 0.09831 s, reader_cost: 0.04088 s, ips: 2604.03912 samples/sec.
[2023/08/02 20:52:46] ppcls INFO: epoch:0   train step:1250 lr: 0.100000, loss:  5.8441 top1:  0.0312 top5:  0.1055 batch_cost: 0.09832 s, reader_cost: 0.04087 s, ips: 2603.61470 samples/sec.
[2023/08/02 20:52:47] ppcls INFO: epoch:0   train step:1260 lr: 0.100000, loss:  5.9012 top1:  0.0195 top5:  0.0703 batch_cost: 0.09832 s, reader_cost: 0.04086 s, ips: 2603.66053 samples/sec.
[2023/08/02 20:52:48] ppcls INFO: epoch:0   train step:1270 lr: 0.100000, loss:  5.8105 top1:  0.0117 top5:  0.1016 batch_cost: 0.09831 s, reader_cost: 0.04085 s, ips: 2604.09269 samples/sec.
[2023/08/02 20:52:49] ppcls INFO: epoch:0   train step:1280 lr: 0.100000, loss:  5.8981 top1:  0.0352 top5:  0.0742 batch_cost: 0.09831 s, reader_cost: 0.04087 s, ips: 2603.90676 samples/sec.
[2023/08/02 20:52:50] ppcls INFO: epoch:0   train step:1290 lr: 0.100000, loss:  5.8131 top1:  0.0391 top5: -0.0859 batch_cost: 0.09832 s, reader_cost: 0.04088 s, ips: 2603.69310 samples/sec.
[2023/08/02 20:52:51] ppcls INFO: epoch:0   train step:1300 lr: 0.100000, loss:  5.8952 top1:  0.0352 top5:  0.1133 batch_cost: 0.09833 s, reader_cost: 0.04089 s, ips: 2603.57149 samples/sec.
[2023/08/02 20:52:52] ppcls INFO: epoch:0   train step:1310 lr: 0.100000, loss:  5.6113 top1:  0.0508 top5:  0.1445 batch_cost: 0.09833 s, reader_cost: 0.04091 s, ips: 2603.42097 samples/sec.
[2023/08/02 20:52:53] ppcls INFO: epoch:0   train step:1320 lr: 0.100000, loss:  5.8221 top1:  0.0430 top5:  0.1016 batch_cost: 0.09832 s, reader_cost: 0.04090 s, ips: 2603.68598 samples/sec.
[2023/08/02 20:52:54] ppcls INFO: epoch:0   train step:1330 lr: 0.100000, loss:  5.7620 top1:  0.0391 top5: -0.1211 batch_cost: 0.09832 s, reader_cost: 0.04091 s, ips: 2603.78847 samples/sec.
[2023/08/02 20:52:55] ppcls INFO: epoch:0   train step:1340 lr: 0.100000, loss:  5.8389 top1:  0.0195 top5:  0.1016 batch_cost: 0.09831 s, reader_cost: 0.04090 s, ips: 2604.12094 samples/sec.
[2023/08/02 20:52:56] ppcls INFO: epoch:0   train step:1350 lr: 0.100000, loss:  5.8740 top1:  0.0312 top5:  0.1133 batch_cost: 0.09830 s, reader_cost: 0.04090 s, ips: 2604.27716 samples/sec.
[2023/08/02 20:52:57] ppcls INFO: epoch:0   train step:1360 lr: 0.100000, loss:  5.7328 top1:  0.0273 top5:  0.1406 batch_cost: 0.09830 s, reader_cost: 0.04091 s, ips: 2604.17667 samples/sec.
[2023/08/02 20:52:58] ppcls INFO: epoch:0   train step:1370 lr: 0.100000, loss:  5.8223 top1:  0.0508 top5: -0.1172 batch_cost: 0.09829 s, reader_cost: 0.04090 s, ips: 2604.56420 samples/sec.
[2023/08/02 20:52:59] ppcls INFO: epoch:0   train step:1380 lr: 0.100000, loss:  5.4919 top1:  0.0547 top5: -0.1406 batch_cost: 0.09828 s, reader_cost: 0.04089 s, ips: 2604.90915 samples/sec.
[2023/08/02 20:53:00] ppcls INFO: epoch:0   train step:1390 lr: 0.100000, loss:  5.7508 top1:  0.0352 top5: -0.0938 batch_cost: 0.09827 s, reader_cost: 0.04089 s, ips: 2605.05902 samples/sec.
[2023/08/02 20:53:01] ppcls INFO: epoch:0   train step:1400 lr: 0.100000, loss:  5.8274 top1:  0.0469 top5:  0.1016 batch_cost: 0.09830 s, reader_cost: 0.04092 s, ips: 2604.24683 samples/sec.
[2023/08/02 20:53:02] ppcls INFO: epoch:0   train step:1410 lr: 0.100000, loss:  5.8028 top1:  0.0312 top5: -0.1133 batch_cost: 0.09828 s, reader_cost: 0.04091 s, ips: 2604.68841 samples/sec.
[2023/08/02 20:53:03] ppcls INFO: epoch:0   train step:1420 lr: 0.100000, loss:  5.7876 top1:  0.0352 top5: -0.0977 batch_cost: 0.09828 s, reader_cost: 0.04091 s, ips: 2604.92481 samples/sec.
[2023/08/02 20:53:04] ppcls INFO: epoch:0   train step:1430 lr: 0.100000, loss:  5.7534 top1:  0.0430 top5: -0.0938 batch_cost: 0.09826 s, reader_cost: 0.04090 s, ips: 2605.33420 samples/sec.
[2023/08/02 20:53:05] ppcls INFO: epoch:0   train step:1440 lr: 0.100000, loss:  5.8482 top1:  0.0273 top5:  0.1055 batch_cost: 0.09826 s, reader_cost: 0.04091 s, ips: 2605.21282 samples/sec.
[2023/08/02 20:53:06] ppcls INFO: epoch:0   train step:1450 lr: 0.100000, loss:  5.8580 top1:  0.0547 top5:  0.1094 batch_cost: 0.09826 s, reader_cost: 0.04091 s, ips: 2605.32439 samples/sec.
[2023/08/02 20:53:07] ppcls INFO: epoch:0   train step:1460 lr: 0.100000, loss:  5.8216 top1:  0.0391 top5:  0.1055 batch_cost: 0.09828 s, reader_cost: 0.04093 s, ips: 2604.87732 samples/sec.
[2023/08/02 20:53:08] ppcls INFO: epoch:0   train step:1470 lr: 0.100000, loss:  5.7162 top1:  0.0586 top5:  0.1641 batch_cost: 0.09826 s, reader_cost: 0.04091 s, ips: 2605.46389 samples/sec.
[2023/08/02 20:53:09] ppcls INFO: epoch:0   train step:1480 lr: 0.100000, loss:  5.7049 top1:  0.0430 top5: -0.1055 batch_cost: 0.09824 s, reader_cost: 0.04090 s, ips: 2605.79559 samples/sec.
[2023/08/02 20:53:10] ppcls INFO: epoch:0   train step:1490 lr: 0.100000, loss:  5.8098 top1:  0.0312 top5: -0.1172 batch_cost: 0.09823 s, reader_cost: 0.04087 s, ips: 2606.17450 samples/sec.
[2023/08/02 20:53:11] ppcls INFO: epoch:0   train step:1500 lr: 0.100000, loss:  5.8130 top1:  0.0469 top5:  0.0977 batch_cost: 0.09823 s, reader_cost: 0.04088 s, ips: 2606.04538 samples/sec.
[2023/08/02 20:53:12] ppcls INFO: epoch:0   train step:1510 lr: 0.100000, loss:  5.6839 top1:  0.0352 top5: -0.1211 batch_cost: 0.09822 s, reader_cost: 0.04087 s, ips: 2606.28000 samples/sec.
[2023/08/02 20:53:13] ppcls INFO: epoch:0   train step:1520 lr: 0.100000, loss:  5.7069 top1:  0.0391 top5:  0.1445 batch_cost: 0.09822 s, reader_cost: 0.04087 s, ips: 2606.35759 samples/sec.
[2023/08/02 20:53:14] ppcls INFO: epoch:0   train step:1530 lr: 0.100000, loss:  5.5553 top1:  0.0547 top5:  0.1680 batch_cost: 0.09822 s, reader_cost: 0.04087 s, ips: 2606.46292 samples/sec.
[2023/08/02 20:53:15] ppcls INFO: epoch:0   train step:1540 lr: 0.100000, loss:  5.7537 top1:  0.0312 top5:  0.0898 batch_cost: 0.09822 s, reader_cost: 0.04088 s, ips: 2606.34464 samples/sec.
[2023/08/02 20:53:16] ppcls INFO: epoch:0   train step:1550 lr: 0.100000, loss:  5.7021 top1:  0.0625 top5: -0.1641 batch_cost: 0.09824 s, reader_cost: 0.04090 s, ips: 2605.82054 samples/sec.
[2023/08/02 20:53:17] ppcls INFO: epoch:0   train step:1560 lr: 0.100000, loss:  5.6257 top1:  0.0312 top5: -0.1055 batch_cost: 0.09824 s, reader_cost: 0.04091 s, ips: 2605.84606 samples/sec.
[2023/08/02 20:53:17] ppcls INFO: END epoch:0   train  loss:  6.4002 top1:  0.0150 top5: -0.0058 batch_cost: 0.09823 s, reader_cost: 0.04090 s, batch_cost_sum: 153.14288 s,
[2023/08/02 20:53:18] ppcls INFO: Already save model in ./output/ResNet50/0
