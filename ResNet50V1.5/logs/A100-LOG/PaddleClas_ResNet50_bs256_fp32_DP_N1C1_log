A new field (fuse_elewise_add_act_ops) detected!
A new field (enable_addto) detected!
[2022/12/12 11:40:31] ppcls INFO: 
===========================================================
==        PaddleClas is powered by PaddlePaddle !        ==
===========================================================
==                                                       ==
==   For more info please go to the following website.   ==
==                                                       ==
==       https://github.com/PaddlePaddle/PaddleClas      ==
===========================================================

[2022/12/12 11:40:31] ppcls INFO: Global : 
[2022/12/12 11:40:31] ppcls INFO:     checkpoints : None
[2022/12/12 11:40:31] ppcls INFO:     pretrained_model : None
[2022/12/12 11:40:31] ppcls INFO:     output_dir : ./output/
[2022/12/12 11:40:31] ppcls INFO:     device : gpu
[2022/12/12 11:40:31] ppcls INFO:     save_interval : 1
[2022/12/12 11:40:31] ppcls INFO:     eval_during_train : False
[2022/12/12 11:40:31] ppcls INFO:     eval_interval : 1
[2022/12/12 11:40:31] ppcls INFO:     epochs : 1
[2022/12/12 11:40:31] ppcls INFO:     print_batch_step : 10
[2022/12/12 11:40:31] ppcls INFO:     use_visualdl : False
[2022/12/12 11:40:31] ppcls INFO:     image_shape : [3, 224, 224]
[2022/12/12 11:40:31] ppcls INFO:     save_inference_dir : ./inference
[2022/12/12 11:40:31] ppcls INFO:     to_static : False
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: Arch : 
[2022/12/12 11:40:31] ppcls INFO:     name : ResNet50
[2022/12/12 11:40:31] ppcls INFO:     class_num : 1000
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: Loss : 
[2022/12/12 11:40:31] ppcls INFO:     Train : 
[2022/12/12 11:40:31] ppcls INFO:         CELoss : 
[2022/12/12 11:40:31] ppcls INFO:             weight : 1.0
[2022/12/12 11:40:31] ppcls INFO:     Eval : 
[2022/12/12 11:40:31] ppcls INFO:         CELoss : 
[2022/12/12 11:40:31] ppcls INFO:             weight : 1.0
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: Optimizer : 
[2022/12/12 11:40:31] ppcls INFO:     name : Momentum
[2022/12/12 11:40:31] ppcls INFO:     momentum : 0.9
[2022/12/12 11:40:31] ppcls INFO:     lr : 
[2022/12/12 11:40:31] ppcls INFO:         name : Piecewise
[2022/12/12 11:40:31] ppcls INFO:         learning_rate : 0.1
[2022/12/12 11:40:31] ppcls INFO:         decay_epochs : [30, 60, 90]
[2022/12/12 11:40:31] ppcls INFO:         values : [0.1, 0.01, 0.001, 0.0001]
[2022/12/12 11:40:31] ppcls INFO:     regularizer : 
[2022/12/12 11:40:31] ppcls INFO:         name : L2
[2022/12/12 11:40:31] ppcls INFO:         coeff : 0.0001
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: DataLoader : 
[2022/12/12 11:40:31] ppcls INFO:     Train : 
[2022/12/12 11:40:31] ppcls INFO:         dataset : 
[2022/12/12 11:40:31] ppcls INFO:             name : ImageNetDataset
[2022/12/12 11:40:31] ppcls INFO:             image_root : ./dataset/ILSVRC2012/
[2022/12/12 11:40:31] ppcls INFO:             cls_label_path : ./dataset/ILSVRC2012/train_list.txt
[2022/12/12 11:40:31] ppcls INFO:             transform_ops : 
[2022/12/12 11:40:31] ppcls INFO:                 DecodeImage : 
[2022/12/12 11:40:31] ppcls INFO:                     to_rgb : True
[2022/12/12 11:40:31] ppcls INFO:                     channel_first : False
[2022/12/12 11:40:31] ppcls INFO:                 RandCropImage : 
[2022/12/12 11:40:31] ppcls INFO:                     size : 224
[2022/12/12 11:40:31] ppcls INFO:                 RandFlipImage : 
[2022/12/12 11:40:31] ppcls INFO:                     flip_code : 1
[2022/12/12 11:40:31] ppcls INFO:                 NormalizeImage : 
[2022/12/12 11:40:31] ppcls INFO:                     scale : 1.0/255.0
[2022/12/12 11:40:31] ppcls INFO:                     mean : [0.485, 0.456, 0.406]
[2022/12/12 11:40:31] ppcls INFO:                     std : [0.229, 0.224, 0.225]
[2022/12/12 11:40:31] ppcls INFO:                     order : 
[2022/12/12 11:40:31] ppcls INFO:         sampler : 
[2022/12/12 11:40:31] ppcls INFO:             name : DistributedBatchSampler
[2022/12/12 11:40:31] ppcls INFO:             batch_size : 256
[2022/12/12 11:40:31] ppcls INFO:             drop_last : False
[2022/12/12 11:40:31] ppcls INFO:             shuffle : True
[2022/12/12 11:40:31] ppcls INFO:         loader : 
[2022/12/12 11:40:31] ppcls INFO:             num_workers : 8
[2022/12/12 11:40:31] ppcls INFO:             use_shared_memory : True
[2022/12/12 11:40:31] ppcls INFO:     Eval : 
[2022/12/12 11:40:31] ppcls INFO:         dataset : 
[2022/12/12 11:40:31] ppcls INFO:             name : ImageNetDataset
[2022/12/12 11:40:31] ppcls INFO:             image_root : ./dataset/ILSVRC2012/
[2022/12/12 11:40:31] ppcls INFO:             cls_label_path : ./dataset/ILSVRC2012/val_list.txt
[2022/12/12 11:40:31] ppcls INFO:             transform_ops : 
[2022/12/12 11:40:31] ppcls INFO:                 DecodeImage : 
[2022/12/12 11:40:31] ppcls INFO:                     to_rgb : True
[2022/12/12 11:40:31] ppcls INFO:                     channel_first : False
[2022/12/12 11:40:31] ppcls INFO:                 ResizeImage : 
[2022/12/12 11:40:31] ppcls INFO:                     resize_short : 256
[2022/12/12 11:40:31] ppcls INFO:                 CropImage : 
[2022/12/12 11:40:31] ppcls INFO:                     size : 224
[2022/12/12 11:40:31] ppcls INFO:                 NormalizeImage : 
[2022/12/12 11:40:31] ppcls INFO:                     scale : 1.0/255.0
[2022/12/12 11:40:31] ppcls INFO:                     mean : [0.485, 0.456, 0.406]
[2022/12/12 11:40:31] ppcls INFO:                     std : [0.229, 0.224, 0.225]
[2022/12/12 11:40:31] ppcls INFO:                     order : 
[2022/12/12 11:40:31] ppcls INFO:         sampler : 
[2022/12/12 11:40:31] ppcls INFO:             name : DistributedBatchSampler
[2022/12/12 11:40:31] ppcls INFO:             batch_size : 64
[2022/12/12 11:40:31] ppcls INFO:             drop_last : False
[2022/12/12 11:40:31] ppcls INFO:             shuffle : False
[2022/12/12 11:40:31] ppcls INFO:         loader : 
[2022/12/12 11:40:31] ppcls INFO:             num_workers : 4
[2022/12/12 11:40:31] ppcls INFO:             use_shared_memory : True
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: Infer : 
[2022/12/12 11:40:31] ppcls INFO:     infer_imgs : docs/images/inference_deployment/whl_demo.jpg
[2022/12/12 11:40:31] ppcls INFO:     batch_size : 10
[2022/12/12 11:40:31] ppcls INFO:     transforms : 
[2022/12/12 11:40:31] ppcls INFO:         DecodeImage : 
[2022/12/12 11:40:31] ppcls INFO:             to_rgb : True
[2022/12/12 11:40:31] ppcls INFO:             channel_first : False
[2022/12/12 11:40:31] ppcls INFO:         ResizeImage : 
[2022/12/12 11:40:31] ppcls INFO:             resize_short : 256
[2022/12/12 11:40:31] ppcls INFO:         CropImage : 
[2022/12/12 11:40:31] ppcls INFO:             size : 224
[2022/12/12 11:40:31] ppcls INFO:         NormalizeImage : 
[2022/12/12 11:40:31] ppcls INFO:             scale : 1.0/255.0
[2022/12/12 11:40:31] ppcls INFO:             mean : [0.485, 0.456, 0.406]
[2022/12/12 11:40:31] ppcls INFO:             std : [0.229, 0.224, 0.225]
[2022/12/12 11:40:31] ppcls INFO:             order : 
[2022/12/12 11:40:31] ppcls INFO:         ToCHWImage : None
[2022/12/12 11:40:31] ppcls INFO:     PostProcess : 
[2022/12/12 11:40:31] ppcls INFO:         name : Topk
[2022/12/12 11:40:31] ppcls INFO:         topk : 5
[2022/12/12 11:40:31] ppcls INFO:         class_id_map_file : ppcls/utils/imagenet1k_label_list.txt
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: Metric : 
[2022/12/12 11:40:31] ppcls INFO:     Train : 
[2022/12/12 11:40:31] ppcls INFO:         TopkAcc : 
[2022/12/12 11:40:31] ppcls INFO:             topk : [1, 5]
[2022/12/12 11:40:31] ppcls INFO:     Eval : 
[2022/12/12 11:40:31] ppcls INFO:         TopkAcc : 
[2022/12/12 11:40:31] ppcls INFO:             topk : [1, 5]
[2022/12/12 11:40:31] ppcls INFO: ------------------------------------------------------------
[2022/12/12 11:40:31] ppcls INFO: fuse_elewise_add_act_ops : True
[2022/12/12 11:40:31] ppcls INFO: enable_addto : True
[2022/12/12 11:40:39] ppcls WARNING: "init_res" will be deprecated, please use "init_net" instead.
/paddle/perf/PaddleClas/ppcls/data/preprocess/ops/timm_autoaugment.py:39: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.
  _RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)
/paddle/perf/PaddleClas/ppcls/data/preprocess/ops/timm_autoaugment.py:39: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  _RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)
[2022-12-12 11:40:39,619] [ WARNING] fleet.py:1073 - It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
W1212 11:40:39.980741  4341 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.7, Runtime API Version: 11.2
W1212 11:40:39.980790  4341 gpu_resources.cc:91] device: 0, cuDNN Version: 8.1.
W1212 11:40:45.665136  4341 build_strategy.cc:124] Currently, fuse_broadcast_ops only works under Reduce mode.
I1212 11:40:45.698443  4341 fuse_pass_base.cc:59] ---  detected 16 subgraphs
I1212 11:40:45.739789  4341 fuse_pass_base.cc:59] ---  detected 16 subgraphs
W1212 11:40:46.083948  4466 gpu_resources.cc:217] WARNING: device:  . The installed Paddle is compiled with CUDNN 8.2, but CUDNN version in your machine is 8.1, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.
[2022/12/12 11:40:53] ppcls INFO: epoch:0   train step:10   lr: 0.100000, loss:  8.2866 top1:  0.0000 top5:  0.0117 batch_cost: 0.31381 s, reader_cost: 0.00036 s, ips: 815.76736 samples/sec.
[2022/12/12 11:40:56] ppcls INFO: epoch:0   train step:20   lr: 0.100000, loss:  7.7945 top1:  0.0039 top5:  0.0078 batch_cost: 0.29456 s, reader_cost: 0.00080 s, ips: 869.10572 samples/sec.
[2022/12/12 11:40:59] ppcls INFO: epoch:0   train step:30   lr: 0.100000, loss:  7.4073 top1:  0.0000 top5:  0.0156 batch_cost: 0.29015 s, reader_cost: 0.00090 s, ips: 882.30599 samples/sec.
[2022/12/12 11:41:02] ppcls INFO: epoch:0   train step:40   lr: 0.100000, loss:  7.3013 top1:  0.0078 top5:  0.0234 batch_cost: 0.29068 s, reader_cost: 0.00324 s, ips: 880.70208 samples/sec.
[2022/12/12 11:41:04] ppcls INFO: epoch:0   train step:50   lr: 0.100000, loss:  6.9368 top1:  0.0039 top5:  0.0156 batch_cost: 0.28903 s, reader_cost: 0.00267 s, ips: 885.73362 samples/sec.
[2022/12/12 11:41:07] ppcls INFO: epoch:0   train step:60   lr: 0.100000, loss:  7.0341 top1:  0.0000 top5:  0.0000 batch_cost: 0.28794 s, reader_cost: 0.00236 s, ips: 889.06716 samples/sec.
[2022/12/12 11:41:10] ppcls INFO: epoch:0   train step:70   lr: 0.100000, loss:  6.9320 top1:  0.0000 top5:  0.0039 batch_cost: 0.28720 s, reader_cost: 0.00214 s, ips: 891.37977 samples/sec.
[2022/12/12 11:41:13] ppcls INFO: epoch:0   train step:80   lr: 0.100000, loss:  6.9853 top1:  0.0000 top5:  0.0000 batch_cost: 0.28663 s, reader_cost: 0.00199 s, ips: 893.12260 samples/sec.
[2022/12/12 11:41:16] ppcls INFO: epoch:0   train step:90   lr: 0.100000, loss:  6.9211 top1:  0.0000 top5:  0.0078 batch_cost: 0.28623 s, reader_cost: 0.00188 s, ips: 894.38235 samples/sec.
[2022/12/12 11:41:19] ppcls INFO: epoch:0   train step:100  lr: 0.100000, loss:  6.9203 top1:  0.0000 top5:  0.0078 batch_cost: 0.28591 s, reader_cost: 0.00177 s, ips: 895.37180 samples/sec.
[2022/12/12 11:41:21] ppcls INFO: epoch:0   train step:110  lr: 0.100000, loss:  6.9001 top1:  0.0000 top5:  0.0039 batch_cost: 0.28565 s, reader_cost: 0.00170 s, ips: 896.19341 samples/sec.
[2022/12/12 11:41:24] ppcls INFO: epoch:0   train step:120  lr: 0.100000, loss:  6.9123 top1:  0.0000 top5:  0.0039 batch_cost: 0.28544 s, reader_cost: 0.00164 s, ips: 896.86997 samples/sec.
[2022/12/12 11:41:27] ppcls INFO: epoch:0   train step:130  lr: 0.100000, loss:  6.9000 top1:  0.0039 top5:  0.0078 batch_cost: 0.28525 s, reader_cost: 0.00157 s, ips: 897.44673 samples/sec.
[2022/12/12 11:41:30] ppcls INFO: epoch:0   train step:140  lr: 0.100000, loss:  6.9291 top1:  0.0000 top5:  0.0039 batch_cost: 0.28510 s, reader_cost: 0.00152 s, ips: 897.94622 samples/sec.
[2022/12/12 11:41:33] ppcls INFO: epoch:0   train step:150  lr: 0.100000, loss:  6.9159 top1:  0.0039 top5:  0.0039 batch_cost: 0.28496 s, reader_cost: 0.00147 s, ips: 898.37869 samples/sec.
[2022/12/12 11:41:36] ppcls INFO: epoch:0   train step:160  lr: 0.100000, loss:  6.8952 top1:  0.0078 top5:  0.0195 batch_cost: 0.28484 s, reader_cost: 0.00142 s, ips: 898.75166 samples/sec.
[2022/12/12 11:41:38] ppcls INFO: epoch:0   train step:170  lr: 0.100000, loss:  6.8980 top1:  0.0039 top5:  0.0117 batch_cost: 0.28474 s, reader_cost: 0.00138 s, ips: 899.06370 samples/sec.
[2022/12/12 11:41:41] ppcls INFO: epoch:0   train step:180  lr: 0.100000, loss:  6.8995 top1:  0.0039 top5:  0.0117 batch_cost: 0.28465 s, reader_cost: 0.00134 s, ips: 899.34132 samples/sec.
[2022/12/12 11:41:44] ppcls INFO: epoch:0   train step:190  lr: 0.100000, loss:  6.9096 top1:  0.0000 top5:  0.0000 batch_cost: 0.28457 s, reader_cost: 0.00131 s, ips: 899.61594 samples/sec.
[2022/12/12 11:41:47] ppcls INFO: epoch:0   train step:200  lr: 0.100000, loss:  6.8611 top1:  0.0000 top5:  0.0156 batch_cost: 0.28449 s, reader_cost: 0.00128 s, ips: 899.87136 samples/sec.
[2022/12/12 11:41:50] ppcls INFO: epoch:0   train step:210  lr: 0.100000, loss:  6.8952 top1:  0.0078 top5:  0.0078 batch_cost: 0.28442 s, reader_cost: 0.00125 s, ips: 900.07855 samples/sec.
[2022/12/12 11:41:53] ppcls INFO: epoch:0   train step:220  lr: 0.100000, loss:  6.9147 top1:  0.0039 top5:  0.0039 batch_cost: 0.28436 s, reader_cost: 0.00122 s, ips: 900.27735 samples/sec.
[2022/12/12 11:41:55] ppcls INFO: epoch:0   train step:230  lr: 0.100000, loss:  6.8945 top1:  0.0000 top5:  0.0039 batch_cost: 0.28430 s, reader_cost: 0.00120 s, ips: 900.45112 samples/sec.
[2022/12/12 11:41:58] ppcls INFO: epoch:0   train step:240  lr: 0.100000, loss:  6.8883 top1:  0.0000 top5:  0.0078 batch_cost: 0.28425 s, reader_cost: 0.00117 s, ips: 900.60739 samples/sec.
[2022/12/12 11:42:01] ppcls INFO: epoch:0   train step:250  lr: 0.100000, loss:  6.8684 top1:  0.0039 top5:  0.0195 batch_cost: 0.28421 s, reader_cost: 0.00114 s, ips: 900.75176 samples/sec.
[2022/12/12 11:42:04] ppcls INFO: epoch:0   train step:260  lr: 0.100000, loss:  6.8793 top1:  0.0000 top5:  0.0000 batch_cost: 0.28417 s, reader_cost: 0.00112 s, ips: 900.88060 samples/sec.
[2022/12/12 11:42:07] ppcls INFO: epoch:0   train step:270  lr: 0.100000, loss:  6.8643 top1:  0.0000 top5:  0.0039 batch_cost: 0.28413 s, reader_cost: 0.00110 s, ips: 900.99090 samples/sec.
[2022/12/12 11:42:10] ppcls INFO: epoch:0   train step:280  lr: 0.100000, loss:  6.9371 top1:  0.0039 top5:  0.0234 batch_cost: 0.28410 s, reader_cost: 0.00108 s, ips: 901.09028 samples/sec.
[2022/12/12 11:42:12] ppcls INFO: epoch:0   train step:290  lr: 0.100000, loss:  6.8586 top1:  0.0039 top5:  0.0156 batch_cost: 0.28407 s, reader_cost: 0.00107 s, ips: 901.18668 samples/sec.
[2022/12/12 11:42:15] ppcls INFO: epoch:0   train step:300  lr: 0.100000, loss:  6.8624 top1:  0.0000 top5:  0.0039 batch_cost: 0.28404 s, reader_cost: 0.00105 s, ips: 901.27784 samples/sec.
[2022/12/12 11:42:18] ppcls INFO: epoch:0   train step:310  lr: 0.100000, loss:  6.8704 top1:  0.0000 top5:  0.0039 batch_cost: 0.28401 s, reader_cost: 0.00103 s, ips: 901.36853 samples/sec.
[2022/12/12 11:42:21] ppcls INFO: epoch:0   train step:320  lr: 0.100000, loss:  6.8756 top1:  0.0000 top5:  0.0117 batch_cost: 0.28399 s, reader_cost: 0.00102 s, ips: 901.44423 samples/sec.
[2022/12/12 11:42:24] ppcls INFO: epoch:0   train step:330  lr: 0.100000, loss:  6.8681 top1:  0.0000 top5:  0.0078 batch_cost: 0.28397 s, reader_cost: 0.00100 s, ips: 901.51551 samples/sec.
[2022/12/12 11:42:27] ppcls INFO: epoch:0   train step:340  lr: 0.100000, loss:  6.8812 top1:  0.0000 top5:  0.0000 batch_cost: 0.28394 s, reader_cost: 0.00098 s, ips: 901.58842 samples/sec.
[2022/12/12 11:42:29] ppcls INFO: epoch:0   train step:350  lr: 0.100000, loss:  6.8374 top1:  0.0000 top5:  0.0039 batch_cost: 0.28392 s, reader_cost: 0.00097 s, ips: 901.66383 samples/sec.
[2022/12/12 11:42:32] ppcls INFO: epoch:0   train step:360  lr: 0.100000, loss:  6.8608 top1:  0.0039 top5:  0.0195 batch_cost: 0.28390 s, reader_cost: 0.00096 s, ips: 901.72675 samples/sec.
[2022/12/12 11:42:35] ppcls INFO: epoch:0   train step:370  lr: 0.100000, loss:  6.8591 top1:  0.0078 top5:  0.0078 batch_cost: 0.28388 s, reader_cost: 0.00095 s, ips: 901.78501 samples/sec.
[2022/12/12 11:42:38] ppcls INFO: epoch:0   train step:380  lr: 0.100000, loss:  6.7778 top1:  0.0000 top5:  0.0195 batch_cost: 0.28387 s, reader_cost: 0.00093 s, ips: 901.83382 samples/sec.
[2022/12/12 11:42:41] ppcls INFO: epoch:0   train step:390  lr: 0.100000, loss:  6.8160 top1:  0.0000 top5:  0.0117 batch_cost: 0.28385 s, reader_cost: 0.00092 s, ips: 901.88340 samples/sec.
[2022/12/12 11:42:44] ppcls INFO: epoch:0   train step:400  lr: 0.100000, loss:  6.8295 top1:  0.0000 top5:  0.0156 batch_cost: 0.28383 s, reader_cost: 0.00091 s, ips: 901.93423 samples/sec.
[2022/12/12 11:42:46] ppcls INFO: epoch:0   train step:410  lr: 0.100000, loss:  6.8558 top1:  0.0039 top5:  0.0117 batch_cost: 0.28382 s, reader_cost: 0.00090 s, ips: 901.98423 samples/sec.
[2022/12/12 11:42:49] ppcls INFO: epoch:0   train step:420  lr: 0.100000, loss:  6.8002 top1:  0.0000 top5:  0.0078 batch_cost: 0.28381 s, reader_cost: 0.00089 s, ips: 902.02621 samples/sec.
[2022/12/12 11:42:52] ppcls INFO: epoch:0   train step:430  lr: 0.100000, loss:  6.7640 top1:  0.0039 top5:  0.0117 batch_cost: 0.28379 s, reader_cost: 0.00088 s, ips: 902.06741 samples/sec.
[2022/12/12 11:42:55] ppcls INFO: epoch:0   train step:440  lr: 0.100000, loss:  6.7399 top1:  0.0195 top5:  0.0391 batch_cost: 0.28378 s, reader_cost: 0.00087 s, ips: 902.10965 samples/sec.
[2022/12/12 11:42:58] ppcls INFO: epoch:0   train step:450  lr: 0.100000, loss:  6.7902 top1:  0.0078 top5:  0.0117 batch_cost: 0.28377 s, reader_cost: 0.00087 s, ips: 902.14702 samples/sec.
[2022/12/12 11:43:01] ppcls INFO: epoch:0   train step:460  lr: 0.100000, loss:  6.7694 top1:  0.0039 top5:  0.0312 batch_cost: 0.28376 s, reader_cost: 0.00086 s, ips: 902.18248 samples/sec.
[2022/12/12 11:43:03] ppcls INFO: epoch:0   train step:470  lr: 0.100000, loss:  6.7469 top1:  0.0039 top5:  0.0195 batch_cost: 0.28375 s, reader_cost: 0.00086 s, ips: 902.20902 samples/sec.
[2022/12/12 11:43:06] ppcls INFO: epoch:0   train step:480  lr: 0.100000, loss:  6.7943 top1:  0.0039 top5:  0.0117 batch_cost: 0.28374 s, reader_cost: 0.00085 s, ips: 902.24920 samples/sec.
[2022/12/12 11:43:09] ppcls INFO: epoch:0   train step:490  lr: 0.100000, loss:  6.7273 top1:  0.0000 top5:  0.0078 batch_cost: 0.28372 s, reader_cost: 0.00085 s, ips: 902.28318 samples/sec.
[2022/12/12 11:43:12] ppcls INFO: epoch:0   train step:500  lr: 0.100000, loss:  6.7459 top1:  0.0117 top5:  0.0312 batch_cost: 0.28372 s, reader_cost: 0.00084 s, ips: 902.30982 samples/sec.
[2022/12/12 11:43:15] ppcls INFO: epoch:0   train step:510  lr: 0.100000, loss:  6.6631 top1:  0.0039 top5:  0.0156 batch_cost: 0.28371 s, reader_cost: 0.00083 s, ips: 902.32960 samples/sec.
[2022/12/12 11:43:18] ppcls INFO: epoch:0   train step:520  lr: 0.100000, loss:  6.7173 top1:  0.0039 top5:  0.0156 batch_cost: 0.28370 s, reader_cost: 0.00082 s, ips: 902.35621 samples/sec.
[2022/12/12 11:43:20] ppcls INFO: epoch:0   train step:530  lr: 0.100000, loss:  6.7869 top1:  0.0039 top5:  0.0156 batch_cost: 0.28369 s, reader_cost: 0.00082 s, ips: 902.38198 samples/sec.
[2022/12/12 11:43:23] ppcls INFO: epoch:0   train step:540  lr: 0.100000, loss:  6.7140 top1:  0.0000 top5:  0.0078 batch_cost: 0.28368 s, reader_cost: 0.00082 s, ips: 902.41913 samples/sec.
[2022/12/12 11:43:26] ppcls INFO: epoch:0   train step:550  lr: 0.100000, loss:  6.7077 top1:  0.0000 top5:  0.0078 batch_cost: 0.28368 s, reader_cost: 0.00081 s, ips: 902.43903 samples/sec.
[2022/12/12 11:43:29] ppcls INFO: epoch:0   train step:560  lr: 0.100000, loss:  6.7011 top1:  0.0000 top5:  0.0156 batch_cost: 0.28367 s, reader_cost: 0.00080 s, ips: 902.46590 samples/sec.
[2022/12/12 11:43:32] ppcls INFO: epoch:0   train step:570  lr: 0.100000, loss:  6.6792 top1:  0.0039 top5:  0.0156 batch_cost: 0.28366 s, reader_cost: 0.00080 s, ips: 902.48372 samples/sec.
[2022/12/12 11:43:35] ppcls INFO: epoch:0   train step:580  lr: 0.100000, loss:  6.6222 top1:  0.0000 top5:  0.0195 batch_cost: 0.28366 s, reader_cost: 0.00079 s, ips: 902.50030 samples/sec.
[2022/12/12 11:43:37] ppcls INFO: epoch:0   train step:590  lr: 0.100000, loss:  6.6822 top1:  0.0000 top5:  0.0156 batch_cost: 0.28365 s, reader_cost: 0.00078 s, ips: 902.52152 samples/sec.
[2022/12/12 11:43:40] ppcls INFO: epoch:0   train step:600  lr: 0.100000, loss:  6.5863 top1:  0.0117 top5:  0.0234 batch_cost: 0.28364 s, reader_cost: 0.00078 s, ips: 902.53997 samples/sec.
[2022/12/12 11:43:43] ppcls INFO: epoch:0   train step:610  lr: 0.100000, loss:  6.5623 top1:  0.0117 top5:  0.0273 batch_cost: 0.28364 s, reader_cost: 0.00078 s, ips: 902.55221 samples/sec.
[2022/12/12 11:43:46] ppcls INFO: epoch:0   train step:620  lr: 0.100000, loss:  6.5882 top1:  0.0078 top5:  0.0469 batch_cost: 0.28363 s, reader_cost: 0.00077 s, ips: 902.56890 samples/sec.
[2022/12/12 11:43:49] ppcls INFO: epoch:0   train step:630  lr: 0.100000, loss:  6.5940 top1:  0.0039 top5:  0.0312 batch_cost: 0.28363 s, reader_cost: 0.00077 s, ips: 902.59405 samples/sec.
[2022/12/12 11:43:52] ppcls INFO: epoch:0   train step:640  lr: 0.100000, loss:  6.6076 top1:  0.0078 top5:  0.0273 batch_cost: 0.28362 s, reader_cost: 0.00086 s, ips: 902.61076 samples/sec.
[2022/12/12 11:43:54] ppcls INFO: epoch:0   train step:650  lr: 0.100000, loss:  6.5197 top1:  0.0078 top5:  0.0430 batch_cost: 0.28364 s, reader_cost: 0.00088 s, ips: 902.55403 samples/sec.
[2022/12/12 11:43:57] ppcls INFO: epoch:0   train step:660  lr: 0.100000, loss:  6.5074 top1:  0.0039 top5:  0.0234 batch_cost: 0.28363 s, reader_cost: 0.00087 s, ips: 902.57789 samples/sec.
[2022/12/12 11:44:00] ppcls INFO: epoch:0   train step:670  lr: 0.100000, loss:  6.5408 top1:  0.0117 top5:  0.0312 batch_cost: 0.28363 s, reader_cost: 0.00086 s, ips: 902.59872 samples/sec.
[2022/12/12 11:44:03] ppcls INFO: epoch:0   train step:680  lr: 0.100000, loss:  6.5389 top1:  0.0039 top5:  0.0195 batch_cost: 0.28362 s, reader_cost: 0.00085 s, ips: 902.62400 samples/sec.
[2022/12/12 11:44:06] ppcls INFO: epoch:0   train step:690  lr: 0.100000, loss:  6.5413 top1:  0.0078 top5:  0.0312 batch_cost: 0.28361 s, reader_cost: 0.00085 s, ips: 902.64102 samples/sec.
[2022/12/12 11:44:09] ppcls INFO: epoch:0   train step:700  lr: 0.100000, loss:  6.5581 top1:  0.0156 top5:  0.0391 batch_cost: 0.28361 s, reader_cost: 0.00085 s, ips: 902.65595 samples/sec.
[2022/12/12 11:44:11] ppcls INFO: epoch:0   train step:710  lr: 0.100000, loss:  6.4456 top1:  0.0078 top5:  0.0312 batch_cost: 0.28360 s, reader_cost: 0.00084 s, ips: 902.67570 samples/sec.
[2022/12/12 11:44:14] ppcls INFO: epoch:0   train step:720  lr: 0.100000, loss:  6.4272 top1:  0.0000 top5:  0.0234 batch_cost: 0.28360 s, reader_cost: 0.00084 s, ips: 902.69288 samples/sec.
[2022/12/12 11:44:17] ppcls INFO: epoch:0   train step:730  lr: 0.100000, loss:  6.4068 top1:  0.0078 top5:  0.0547 batch_cost: 0.28359 s, reader_cost: 0.00083 s, ips: 902.70596 samples/sec.
[2022/12/12 11:44:20] ppcls INFO: epoch:0   train step:740  lr: 0.100000, loss:  6.4842 top1:  0.0117 top5:  0.0352 batch_cost: 0.28359 s, reader_cost: 0.00083 s, ips: 902.72241 samples/sec.
[2022/12/12 11:44:23] ppcls INFO: epoch:0   train step:750  lr: 0.100000, loss:  6.4129 top1:  0.0039 top5:  0.0312 batch_cost: 0.28358 s, reader_cost: 0.00083 s, ips: 902.73968 samples/sec.
[2022/12/12 11:44:26] ppcls INFO: epoch:0   train step:760  lr: 0.100000, loss:  6.4341 top1:  0.0195 top5:  0.0391 batch_cost: 0.28358 s, reader_cost: 0.00082 s, ips: 902.75399 samples/sec.
[2022/12/12 11:44:28] ppcls INFO: epoch:0   train step:770  lr: 0.100000, loss:  6.4431 top1:  0.0039 top5:  0.0234 batch_cost: 0.28357 s, reader_cost: 0.00086 s, ips: 902.76466 samples/sec.
[2022/12/12 11:44:31] ppcls INFO: epoch:0   train step:780  lr: 0.100000, loss:  6.3147 top1:  0.0117 top5:  0.0508 batch_cost: 0.28357 s, reader_cost: 0.00086 s, ips: 902.78052 samples/sec.
[2022/12/12 11:44:34] ppcls INFO: epoch:0   train step:790  lr: 0.100000, loss:  6.3703 top1:  0.0039 top5:  0.0508 batch_cost: 0.28356 s, reader_cost: 0.00085 s, ips: 902.79620 samples/sec.
[2022/12/12 11:44:37] ppcls INFO: epoch:0   train step:800  lr: 0.100000, loss:  6.3681 top1:  0.0195 top5:  0.0469 batch_cost: 0.28356 s, reader_cost: 0.00085 s, ips: 902.80870 samples/sec.
[2022/12/12 11:44:40] ppcls INFO: epoch:0   train step:810  lr: 0.100000, loss:  6.2919 top1:  0.0078 top5:  0.0430 batch_cost: 0.28355 s, reader_cost: 0.00084 s, ips: 902.82864 samples/sec.
[2022/12/12 11:44:43] ppcls INFO: epoch:0   train step:820  lr: 0.100000, loss:  6.3908 top1:  0.0117 top5:  0.0391 batch_cost: 0.28355 s, reader_cost: 0.00084 s, ips: 902.84177 samples/sec.
[2022/12/12 11:44:45] ppcls INFO: epoch:0   train step:830  lr: 0.100000, loss:  6.4113 top1:  0.0312 top5:  0.0547 batch_cost: 0.28354 s, reader_cost: 0.00084 s, ips: 902.85637 samples/sec.
[2022/12/12 11:44:48] ppcls INFO: epoch:0   train step:840  lr: 0.100000, loss:  6.3712 top1:  0.0039 top5:  0.0312 batch_cost: 0.28354 s, reader_cost: 0.00083 s, ips: 902.86943 samples/sec.
[2022/12/12 11:44:51] ppcls INFO: epoch:0   train step:850  lr: 0.100000, loss:  6.4511 top1:  0.0078 top5:  0.0234 batch_cost: 0.28354 s, reader_cost: 0.00083 s, ips: 902.88490 samples/sec.
[2022/12/12 11:44:54] ppcls INFO: epoch:0   train step:860  lr: 0.100000, loss:  6.3846 top1:  0.0234 top5:  0.0586 batch_cost: 0.28353 s, reader_cost: 0.00082 s, ips: 902.90455 samples/sec.
[2022/12/12 11:44:57] ppcls INFO: epoch:0   train step:870  lr: 0.100000, loss:  6.2668 top1:  0.0117 top5:  0.0430 batch_cost: 0.28353 s, reader_cost: 0.00082 s, ips: 902.91700 samples/sec.
[2022/12/12 11:45:00] ppcls INFO: epoch:0   train step:880  lr: 0.100000, loss:  6.3719 top1:  0.0117 top5:  0.0391 batch_cost: 0.28352 s, reader_cost: 0.00081 s, ips: 902.93072 samples/sec.
[2022/12/12 11:45:02] ppcls INFO: epoch:0   train step:890  lr: 0.100000, loss:  6.2957 top1:  0.0156 top5:  0.0391 batch_cost: 0.28352 s, reader_cost: 0.00081 s, ips: 902.94270 samples/sec.
[2022/12/12 11:45:05] ppcls INFO: epoch:0   train step:900  lr: 0.100000, loss:  6.3121 top1:  0.0078 top5:  0.0508 batch_cost: 0.28352 s, reader_cost: 0.00081 s, ips: 902.94747 samples/sec.
[2022/12/12 11:45:08] ppcls INFO: epoch:0   train step:910  lr: 0.100000, loss:  6.1912 top1:  0.0156 top5:  0.0586 batch_cost: 0.28351 s, reader_cost: 0.00080 s, ips: 902.96931 samples/sec.
[2022/12/12 11:45:11] ppcls INFO: epoch:0   train step:920  lr: 0.100000, loss:  6.3237 top1:  0.0156 top5:  0.0469 batch_cost: 0.28351 s, reader_cost: 0.00079 s, ips: 902.98048 samples/sec.
[2022/12/12 11:45:14] ppcls INFO: epoch:0   train step:930  lr: 0.100000, loss:  6.2328 top1:  0.0352 top5:  0.0781 batch_cost: 0.28350 s, reader_cost: 0.00079 s, ips: 902.99184 samples/sec.
[2022/12/12 11:45:17] ppcls INFO: epoch:0   train step:940  lr: 0.100000, loss:  6.2155 top1:  0.0234 top5:  0.0742 batch_cost: 0.28350 s, reader_cost: 0.00079 s, ips: 903.00143 samples/sec.
[2022/12/12 11:45:19] ppcls INFO: epoch:0   train step:950  lr: 0.100000, loss:  6.1465 top1:  0.0312 top5:  0.0859 batch_cost: 0.28350 s, reader_cost: 0.00079 s, ips: 903.00848 samples/sec.
[2022/12/12 11:45:22] ppcls INFO: epoch:0   train step:960  lr: 0.100000, loss:  6.2891 top1:  0.0078 top5:  0.0430 batch_cost: 0.28349 s, reader_cost: 0.00078 s, ips: 903.01828 samples/sec.
[2022/12/12 11:45:25] ppcls INFO: epoch:0   train step:970  lr: 0.100000, loss:  6.2573 top1:  0.0234 top5:  0.0820 batch_cost: 0.28349 s, reader_cost: 0.00078 s, ips: 903.03089 samples/sec.
[2022/12/12 11:45:28] ppcls INFO: epoch:0   train step:980  lr: 0.100000, loss:  6.2407 top1:  0.0078 top5:  0.0703 batch_cost: 0.28349 s, reader_cost: 0.00078 s, ips: 903.03831 samples/sec.
[2022/12/12 11:45:31] ppcls INFO: epoch:0   train step:990  lr: 0.100000, loss:  6.2798 top1:  0.0078 top5:  0.0312 batch_cost: 0.28349 s, reader_cost: 0.00078 s, ips: 903.04554 samples/sec.
[2022/12/12 11:45:34] ppcls INFO: epoch:0   train step:1000 lr: 0.100000, loss:  6.1928 top1:  0.0156 top5:  0.0703 batch_cost: 0.28348 s, reader_cost: 0.00077 s, ips: 903.05537 samples/sec.
[2022/12/12 11:45:36] ppcls INFO: epoch:0   train step:1010 lr: 0.100000, loss:  6.1464 top1:  0.0156 top5:  0.0625 batch_cost: 0.28348 s, reader_cost: 0.00077 s, ips: 903.06339 samples/sec.
[2022/12/12 11:45:39] ppcls INFO: epoch:0   train step:1020 lr: 0.100000, loss:  6.2160 top1:  0.0234 top5:  0.0703 batch_cost: 0.28348 s, reader_cost: 0.00077 s, ips: 903.07028 samples/sec.
[2022/12/12 11:45:42] ppcls INFO: epoch:0   train step:1030 lr: 0.100000, loss:  6.1757 top1:  0.0391 top5:  0.0781 batch_cost: 0.28347 s, reader_cost: 0.00077 s, ips: 903.08072 samples/sec.
[2022/12/12 11:45:45] ppcls INFO: epoch:0   train step:1040 lr: 0.100000, loss:  6.1421 top1:  0.0195 top5:  0.0742 batch_cost: 0.28347 s, reader_cost: 0.00076 s, ips: 903.08959 samples/sec.
[2022/12/12 11:45:48] ppcls INFO: epoch:0   train step:1050 lr: 0.100000, loss:  6.1400 top1:  0.0078 top5:  0.0664 batch_cost: 0.28347 s, reader_cost: 0.00076 s, ips: 903.09484 samples/sec.
[2022/12/12 11:45:51] ppcls INFO: epoch:0   train step:1060 lr: 0.100000, loss:  6.1430 top1:  0.0234 top5:  0.0859 batch_cost: 0.28347 s, reader_cost: 0.00076 s, ips: 903.10000 samples/sec.
[2022/12/12 11:45:53] ppcls INFO: epoch:0   train step:1070 lr: 0.100000, loss:  6.1780 top1:  0.0117 top5:  0.0469 batch_cost: 0.28347 s, reader_cost: 0.00075 s, ips: 903.10681 samples/sec.
[2022/12/12 11:45:56] ppcls INFO: epoch:0   train step:1080 lr: 0.100000, loss:  6.1163 top1:  0.0117 top5:  0.0625 batch_cost: 0.28347 s, reader_cost: 0.00075 s, ips: 903.10952 samples/sec.
[2022/12/12 11:45:59] ppcls INFO: epoch:0   train step:1090 lr: 0.100000, loss:  6.1173 top1:  0.0156 top5:  0.0703 batch_cost: 0.28346 s, reader_cost: 0.00075 s, ips: 903.11894 samples/sec.
[2022/12/12 11:46:02] ppcls INFO: epoch:0   train step:1100 lr: 0.100000, loss:  6.1084 top1:  0.0312 top5:  0.0625 batch_cost: 0.28346 s, reader_cost: 0.00075 s, ips: 903.12302 samples/sec.
[2022/12/12 11:46:05] ppcls INFO: epoch:0   train step:1110 lr: 0.100000, loss:  6.1030 top1:  0.0156 top5:  0.0938 batch_cost: 0.28346 s, reader_cost: 0.00075 s, ips: 903.13190 samples/sec.
[2022/12/12 11:46:08] ppcls INFO: epoch:0   train step:1120 lr: 0.100000, loss:  6.1261 top1:  0.0234 top5:  0.0703 batch_cost: 0.28346 s, reader_cost: 0.00074 s, ips: 903.13772 samples/sec.
[2022/12/12 11:46:10] ppcls INFO: epoch:0   train step:1130 lr: 0.100000, loss:  6.0714 top1:  0.0234 top5:  0.0781 batch_cost: 0.28345 s, reader_cost: 0.00074 s, ips: 903.14232 samples/sec.
[2022/12/12 11:46:13] ppcls INFO: epoch:0   train step:1140 lr: 0.100000, loss:  6.0517 top1:  0.0352 top5:  0.0820 batch_cost: 0.28345 s, reader_cost: 0.00074 s, ips: 903.14858 samples/sec.
[2022/12/12 11:46:16] ppcls INFO: epoch:0   train step:1150 lr: 0.100000, loss:  5.9971 top1:  0.0117 top5:  0.0781 batch_cost: 0.28345 s, reader_cost: 0.00073 s, ips: 903.15615 samples/sec.
[2022/12/12 11:46:19] ppcls INFO: epoch:0   train step:1160 lr: 0.100000, loss:  6.0864 top1:  0.0195 top5:  0.0742 batch_cost: 0.28345 s, reader_cost: 0.00073 s, ips: 903.16255 samples/sec.
[2022/12/12 11:46:22] ppcls INFO: epoch:0   train step:1170 lr: 0.100000, loss:  6.2128 top1:  0.0195 top5:  0.0781 batch_cost: 0.28345 s, reader_cost: 0.00073 s, ips: 903.16883 samples/sec.
[2022/12/12 11:46:25] ppcls INFO: epoch:0   train step:1180 lr: 0.100000, loss:  6.0638 top1:  0.0234 top5:  0.0664 batch_cost: 0.28344 s, reader_cost: 0.00073 s, ips: 903.17630 samples/sec.
[2022/12/12 11:46:27] ppcls INFO: epoch:0   train step:1190 lr: 0.100000, loss:  5.9072 top1:  0.0312 top5:  0.1055 batch_cost: 0.28344 s, reader_cost: 0.00072 s, ips: 903.18495 samples/sec.
[2022/12/12 11:46:30] ppcls INFO: epoch:0   train step:1200 lr: 0.100000, loss:  5.9487 top1:  0.0312 top5:  0.0977 batch_cost: 0.28344 s, reader_cost: 0.00072 s, ips: 903.19060 samples/sec.
[2022/12/12 11:46:33] ppcls INFO: epoch:0   train step:1210 lr: 0.100000, loss:  6.0918 top1:  0.0234 top5:  0.0781 batch_cost: 0.28344 s, reader_cost: 0.00072 s, ips: 903.19598 samples/sec.
[2022/12/12 11:46:36] ppcls INFO: epoch:0   train step:1220 lr: 0.100000, loss:  5.9440 top1:  0.0195 top5:  0.1133 batch_cost: 0.28344 s, reader_cost: 0.00071 s, ips: 903.20090 samples/sec.
[2022/12/12 11:46:39] ppcls INFO: epoch:0   train step:1230 lr: 0.100000, loss:  5.9247 top1:  0.0430 top5:  0.0859 batch_cost: 0.28343 s, reader_cost: 0.00071 s, ips: 903.20731 samples/sec.
[2022/12/12 11:46:42] ppcls INFO: epoch:0   train step:1240 lr: 0.100000, loss:  6.0063 top1:  0.0117 top5:  0.0625 batch_cost: 0.28343 s, reader_cost: 0.00071 s, ips: 903.21150 samples/sec.
[2022/12/12 11:46:44] ppcls INFO: epoch:0   train step:1250 lr: 0.100000, loss:  5.9656 top1:  0.0312 top5:  0.0898 batch_cost: 0.28343 s, reader_cost: 0.00071 s, ips: 903.21795 samples/sec.
[2022/12/12 11:46:47] ppcls INFO: epoch:0   train step:1260 lr: 0.100000, loss:  6.0661 top1:  0.0273 top5:  0.1055 batch_cost: 0.28343 s, reader_cost: 0.00071 s, ips: 903.22254 samples/sec.
[2022/12/12 11:46:50] ppcls INFO: epoch:0   train step:1270 lr: 0.100000, loss:  5.8599 top1:  0.0352 top5:  0.1094 batch_cost: 0.28343 s, reader_cost: 0.00070 s, ips: 903.22817 samples/sec.
[2022/12/12 11:46:53] ppcls INFO: epoch:0   train step:1280 lr: 0.100000, loss:  5.8656 top1:  0.0234 top5:  0.0977 batch_cost: 0.28343 s, reader_cost: 0.00070 s, ips: 903.23067 samples/sec.
[2022/12/12 11:46:56] ppcls INFO: epoch:0   train step:1290 lr: 0.100000, loss:  5.8819 top1:  0.0273 top5:  0.1016 batch_cost: 0.28343 s, reader_cost: 0.00070 s, ips: 903.23579 samples/sec.
[2022/12/12 11:46:59] ppcls INFO: epoch:0   train step:1300 lr: 0.100000, loss:  5.7905 top1:  0.0469 top5:  0.0977 batch_cost: 0.28342 s, reader_cost: 0.00070 s, ips: 903.24386 samples/sec.
[2022/12/12 11:47:01] ppcls INFO: epoch:0   train step:1310 lr: 0.100000, loss:  5.9020 top1:  0.0234 top5:  0.0977 batch_cost: 0.28342 s, reader_cost: 0.00069 s, ips: 903.24897 samples/sec.
[2022/12/12 11:47:04] ppcls INFO: epoch:0   train step:1320 lr: 0.100000, loss:  5.9320 top1:  0.0234 top5:  0.0977 batch_cost: 0.28342 s, reader_cost: 0.00069 s, ips: 903.25501 samples/sec.
[2022/12/12 11:47:07] ppcls INFO: epoch:0   train step:1330 lr: 0.100000, loss:  5.9798 top1:  0.0156 top5:  0.0898 batch_cost: 0.28342 s, reader_cost: 0.00069 s, ips: 903.26117 samples/sec.
[2022/12/12 11:47:10] ppcls INFO: epoch:0   train step:1340 lr: 0.100000, loss:  5.9350 top1:  0.0273 top5:  0.0781 batch_cost: 0.28341 s, reader_cost: 0.00069 s, ips: 903.26996 samples/sec.
[2022/12/12 11:47:13] ppcls INFO: epoch:0   train step:1350 lr: 0.100000, loss:  5.7270 top1:  0.0430 top5:  0.1484 batch_cost: 0.28341 s, reader_cost: 0.00068 s, ips: 903.27430 samples/sec.
[2022/12/12 11:47:16] ppcls INFO: epoch:0   train step:1360 lr: 0.100000, loss:  5.9743 top1:  0.0273 top5:  0.0820 batch_cost: 0.28341 s, reader_cost: 0.00068 s, ips: 903.28006 samples/sec.
[2022/12/12 11:47:18] ppcls INFO: epoch:0   train step:1370 lr: 0.100000, loss:  5.8687 top1:  0.0391 top5:  0.1055 batch_cost: 0.28341 s, reader_cost: 0.00068 s, ips: 903.28479 samples/sec.
[2022/12/12 11:47:21] ppcls INFO: epoch:0   train step:1380 lr: 0.100000, loss:  5.8400 top1:  0.0273 top5:  0.0859 batch_cost: 0.28341 s, reader_cost: 0.00068 s, ips: 903.28958 samples/sec.
[2022/12/12 11:47:24] ppcls INFO: epoch:0   train step:1390 lr: 0.100000, loss:  5.8341 top1:  0.0312 top5:  0.1172 batch_cost: 0.28341 s, reader_cost: 0.00068 s, ips: 903.29587 samples/sec.
[2022/12/12 11:47:27] ppcls INFO: epoch:0   train step:1400 lr: 0.100000, loss:  5.9589 top1:  0.0508 top5:  0.1016 batch_cost: 0.28340 s, reader_cost: 0.00068 s, ips: 903.30145 samples/sec.
[2022/12/12 11:47:30] ppcls INFO: epoch:0   train step:1410 lr: 0.100000, loss:  5.9237 top1:  0.0117 top5:  0.0859 batch_cost: 0.28340 s, reader_cost: 0.00068 s, ips: 903.30459 samples/sec.
[2022/12/12 11:47:33] ppcls INFO: epoch:0   train step:1420 lr: 0.100000, loss:  5.7598 top1:  0.0273 top5:  0.0977 batch_cost: 0.28340 s, reader_cost: 0.00068 s, ips: 903.30944 samples/sec.
[2022/12/12 11:47:35] ppcls INFO: epoch:0   train step:1430 lr: 0.100000, loss:  5.7260 top1:  0.0391 top5:  0.1055 batch_cost: 0.28340 s, reader_cost: 0.00068 s, ips: 903.31443 samples/sec.
[2022/12/12 11:47:38] ppcls INFO: epoch:0   train step:1440 lr: 0.100000, loss:  5.7694 top1:  0.0117 top5:  0.1016 batch_cost: 0.28340 s, reader_cost: 0.00068 s, ips: 903.31889 samples/sec.
[2022/12/12 11:47:41] ppcls INFO: epoch:0   train step:1450 lr: 0.100000, loss:  5.9606 top1:  0.0664 top5:  0.1016 batch_cost: 0.28340 s, reader_cost: 0.00067 s, ips: 903.32315 samples/sec.
[2022/12/12 11:47:44] ppcls INFO: epoch:0   train step:1460 lr: 0.100000, loss:  5.8018 top1:  0.0391 top5:  0.1172 batch_cost: 0.28340 s, reader_cost: 0.00067 s, ips: 903.32667 samples/sec.
[2022/12/12 11:47:47] ppcls INFO: epoch:0   train step:1470 lr: 0.100000, loss:  5.8113 top1:  0.0312 top5:  0.0977 batch_cost: 0.28340 s, reader_cost: 0.00067 s, ips: 903.32725 samples/sec.
[2022/12/12 11:47:50] ppcls INFO: epoch:0   train step:1480 lr: 0.100000, loss:  5.8003 top1:  0.0352 top5:  0.1367 batch_cost: 0.28340 s, reader_cost: 0.00067 s, ips: 903.32718 samples/sec.
[2022/12/12 11:47:52] ppcls INFO: epoch:0   train step:1490 lr: 0.100000, loss:  5.7244 top1:  0.0312 top5:  0.0938 batch_cost: 0.28340 s, reader_cost: 0.00067 s, ips: 903.33089 samples/sec.
[2022/12/12 11:47:55] ppcls INFO: epoch:0   train step:1500 lr: 0.100000, loss:  5.7443 top1:  0.0234 top5:  0.1172 batch_cost: 0.28339 s, reader_cost: 0.00067 s, ips: 903.33343 samples/sec.
[2022/12/12 11:47:58] ppcls INFO: epoch:0   train step:1510 lr: 0.100000, loss:  5.6988 top1:  0.0391 top5:  0.1016 batch_cost: 0.28339 s, reader_cost: 0.00067 s, ips: 903.33743 samples/sec.
[2022/12/12 11:48:01] ppcls INFO: epoch:0   train step:1520 lr: 0.100000, loss:  5.7518 top1:  0.0547 top5:  0.1211 batch_cost: 0.28339 s, reader_cost: 0.00066 s, ips: 903.34029 samples/sec.
[2022/12/12 11:48:04] ppcls INFO: epoch:0   train step:1530 lr: 0.100000, loss:  5.7349 top1:  0.0547 top5:  0.1367 batch_cost: 0.28339 s, reader_cost: 0.00066 s, ips: 903.34475 samples/sec.
[2022/12/12 11:48:07] ppcls INFO: epoch:0   train step:1540 lr: 0.100000, loss:  5.8061 top1:  0.0273 top5:  0.0781 batch_cost: 0.28339 s, reader_cost: 0.00066 s, ips: 903.34761 samples/sec.
[2022/12/12 11:48:09] ppcls INFO: epoch:0   train step:1550 lr: 0.100000, loss:  5.6441 top1:  0.0352 top5:  0.1172 batch_cost: 0.28339 s, reader_cost: 0.00066 s, ips: 903.35419 samples/sec.
[2022/12/12 11:48:12] ppcls INFO: epoch:0   train step:1560 lr: 0.100000, loss:  5.6225 top1:  0.0391 top5:  0.1367 batch_cost: 0.28339 s, reader_cost: 0.00066 s, ips: 903.35622 samples/sec.
[2022/12/12 11:48:15] ppcls INFO: epoch:0   train step:1570 lr: 0.100000, loss:  5.6477 top1:  0.0586 top5:  0.1211 batch_cost: 0.28339 s, reader_cost: 0.00066 s, ips: 903.35936 samples/sec.
[2022/12/12 11:48:18] ppcls INFO: epoch:0   train step:1580 lr: 0.100000, loss:  5.6572 top1:  0.0508 top5:  0.1211 batch_cost: 0.28339 s, reader_cost: 0.00065 s, ips: 903.36129 samples/sec.
[2022/12/12 11:48:21] ppcls INFO: epoch:0   train step:1590 lr: 0.100000, loss:  5.7008 top1:  0.0234 top5:  0.1445 batch_cost: 0.28339 s, reader_cost: 0.00065 s, ips: 903.36211 samples/sec.
[2022/12/12 11:48:24] ppcls INFO: epoch:0   train step:1600 lr: 0.100000, loss:  5.4124 top1:  0.0430 top5:  0.1406 batch_cost: 0.28338 s, reader_cost: 0.00065 s, ips: 903.36481 samples/sec.
[2022/12/12 11:48:26] ppcls INFO: epoch:0   train step:1610 lr: 0.100000, loss:  5.6669 top1:  0.0508 top5:  0.1328 batch_cost: 0.28338 s, reader_cost: 0.00065 s, ips: 903.37099 samples/sec.
[2022/12/12 11:48:29] ppcls INFO: epoch:0   train step:1620 lr: 0.100000, loss:  5.7532 top1:  0.0391 top5:  0.1016 batch_cost: 0.28338 s, reader_cost: 0.00065 s, ips: 903.37501 samples/sec.
[2022/12/12 11:48:32] ppcls INFO: epoch:0   train step:1630 lr: 0.100000, loss:  5.5758 top1:  0.0625 top5:  0.1602 batch_cost: 0.28338 s, reader_cost: 0.00065 s, ips: 903.37542 samples/sec.
[2022/12/12 11:48:35] ppcls INFO: epoch:0   train step:1640 lr: 0.100000, loss:  5.6072 top1:  0.0508 top5:  0.1328 batch_cost: 0.28338 s, reader_cost: 0.00065 s, ips: 903.37841 samples/sec.
[2022/12/12 11:48:38] ppcls INFO: epoch:0   train step:1650 lr: 0.100000, loss:  5.7206 top1:  0.0430 top5:  0.1328 batch_cost: 0.28338 s, reader_cost: 0.00065 s, ips: 903.38182 samples/sec.
[2022/12/12 11:48:41] ppcls INFO: epoch:0   train step:1660 lr: 0.100000, loss:  5.6093 top1:  0.0430 top5:  0.1289 batch_cost: 0.28338 s, reader_cost: 0.00064 s, ips: 903.38619 samples/sec.
[2022/12/12 11:48:43] ppcls INFO: epoch:0   train step:1670 lr: 0.100000, loss:  5.5201 top1:  0.0391 top5:  0.1523 batch_cost: 0.28338 s, reader_cost: 0.00064 s, ips: 903.38868 samples/sec.
[2022/12/12 11:48:46] ppcls INFO: epoch:0   train step:1680 lr: 0.100000, loss:  5.4571 top1:  0.0430 top5:  0.1445 batch_cost: 0.28338 s, reader_cost: 0.00064 s, ips: 903.39289 samples/sec.
[2022/12/12 11:48:49] ppcls INFO: epoch:0   train step:1690 lr: 0.100000, loss:  5.2594 top1:  0.0625 top5:  0.2031 batch_cost: 0.28338 s, reader_cost: 0.00064 s, ips: 903.39581 samples/sec.
[2022/12/12 11:48:52] ppcls INFO: epoch:0   train step:1700 lr: 0.100000, loss:  5.5161 top1:  0.0625 top5:  0.1523 batch_cost: 0.28338 s, reader_cost: 0.00064 s, ips: 903.39617 samples/sec.
[2022/12/12 11:48:55] ppcls INFO: epoch:0   train step:1710 lr: 0.100000, loss:  5.6072 top1:  0.0586 top5:  0.1367 batch_cost: 0.28337 s, reader_cost: 0.00064 s, ips: 903.39916 samples/sec.
[2022/12/12 11:48:58] ppcls INFO: epoch:0   train step:1720 lr: 0.100000, loss:  5.6005 top1:  0.0430 top5:  0.1523 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.40194 samples/sec.
[2022/12/12 11:49:00] ppcls INFO: epoch:0   train step:1730 lr: 0.100000, loss:  5.6426 top1:  0.0508 top5:  0.1328 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.40401 samples/sec.
[2022/12/12 11:49:03] ppcls INFO: epoch:0   train step:1740 lr: 0.100000, loss:  5.6751 top1:  0.0273 top5:  0.1406 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.40766 samples/sec.
[2022/12/12 11:49:06] ppcls INFO: epoch:0   train step:1750 lr: 0.100000, loss:  5.3716 top1:  0.0508 top5:  0.1602 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.40973 samples/sec.
[2022/12/12 11:49:09] ppcls INFO: epoch:0   train step:1760 lr: 0.100000, loss:  5.5010 top1:  0.0430 top5:  0.1406 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.41172 samples/sec.
[2022/12/12 11:49:12] ppcls INFO: epoch:0   train step:1770 lr: 0.100000, loss:  5.5587 top1:  0.0469 top5:  0.1055 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.41187 samples/sec.
[2022/12/12 11:49:15] ppcls INFO: epoch:0   train step:1780 lr: 0.100000, loss:  5.6435 top1:  0.0469 top5:  0.1172 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.41340 samples/sec.
[2022/12/12 11:49:17] ppcls INFO: epoch:0   train step:1790 lr: 0.100000, loss:  5.3886 top1:  0.0781 top5:  0.1953 batch_cost: 0.28337 s, reader_cost: 0.00063 s, ips: 903.41330 samples/sec.
[2022/12/12 11:49:20] ppcls INFO: epoch:0   train step:1800 lr: 0.100000, loss:  5.6508 top1:  0.0508 top5:  0.1445 batch_cost: 0.28337 s, reader_cost: 0.00062 s, ips: 903.41637 samples/sec.
[2022/12/12 11:49:23] ppcls INFO: epoch:0   train step:1810 lr: 0.100000, loss:  5.6986 top1:  0.0234 top5:  0.1133 batch_cost: 0.28337 s, reader_cost: 0.00062 s, ips: 903.41996 samples/sec.
[2022/12/12 11:49:26] ppcls INFO: epoch:0   train step:1820 lr: 0.100000, loss:  5.5256 top1:  0.0625 top5:  0.1367 batch_cost: 0.28337 s, reader_cost: 0.00062 s, ips: 903.42134 samples/sec.
[2022/12/12 11:49:29] ppcls INFO: epoch:0   train step:1830 lr: 0.100000, loss:  5.5532 top1:  0.0469 top5:  0.1289 batch_cost: 0.28337 s, reader_cost: 0.00062 s, ips: 903.42235 samples/sec.
[2022/12/12 11:49:32] ppcls INFO: epoch:0   train step:1840 lr: 0.100000, loss:  5.5483 top1:  0.0508 top5:  0.1367 batch_cost: 0.28337 s, reader_cost: 0.00062 s, ips: 903.42484 samples/sec.
[2022/12/12 11:49:34] ppcls INFO: epoch:0   train step:1850 lr: 0.100000, loss:  5.3011 top1:  0.0625 top5:  0.1836 batch_cost: 0.28337 s, reader_cost: 0.00062 s, ips: 903.42634 samples/sec.
[2022/12/12 11:49:37] ppcls INFO: epoch:0   train step:1860 lr: 0.100000, loss:  5.6132 top1:  0.0625 top5:  0.1055 batch_cost: 0.28336 s, reader_cost: 0.00062 s, ips: 903.43091 samples/sec.
[2022/12/12 11:49:40] ppcls INFO: epoch:0   train step:1870 lr: 0.100000, loss:  5.4253 top1:  0.0586 top5:  0.1250 batch_cost: 0.28336 s, reader_cost: 0.00062 s, ips: 903.43107 samples/sec.
[2022/12/12 11:49:43] ppcls INFO: epoch:0   train step:1880 lr: 0.100000, loss:  5.5383 top1:  0.0508 top5:  0.1758 batch_cost: 0.28336 s, reader_cost: 0.00061 s, ips: 903.43199 samples/sec.
[2022/12/12 11:49:46] ppcls INFO: epoch:0   train step:1890 lr: 0.100000, loss:  5.4477 top1:  0.0430 top5:  0.1484 batch_cost: 0.28336 s, reader_cost: 0.00061 s, ips: 903.43205 samples/sec.
[2022/12/12 11:49:49] ppcls INFO: epoch:0   train step:1900 lr: 0.100000, loss:  5.4391 top1:  0.0508 top5:  0.1367 batch_cost: 0.28336 s, reader_cost: 0.00061 s, ips: 903.43457 samples/sec.
[2022/12/12 11:49:51] ppcls INFO: epoch:0   train step:1910 lr: 0.100000, loss:  5.4380 top1:  0.0586 top5:  0.1719 batch_cost: 0.28336 s, reader_cost: 0.00061 s, ips: 903.43533 samples/sec.
[2022/12/12 11:49:54] ppcls INFO: epoch:0   train step:1920 lr: 0.100000, loss:  5.4073 top1:  0.0469 top5:  0.1406 batch_cost: 0.28336 s, reader_cost: 0.00061 s, ips: 903.43900 samples/sec.
[2022/12/12 11:49:57] ppcls INFO: epoch:0   train step:1930 lr: 0.100000, loss:  5.2804 top1:  0.0508 top5:  0.1953 batch_cost: 0.28336 s, reader_cost: 0.00061 s, ips: 903.44267 samples/sec.
[2022/12/12 11:50:00] ppcls INFO: epoch:0   train step:1940 lr: 0.100000, loss:  5.3127 top1:  0.0469 top5:  0.1797 batch_cost: 0.28336 s, reader_cost: 0.00060 s, ips: 903.44422 samples/sec.
[2022/12/12 11:50:03] ppcls INFO: epoch:0   train step:1950 lr: 0.100000, loss:  5.4373 top1:  0.0586 top5:  0.1797 batch_cost: 0.28336 s, reader_cost: 0.00060 s, ips: 903.44536 samples/sec.
[2022/12/12 11:50:06] ppcls INFO: epoch:0   train step:1960 lr: 0.100000, loss:  5.1906 top1:  0.0859 top5:  0.1836 batch_cost: 0.28336 s, reader_cost: 0.00060 s, ips: 903.44771 samples/sec.
[2022/12/12 11:50:08] ppcls INFO: epoch:0   train step:1970 lr: 0.100000, loss:  5.3296 top1:  0.0742 top5:  0.2344 batch_cost: 0.28336 s, reader_cost: 0.00060 s, ips: 903.45224 samples/sec.
[2022/12/12 11:50:11] ppcls INFO: epoch:0   train step:1980 lr: 0.100000, loss:  5.3780 top1:  0.0625 top5:  0.1602 batch_cost: 0.28336 s, reader_cost: 0.00060 s, ips: 903.45595 samples/sec.
[2022/12/12 11:50:14] ppcls INFO: epoch:0   train step:1990 lr: 0.100000, loss:  5.3035 top1:  0.0820 top5:  0.1875 batch_cost: 0.28336 s, reader_cost: 0.00060 s, ips: 903.46023 samples/sec.
[2022/12/12 11:50:17] ppcls INFO: epoch:0   train step:2000 lr: 0.100000, loss:  5.3327 top1:  0.0625 top5:  0.1836 batch_cost: 0.28335 s, reader_cost: 0.00061 s, ips: 903.46236 samples/sec.
[2022/12/12 11:50:20] ppcls INFO: epoch:0   train step:2010 lr: 0.100000, loss:  5.2166 top1:  0.0820 top5:  0.1836 batch_cost: 0.28335 s, reader_cost: 0.00060 s, ips: 903.46551 samples/sec.
[2022/12/12 11:50:23] ppcls INFO: epoch:0   train step:2020 lr: 0.100000, loss:  5.1937 top1:  0.0742 top5:  0.1914 batch_cost: 0.28335 s, reader_cost: 0.00060 s, ips: 903.46849 samples/sec.
[2022/12/12 11:50:25] ppcls INFO: epoch:0   train step:2030 lr: 0.100000, loss:  5.3600 top1:  0.0781 top5:  0.1875 batch_cost: 0.28335 s, reader_cost: 0.00060 s, ips: 903.47211 samples/sec.


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::ParallelExecutor::RunAndMerge(std::vector<std::string, std::allocator<std::string > > const&)
1   paddle::framework::details::ScopeBufferedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)
2   paddle::framework::details::ScopeBufferedMonitor::Apply(std::function<void ()> const&, bool)
3   paddle::framework::details::FastThreadedSSAGraphExecutor::Run(std::vector<std::string, std::allocator<std::string > > const&, bool)

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1670817027 (unix time) try "date -d @1670817027" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x10f4) received by PID 4341 (TID 0x7f5aff8b5700) from PID 4340 ***]

