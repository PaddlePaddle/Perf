LAUNCH INFO 2022-06-06 15:57:13,314 -----------  Configuration  ----------------------
LAUNCH INFO 2022-06-06 15:57:13,315 devices: None
LAUNCH INFO 2022-06-06 15:57:13,315 elastic_level: -1
LAUNCH INFO 2022-06-06 15:57:13,315 elastic_timeout: 30
LAUNCH INFO 2022-06-06 15:57:13,315 gloo_port: 6767
LAUNCH INFO 2022-06-06 15:57:13,315 host: None
LAUNCH INFO 2022-06-06 15:57:13,315 job_id: default
LAUNCH INFO 2022-06-06 15:57:13,315 legacy: False
LAUNCH INFO 2022-06-06 15:57:13,315 log_dir: log
LAUNCH INFO 2022-06-06 15:57:13,315 log_level: INFO
LAUNCH INFO 2022-06-06 15:57:13,315 master: None
LAUNCH INFO 2022-06-06 15:57:13,315 max_restart: 3
LAUNCH INFO 2022-06-06 15:57:13,315 nnodes: 1
LAUNCH INFO 2022-06-06 15:57:13,315 nproc_per_node: None
LAUNCH INFO 2022-06-06 15:57:13,315 rank: -1
LAUNCH INFO 2022-06-06 15:57:13,315 run_mode: collective
LAUNCH INFO 2022-06-06 15:57:13,315 server_num: None
LAUNCH INFO 2022-06-06 15:57:13,315 servers: 
LAUNCH INFO 2022-06-06 15:57:13,315 trainer_num: None
LAUNCH INFO 2022-06-06 15:57:13,315 trainers: 
LAUNCH INFO 2022-06-06 15:57:13,315 training_script: 0,1,2,3,4,5,6,7
LAUNCH INFO 2022-06-06 15:57:13,315 training_script_args: ['ppcls/static/train.py', '-c', 'ppcls/configs/ImageNet/ResNet/ResNet50_amp_O2_ultra.yaml', '-o', 'DataLoader.Train.sampler.batch_size=256', '-o', 'Global.epochs=8', '-o', 'DataLoader.Train.loader.num_workers=8', '-o', 'Global.eval_during_train=False', '-o', 'fuse_elewise_add_act_ops=True', '-o', 'enable_addto=True']
LAUNCH INFO 2022-06-06 15:57:13,315 with_gloo: 0
LAUNCH INFO 2022-06-06 15:57:13,315 --------------------------------------------------
LAUNCH WARNING 2022-06-06 15:57:13,315 Compatible mode enable with args ['--gpus']
WARNING 2022-06-06 15:57:13,316 launch.py:519] Not found distinct arguments and compiled with cuda or xpu or npu or mlu. Default use collective mode
WARNING 2022-06-06 15:57:13,316 launch.py:519] Not found distinct arguments and compiled with cuda or xpu or npu or mlu. Default use collective mode
INFO 2022-06-06 15:57:13,317 launch_utils.py:679] Change selected_gpus into reletive values. --ips:0,1,2,3,4,5,6,7 will change into relative_ips:[0, 1, 2, 3, 4, 5, 6, 7] according to your CUDA_VISIBLE_DEVICES:['0', '1', '2', '3', '4', '5', '6', '7']
INFO 2022-06-06 15:57:13,317 launch_utils.py:679] Change selected_gpus into reletive values. --ips:0,1,2,3,4,5,6,7 will change into relative_ips:[0, 1, 2, 3, 4, 5, 6, 7] according to your CUDA_VISIBLE_DEVICES:['0', '1', '2', '3', '4', '5', '6', '7']
INFO 2022-06-06 15:57:13,318 launch_utils.py:561] Local start 8 processes. First process distributed environment info (Only For Debug): 
    +=======================================================================================+
    |                        Distributed Envs                      Value                    |
    +---------------------------------------------------------------------------------------+
    |                       PADDLE_TRAINER_ID                        0                      |
    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:51969               |
    |                     PADDLE_TRAINERS_NUM                        8                      |
    |                PADDLE_TRAINER_ENDPOINTS  ... 0.1:48398,127.0.0.1:34775,127.0.0.1:35487|
    |                     PADDLE_RANK_IN_NODE                        0                      |
    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |
    |                 PADDLE_WORLD_DEVICE_IDS                 0,1,2,3,4,5,6,7               |
    |                     FLAGS_selected_gpus                        0                      |
    |             FLAGS_selected_accelerators                        0                      |
    +=======================================================================================+

INFO 2022-06-06 15:57:13,318 launch_utils.py:561] Local start 8 processes. First process distributed environment info (Only For Debug): 
    +=======================================================================================+
    |                        Distributed Envs                      Value                    |
    +---------------------------------------------------------------------------------------+
    |                       PADDLE_TRAINER_ID                        0                      |
    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:51969               |
    |                     PADDLE_TRAINERS_NUM                        8                      |
    |                PADDLE_TRAINER_ENDPOINTS  ... 0.1:48398,127.0.0.1:34775,127.0.0.1:35487|
    |                     PADDLE_RANK_IN_NODE                        0                      |
    |                 PADDLE_LOCAL_DEVICE_IDS                        0                      |
    |                 PADDLE_WORLD_DEVICE_IDS                 0,1,2,3,4,5,6,7               |
    |                     FLAGS_selected_gpus                        0                      |
    |             FLAGS_selected_accelerators                        0                      |
    +=======================================================================================+

INFO 2022-06-06 15:57:13,318 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0
INFO 2022-06-06 15:57:13,318 launch_utils.py:566] details about PADDLE_TRAINER_ENDPOINTS can be found in log/endpoints.log, and detail running logs maybe found in log/workerlog.0
-----------  Configuration Arguments -----------
backend: auto
cluster_topo_path: None
elastic_pre_hook: None
elastic_server: None
enable_auto_mapping: False
force: False
gpus: 0,1,2,3,4,5,6,7
heter_devices: 
heter_worker_num: None
heter_workers: 
host: None
http_port: None
ips: 127.0.0.1
job_id: None
log_dir: log
np: None
nproc_per_node: None
rank_mapping_path: None
run_mode: None
scale: 0
server_num: None
servers: 
training_script: ppcls/static/train.py
training_script_args: ['-c', 'ppcls/configs/ImageNet/ResNet/ResNet50_amp_O2_ultra.yaml', '-o', 'DataLoader.Train.sampler.batch_size=256', '-o', 'Global.epochs=8', '-o', 'DataLoader.Train.loader.num_workers=8', '-o', 'Global.eval_during_train=False', '-o', 'fuse_elewise_add_act_ops=True', '-o', 'enable_addto=True']
worker_num: None
workers: 
------------------------------------------------
launch train in GPU mode!
launch proc_id:7312 idx:0
launch proc_id:7315 idx:1
launch proc_id:7318 idx:2
launch proc_id:7321 idx:3
launch proc_id:7326 idx:4
launch proc_id:7331 idx:5
launch proc_id:7336 idx:6
launch proc_id:7347 idx:7
/paddle/benchmark/frame_benchmark/paddle/PaddleClas/ppcls/data/preprocess/ops/timm_autoaugment.py:39: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.
  _RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)
/paddle/benchmark/frame_benchmark/paddle/PaddleClas/ppcls/data/preprocess/ops/timm_autoaugment.py:39: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  _RANDOM_INTERPOLATION = (Image.BILINEAR, Image.BICUBIC)
A new field (fuse_elewise_add_act_ops) detected!
A new field (enable_addto) detected!
[2022/06/06 15:57:16] ppcls INFO: 
===========================================================
==        PaddleClas is powered by PaddlePaddle !        ==
===========================================================
==                                                       ==
==   For more info please go to the following website.   ==
==                                                       ==
==       https://github.com/PaddlePaddle/PaddleClas      ==
===========================================================

[2022/06/06 15:57:16] ppcls INFO: AMP : 
[2022/06/06 15:57:16] ppcls INFO:     level : O2
[2022/06/06 15:57:16] ppcls INFO:     scale_loss : 128.0
[2022/06/06 15:57:16] ppcls INFO:     use_dynamic_loss_scaling : True
[2022/06/06 15:57:16] ppcls INFO: ------------------------------------------------------------
[2022/06/06 15:57:16] ppcls INFO: Arch : 
[2022/06/06 15:57:16] ppcls INFO:     class_num : 1000
[2022/06/06 15:57:16] ppcls INFO:     data_format : NHWC
[2022/06/06 15:57:16] ppcls INFO:     input_image_channel : 4
[2022/06/06 15:57:16] ppcls INFO:     name : ResNet50
[2022/06/06 15:57:16] ppcls INFO: DataLoader : 
[2022/06/06 15:57:16] ppcls INFO:     Eval : 
[2022/06/06 15:57:16] ppcls INFO:         dataset : 
[2022/06/06 15:57:16] ppcls INFO:             cls_label_path : ./dataset/ILSVRC2012/val_list.txt
[2022/06/06 15:57:16] ppcls INFO:             image_root : ./dataset/ILSVRC2012/
[2022/06/06 15:57:16] ppcls INFO:             name : ImageNetDataset
[2022/06/06 15:57:16] ppcls INFO:             transform_ops : 
[2022/06/06 15:57:16] ppcls INFO:                 DecodeImage : 
[2022/06/06 15:57:16] ppcls INFO:                     channel_first : False
[2022/06/06 15:57:16] ppcls INFO:                     to_rgb : True
[2022/06/06 15:57:16] ppcls INFO:                 ResizeImage : 
[2022/06/06 15:57:16] ppcls INFO:                     resize_short : 256
[2022/06/06 15:57:16] ppcls INFO:                 CropImage : 
[2022/06/06 15:57:16] ppcls INFO:                     size : 224
[2022/06/06 15:57:16] ppcls INFO:                 NormalizeImage : 
[2022/06/06 15:57:16] ppcls INFO:                     channel_num : 4
[2022/06/06 15:57:16] ppcls INFO:                     mean : [0.485, 0.456, 0.406]
[2022/06/06 15:57:16] ppcls INFO:                     order : 
[2022/06/06 15:57:16] ppcls INFO:                     scale : 1.0/255.0
[2022/06/06 15:57:16] ppcls INFO:                     std : [0.229, 0.224, 0.225]
[2022/06/06 15:57:16] ppcls INFO:         loader : 
[2022/06/06 15:57:16] ppcls INFO:             num_workers : 4
[2022/06/06 15:57:16] ppcls INFO:             use_shared_memory : True
[2022/06/06 15:57:16] ppcls INFO:         sampler : 
[2022/06/06 15:57:16] ppcls INFO:             batch_size : 64
[2022/06/06 15:57:16] ppcls INFO:             drop_last : False
[2022/06/06 15:57:16] ppcls INFO:             name : DistributedBatchSampler
[2022/06/06 15:57:16] ppcls INFO:             shuffle : False
[2022/06/06 15:57:16] ppcls INFO:     Train : 
[2022/06/06 15:57:16] ppcls INFO:         dataset : 
[2022/06/06 15:57:16] ppcls INFO:             cls_label_path : ./dataset/ILSVRC2012/train_list.txt
[2022/06/06 15:57:16] ppcls INFO:             image_root : ./dataset/ILSVRC2012/
[2022/06/06 15:57:16] ppcls INFO:             name : ImageNetDataset
[2022/06/06 15:57:16] ppcls INFO:             transform_ops : 
[2022/06/06 15:57:16] ppcls INFO:                 DecodeImage : 
[2022/06/06 15:57:16] ppcls INFO:                     channel_first : False
[2022/06/06 15:57:16] ppcls INFO:                     to_rgb : True
[2022/06/06 15:57:16] ppcls INFO:                 RandCropImage : 
[2022/06/06 15:57:16] ppcls INFO:                     size : 224
[2022/06/06 15:57:16] ppcls INFO:                 RandFlipImage : 
[2022/06/06 15:57:16] ppcls INFO:                     flip_code : 1
[2022/06/06 15:57:16] ppcls INFO:                 NormalizeImage : 
[2022/06/06 15:57:16] ppcls INFO:                     channel_num : 4
[2022/06/06 15:57:16] ppcls INFO:                     mean : [0.485, 0.456, 0.406]
[2022/06/06 15:57:16] ppcls INFO:                     order : 
[2022/06/06 15:57:16] ppcls INFO:                     output_fp16 : True
[2022/06/06 15:57:16] ppcls INFO:                     scale : 1.0/255.0
[2022/06/06 15:57:16] ppcls INFO:                     std : [0.229, 0.224, 0.225]
[2022/06/06 15:57:16] ppcls INFO:         loader : 
[2022/06/06 15:57:16] ppcls INFO:             num_workers : 8
[2022/06/06 15:57:16] ppcls INFO:             use_shared_memory : True
[2022/06/06 15:57:16] ppcls INFO:         sampler : 
[2022/06/06 15:57:16] ppcls INFO:             batch_size : 256
[2022/06/06 15:57:16] ppcls INFO:             drop_last : False
[2022/06/06 15:57:16] ppcls INFO:             name : DistributedBatchSampler
[2022/06/06 15:57:16] ppcls INFO:             shuffle : True
[2022/06/06 15:57:16] ppcls INFO: Global : 
[2022/06/06 15:57:16] ppcls INFO:     checkpoints : None
[2022/06/06 15:57:16] ppcls INFO:     device : gpu
[2022/06/06 15:57:16] ppcls INFO:     epochs : 8
[2022/06/06 15:57:16] ppcls INFO:     eval_during_train : False
[2022/06/06 15:57:16] ppcls INFO:     eval_interval : 1
[2022/06/06 15:57:16] ppcls INFO:     image_channel : 4
[2022/06/06 15:57:16] ppcls INFO:     image_shape : [4, 224, 224]
[2022/06/06 15:57:16] ppcls INFO:     output_dir : ./output/
[2022/06/06 15:57:16] ppcls INFO:     pretrained_model : None
[2022/06/06 15:57:16] ppcls INFO:     print_batch_step : 10
[2022/06/06 15:57:16] ppcls INFO:     save_inference_dir : ./inference
[2022/06/06 15:57:16] ppcls INFO:     save_interval : 1
[2022/06/06 15:57:16] ppcls INFO:     to_static : False
[2022/06/06 15:57:16] ppcls INFO:     use_dali : True
[2022/06/06 15:57:16] ppcls INFO:     use_visualdl : False
[2022/06/06 15:57:16] ppcls INFO: Infer : 
[2022/06/06 15:57:16] ppcls INFO:     PostProcess : 
[2022/06/06 15:57:16] ppcls INFO:         class_id_map_file : ppcls/utils/imagenet1k_label_list.txt
[2022/06/06 15:57:16] ppcls INFO:         name : Topk
[2022/06/06 15:57:16] ppcls INFO:         topk : 5
[2022/06/06 15:57:16] ppcls INFO:     batch_size : 10
[2022/06/06 15:57:16] ppcls INFO:     infer_imgs : docs/images/inference_deployment/whl_demo.jpg
[2022/06/06 15:57:16] ppcls INFO:     transforms : 
[2022/06/06 15:57:16] ppcls INFO:         DecodeImage : 
[2022/06/06 15:57:16] ppcls INFO:             channel_first : False
[2022/06/06 15:57:16] ppcls INFO:             to_rgb : True
[2022/06/06 15:57:16] ppcls INFO:         ResizeImage : 
[2022/06/06 15:57:16] ppcls INFO:             resize_short : 256
[2022/06/06 15:57:16] ppcls INFO:         CropImage : 
[2022/06/06 15:57:16] ppcls INFO:             size : 224
[2022/06/06 15:57:16] ppcls INFO:         NormalizeImage : 
[2022/06/06 15:57:16] ppcls INFO:             channel_num : 4
[2022/06/06 15:57:16] ppcls INFO:             mean : [0.485, 0.456, 0.406]
[2022/06/06 15:57:16] ppcls INFO:             order : 
[2022/06/06 15:57:16] ppcls INFO:             scale : 1.0/255.0
[2022/06/06 15:57:16] ppcls INFO:             std : [0.229, 0.224, 0.225]
[2022/06/06 15:57:16] ppcls INFO:         ToCHWImage : None
[2022/06/06 15:57:16] ppcls INFO: Loss : 
[2022/06/06 15:57:16] ppcls INFO:     Eval : 
[2022/06/06 15:57:16] ppcls INFO:         CELoss : 
[2022/06/06 15:57:16] ppcls INFO:             weight : 1.0
[2022/06/06 15:57:16] ppcls INFO:     Train : 
[2022/06/06 15:57:16] ppcls INFO:         CELoss : 
[2022/06/06 15:57:16] ppcls INFO:             weight : 1.0
[2022/06/06 15:57:16] ppcls INFO: Metric : 
[2022/06/06 15:57:16] ppcls INFO:     Eval : 
[2022/06/06 15:57:16] ppcls INFO:         TopkAcc : 
[2022/06/06 15:57:16] ppcls INFO:             topk : [1, 5]
[2022/06/06 15:57:16] ppcls INFO:     Train : 
[2022/06/06 15:57:16] ppcls INFO:         TopkAcc : 
[2022/06/06 15:57:16] ppcls INFO:             topk : [1, 5]
[2022/06/06 15:57:16] ppcls INFO: Optimizer : 
[2022/06/06 15:57:16] ppcls INFO:     lr : 
[2022/06/06 15:57:16] ppcls INFO:         decay_epochs : [30, 60, 90]
[2022/06/06 15:57:16] ppcls INFO:         learning_rate : 0.1
[2022/06/06 15:57:16] ppcls INFO:         name : Piecewise
[2022/06/06 15:57:16] ppcls INFO:         values : [0.1, 0.01, 0.001, 0.0001]
[2022/06/06 15:57:16] ppcls INFO:     momentum : 0.9
[2022/06/06 15:57:16] ppcls INFO:     multi_precision : True
[2022/06/06 15:57:16] ppcls INFO:     name : Momentum
[2022/06/06 15:57:16] ppcls INFO:     regularizer : 
[2022/06/06 15:57:16] ppcls INFO:         coeff : 0.0001
[2022/06/06 15:57:16] ppcls INFO:         name : L2
[2022/06/06 15:57:16] ppcls INFO: enable_addto : True
[2022/06/06 15:57:16] ppcls INFO: fuse_elewise_add_act_ops : True
W0606 15:57:20.564185  7312 gpu_context.cc:278] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0606 15:57:20.568419  7312 gpu_context.cc:306] device: 0, cuDNN Version: 8.1.
server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:45577', '127.0.0.1:57833', '127.0.0.1:50313', '127.0.0.1:48398', '127.0.0.1:34775', '127.0.0.1:35487']
[2022/06/06 15:57:26] ppcls WARNING: Only support FP16 evaluation when AMP O2 is enabled.
W0606 15:57:28.243492  7312 build_strategy.cc:123] Currently, fuse_broadcast_ops only works under Reduce mode.
I0606 15:57:28.308193  7312 fuse_pass_base.cc:57] ---  detected 33 subgraphs
I0606 15:57:28.432545  7312 fuse_pass_base.cc:57] ---  detected 33 subgraphs
I0606 15:57:28.471655  7312 fuse_pass_base.cc:57] ---  detected 16 subgraphs
I0606 15:57:28.499672  7312 fuse_pass_base.cc:57] ---  detected 16 subgraphs
W0606 15:57:28.542165  7312 fuse_all_reduce_op_pass.cc:76] Find all_reduce operators: 161. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 10.
[2022/06/06 15:57:43] ppcls INFO: epoch:0   train step:10   lr: 0.100000, loss:  7.3520 top1:  0.0000 top5:  0.0000 batch_cost: 0.19050 s, reader_cost: 0.00093 s, ips: 1343.80244 samples/sec.
[2022/06/06 15:57:45] ppcls INFO: epoch:0   train step:20   lr: 0.100000, loss:  7.1833 top1:  0.0039 top5:  0.0078 batch_cost: 0.19006 s, reader_cost: 0.00112 s, ips: 1346.94504 samples/sec.
[2022/06/06 15:57:46] ppcls INFO: END epoch:0   train  loss:  7.1801 top1:  0.0016 top5:  0.0052 batch_cost: 0.18969 s, reader_cost: 0.00107 s, batch_cost_sum: 3.98342 s,
[2022/06/06 15:57:47] ppcls INFO: Already save model in ./output/ResNet50/0
[2022/06/06 15:57:48] ppcls INFO: epoch:1   train step:10   lr: 0.100000, loss:  7.2268 top1:  0.0000 top5:  0.0039 batch_cost: 0.19055 s, reader_cost: 0.00090 s, ips: 1343.45384 samples/sec.
[2022/06/06 15:57:50] ppcls INFO: epoch:1   train step:20   lr: 0.100000, loss:  7.5525 top1:  0.0000 top5:  0.0078 batch_cost: 0.19122 s, reader_cost: 0.00097 s, ips: 1338.79411 samples/sec.
[2022/06/06 15:57:51] ppcls INFO: END epoch:1   train  loss:  7.1619 top1:  0.0011 top5:  0.0049 batch_cost: 0.19100 s, reader_cost: 0.00097 s, batch_cost_sum: 3.82000 s,
[2022/06/06 15:57:52] ppcls INFO: Already save model in ./output/ResNet50/1
[2022/06/06 15:57:54] ppcls INFO: epoch:2   train step:10   lr: 0.100000, loss:  6.9405 top1:  0.0039 top5:  0.0039 batch_cost: 0.19019 s, reader_cost: 0.00091 s, ips: 1346.01398 samples/sec.
[2022/06/06 15:57:56] ppcls INFO: epoch:2   train step:20   lr: 0.100000, loss:  6.9234 top1:  0.0078 top5:  0.0078 batch_cost: 0.19021 s, reader_cost: 0.00109 s, ips: 1345.87908 samples/sec.
[2022/06/06 15:57:57] ppcls INFO: END epoch:2   train  loss:  6.9430 top1:  0.0013 top5:  0.0059 batch_cost: 0.18983 s, reader_cost: 0.00106 s, batch_cost_sum: 3.98647 s,
[2022/06/06 15:57:58] ppcls INFO: Already save model in ./output/ResNet50/2
[2022/06/06 15:58:00] ppcls INFO: epoch:3   train step:10   lr: 0.100000, loss:  6.8919 top1:  0.0000 top5:  0.0195 batch_cost: 0.18945 s, reader_cost: 0.00097 s, ips: 1351.26198 samples/sec.
[2022/06/06 15:58:02] ppcls INFO: epoch:3   train step:20   lr: 0.100000, loss:  6.8178 top1:  0.0039 top5:  0.0156 batch_cost: 0.19178 s, reader_cost: 0.00317 s, ips: 1334.88339 samples/sec.
[2022/06/06 15:58:03] ppcls INFO: END epoch:3   train  loss:  6.8624 top1:  0.0033 top5:  0.0124 batch_cost: 0.19123 s, reader_cost: 0.00271 s, batch_cost_sum: 3.82464 s,
[2022/06/06 15:58:04] ppcls INFO: Already save model in ./output/ResNet50/3
[2022/06/06 15:58:06] ppcls INFO: epoch:4   train step:10   lr: 0.100000, loss:  6.6996 top1:  0.0039 top5:  0.0312 batch_cost: 0.18853 s, reader_cost: 0.00083 s, ips: 1357.84826 samples/sec.
[2022/06/06 15:58:08] ppcls INFO: epoch:4   train step:20   lr: 0.100000, loss:  6.5672 top1:  0.0039 top5:  0.0234 batch_cost: 0.18939 s, reader_cost: 0.00088 s, ips: 1351.69799 samples/sec.
[2022/06/06 15:58:08] ppcls INFO: END epoch:4   train  loss:  6.6995 top1:  0.0052 top5:  0.0217 batch_cost: 0.18962 s, reader_cost: 0.00090 s, batch_cost_sum: 3.98202 s,
[2022/06/06 15:58:10] ppcls INFO: Already save model in ./output/ResNet50/4
[2022/06/06 15:58:12] ppcls INFO: epoch:5   train step:10   lr: 0.100000, loss:  6.5489 top1:  0.0039 top5:  0.0195 batch_cost: 0.18856 s, reader_cost: 0.00094 s, ips: 1357.63909 samples/sec.
[2022/06/06 15:58:13] ppcls INFO: epoch:5   train step:20   lr: 0.100000, loss:  6.6024 top1:  0.0078 top5:  0.0234 batch_cost: 0.19140 s, reader_cost: 0.00357 s, ips: 1337.49000 samples/sec.
[2022/06/06 15:58:14] ppcls INFO: END epoch:5   train  loss:  6.5562 top1:  0.0067 top5:  0.0270 batch_cost: 0.19096 s, reader_cost: 0.00303 s, batch_cost_sum: 3.81930 s,
[2022/06/06 15:58:15] ppcls INFO: Already save model in ./output/ResNet50/5
[2022/06/06 15:58:17] ppcls INFO: epoch:6   train step:10   lr: 0.100000, loss:  6.3516 top1:  0.0117 top5:  0.0430 batch_cost: 0.19054 s, reader_cost: 0.00088 s, ips: 1343.55302 samples/sec.
[2022/06/06 15:58:19] ppcls INFO: epoch:6   train step:20   lr: 0.100000, loss:  6.3752 top1:  0.0039 top5:  0.0234 batch_cost: 0.18962 s, reader_cost: 0.00092 s, ips: 1350.10249 samples/sec.
[2022/06/06 15:58:20] ppcls INFO: END epoch:6   train  loss:  6.3920 top1:  0.0083 top5:  0.0397 batch_cost: 0.18949 s, reader_cost: 0.00090 s, batch_cost_sum: 3.78982 s,
[2022/06/06 15:58:21] ppcls INFO: Already save model in ./output/ResNet50/6
[2022/06/06 15:58:23] ppcls INFO: epoch:7   train step:10   lr: 0.100000, loss:  6.3318 top1:  0.0195 top5:  0.0547 batch_cost: 0.19820 s, reader_cost: 0.00093 s, ips: 1291.61331 samples/sec.
[2022/06/06 15:58:25] ppcls INFO: epoch:7   train step:20   lr: 0.100000, loss:  6.1608 top1:  0.0312 top5:  0.0781 batch_cost: 0.19586 s, reader_cost: 0.00380 s, ips: 1307.02594 samples/sec.
[2022/06/06 15:58:26] ppcls INFO: END epoch:7   train  loss:  6.2336 top1:  0.0184 top5:  0.0605 batch_cost: 0.19515 s, reader_cost: 0.00313 s, batch_cost_sum: 4.09807 s,
INFO 2022-06-06 15:58:34,603 launch.py:402] Local processes completed.
INFO 2022-06-06 15:58:34,603 launch.py:402] Local processes completed.
[2022/06/06 15:58:27] ppcls INFO: Already save model in ./output/ResNet50/7
