A new filed (is_distributed) detected!
[2021/12/21 17:26:58] root INFO: 
===========================================================
==        PaddleClas is powered by PaddlePaddle !        ==
===========================================================
==                                                       ==
==   For more info please go to the following website.   ==
==                                                       ==
==       https://github.com/PaddlePaddle/PaddleClas      ==
===========================================================

[2021/12/21 17:26:58] root INFO: AMP : 
[2021/12/21 17:26:58] root INFO:     scale_loss : 128.0
[2021/12/21 17:26:58] root INFO:     use_dynamic_loss_scaling : True
[2021/12/21 17:26:58] root INFO:     use_pure_fp16 : False
[2021/12/21 17:26:58] root INFO: ------------------------------------------------------------
[2021/12/21 17:26:58] root INFO: Arch : 
[2021/12/21 17:26:58] root INFO:     class_num : 1000
[2021/12/21 17:26:58] root INFO:     data_format : NHWC
[2021/12/21 17:26:58] root INFO:     input_image_channel : 4
[2021/12/21 17:26:58] root INFO:     name : ResNet50
[2021/12/21 17:26:58] root INFO: DataLoader : 
[2021/12/21 17:26:58] root INFO:     Eval : 
[2021/12/21 17:26:58] root INFO:         dataset : 
[2021/12/21 17:26:58] root INFO:             cls_label_path : ./dataset/ILSVRC2012/val_list.txt
[2021/12/21 17:26:58] root INFO:             image_root : ./dataset/ILSVRC2012/
[2021/12/21 17:26:58] root INFO:             name : ImageNetDataset
[2021/12/21 17:26:58] root INFO:             transform_ops : 
[2021/12/21 17:26:58] root INFO:                 DecodeImage : 
[2021/12/21 17:26:58] root INFO:                     channel_first : False
[2021/12/21 17:26:58] root INFO:                     to_rgb : True
[2021/12/21 17:26:58] root INFO:                 ResizeImage : 
[2021/12/21 17:26:58] root INFO:                     resize_short : 256
[2021/12/21 17:26:58] root INFO:                 CropImage : 
[2021/12/21 17:26:58] root INFO:                     size : 224
[2021/12/21 17:26:58] root INFO:                 NormalizeImage : 
[2021/12/21 17:26:58] root INFO:                     channel_num : 4
[2021/12/21 17:26:58] root INFO:                     mean : [0.485, 0.456, 0.406]
[2021/12/21 17:26:58] root INFO:                     order : 
[2021/12/21 17:26:58] root INFO:                     output_fp16 : False
[2021/12/21 17:26:58] root INFO:                     scale : 1.0/255.0
[2021/12/21 17:26:58] root INFO:                     std : [0.229, 0.224, 0.225]
[2021/12/21 17:26:58] root INFO:         loader : 
[2021/12/21 17:26:58] root INFO:             num_workers : 4
[2021/12/21 17:26:58] root INFO:             use_shared_memory : True
[2021/12/21 17:26:58] root INFO:         sampler : 
[2021/12/21 17:26:58] root INFO:             batch_size : 64
[2021/12/21 17:26:58] root INFO:             drop_last : False
[2021/12/21 17:26:58] root INFO:             name : DistributedBatchSampler
[2021/12/21 17:26:58] root INFO:             shuffle : False
[2021/12/21 17:26:58] root INFO:     Train : 
[2021/12/21 17:26:58] root INFO:         dataset : 
[2021/12/21 17:26:58] root INFO:             cls_label_path : ./dataset/imagenet100_data/train_list.txt
[2021/12/21 17:26:58] root INFO:             image_root : ./dataset/imagenet100_data
[2021/12/21 17:26:58] root INFO:             name : ImageNetDataset
[2021/12/21 17:26:58] root INFO:             transform_ops : 
[2021/12/21 17:26:58] root INFO:                 DecodeImage : 
[2021/12/21 17:26:58] root INFO:                     channel_first : False
[2021/12/21 17:26:58] root INFO:                     to_rgb : True
[2021/12/21 17:26:58] root INFO:                 RandCropImage : 
[2021/12/21 17:26:58] root INFO:                     size : 224
[2021/12/21 17:26:58] root INFO:                 RandFlipImage : 
[2021/12/21 17:26:58] root INFO:                     flip_code : 1
[2021/12/21 17:26:58] root INFO:                 NormalizeImage : 
[2021/12/21 17:26:58] root INFO:                     channel_num : 4
[2021/12/21 17:26:58] root INFO:                     mean : [0.485, 0.456, 0.406]
[2021/12/21 17:26:58] root INFO:                     order : 
[2021/12/21 17:26:58] root INFO:                     output_fp16 : False
[2021/12/21 17:26:58] root INFO:                     scale : 1.0/255.0
[2021/12/21 17:26:58] root INFO:                     std : [0.229, 0.224, 0.225]
[2021/12/21 17:26:58] root INFO:         loader : 
[2021/12/21 17:26:58] root INFO:             num_workers : 8
[2021/12/21 17:26:58] root INFO:             use_shared_memory : True
[2021/12/21 17:26:58] root INFO:         sampler : 
[2021/12/21 17:26:58] root INFO:             batch_size : 128
[2021/12/21 17:26:58] root INFO:             drop_last : False
[2021/12/21 17:26:58] root INFO:             name : DistributedBatchSampler
[2021/12/21 17:26:58] root INFO:             shuffle : True
[2021/12/21 17:26:58] root INFO: Global : 
[2021/12/21 17:26:58] root INFO:     checkpoints : None
[2021/12/21 17:26:58] root INFO:     device : gpu
[2021/12/21 17:26:58] root INFO:     epochs : 1
[2021/12/21 17:26:58] root INFO:     eval_during_train : False
[2021/12/21 17:26:58] root INFO:     eval_interval : 1
[2021/12/21 17:26:58] root INFO:     image_channel : 4
[2021/12/21 17:26:58] root INFO:     image_shape : [4, 224, 224]
[2021/12/21 17:26:58] root INFO:     is_distributed : True
[2021/12/21 17:26:58] root INFO:     output_dir : ./output/
[2021/12/21 17:26:58] root INFO:     pretrained_model : None
[2021/12/21 17:26:58] root INFO:     print_batch_step : 10
[2021/12/21 17:26:58] root INFO:     save_inference_dir : ./inference
[2021/12/21 17:26:58] root INFO:     save_interval : 1
[2021/12/21 17:26:58] root INFO:     to_static : False
[2021/12/21 17:26:58] root INFO:     use_dali : True
[2021/12/21 17:26:58] root INFO:     use_visualdl : False
[2021/12/21 17:26:58] root INFO: Infer : 
[2021/12/21 17:26:58] root INFO:     PostProcess : 
[2021/12/21 17:26:58] root INFO:         class_id_map_file : ppcls/utils/imagenet1k_label_list.txt
[2021/12/21 17:26:58] root INFO:         name : Topk
[2021/12/21 17:26:58] root INFO:         topk : 5
[2021/12/21 17:26:58] root INFO:     batch_size : 10
[2021/12/21 17:26:58] root INFO:     infer_imgs : docs/images/whl/demo.jpg
[2021/12/21 17:26:58] root INFO:     transforms : 
[2021/12/21 17:26:58] root INFO:         DecodeImage : 
[2021/12/21 17:26:58] root INFO:             channel_first : False
[2021/12/21 17:26:58] root INFO:             to_rgb : True
[2021/12/21 17:26:58] root INFO:         ResizeImage : 
[2021/12/21 17:26:58] root INFO:             resize_short : 256
[2021/12/21 17:26:58] root INFO:         CropImage : 
[2021/12/21 17:26:58] root INFO:             size : 224
[2021/12/21 17:26:58] root INFO:         NormalizeImage : 
[2021/12/21 17:26:58] root INFO:             channel_num : 4
[2021/12/21 17:26:58] root INFO:             mean : [0.485, 0.456, 0.406]
[2021/12/21 17:26:58] root INFO:             order : 
[2021/12/21 17:26:58] root INFO:             output_fp16 : False
[2021/12/21 17:26:58] root INFO:             scale : 1.0/255.0
[2021/12/21 17:26:58] root INFO:             std : [0.229, 0.224, 0.225]
[2021/12/21 17:26:58] root INFO:         ToCHWImage : None
[2021/12/21 17:26:58] root INFO: Loss : 
[2021/12/21 17:26:58] root INFO:     Eval : 
[2021/12/21 17:26:58] root INFO:         CELoss : 
[2021/12/21 17:26:58] root INFO:             weight : 1.0
[2021/12/21 17:26:58] root INFO:     Train : 
[2021/12/21 17:26:58] root INFO:         CELoss : 
[2021/12/21 17:26:58] root INFO:             weight : 1.0
[2021/12/21 17:26:58] root INFO: Metric : 
[2021/12/21 17:26:58] root INFO:     Eval : 
[2021/12/21 17:26:58] root INFO:         TopkAcc : 
[2021/12/21 17:26:58] root INFO:             topk : [1, 5]
[2021/12/21 17:26:58] root INFO:     Train : 
[2021/12/21 17:26:58] root INFO:         TopkAcc : 
[2021/12/21 17:26:58] root INFO:             topk : [1, 5]
[2021/12/21 17:26:58] root INFO: Optimizer : 
[2021/12/21 17:26:58] root INFO:     lr : 
[2021/12/21 17:26:58] root INFO:         decay_epochs : [30, 60, 90]
[2021/12/21 17:26:58] root INFO:         learning_rate : 0.1
[2021/12/21 17:26:58] root INFO:         name : Piecewise
[2021/12/21 17:26:58] root INFO:         values : [0.1, 0.01, 0.001, 0.0001]
[2021/12/21 17:26:58] root INFO:     momentum : 0.9
[2021/12/21 17:26:58] root INFO:     multi_precision : True
[2021/12/21 17:26:58] root INFO:     name : Momentum
[2021/12/21 17:26:58] root INFO:     regularizer : 
[2021/12/21 17:26:58] root INFO:         coeff : 0.0001
[2021/12/21 17:26:58] root INFO:         name : L2
/usr/local/lib/python3.7/site-packages/nvidia/dali/plugin/base_iterator.py:202: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  self._shards_id = np.array([meta["shard_id"] for meta in readers_meta], dtype=np.int)
/usr/local/lib/python3.7/site-packages/nvidia/dali/plugin/base_iterator.py:216: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  self._counter_per_gpu = np.zeros(self._shards_num, dtype=np.long)
/usr/local/lib/python3.7/site-packages/nvidia/dali/plugin/base_iterator.py:175: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  shards_beg = np.floor(shard_nums * self._size_no_pad / self._shards_num).astype(np.int)
/usr/local/lib/python3.7/site-packages/nvidia/dali/plugin/base_iterator.py:176: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  shards_end = np.floor((shard_nums + 1) * self._size_no_pad / self._shards_num).astype(np.int)
W1221 17:27:02.422268 28073 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W1221 17:27:02.427273 28073 device_context.cc:465] device: 0, cuDNN Version: 8.1.
/usr/local/lib/python3.7/site-packages/paddle/distributed/fleet/base/fleet_base.py:865: UserWarning: It is recommended to use DistributedStrategy in fleet.init(). The strategy here is only for compatibility. If the strategy in fleet.distributed_optimizer() is not None, then it will overwrite the DistributedStrategy in fleet.init(), which will take effect in distributed training.
  "It is recommended to use DistributedStrategy "
/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py:744: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  elif dtype == np.bool:
server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:37254', '127.0.0.1:52752', '127.0.0.1:43316', '127.0.0.1:53301', '127.0.0.1:46809', '127.0.0.1:43930', '127.0.0.1:36187']
W1221 17:27:09.603116 28073 build_strategy.cc:110] Currently, fuse_broadcast_ops only works under Reduce mode.
I1221 17:27:09.653863 28073 fuse_pass_base.cc:57] ---  detected 33 subgraphs
I1221 17:27:09.771126 28073 fuse_pass_base.cc:57] ---  detected 33 subgraphs
I1221 17:27:09.808224 28073 fuse_pass_base.cc:57] ---  detected 16 subgraphs
I1221 17:27:09.834734 28073 fuse_pass_base.cc:57] ---  detected 16 subgraphs
W1221 17:27:09.881001 28073 fuse_all_reduce_op_pass.cc:76] Find all_reduce operators: 161. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 10.
[2021/12/21 17:27:18] root INFO: epoch:0   train step:10   lr: 0.100000, loss:  7.6678 top1:  0.0234 top5:  0.0859 batch_cost: 0.10525 s, reader_cost: 0.00095 s, ips: 1216.16303 images/sec.
[2021/12/21 17:27:19] root INFO: epoch:0   train step:20   lr: 0.100000, loss:  6.9123 top1:  0.0312 top5:  0.0703 batch_cost: 0.10457 s, reader_cost: 0.00087 s, ips: 1224.11258 images/sec.
[2021/12/21 17:27:20] root INFO: epoch:0   train step:30   lr: 0.100000, loss:  5.4743 top1:  0.0156 top5:  0.0625 batch_cost: 0.10455 s, reader_cost: 0.00085 s, ips: 1224.34072 images/sec.
[2021/12/21 17:27:21] root INFO: epoch:0   train step:40   lr: 0.100000, loss:  4.9734 top1:  0.0156 top5:  0.1094 batch_cost: 0.10418 s, reader_cost: 0.00085 s, ips: 1228.65088 images/sec.
[2021/12/21 17:27:22] root INFO: epoch:0   train step:50   lr: 0.100000, loss:  4.6381 top1:  0.0078 top5:  0.1016 batch_cost: 0.10383 s, reader_cost: 0.00084 s, ips: 1232.82909 images/sec.
[2021/12/21 17:27:23] root INFO: epoch:0   train step:60   lr: 0.100000, loss:  4.4982 top1:  0.0312 top5:  0.1328 batch_cost: 0.10355 s, reader_cost: 0.00083 s, ips: 1236.15594 images/sec.
[2021/12/21 17:27:24] root INFO: epoch:0   train step:70   lr: 0.100000, loss:  4.4125 top1:  0.0156 top5:  0.0859 batch_cost: 0.10340 s, reader_cost: 0.00083 s, ips: 1237.95554 images/sec.
[2021/12/21 17:27:25] root INFO: epoch:0   train step:80   lr: 0.100000, loss:  4.1628 top1:  0.0391 top5:  0.1172 batch_cost: 0.10322 s, reader_cost: 0.00084 s, ips: 1240.08730 images/sec.
[2021/12/21 17:27:25] root INFO: END epoch:0   train  loss:  5.7283 top1:  0.0192 top5:  0.0927 batch_cost: 0.10316 s, reader_cost: 0.00083 s, batch_cost_sum: 8.25273 s, ips: 1240.80183 images/sec.
[2021/12/21 17:27:26] root INFO: Already save model in ./output/ResNet50/0
