[1,0]<stdout>:DLL 2022-06-07 09:37:04.001204 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float16  amp : False  batch_size : 256  num_epochs : 3  run_epochs : -1  lr : 0.256  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-1,256  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[09:37:04] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[[1,0]<stderr>:09:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2022-06-07 09:37:10,204:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2022-06-07 09:37:10,205:INFO: Starting epoch 0
[1,0]<stderr>:[09:37:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2022-06-07 09:37:26.831565 - Epoch: 0 Iteration: 19  train.loss : 7.105642032623291  train.ips : 307.93005261464145  train.lr : 0.0077824 
[1,0]<stdout>:DLL 2022-06-07 09:37:30.564238 - Epoch: 0 Iteration: 39  train.loss : 7.000428986549378  train.ips : 1371.9108759022897  train.lr : 0.0159744 
[1,0]<stdout>:DLL 2022-06-07 09:37:34.304378 - Epoch: 0 Iteration: 59  train.loss : 6.921148633956909  train.ips : 1369.2032120253618  train.lr : 0.024166399999999998 
[1,0]<stdout>:DLL 2022-06-07 09:37:38.049807 - Epoch: 0 Iteration: 79  train.loss : 6.876346778869629  train.ips : 1367.0873198263866  train.lr : 0.032358399999999995 
[1,0]<stdout>:DLL 2022-06-07 09:37:41.795787 - Epoch: 0 Iteration: 99  train.loss : 6.847845101356507  train.ips : 1366.8863130196673  train.lr : 0.0405504 
[1,0]<stdout>:DLL 2022-06-07 09:37:45.541347 - Epoch: 0 Iteration: 119  train.loss : 6.818706083297729  train.ips : 1367.031275622085  train.lr : 0.0487424 
[1,0]<stdout>:DLL 2022-06-07 09:37:49.289184 - Epoch: 0 Iteration: 139  train.loss : 6.785588598251342  train.ips : 1366.1801255572038  train.lr : 0.05693440000000001 
[1,0]<stdout>:DLL 2022-06-07 09:37:53.037117 - Epoch: 0 Iteration: 159  train.loss : 6.775366616249085  train.ips : 1366.166741045655  train.lr : 0.0651264 
[1,0]<stdout>:DLL 2022-06-07 09:37:56.792855 - Epoch: 0 Iteration: 179  train.loss : 6.757474279403686  train.ips : 1363.3366049428646  train.lr : 0.07331839999999999 
[1,0]<stdout>:DLL 2022-06-07 09:38:00.539826 - Epoch: 0 Iteration: 199  train.loss : 6.7118343114852905  train.ips : 1366.536475952084  train.lr : 0.08151040000000001 
[1,0]<stdout>:DLL 2022-06-07 09:38:04.291454 - Epoch: 0 Iteration: 219  train.loss : 6.684133410453796  train.ips : 1364.8348175031945  train.lr : 0.0897024 
[1,0]<stdout>:DLL 2022-06-07 09:38:08.039928 - Epoch: 0 Iteration: 239  train.loss : 6.686648845672607  train.ips : 1366.003366850233  train.lr : 0.09789439999999999 
[1,0]<stdout>:DLL 2022-06-07 09:38:11.792890 - Epoch: 0 Iteration: 259  train.loss : 6.680848336219787  train.ips : 1364.3468937634864  train.lr : 0.1060864 
[1,0]<stdout>:DLL 2022-06-07 09:38:15.544300 - Epoch: 0 Iteration: 279  train.loss : 6.640470027923584  train.ips : 1364.8833081031912  train.lr : 0.1142784 
[1,0]<stdout>:DLL 2022-06-07 09:38:19.306749 - Epoch: 0 Iteration: 299  train.loss : 6.6081619501113895  train.ips : 1360.8884758769511  train.lr : 0.12247040000000001 
[1,0]<stdout>:DLL 2022-06-07 09:38:23.062345 - Epoch: 0 Iteration: 319  train.loss : 6.597920894622803  train.ips : 1363.4153716714477  train.lr : 0.1306624 
[1,0]<stdout>:DLL 2022-06-07 09:38:26.812336 - Epoch: 0 Iteration: 339  train.loss : 6.557349443435669  train.ips : 1365.4475790032684  train.lr : 0.13885440000000002 
[1,0]<stdout>:DLL 2022-06-07 09:38:30.567005 - Epoch: 0 Iteration: 359  train.loss : 6.5686849594116214  train.ips : 1363.803279071649  train.lr : 0.1470464 
[1,0]<stdout>:DLL 2022-06-07 09:38:34.330620 - Epoch: 0 Iteration: 379  train.loss : 6.5385452032089235  train.ips : 1360.6835974378528  train.lr : 0.1552384 
[1,0]<stdout>:DLL 2022-06-07 09:38:38.086084 - Epoch: 0 Iteration: 399  train.loss : 6.526641917228699  train.ips : 1363.4465346480592  train.lr : 0.16343040000000003 
[1,0]<stdout>:DLL 2022-06-07 09:38:41.845601 - Epoch: 0 Iteration: 419  train.loss : 6.490296721458435  train.ips : 1361.9763299078706  train.lr : 0.1716224 
[1,0]<stdout>:DLL 2022-06-07 09:38:45.604055 - Epoch: 0 Iteration: 439  train.loss : 6.471405625343323  train.ips : 1362.3387007243573  train.lr : 0.17981439999999999 
[1,0]<stdout>:DLL 2022-06-07 09:38:49.361578 - Epoch: 0 Iteration: 459  train.loss : 6.443807172775268  train.ips : 1362.6838839305572  train.lr : 0.18800640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:38:53.122642 - Epoch: 0 Iteration: 479  train.loss : 6.444887661933899  train.ips : 1361.3899811965096  train.lr : 0.1961984 
[1,0]<stderr>:2022-06-07 09:38:56,880:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-06-07 09:38:56.879818 - Epoch: 0 Iteration: 499  train.loss : 6.438892674446106  train.ips : 1362.809707924334  train.lr : 0.2043904 
[1,0]<stdout>:DLL 2022-06-07 09:38:56.880269 - Epoch: 0  train.loss : 6.6791630506515505  train.ips : 1364.2205257831702 
[1,0]<stdout>:DLL 2022-06-07 09:39:00.644747 - Epoch: 1 Iteration: 19  train.loss : 6.388564586639404  train.ips : 1360.1277358093103  train.lr : 0.058982400000000004 
[1,0]<stdout>:DLL 2022-06-07 09:39:04.404089 - Epoch: 1 Iteration: 39  train.loss : 6.296165657043457  train.ips : 1362.0279866377537  train.lr : 0.0671744 
[1,0]<stdout>:DLL 2022-06-07 09:39:08.167219 - Epoch: 1 Iteration: 59  train.loss : 6.274930810928344  train.ips : 1360.6348013179281  train.lr : 0.0753664 
[1,0]<stdout>:DLL 2022-06-07 09:39:11.930028 - Epoch: 1 Iteration: 79  train.loss : 6.272459030151367  train.ips : 1360.7574017528843  train.lr : 0.0835584 
[1,0]<stdout>:DLL 2022-06-07 09:39:15.696304 - Epoch: 1 Iteration: 99  train.loss : 6.271387338638306  train.ips : 1359.5153491876083  train.lr : 0.0917504 
[1,0]<stdout>:DLL 2022-06-07 09:39:19.462419 - Epoch: 1 Iteration: 119  train.loss : 6.233328008651734  train.ips : 1359.5479694909416  train.lr : 0.0999424 
[1,0]<stdout>:DLL 2022-06-07 09:39:23.231938 - Epoch: 1 Iteration: 139  train.loss : 6.233536505699158  train.ips : 1358.3582128259595  train.lr : 0.1081344 
[1,0]<stdout>:DLL 2022-06-07 09:39:26.997660 - Epoch: 1 Iteration: 159  train.loss : 6.232609105110169  train.ips : 1359.7197898512527  train.lr : 0.11632640000000001 
[1,0]<stdout>:DLL 2022-06-07 09:39:30.766487 - Epoch: 1 Iteration: 179  train.loss : 6.206891751289367  train.ips : 1358.5763150549494  train.lr : 0.1245184 
[1,0]<stdout>:DLL 2022-06-07 09:39:34.531113 - Epoch: 1 Iteration: 199  train.loss : 6.200773572921753  train.ips : 1360.1109377629396  train.lr : 0.1327104 
[1,0]<stdout>:DLL 2022-06-07 09:39:38.302822 - Epoch: 1 Iteration: 219  train.loss : 6.24239330291748  train.ips : 1357.5581594038913  train.lr : 0.14090239999999998 
[1,0]<stdout>:DLL 2022-06-07 09:39:42.064243 - Epoch: 1 Iteration: 239  train.loss : 6.2272422313690186  train.ips : 1361.253460605215  train.lr : 0.14909440000000002 
[1,0]<stdout>:DLL 2022-06-07 09:39:45.829223 - Epoch: 1 Iteration: 259  train.loss : 6.241890525817871  train.ips : 1359.9728649308363  train.lr : 0.1572864 
[1,0]<stdout>:DLL 2022-06-07 09:39:49.600660 - Epoch: 1 Iteration: 279  train.loss : 6.20811824798584  train.ips : 1357.6551425997623  train.lr : 0.1654784 
[1,0]<stdout>:DLL 2022-06-07 09:39:53.368755 - Epoch: 1 Iteration: 299  train.loss : 6.196884489059448  train.ips : 1358.8385085173722  train.lr : 0.1736704 
[1,0]<stdout>:DLL 2022-06-07 09:39:57.134748 - Epoch: 1 Iteration: 319  train.loss : 6.1998351335525514  train.ips : 1359.6035739327663  train.lr : 0.1818624 
[1,0]<stdout>:DLL 2022-06-07 09:40:00.912578 - Epoch: 1 Iteration: 339  train.loss : 6.1854695081710815  train.ips : 1355.3595065608104  train.lr : 0.1900544 
[1,0]<stdout>:DLL 2022-06-07 09:40:04.676600 - Epoch: 1 Iteration: 359  train.loss : 6.183704972267151  train.ips : 1360.3168501371697  train.lr : 0.1982464 
[1,0]<stdout>:DLL 2022-06-07 09:40:08.440930 - Epoch: 1 Iteration: 379  train.loss : 6.168203735351563  train.ips : 1360.2287912747072  train.lr : 0.2064384 
[1,0]<stdout>:DLL 2022-06-07 09:40:12.208639 - Epoch: 1 Iteration: 399  train.loss : 6.1749855279922485  train.ips : 1358.9802210709036  train.lr : 0.21463040000000003 
[1,0]<stdout>:DLL 2022-06-07 09:40:15.977204 - Epoch: 1 Iteration: 419  train.loss : 6.130462646484375  train.ips : 1358.6839310786747  train.lr : 0.22282240000000003 
[1,0]<stdout>:DLL 2022-06-07 09:40:19.747966 - Epoch: 1 Iteration: 439  train.loss : 6.1511242389678955  train.ips : 1357.8960298358745  train.lr : 0.2310144 
[1,0]<stdout>:DLL 2022-06-07 09:40:23.515674 - Epoch: 1 Iteration: 459  train.loss : 6.123205327987671  train.ips : 1359.0005172784547  train.lr : 0.23920640000000004 
[1,0]<stdout>:DLL 2022-06-07 09:40:27.288634 - Epoch: 1 Iteration: 479  train.loss : 6.080684661865234  train.ips : 1357.1008086802535  train.lr : 0.24739840000000002 
[1,0]<stderr>:2022-06-07 09:40:31,070:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-06-07 09:40:31.070026 - Epoch: 1 Iteration: 499  train.loss : 6.096847295761108  train.ips : 1354.0995339781314  train.lr : 0.2555904 
[1,0]<stdout>:DLL 2022-06-07 09:40:31.070561 - Epoch: 1  train.loss : 6.208867928504944  train.ips : 1360.8305524432344 
[1,0]<stdout>:DLL 2022-06-07 09:40:34.850482 - Epoch: 2 Iteration: 19  train.loss : 6.002778649330139  train.ips : 1354.576907690889  train.lr : 0.11018240000000001 
[1,0]<stdout>:DLL 2022-06-07 09:40:38.634463 - Epoch: 2 Iteration: 39  train.loss : 5.966304039955139  train.ips : 1353.173676737296  train.lr : 0.11837439999999999 
[1,0]<stdout>:DLL 2022-06-07 09:40:42.407617 - Epoch: 2 Iteration: 59  train.loss : 5.9883334875106815  train.ips : 1357.0473811250617  train.lr : 0.12656640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:40:46.182821 - Epoch: 2 Iteration: 79  train.loss : 5.964422178268433  train.ips : 1356.295296818407  train.lr : 0.1347584 
[1,0]<stdout>:DLL 2022-06-07 09:40:49.960085 - Epoch: 2 Iteration: 99  train.loss : 5.919419980049133  train.ips : 1355.5797273165124  train.lr : 0.14295039999999998 
[1,0]<stdout>:DLL 2022-06-07 09:40:53.735570 - Epoch: 2 Iteration: 119  train.loss : 5.967057609558106  train.ips : 1356.2113551026018  train.lr : 0.1511424 
[1,0]<stdout>:DLL 2022-06-07 09:40:57.510733 - Epoch: 2 Iteration: 139  train.loss : 5.927665448188781  train.ips : 1356.3287050855988  train.lr : 0.15933440000000001 
[1,0]<stdout>:DLL 2022-06-07 09:41:01.293271 - Epoch: 2 Iteration: 159  train.loss : 5.968543219566345  train.ips : 1353.723697058599  train.lr : 0.16752640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:41:05.075104 - Epoch: 2 Iteration: 179  train.loss : 5.9374254703521725  train.ips : 1353.9123149901773  train.lr : 0.1757184 
[1,0]<stdout>:DLL 2022-06-07 09:41:08.858316 - Epoch: 2 Iteration: 199  train.loss : 5.957291007041931  train.ips : 1353.4334476255397  train.lr : 0.1839104 
[1,0]<stdout>:DLL 2022-06-07 09:41:12.636396 - Epoch: 2 Iteration: 219  train.loss : 5.926284146308899  train.ips : 1355.2572061104738  train.lr : 0.19210239999999998 
[1,0]<stdout>:DLL 2022-06-07 09:41:16.413560 - Epoch: 2 Iteration: 239  train.loss : 5.9371887922286986  train.ips : 1355.6024036796916  train.lr : 0.20029439999999998 
[1,0]<stdout>:DLL 2022-06-07 09:41:20.191717 - Epoch: 2 Iteration: 259  train.loss : 5.91323299407959  train.ips : 1355.2384755101336  train.lr : 0.20848640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:41:23.967438 - Epoch: 2 Iteration: 279  train.loss : 5.927096056938171  train.ips : 1356.1143211498927  train.lr : 0.21667840000000002 
[1,0]<stdout>:DLL 2022-06-07 09:41:27.748356 - Epoch: 2 Iteration: 299  train.loss : 5.92558867931366  train.ips : 1354.272029570085  train.lr : 0.22487039999999997 
[1,0]<stdout>:DLL 2022-06-07 09:41:31.533494 - Epoch: 2 Iteration: 319  train.loss : 5.908485841751099  train.ips : 1352.746627588002  train.lr : 0.23306239999999998 
[1,0]<stdout>:DLL 2022-06-07 09:41:35.314881 - Epoch: 2 Iteration: 339  train.loss : 5.908028864860535  train.ips : 1354.0730657715026  train.lr : 0.2412544 
[1,0]<stdout>:DLL 2022-06-07 09:41:39.096677 - Epoch: 2 Iteration: 359  train.loss : 5.8603877305984495  train.ips : 1353.9578984294978  train.lr : 0.24944639999999998 
[1,0]<stdout>:DLL 2022-06-07 09:41:42.879335 - Epoch: 2 Iteration: 379  train.loss : 5.9055379867553714  train.ips : 1353.650909713917  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:41:46.658425 - Epoch: 2 Iteration: 399  train.loss : 5.879492163658142  train.ips : 1354.9292816170187  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:41:50.438596 - Epoch: 2 Iteration: 419  train.loss : 5.904443740844727  train.ips : 1354.5447818122389  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:41:54.216224 - Epoch: 2 Iteration: 439  train.loss : 5.920543837547302  train.ips : 1355.413998973854  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:41:57.995514 - Epoch: 2 Iteration: 459  train.loss : 5.88010880947113  train.ips : 1354.8490989443578  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:42:01.780037 - Epoch: 2 Iteration: 479  train.loss : 5.882662224769592  train.ips : 1352.964039485556  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:42:05.556131 - Epoch: 2 Iteration: 499  train.loss : 5.8732164859771725  train.ips : 1355.9675547800857  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:42:05.556576 - Epoch: 2  train.loss : 5.926061577796936  train.ips : 1358.0593060998426 
[1,0]<stdout>:DLL 2022-06-07 09:42:05.672450 - Summary: train.loss : 5.926061577796936  train.ips : 1361.0367947754157 
[1,0]<stdout>:DLL 2022-06-07 09:42:12.690250 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 2048  num_epochs : 3  run_epochs : -1  lr : 2.048  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,256  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,4]<stderr>:[09:42:12] ../src/storage/storage.cc:[1,7]<stderr>:[09:42:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU[1,3]<stderr>:[09:42:12] ../src/storage/storage.cc:[1,4]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:
[1,1]<stderr>:[09:42:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:09:42:12] ../src/storage/storage.cc:199[1,6]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:[[1,2]<stderr>:09:42:12] ../src/storage/storage.cc:[1,2]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:[[1,5]<stderr>:09:42:12] ../src/storage/storage.cc:[1,5]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[[1,0]<stderr>:09:42:12] ../src/storage/storage.cc:199: [1,0]<stderr>:Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[09:42:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[09:42:16] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[[1,3]<stderr>:09:42:16] ../src/storage/storage.cc:199[1,3]<stderr>:: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[09:42:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:[09:42:16] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,5]<stderr>:GPU
[1,0]<stderr>:[09:42:16[1,0]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,0]<stderr>:GPU
[1,7]<stderr>:[[1,7]<stderr>:09:42:16] ../src/storage/storage.cc:199: Using [1,7]<stderr>:Pooled (Naive) StorageManager for GPU
[1,4]<stderr>:[09:42:16] [1,4]<stderr>:../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2022-06-07 09:42:20,815:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2022-06-07 09:42:20,815:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2022-06-07 09:42:20,960:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2022-06-07 09:42:20,960:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2022-06-07 09:42:21,189:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2022-06-07 09:42:21,190:INFO: Starting epoch 0
[1,0]<stderr>:[5f90c357778b:10223] Read -1, expected 7745, errno = 1
[1,0]<stderr>:[5f90c357778b:10223] Read -1, expected 5929, errno = 1
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2022-06-07 09:42:21,327:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2022-06-07 09:42:21,328:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2022-06-07 09:42:21,542:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2022-06-07 09:42:21,542:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2022-06-07 09:42:21,650:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2022-06-07 09:42:21,652:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2022-06-07 09:42:21,661:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2022-06-07 09:42:21,693:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2022-06-07 09:42:21,726:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2022-06-07 09:42:21,726:INFO: Starting epoch 0
[1,0]<stderr>:[5f90c357778b:10223] Read -1, expected 28321, errno = 1
[1,0]<stderr>:[5f90c357778b:10223] Read -1, expected 28321, errno = 1
[1,0]<stderr>:[5f90c357778b:10223] Read -1, expected 28697, errno = 1
[1,7]<stderr>:[5f90c357778b:10230] Read -1, expected 19052, errno = 1
[1,4]<stderr>:[5f90c357778b:10227] Read -1, expected 19053, errno = 1
[1,2]<stderr>:[5f90c357778b:10225] Read -1, expected 19053, errno = 1
[1,6]<stderr>:[5f90c357778b:10229] Read -1, expected 19053, errno = 1
[1,5]<stderr>:[5f90c357778b:10228] Read -1, expected 19052, errno = 1
[1,1]<stderr>:[5f90c357778b:10224] Read -1, expected 19052, errno = 1
[1,3]<stderr>:[5f90c357778b:10226] Read -1, expected 19052, errno = 1
[1,3]<stderr>:[09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:[09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[[1,7]<stderr>:09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,7]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:[09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[[1,5]<stderr>:09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,5]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[[1,4]<stderr>:09:42:23] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,4]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2022-06-07 09:42:40.192460 - Epoch: 0 Iteration: 19  train.loss : 6.952762699127197  train.ips : 2196.224513534484  train.lr : 0.4864 
[1,0]<stdout>:DLL 2022-06-07 09:42:44.079363 - Epoch: 0 Iteration: 39  train.loss : 6.679563212394714  train.ips : 10540.435938080172  train.lr : 0.9984 
[1,0]<stdout>:DLL 2022-06-07 09:42:47.981072 - Epoch: 0 Iteration: 59  train.loss : 6.572577476501465  train.ips : 10498.50507238096  train.lr : 1.5104000000000002 
[1,0]<stdout>:DLL 2022-06-07 09:42:51.894300 - Epoch: 0 Iteration: 79  train.loss : 6.4184650182724  train.ips : 10467.874399661614  train.lr : 2.0224 
[1,0]<stdout>:DLL 2022-06-07 09:42:55.799185 - Epoch: 0 Iteration: 99  train.loss : 6.366794586181641  train.ips : 10490.23230668104  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:42:59.687063 - Epoch: 0 Iteration: 119  train.loss : 6.360720777511597  train.ips : 10536.219901783039  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:03.587959 - Epoch: 0 Iteration: 139  train.loss : 6.370234060287475  train.ips : 10500.943554248055  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:07.474034 - Epoch: 0 Iteration: 159  train.loss : 6.355058288574218  train.ips : 10541.041923049195  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:11.358988 - Epoch: 0 Iteration: 179  train.loss : 6.356290507316589  train.ips : 10543.972587917486  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:15.247799 - Epoch: 0 Iteration: 199  train.loss : 6.342101263999939  train.ips : 10533.528626522866  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:19.137036 - Epoch: 0 Iteration: 219  train.loss : 6.3495991945266725  train.ips : 10532.805330449359  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:23.064094 - Epoch: 0 Iteration: 239  train.loss : 6.377503275871277  train.ips : 10431.198668002291  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:26.958608 - Epoch: 0 Iteration: 259  train.loss : 6.344584512710571  train.ips : 10518.24818773122  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:30.844089 - Epoch: 0 Iteration: 279  train.loss : 6.354831552505493  train.ips : 10542.575628521481  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:34.744213 - Epoch: 0 Iteration: 299  train.loss : 6.341461277008056  train.ips : 10502.949091610257  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:38.644706 - Epoch: 0 Iteration: 319  train.loss : 6.340681004524231  train.ips : 10501.923758020386  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:42.553034 - Epoch: 0 Iteration: 339  train.loss : 6.347500681877136  train.ips : 10480.831117934345  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:46.461716 - Epoch: 0 Iteration: 359  train.loss : 6.363503003120423  train.ips : 10480.047274035376  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:50.349338 - Epoch: 0 Iteration: 379  train.loss : 6.368340635299683  train.ips : 10536.874517196795  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:54.247271 - Epoch: 0 Iteration: 399  train.loss : 6.350564694404602  train.ips : 10508.969017023435  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:43:58.143581 - Epoch: 0 Iteration: 419  train.loss : 6.357436752319336  train.ips : 10513.27456910698  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:02.037227 - Epoch: 0 Iteration: 439  train.loss : 6.3728663444519045  train.ips : 10520.428484760787  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:05.968378 - Epoch: 0 Iteration: 459  train.loss : 6.347975754737854  train.ips : 10420.070436088121  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:09.876446 - Epoch: 0 Iteration: 479  train.loss : 6.368097805976868  train.ips : 10481.553048532278  train.lr : 0 
[1,2]<stderr>:2022-06-07 09:44:13,768:INFO: Starting epoch 1
[1,7]<stderr>:2022-06-07 09:44:13,768:INFO: Starting epoch 1
[1,3]<stderr>:2022-06-07 09:44:13,768:INFO: Starting epoch 1
[1,5]<stderr>:2022-06-07 09:44:13,768:INFO: Starting epoch 1
[1,4]<stderr>:2022-06-07 09:44:13,768:INFO: Starting epoch 1
[1,1]<stderr>:2022-06-07 09:44:13,769:INFO: Starting epoch 1
[1,6]<stderr>:2022-06-07 09:44:13,770:INFO: Starting epoch 1
[1,0]<stderr>:2022-06-07 09:44:13,772:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-06-07 09:44:13.771227 - Epoch: 0 Iteration: 499  train.loss : 6.377384233474731  train.ips : 10517.28360616036  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:13.771945 - Epoch: 0  train.loss : 6.405475944519043  train.ips : 10504.639056766617 
[1,0]<stdout>:DLL 2022-06-07 09:44:17.683540 - Epoch: 1 Iteration: 19  train.loss : 6.320754742622375  train.ips : 10472.036544394245  train.lr : 0.8960000000000001 
[1,0]<stdout>:DLL 2022-06-07 09:44:21.584841 - Epoch: 1 Iteration: 39  train.loss : 6.220590400695801  train.ips : 10500.045034412662  train.lr : 1.408 
[1,0]<stdout>:DLL 2022-06-07 09:44:25.485867 - Epoch: 1 Iteration: 59  train.loss : 6.202488374710083  train.ips : 10500.452558282386  train.lr : 1.92 
[1,0]<stdout>:DLL 2022-06-07 09:44:29.385557 - Epoch: 1 Iteration: 79  train.loss : 6.191695427894592  train.ips : 10504.154451621795  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:33.290991 - Epoch: 1 Iteration: 99  train.loss : 6.188262939453125  train.ips : 10488.869401775171  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:37.205940 - Epoch: 1 Iteration: 119  train.loss : 6.189690709114075  train.ips : 10463.630163038364  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:41.102187 - Epoch: 1 Iteration: 139  train.loss : 6.208734750747681  train.ips : 10513.751966218164  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:44.994582 - Epoch: 1 Iteration: 159  train.loss : 6.183988952636719  train.ips : 10523.900145436752  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:48.891327 - Epoch: 1 Iteration: 179  train.loss : 6.155399966239929  train.ips : 10512.08834137502  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:52.780726 - Epoch: 1 Iteration: 199  train.loss : 6.159485530853272  train.ips : 10531.910389066936  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:44:56.692983 - Epoch: 1 Iteration: 219  train.loss : 6.1994620084762575  train.ips : 10470.345892155836  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:00.600093 - Epoch: 1 Iteration: 239  train.loss : 6.193211388587952  train.ips : 10484.299723390577  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:04.506789 - Epoch: 1 Iteration: 259  train.loss : 6.203898072242737  train.ips : 10485.644801265611  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:08.408052 - Epoch: 1 Iteration: 279  train.loss : 6.187205171585083  train.ips : 10500.009738558158  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:12.299773 - Epoch: 1 Iteration: 299  train.loss : 6.170970249176025  train.ips : 10525.713898502305  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:16.210088 - Epoch: 1 Iteration: 319  train.loss : 6.199964094161987  train.ips : 10475.694152036407  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:20.111954 - Epoch: 1 Iteration: 339  train.loss : 6.187928009033203  train.ips : 10498.37547951909  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:24.006846 - Epoch: 1 Iteration: 359  train.loss : 6.210451245307922  train.ips : 10517.264934430965  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:27.911302 - Epoch: 1 Iteration: 379  train.loss : 6.182950091362  train.ips : 10491.6916735823  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:31.815200 - Epoch: 1 Iteration: 399  train.loss : 6.180654740333557  train.ips : 10493.27129673878  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:35.726283 - Epoch: 1 Iteration: 419  train.loss : 6.194057369232178  train.ips : 10473.744983095869  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:39.624638 - Epoch: 1 Iteration: 439  train.loss : 6.191709756851196  train.ips : 10508.030559885343  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:43.523528 - Epoch: 1 Iteration: 459  train.loss : 6.190699911117553  train.ips : 10506.334049171975  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:47.420804 - Epoch: 1 Iteration: 479  train.loss : 6.1734572649002075  train.ips : 10510.767337743688  train.lr : 0 
[1,4]<stderr>:2022-06-07 09:45:51,328:INFO: Starting epoch 2
[1,1]<stderr>:2022-06-07 09:45:51,328:INFO: Starting epoch 2
[1,3]<stderr>:2022-06-07 09:45:51,328:INFO: Starting epoch 2
[1,6]<stderr>:2022-06-07 09:45:51,329:INFO: Starting epoch 2
[1,2]<stderr>:2022-06-07 09:45:51,330:INFO: Starting epoch 2
[1,5]<stderr>:2022-06-07 09:45:51,331:INFO: Starting epoch 2
[1,7]<stderr>:2022-06-07 09:45:51,330:INFO: Starting epoch 2
[1,0]<stderr>:2022-06-07 09:45:51,331:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-06-07 09:45:51.330263 - Epoch: 1 Iteration: 499  train.loss : 6.194335317611694  train.ips : 10478.263922641767  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:45:51.331239 - Epoch: 1  train.loss : 6.1952818593978884  train.ips : 10500.038797105643 
[1,0]<stdout>:DLL 2022-06-07 09:45:55.235300 - Epoch: 2 Iteration: 19  train.loss : 6.1536048412322994  train.ips : 10492.109442451288  train.lr : 1.3056 
[1,0]<stdout>:DLL 2022-06-07 09:45:59.138730 - Epoch: 2 Iteration: 39  train.loss : 6.02631196975708  train.ips : 10494.213529673134  train.lr : 1.8176 
[1,0]<stdout>:DLL 2022-06-07 09:46:03.042187 - Epoch: 2 Iteration: 59  train.loss : 5.998839330673218  train.ips : 10494.55905748124  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:06.962704 - Epoch: 2 Iteration: 79  train.loss : 5.984395623207092  train.ips : 10448.432236079441  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:10.882538 - Epoch: 2 Iteration: 99  train.loss : 5.955901432037353  train.ips : 10451.305902441243  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:14.790956 - Epoch: 2 Iteration: 119  train.loss : 5.971645641326904  train.ips : 10483.74118875424  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:18.716270 - Epoch: 2 Iteration: 139  train.loss : 5.945245242118835  train.ips : 10435.770975482312  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:22.616488 - Epoch: 2 Iteration: 159  train.loss : 5.976478433609008  train.ips : 10503.18346333924  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:26.523527 - Epoch: 2 Iteration: 179  train.loss : 5.964946699142456  train.ips : 10484.535822935224  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:30.433312 - Epoch: 2 Iteration: 199  train.loss : 5.984182691574096  train.ips : 10478.207683439103  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:34.353849 - Epoch: 2 Iteration: 219  train.loss : 5.982229685783386  train.ips : 10448.348357154999  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:38.265199 - Epoch: 2 Iteration: 239  train.loss : 5.978423643112182  train.ips : 10472.99986673951  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:42.187411 - Epoch: 2 Iteration: 259  train.loss : 5.962169480323792  train.ips : 10443.858987863206  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:46.094517 - Epoch: 2 Iteration: 279  train.loss : 5.990090441703797  train.ips : 10484.299723390577  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:50.006056 - Epoch: 2 Iteration: 299  train.loss : 5.977939081192017  train.ips : 10472.364015805466  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:53.925972 - Epoch: 2 Iteration: 319  train.loss : 5.965558385848999  train.ips : 10450.16794241196  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:46:57.836619 - Epoch: 2 Iteration: 339  train.loss : 5.97991418838501  train.ips : 10474.909160261965  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:01.747058 - Epoch: 2 Iteration: 359  train.loss : 5.958609962463379  train.ips : 10475.18826916317  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:05.652274 - Epoch: 2 Iteration: 379  train.loss : 5.977513241767883  train.ips : 10489.57963086412  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:09.568061 - Epoch: 2 Iteration: 399  train.loss : 5.984586310386658  train.ips : 10461.084763076547  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:13.484383 - Epoch: 2 Iteration: 419  train.loss : 5.993342065811158  train.ips : 10460.114715088477  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:17.400792 - Epoch: 2 Iteration: 439  train.loss : 6.005475330352783  train.ips : 10459.491890087802  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:21.305808 - Epoch: 2 Iteration: 459  train.loss : 5.986335301399231  train.ips : 10490.286753378075  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:25.212262 - Epoch: 2 Iteration: 479  train.loss : 5.989208507537842  train.ips : 10486.098570931643  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:29.120224 - Epoch: 2 Iteration: 499  train.loss : 5.963674378395081  train.ips : 10482.019894512736  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:47:29.120859 - Epoch: 2  train.loss : 5.986264876365661  train.ips : 10487.581822767985 
[1,0]<stdout>:DLL 2022-06-07 09:47:29.244477 - Summary: train.loss : 5.986264876365661  train.ips : 10497.419892213415 
train.ips
           |    256    |
------------------------
     1     |   1359.4  |
     8     |   10494   |

