[1,0]<stdout>:DLL 2022-06-07 08:56:25.086523 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 0  fuse_bn_add_relu : 0  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float32  amp : False  batch_size : 256  num_epochs : 3  run_epochs : -1  lr : 0.256  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp32.json-1,256  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [3, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NCHW  batchnorm_layout : NCHW  pooling_layout : NCHW  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[08:56:25] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[08:56:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2022-06-07 08:56:31,042:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2022-06-07 08:56:31,043:INFO: Starting epoch 0
[1,0]<stderr>:[08:56:31] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2022-06-07 08:56:51.594374 - Epoch: 0 Iteration: 19  train.loss : 7.091642880439759  train.ips : 249.12727620247836  train.lr : 0.0077824 
[1,0]<stdout>:DLL 2022-06-07 08:57:05.021045 - Epoch: 0 Iteration: 39  train.loss : 6.9973831415176395  train.ips : 381.34153118802595  train.lr : 0.0159744 
[1,0]<stdout>:DLL 2022-06-07 08:57:18.426039 - Epoch: 0 Iteration: 59  train.loss : 6.920958185195923  train.ips : 381.9597732377825  train.lr : 0.024166399999999998 
[1,0]<stdout>:DLL 2022-06-07 08:57:31.842286 - Epoch: 0 Iteration: 79  train.loss : 6.870565509796142  train.ips : 381.6363486341322  train.lr : 0.032358399999999995 
[1,0]<stdout>:DLL 2022-06-07 08:57:45.256953 - Epoch: 0 Iteration: 99  train.loss : 6.844729590415954  train.ips : 381.68018692749536  train.lr : 0.0405504 
[1,0]<stdout>:DLL 2022-06-07 08:57:58.675658 - Epoch: 0 Iteration: 119  train.loss : 6.81592698097229  train.ips : 381.56543372859784  train.lr : 0.0487424 
[1,0]<stdout>:DLL 2022-06-07 08:58:12.109451 - Epoch: 0 Iteration: 139  train.loss : 6.787880158424377  train.ips : 381.1365128329419  train.lr : 0.05693440000000001 
[1,0]<stdout>:DLL 2022-06-07 08:58:25.549668 - Epoch: 0 Iteration: 159  train.loss : 6.77328851222992  train.ips : 380.95421072915366  train.lr : 0.0651264 
[1,0]<stdout>:DLL 2022-06-07 08:58:38.981525 - Epoch: 0 Iteration: 179  train.loss : 6.755357146263123  train.ips : 381.1910284113466  train.lr : 0.07331839999999999 
[1,0]<stdout>:DLL 2022-06-07 08:58:52.421531 - Epoch: 0 Iteration: 199  train.loss : 6.714752840995788  train.ips : 380.96030650765164  train.lr : 0.08151040000000001 
[1,0]<stdout>:DLL 2022-06-07 08:59:05.882451 - Epoch: 0 Iteration: 219  train.loss : 6.6907597303390505  train.ips : 380.3689122997577  train.lr : 0.0897024 
[1,0]<stdout>:DLL 2022-06-07 08:59:19.320287 - Epoch: 0 Iteration: 239  train.loss : 6.694671273231506  train.ips : 381.0218902158192  train.lr : 0.09789439999999999 
[1,0]<stdout>:DLL 2022-06-07 08:59:32.747986 - Epoch: 0 Iteration: 259  train.loss : 6.691751456260681  train.ips : 381.3095781664752  train.lr : 0.1060864 
[1,0]<stdout>:DLL 2022-06-07 08:59:46.169869 - Epoch: 0 Iteration: 279  train.loss : 6.657416939735413  train.ips : 381.4805576575882  train.lr : 0.1142784 
[1,0]<stdout>:DLL 2022-06-07 08:59:59.625553 - Epoch: 0 Iteration: 299  train.loss : 6.622826933860779  train.ips : 380.53759251851903  train.lr : 0.12247040000000001 
[1,0]<stdout>:DLL 2022-06-07 09:00:13.075028 - Epoch: 0 Iteration: 319  train.loss : 6.59296441078186  train.ips : 380.69932916278697  train.lr : 0.1306624 
[1,0]<stdout>:DLL 2022-06-07 09:00:26.517085 - Epoch: 0 Iteration: 339  train.loss : 6.542403531074524  train.ips : 380.91993067718874  train.lr : 0.13885440000000002 
[1,0]<stdout>:DLL 2022-06-07 09:00:39.935039 - Epoch: 0 Iteration: 359  train.loss : 6.552813220024109  train.ips : 381.58641116287083  train.lr : 0.1470464 
[1,0]<stdout>:DLL 2022-06-07 09:00:53.392101 - Epoch: 0 Iteration: 379  train.loss : 6.526819801330566  train.ips : 380.47856506523567  train.lr : 0.1552384 
[1,0]<stdout>:DLL 2022-06-07 09:01:06.848799 - Epoch: 0 Iteration: 399  train.loss : 6.506050252914429  train.ips : 380.4889803439579  train.lr : 0.16343040000000003 
[1,0]<stdout>:DLL 2022-06-07 09:01:20.297305 - Epoch: 0 Iteration: 419  train.loss : 6.469693565368653  train.ips : 380.724490803931  train.lr : 0.1716224 
[1,0]<stdout>:DLL 2022-06-07 09:01:33.770831 - Epoch: 0 Iteration: 439  train.loss : 6.457995104789734  train.ips : 380.0140511597126  train.lr : 0.17981439999999999 
[1,0]<stdout>:DLL 2022-06-07 09:01:47.227384 - Epoch: 0 Iteration: 459  train.loss : 6.422537565231323  train.ips : 380.49297807486204  train.lr : 0.18800640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:02:00.668989 - Epoch: 0 Iteration: 479  train.loss : 6.423456716537475  train.ips : 380.9226401511981  train.lr : 0.1961984 
[1,0]<stderr>:2022-06-07 09:02:14,131:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-06-07 09:02:14.130080 - Epoch: 0 Iteration: 499  train.loss : 6.41792733669281  train.ips : 380.3744436306111  train.lr : 0.2043904 
[1,0]<stdout>:DLL 2022-06-07 09:02:14.130603 - Epoch: 0  train.loss : 6.673702911376953  train.ips : 380.941528260425 
[1,0]<stdout>:DLL 2022-06-07 09:02:27.586819 - Epoch: 1 Iteration: 19  train.loss : 6.373810410499573  train.ips : 380.4969624062772  train.lr : 0.058982400000000004 
[1,0]<stdout>:DLL 2022-06-07 09:02:41.036937 - Epoch: 1 Iteration: 39  train.loss : 6.282322216033935  train.ips : 380.6760535566981  train.lr : 0.0671744 
[1,0]<stdout>:DLL 2022-06-07 09:02:54.499424 - Epoch: 1 Iteration: 59  train.loss : 6.255197072029114  train.ips : 380.324283512297  train.lr : 0.0753664 
[1,0]<stdout>:DLL 2022-06-07 09:03:07.967915 - Epoch: 1 Iteration: 79  train.loss : 6.260674953460693  train.ips : 380.1550520433131  train.lr : 0.0835584 
[1,0]<stdout>:DLL 2022-06-07 09:03:21.403728 - Epoch: 1 Iteration: 99  train.loss : 6.2481361627578735  train.ips : 381.07887507285807  train.lr : 0.0917504 
[1,0]<stdout>:DLL 2022-06-07 09:03:34.874015 - Epoch: 1 Iteration: 119  train.loss : 6.217444276809692  train.ips : 380.1043846272899  train.lr : 0.0999424 
[1,0]<stdout>:DLL 2022-06-07 09:03:48.365716 - Epoch: 1 Iteration: 139  train.loss : 6.223341798782348  train.ips : 379.5022158326738  train.lr : 0.1081344 
[1,0]<stdout>:DLL 2022-06-07 09:04:01.838519 - Epoch: 1 Iteration: 159  train.loss : 6.222803997993469  train.ips : 380.0336074374249  train.lr : 0.11632640000000001 
[1,0]<stdout>:DLL 2022-06-07 09:04:15.298533 - Epoch: 1 Iteration: 179  train.loss : 6.1845509052276615  train.ips : 380.39386856743533  train.lr : 0.1245184 
[1,0]<stdout>:DLL 2022-06-07 09:04:28.738232 - Epoch: 1 Iteration: 199  train.loss : 6.1826468229293825  train.ips : 380.9691328918623  train.lr : 0.1327104 
[1,0]<stdout>:DLL 2022-06-07 09:04:42.208930 - Epoch: 1 Iteration: 219  train.loss : 6.225564455986023  train.ips : 380.09345892318623  train.lr : 0.14090239999999998 
[1,0]<stdout>:DLL 2022-06-07 09:04:55.703309 - Epoch: 1 Iteration: 239  train.loss : 6.215254092216492  train.ips : 379.42633975621476  train.lr : 0.14909440000000002 
[1,0]<stdout>:DLL 2022-06-07 09:05:09.161760 - Epoch: 1 Iteration: 259  train.loss : 6.214365696907043  train.ips : 380.4389180691845  train.lr : 0.1572864 
[1,0]<stdout>:DLL 2022-06-07 09:05:22.598785 - Epoch: 1 Iteration: 279  train.loss : 6.174279904365539  train.ips : 381.04532983472797  train.lr : 0.1654784 
[1,0]<stdout>:DLL 2022-06-07 09:05:36.050691 - Epoch: 1 Iteration: 299  train.loss : 6.170238399505616  train.ips : 380.6237562503416  train.lr : 0.1736704 
[1,0]<stdout>:DLL 2022-06-07 09:05:49.488652 - Epoch: 1 Iteration: 319  train.loss : 6.181094169616699  train.ips : 381.01905764495854  train.lr : 0.1818624 
[1,0]<stdout>:DLL 2022-06-07 09:06:02.944217 - Epoch: 1 Iteration: 339  train.loss : 6.1685981273651125  train.ips : 380.5202026314302  train.lr : 0.1900544 
[1,0]<stdout>:DLL 2022-06-07 09:06:16.395079 - Epoch: 1 Iteration: 359  train.loss : 6.1871219873428345  train.ips : 380.652598620306  train.lr : 0.1982464 
[1,0]<stdout>:DLL 2022-06-07 09:06:29.864341 - Epoch: 1 Iteration: 379  train.loss : 6.151591205596924  train.ips : 380.13306086037716  train.lr : 0.2064384 
[1,0]<stdout>:DLL 2022-06-07 09:06:43.317005 - Epoch: 1 Iteration: 399  train.loss : 6.169769263267517  train.ips : 380.60168382657207  train.lr : 0.21463040000000003 
[1,0]<stdout>:DLL 2022-06-07 09:06:56.752887 - Epoch: 1 Iteration: 419  train.loss : 6.118256640434265  train.ips : 381.0769207536568  train.lr : 0.22282240000000003 
[1,0]<stdout>:DLL 2022-06-07 09:07:10.206584 - Epoch: 1 Iteration: 439  train.loss : 6.134206318855286  train.ips : 380.5730177825271  train.lr : 0.2310144 
[1,0]<stdout>:DLL 2022-06-07 09:07:23.667287 - Epoch: 1 Iteration: 459  train.loss : 6.11222357749939  train.ips : 380.3777719388779  train.lr : 0.23920640000000004 
[1,0]<stdout>:DLL 2022-06-07 09:07:37.114268 - Epoch: 1 Iteration: 479  train.loss : 6.062737655639649  train.ips : 380.763171163808  train.lr : 0.24739840000000002 
[1,0]<stderr>:2022-06-07 09:07:50,575:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-06-07 09:07:50.575296 - Epoch: 1 Iteration: 499  train.loss : 6.09126238822937  train.ips : 380.365873841766  train.lr : 0.2555904 
[1,0]<stdout>:DLL 2022-06-07 09:07:50.575693 - Epoch: 1  train.loss : 6.19309969997406  train.ips : 380.5902009550757 
[1,0]<stdout>:DLL 2022-06-07 09:08:04.022998 - Epoch: 2 Iteration: 19  train.loss : 5.999663043022156  train.ips : 380.74867017084586  train.lr : 0.11018240000000001 
[1,0]<stdout>:DLL 2022-06-07 09:08:17.485655 - Epoch: 2 Iteration: 39  train.loss : 5.955482912063599  train.ips : 380.3194810684907  train.lr : 0.11837439999999999 
[1,0]<stdout>:DLL 2022-06-07 09:08:30.935251 - Epoch: 2 Iteration: 59  train.loss : 5.97639753818512  train.ips : 380.6899348962959  train.lr : 0.12656640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:08:44.389892 - Epoch: 2 Iteration: 79  train.loss : 5.941119122505188  train.ips : 380.54619027745014  train.lr : 0.1347584 
[1,0]<stdout>:DLL 2022-06-07 09:08:57.846110 - Epoch: 2 Iteration: 99  train.loss : 5.9177724599838255  train.ips : 380.501917655675  train.lr : 0.14295039999999998 
[1,0]<stdout>:DLL 2022-06-07 09:09:11.302977 - Epoch: 2 Iteration: 119  train.loss : 5.94893445968628  train.ips : 380.483809710368  train.lr : 0.1511424 
[1,0]<stdout>:DLL 2022-06-07 09:09:24.760452 - Epoch: 2 Iteration: 139  train.loss : 5.906948447227478  train.ips : 380.46870983787784  train.lr : 0.15933440000000001 
[1,0]<stdout>:DLL 2022-06-07 09:09:38.229075 - Epoch: 2 Iteration: 159  train.loss : 5.955381608009338  train.ips : 380.1529927854113  train.lr : 0.16752640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:09:51.682029 - Epoch: 2 Iteration: 179  train.loss : 5.91816349029541  train.ips : 380.5940481195055  train.lr : 0.1757184 
[1,0]<stdout>:DLL 2022-06-07 09:10:05.142332 - Epoch: 2 Iteration: 199  train.loss : 5.943753600120544  train.ips : 380.38562131757124  train.lr : 0.1839104 
[1,0]<stdout>:DLL 2022-06-07 09:10:18.597398 - Epoch: 2 Iteration: 219  train.loss : 5.91851658821106  train.ips : 380.53420746826265  train.lr : 0.19210239999999998 
[1,0]<stdout>:DLL 2022-06-07 09:10:32.039163 - Epoch: 2 Iteration: 239  train.loss : 5.921097946166992  train.ips : 380.91081604631  train.lr : 0.20029439999999998 
[1,0]<stdout>:DLL 2022-06-07 09:10:45.516008 - Epoch: 2 Iteration: 259  train.loss : 5.906207609176636  train.ips : 379.9189413988925  train.lr : 0.20848640000000002 
[1,0]<stdout>:DLL 2022-06-07 09:10:58.960238 - Epoch: 2 Iteration: 279  train.loss : 5.919943022727966  train.ips : 380.8401704935558  train.lr : 0.21667840000000002 
[1,0]<stdout>:DLL 2022-06-07 09:11:12.408539 - Epoch: 2 Iteration: 299  train.loss : 5.9084340810775755  train.ips : 380.72569227449833  train.lr : 0.22487039999999997 
[1,0]<stdout>:DLL 2022-06-07 09:11:25.880115 - Epoch: 2 Iteration: 319  train.loss : 5.892187905311585  train.ips : 380.06836716536856  train.lr : 0.23306239999999998 
[1,0]<stdout>:DLL 2022-06-07 09:11:39.341367 - Epoch: 2 Iteration: 339  train.loss : 5.905217981338501  train.ips : 380.3601069685265  train.lr : 0.2412544 
[1,0]<stdout>:DLL 2022-06-07 09:11:52.800823 - Epoch: 2 Iteration: 359  train.loss : 5.846478843688965  train.ips : 380.4097037506096  train.lr : 0.24944639999999998 
[1,0]<stdout>:DLL 2022-06-07 09:12:06.241110 - Epoch: 2 Iteration: 379  train.loss : 5.89591281414032  train.ips : 380.95246042525724  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:12:19.701351 - Epoch: 2 Iteration: 399  train.loss : 5.874342346191407  train.ips : 380.38709016433006  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:12:33.158920 - Epoch: 2 Iteration: 419  train.loss : 5.892152047157287  train.ips : 380.4634319062093  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:12:46.630210 - Epoch: 2 Iteration: 439  train.loss : 5.91688289642334  train.ips : 380.07464315763355  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:13:00.097977 - Epoch: 2 Iteration: 459  train.loss : 5.870083975791931  train.ips : 380.175955446544  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:13:13.560426 - Epoch: 2 Iteration: 479  train.loss : 5.880663728713989  train.ips : 380.32616276245386  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:13:27.030424 - Epoch: 2 Iteration: 499  train.loss : 5.865619421005249  train.ips : 380.1123774736698  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:13:27.030868 - Epoch: 2  train.loss : 5.9150943155288696  train.ips : 380.5061708095294 
[1,0]<stdout>:DLL 2022-06-07 09:13:27.486359 - Summary: train.loss : 5.9150943155288696  train.ips : 380.6793000083433 
[1,0]<stdout>:DLL 2022-06-07 09:13:35.206620 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 0  fuse_bn_add_relu : 0  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float32  amp : False  batch_size : 2048  num_epochs : 3  run_epochs : -1  lr : 2.048  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp32.json-8,256  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [3, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NCHW  batchnorm_layout : NCHW  pooling_layout : NCHW  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,3]<stderr>:[09:13:35] ../src/storage/storage.cc:199: Using Pooled (Naive)[1,3]<stderr>: StorageManager for CPU
[1,5]<stderr>:[[1,5]<stderr>:09:13:35] ../src/storage/storage.cc:[1,5]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[[1,1]<stderr>:09:13:35] ../src/storage/storage.cc:199[1,1]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:09:13:35] ../src/storage/storage.cc:199: [1,6]<stderr>:Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[[1,0]<stderr>:[[1,4]<stderr>:09:13:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:09:13:35] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:[[1,7]<stderr>:09:13:35] ../src/storage/storage.cc:199[1,7]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:[[1,2]<stderr>:09:13:35] ../src/storage/storage.cc:199[1,2]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[09:13:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,0]<stderr>:GPU
[1,2]<stderr>:[09:13:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:[09:13:40] ../src/storage/storage.cc:[1,5]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[[1,7]<stderr>:09:13:40] ../src/storage/storage.cc:[1,7]<stderr>:199: Using Pooled (Naive) StorageManager for [1,7]<stderr>:GPU
[1,4]<stderr>:[[1,4]<stderr>:09:13:40] ../src/storage/storage.cc:[1,4]<stderr>:199: Using Pooled (Naive) StorageManager for GPU[1,4]<stderr>:
[1,6]<stderr>:[[1,6]<stderr>:09:13:40] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[09:13:40[1,1]<stderr>:] ../src/storage/storage.cc:199: [1,1]<stderr>:Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[[1,3]<stderr>:09:13:40] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2022-06-07 09:13:44,857:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2022-06-07 09:13:44,858:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2022-06-07 09:13:44,920:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2022-06-07 09:13:44,920:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2022-06-07 09:13:45,003:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2022-06-07 09:13:45,021:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2022-06-07 09:13:45,476:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2022-06-07 09:13:45,476:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2022-06-07 09:13:45,522:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2022-06-07 09:13:45,522:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2022-06-07 09:13:45,742:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2022-06-07 09:13:45,743:INFO: Starting epoch 0
[1,0]<stderr>:[5f90c357778b:07138] Read -1, expected 4769, errno = 1
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2022-06-07 09:13:45,898:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2022-06-07 09:13:45,899:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2022-06-07 09:13:45,989:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2022-06-07 09:13:45,990:INFO: Starting epoch 0
[1,0]<stderr>:[5f90c357778b:07138] Read -1, expected 28137, errno = 1
[1,0]<stderr>:[5f90c357778b:07138] Read -1, expected 21969, errno = 1
[1,7]<stderr>:[5f90c357778b:07145] Read -1, expected 18720, errno = 1
[1,4]<stderr>:[5f90c357778b:07142] Read -1, expected 18721, errno = 1
[1,2]<stderr>:[5f90c357778b:07140] Read -1, expected 18721, errno = 1
[1,6]<stderr>:[5f90c357778b:07144] Read -1, expected 18721, errno = 1
[1,1]<stderr>:[5f90c357778b:07139] Read -1, expected 18720, errno = 1
[1,3]<stderr>:[5f90c357778b:07141] Read -1, expected 18720, errno = 1
[1,5]<stderr>:[5f90c357778b:07143] Read -1, expected 18720, errno = 1
[1,6]<stderr>:[09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,6]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[[1,4]<stderr>:09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,4]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:[[1,2]<stderr>:09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,2]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[[1,1]<stderr>:09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,1]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[09:13:47] [1,7]<stderr>:../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)[1,0]<stderr>:[09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:
[1,5]<stderr>:[09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,5]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,3]<stderr>:[[1,3]<stderr>:09:13:47] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,3]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2022-06-07 09:14:09.616495 - Epoch: 0 Iteration: 19  train.loss : 6.945267963409424  train.ips : 1654.3171640766664  train.lr : 0.4864 
[1,0]<stdout>:DLL 2022-06-07 09:14:23.122513 - Epoch: 0 Iteration: 39  train.loss : 6.693511986732483  train.ips : 3032.795624225146  train.lr : 0.9984 
[1,0]<stdout>:DLL 2022-06-07 09:14:36.639790 - Epoch: 0 Iteration: 59  train.loss : 6.579731822013855  train.ips : 3030.264509358253  train.lr : 1.5104000000000002 
[1,0]<stdout>:DLL 2022-06-07 09:14:50.141273 - Epoch: 0 Iteration: 79  train.loss : 6.405325531959534  train.ips : 3033.8107867381127  train.lr : 2.0224 
[1,0]<stdout>:DLL 2022-06-07 09:15:03.630835 - Epoch: 0 Iteration: 99  train.loss : 6.364186573028564  train.ips : 3036.4912825082683  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:15:17.240876 - Epoch: 0 Iteration: 119  train.loss : 6.35593569278717  train.ips : 3009.6364429596324  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:15:30.796460 - Epoch: 0 Iteration: 139  train.loss : 6.370120429992676  train.ips : 3021.7021574853857  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:15:44.371645 - Epoch: 0 Iteration: 159  train.loss : 6.35013484954834  train.ips : 3017.3393099587515  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:15:57.959154 - Epoch: 0 Iteration: 179  train.loss : 6.355223989486694  train.ips : 3014.592896220937  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:16:11.582299 - Epoch: 0 Iteration: 199  train.loss : 6.342487406730652  train.ips : 3006.7239968241893  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:16:25.200501 - Epoch: 0 Iteration: 219  train.loss : 6.34241669178009  train.ips : 3007.807031637591  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:16:38.830829 - Epoch: 0 Iteration: 239  train.loss : 6.376862788200379  train.ips : 3005.128187797523  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:16:52.609863 - Epoch: 0 Iteration: 259  train.loss : 6.336639165878296  train.ips : 2972.704170528068  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:17:06.286457 - Epoch: 0 Iteration: 279  train.loss : 6.3571511030197145  train.ips : 2994.9751298369956  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:17:19.901177 - Epoch: 0 Iteration: 299  train.loss : 6.345475602149963  train.ips : 3008.596136673963  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:17:33.511794 - Epoch: 0 Iteration: 319  train.loss : 6.33417592048645  train.ips : 3009.4700025465077  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:17:47.160097 - Epoch: 0 Iteration: 339  train.loss : 6.3342793703079225  train.ips : 3001.1562896879955  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:18:00.808329 - Epoch: 0 Iteration: 359  train.loss : 6.363360834121704  train.ips : 3001.1787287339844  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:18:14.446823 - Epoch: 0 Iteration: 379  train.loss : 6.37067232131958  train.ips : 3003.3223648298413  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:18:28.109860 - Epoch: 0 Iteration: 399  train.loss : 6.355039167404175  train.ips : 2997.929351075626  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:18:41.733401 - Epoch: 0 Iteration: 419  train.loss : 6.3524068832397464  train.ips : 3006.627070241696  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:18:55.352378 - Epoch: 0 Iteration: 439  train.loss : 6.373525381088257  train.ips : 3007.6260504275238  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:19:08.990658 - Epoch: 0 Iteration: 459  train.loss : 6.3552231073379515  train.ips : 3003.375708816487  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:19:22.641924 - Epoch: 0 Iteration: 479  train.loss : 6.363699150085449  train.ips : 3000.5201146060704  train.lr : 0 
[1,2]<stderr>:2022-06-07 09:19:36,268:INFO: Starting epoch 1
[1,6]<stderr>:2022-06-07 09:19:36,269:INFO: Starting epoch 1
[1,4]<stderr>:2022-06-07 09:19:36,269:INFO: Starting epoch 1
[1,3]<stderr>:2022-06-07 09:19:36,270:INFO: Starting epoch 1
[1,7]<stderr>:2022-06-07 09:19:36,271:INFO: Starting epoch 1
[1,5]<stderr>:2022-06-07 09:19:36,271:INFO: Starting epoch 1
[1,0]<stderr>:2022-06-07 09:19:36,272:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-06-07 09:19:36.271856 - Epoch: 0 Iteration: 499  train.loss : 6.377524971961975  train.ips : 3005.2155027058866  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:19:36.272309 - Epoch: 0  train.loss : 6.404015148162842  train.ips : 3008.036731798697 
[1,1]<stderr>:2022-06-07 09:19:36,276:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-06-07 09:19:49.918190 - Epoch: 1 Iteration: 19  train.loss : 6.265925550460816  train.ips : 3001.681178601093  train.lr : 0.8960000000000001 
[1,0]<stdout>:DLL 2022-06-07 09:20:03.590476 - Epoch: 1 Iteration: 39  train.loss : 6.194359374046326  train.ips : 2995.9079707959177  train.lr : 1.408 
[1,0]<stdout>:DLL 2022-06-07 09:20:17.207949 - Epoch: 1 Iteration: 59  train.loss : 6.172127199172974  train.ips : 3007.9699702161433  train.lr : 1.92 
[1,0]<stdout>:DLL 2022-06-07 09:20:30.844540 - Epoch: 1 Iteration: 79  train.loss : 6.137072420120239  train.ips : 3003.746806484044  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:20:44.483248 - Epoch: 1 Iteration: 99  train.loss : 6.13273663520813  train.ips : 3003.279470498568  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:20:58.117762 - Epoch: 1 Iteration: 119  train.loss : 6.132517266273498  train.ips : 3004.2023627234753  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:21:11.771878 - Epoch: 1 Iteration: 139  train.loss : 6.134983992576599  train.ips : 2999.8972525621202  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:21:25.383168 - Epoch: 1 Iteration: 159  train.loss : 6.135062670707702  train.ips : 3009.3463835561333  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:21:39.018990 - Epoch: 1 Iteration: 179  train.loss : 6.0926020860672  train.ips : 3003.914872950394  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:21:52.666309 - Epoch: 1 Iteration: 199  train.loss : 6.10126838684082  train.ips : 3001.3867777353616  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:22:06.311934 - Epoch: 1 Iteration: 219  train.loss : 6.138361310958862  train.ips : 3001.759586859685  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:22:19.929066 - Epoch: 1 Iteration: 239  train.loss : 6.140372681617737  train.ips : 3008.043177199237  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:22:33.586291 - Epoch: 1 Iteration: 259  train.loss : 6.1355060338974  train.ips : 2999.208884373786  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:22:47.246124 - Epoch: 1 Iteration: 279  train.loss : 6.127975392341614  train.ips : 2998.6428827908494  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:23:00.902084 - Epoch: 1 Iteration: 299  train.loss : 6.104273080825806  train.ips : 2999.487618665077  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:23:14.558462 - Epoch: 1 Iteration: 319  train.loss : 6.135708928108215  train.ips : 2999.392519573324  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:23:28.162291 - Epoch: 1 Iteration: 339  train.loss : 6.126578831672669  train.ips : 3010.974803504794  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:23:41.806207 - Epoch: 1 Iteration: 359  train.loss : 6.156379532814026  train.ips : 3002.1317016897065  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:23:55.458735 - Epoch: 1 Iteration: 379  train.loss : 6.121787667274475  train.ips : 3000.23825426158  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:24:09.116380 - Epoch: 1 Iteration: 399  train.loss : 6.127219867706299  train.ips : 2999.1219705058725  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:24:22.774693 - Epoch: 1 Iteration: 419  train.loss : 6.137836480140686  train.ips : 2998.971506237053  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:24:36.408221 - Epoch: 1 Iteration: 439  train.loss : 6.131534576416016  train.ips : 3004.425963061823  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:24:50.043456 - Epoch: 1 Iteration: 459  train.loss : 6.118334102630615  train.ips : 3004.052543901948  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:25:03.693821 - Epoch: 1 Iteration: 479  train.loss : 6.10583131313324  train.ips : 3000.7326845925772  train.lr : 0 
[1,2]<stderr>:2022-06-07 09:25:17,367:INFO: Starting epoch 2
[1,6]<stderr>:2022-06-07 09:25:17,368:INFO: Starting epoch 2
[1,4]<stderr>:2022-06-07 09:25:17,369:INFO: Starting epoch 2
[1,3]<stderr>:2022-06-07 09:25:17,370:INFO: Starting epoch 2
[1,7]<stderr>:2022-06-07 09:25:17,370:INFO: Starting epoch 2
[1,0]<stderr>:2022-06-07 09:25:17,372:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-06-07 09:25:17.371702 - Epoch: 1 Iteration: 499  train.loss : 6.130456757545471  train.ips : 2994.679537216341  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:25:17.372129 - Epoch: 1  train.loss : 6.137472485542298  train.ips : 3002.6165365348693 
[1,1]<stderr>:2022-06-07 09:25:17,375:INFO: Starting epoch 2
[1,5]<stderr>:2022-06-07 09:25:17,375:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-06-07 09:25:31.013282 - Epoch: 2 Iteration: 19  train.loss : 6.113405108451843  train.ips : 3002.7039019700246  train.lr : 1.3056 
[1,0]<stdout>:DLL 2022-06-07 09:25:44.679637 - Epoch: 2 Iteration: 39  train.loss : 5.993874549865723  train.ips : 2997.2070604687115  train.lr : 1.8176 
[1,0]<stdout>:DLL 2022-06-07 09:25:58.275958 - Epoch: 2 Iteration: 59  train.loss : 6.000331234931946  train.ips : 3012.645717723854  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:26:11.904025 - Epoch: 2 Iteration: 79  train.loss : 5.988268876075745  train.ips : 3005.626492360463  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:26:25.526149 - Epoch: 2 Iteration: 99  train.loss : 5.9527015209198  train.ips : 3006.9412360971446  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:26:39.160318 - Epoch: 2 Iteration: 119  train.loss : 5.96304669380188  train.ips : 3004.2777505657546  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:26:52.792704 - Epoch: 2 Iteration: 139  train.loss : 5.92645046710968  train.ips : 3004.698678634343  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:27:06.418585 - Epoch: 2 Iteration: 159  train.loss : 5.96451768875122  train.ips : 3006.1314847478698  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:27:20.051235 - Epoch: 2 Iteration: 179  train.loss : 5.958225440979004  train.ips : 3004.617174053831  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:27:33.662498 - Epoch: 2 Iteration: 199  train.loss : 5.964973640441895  train.ips : 3009.339214493424  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:27:47.281236 - Epoch: 2 Iteration: 219  train.loss : 5.965223240852356  train.ips : 3007.733414889399  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:28:00.926212 - Epoch: 2 Iteration: 239  train.loss : 5.9778400421142575  train.ips : 3001.9099638571133  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:28:14.578108 - Epoch: 2 Iteration: 259  train.loss : 5.952115941047668  train.ips : 3000.381142820697  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:28:28.222918 - Epoch: 2 Iteration: 279  train.loss : 5.976571655273437  train.ips : 3001.9412789953826  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:28:41.866769 - Epoch: 2 Iteration: 299  train.loss : 5.968287825584412  train.ips : 3002.150850211925  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:28:55.538272 - Epoch: 2 Iteration: 319  train.loss : 5.954141473770141  train.ips : 2996.081796934493  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:29:09.183887 - Epoch: 2 Iteration: 339  train.loss : 5.975680875778198  train.ips : 3001.7651988453076  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:29:22.805281 - Epoch: 2 Iteration: 359  train.loss : 5.9474619150161745  train.ips : 3007.1211874515343  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:29:36.431293 - Epoch: 2 Iteration: 379  train.loss : 5.969317221641541  train.ips : 3006.0811987909165  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:29:50.052032 - Epoch: 2 Iteration: 399  train.loss : 5.975307822227478  train.ips : 3007.2472030637605  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:30:03.691178 - Epoch: 2 Iteration: 419  train.loss : 5.9760325908660885  train.ips : 3003.190115618456  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:30:17.329238 - Epoch: 2 Iteration: 439  train.loss : 5.987248778343201  train.ips : 3003.425011686  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:30:30.989346 - Epoch: 2 Iteration: 459  train.loss : 5.9783522367477415  train.ips : 2998.5834786252344  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:30:44.624164 - Epoch: 2 Iteration: 479  train.loss : 5.9874578475952145  train.ips : 3004.136907080411  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:30:58.282838 - Epoch: 2 Iteration: 499  train.loss : 5.959925866127014  train.ips : 2998.8891080565577  train.lr : 0 
[1,0]<stdout>:DLL 2022-06-07 09:30:58.283307 - Epoch: 2  train.loss : 5.975070422172546  train.ips : 3002.993710109501 
[1,0]<stdout>:DLL 2022-06-07 09:30:58.753552 - Summary: train.loss : 5.975070422172546  train.ips : 3004.5489928143556 
train.ips
           |    256    |
------------------------
     1     |   380.55  |
     8     |   3002.8  |

