[1,0]<stdout>:DLL 2021-12-17 10:38:07.422927 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 0  fuse_bn_add_relu : 0  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float32  amp : False  batch_size : 96  num_epochs : 3  run_epochs : -1  lr : 0.096  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp32.json-1,96  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [3, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NCHW  batchnorm_layout : NCHW  pooling_layout : NCHW  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[10:38:07] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU[1,0]<stderr>:
[1,0]<stderr>:[10:38:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,0]<stderr>:GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-12-17 10:38:13,198:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-12-17 10:38:13,198:INFO: Starting epoch 0
[1,0]<stderr>:[10:38:13] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-12-17 10:38:22.698057 - Epoch: 0 Iteration: 19  train.loss : 7.109247756004334  train.ips : 202.11147168915767  train.lr : 0.0010922155688622753 
[1,0]<stdout>:DLL 2021-12-17 10:38:27.688385 - Epoch: 0 Iteration: 39  train.loss : 7.077772760391236  train.ips : 384.7673874257311  train.lr : 0.002241916167664671 
[1,0]<stdout>:DLL 2021-12-17 10:38:32.702581 - Epoch: 0 Iteration: 59  train.loss : 7.054974174499511  train.ips : 382.93181271344486  train.lr : 0.003391616766467066 
[1,0]<stdout>:DLL 2021-12-17 10:38:37.713334 - Epoch: 0 Iteration: 79  train.loss : 7.0242225408554075  train.ips : 383.1961503866215  train.lr : 0.004541317365269462 
[1,0]<stdout>:DLL 2021-12-17 10:38:42.717301 - Epoch: 0 Iteration: 99  train.loss : 6.9770797967910765  train.ips : 383.71727374487375  train.lr : 0.005691017964071857 
[1,0]<stdout>:DLL 2021-12-17 10:38:47.735906 - Epoch: 0 Iteration: 119  train.loss : 6.943644261360168  train.ips : 382.59575460322765  train.lr : 0.0068407185628742515 
[1,0]<stdout>:DLL 2021-12-17 10:38:52.755983 - Epoch: 0 Iteration: 139  train.loss : 6.931156826019287  train.ips : 382.48289135211263  train.lr : 0.007990419161676646 
[1,0]<stdout>:DLL 2021-12-17 10:38:57.767027 - Epoch: 0 Iteration: 159  train.loss : 6.891799712181092  train.ips : 383.17253885556744  train.lr : 0.009140119760479041 
[1,0]<stdout>:DLL 2021-12-17 10:39:02.775968 - Epoch: 0 Iteration: 179  train.loss : 6.873582410812378  train.ips : 383.33182264438796  train.lr : 0.010289820359281436 
[1,0]<stdout>:DLL 2021-12-17 10:39:07.796698 - Epoch: 0 Iteration: 199  train.loss : 6.8632043361663815  train.ips : 382.42896365752114  train.lr : 0.011439520958083833 
[1,0]<stdout>:DLL 2021-12-17 10:39:12.821219 - Epoch: 0 Iteration: 219  train.loss : 6.862267684936524  train.ips : 382.14343139405185  train.lr : 0.01258922155688623 
[1,0]<stdout>:DLL 2021-12-17 10:39:17.845771 - Epoch: 0 Iteration: 239  train.loss : 6.859570384025574  train.ips : 382.13441904900105  train.lr : 0.013738922155688624 
[1,0]<stdout>:DLL 2021-12-17 10:39:22.865789 - Epoch: 0 Iteration: 259  train.loss : 6.8112571239471436  train.ips : 382.47974863399816  train.lr : 0.014888622754491019 
[1,0]<stdout>:DLL 2021-12-17 10:39:27.887838 - Epoch: 0 Iteration: 279  train.loss : 6.840917301177979  train.ips : 382.3252741499312  train.lr : 0.016038323353293412 
[1,0]<stdout>:DLL 2021-12-17 10:39:32.916715 - Epoch: 0 Iteration: 299  train.loss : 6.813934803009033  train.ips : 381.80866449903976  train.lr : 0.01718802395209581 
[1,0]<stdout>:DLL 2021-12-17 10:39:37.952568 - Epoch: 0 Iteration: 319  train.loss : 6.7723098516464235  train.ips : 381.28205776484026  train.lr : 0.018337724550898205 
[1,0]<stdout>:DLL 2021-12-17 10:39:42.984703 - Epoch: 0 Iteration: 339  train.loss : 6.78973159790039  train.ips : 381.5587829939368  train.lr : 0.0194874251497006 
[1,0]<stdout>:DLL 2021-12-17 10:39:48.024437 - Epoch: 0 Iteration: 359  train.loss : 6.780641508102417  train.ips : 380.9843738978424  train.lr : 0.020637125748502995 
[1,0]<stdout>:DLL 2021-12-17 10:39:53.068180 - Epoch: 0 Iteration: 379  train.loss : 6.802475070953369  train.ips : 380.6855528635122  train.lr : 0.021786826347305388 
[1,0]<stdout>:DLL 2021-12-17 10:39:58.108376 - Epoch: 0 Iteration: 399  train.loss : 6.772435188293457  train.ips : 380.9528343627052  train.lr : 0.02293652694610778 
[1,0]<stdout>:DLL 2021-12-17 10:40:03.157668 - Epoch: 0 Iteration: 419  train.loss : 6.74699375629425  train.ips : 380.26926137352854  train.lr : 0.02408622754491018 
[1,0]<stdout>:DLL 2021-12-17 10:40:08.205583 - Epoch: 0 Iteration: 439  train.loss : 6.742879152297974  train.ips : 380.3661612917365  train.lr : 0.025235928143712578 
[1,0]<stdout>:DLL 2021-12-17 10:40:13.245803 - Epoch: 0 Iteration: 459  train.loss : 6.773387217521668  train.ips : 380.9469235337763  train.lr : 0.02638562874251497 
[1,0]<stdout>:DLL 2021-12-17 10:40:18.286033 - Epoch: 0 Iteration: 479  train.loss : 6.72623462677002  train.ips : 380.94627479543044  train.lr : 0.027535329341317367 
[1,0]<stderr>:2021-12-17 10:40:23,332:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-12-17 10:40:23,332:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-12-17 10:40:23.331886 - Epoch: 0 Iteration: 499  train.loss : 6.718836069107056  train.ips : 380.52950311263396  train.lr : 0.02868502994011976 
[1,0]<stdout>:DLL 2021-12-17 10:40:23.332225 - Epoch: 0  train.loss : 6.8624222364425655  train.ips : 381.86887977067965 
[1,0]<stdout>:DLL 2021-12-17 10:40:28.381931 - Epoch: 1 Iteration: 19  train.loss : 6.665162849426269  train.ips : 380.22512945753544  train.lr : 0.020292215568862276 
[1,0]<stdout>:DLL 2021-12-17 10:40:33.421458 - Epoch: 1 Iteration: 39  train.loss : 6.665489053726196  train.ips : 380.99845122728505  train.lr : 0.021441916167664672 
[1,0]<stdout>:DLL 2021-12-17 10:40:38.468782 - Epoch: 1 Iteration: 59  train.loss : 6.647987198829651  train.ips : 380.4133089659113  train.lr : 0.022591616766467065 
[1,0]<stdout>:DLL 2021-12-17 10:40:43.524213 - Epoch: 1 Iteration: 79  train.loss : 6.597137594223023  train.ips : 379.8022845966702  train.lr : 0.02374131736526946 
[1,0]<stdout>:DLL 2021-12-17 10:40:48.568711 - Epoch: 1 Iteration: 99  train.loss : 6.664629602432251  train.ips : 380.6281368605635  train.lr : 0.02489101796407186 
[1,0]<stdout>:DLL 2021-12-17 10:40:53.627486 - Epoch: 1 Iteration: 119  train.loss : 6.637016010284424  train.ips : 379.55230244041763  train.lr : 0.026040718562874255 
[1,0]<stdout>:DLL 2021-12-17 10:40:58.694016 - Epoch: 1 Iteration: 139  train.loss : 6.620481657981872  train.ips : 378.9732668074938  train.lr : 0.027190419161676648 
[1,0]<stdout>:DLL 2021-12-17 10:41:03.752780 - Epoch: 1 Iteration: 159  train.loss : 6.6292894840240475  train.ips : 379.55208777448496  train.lr : 0.028340119760479045 
[1,0]<stdout>:DLL 2021-12-17 10:41:08.808674 - Epoch: 1 Iteration: 179  train.loss : 6.635442304611206  train.ips : 379.7710300140768  train.lr : 0.029489820359281438 
[1,0]<stdout>:DLL 2021-12-17 10:41:13.860543 - Epoch: 1 Iteration: 199  train.loss : 6.638508582115174  train.ips : 380.0751431830808  train.lr : 0.03063952095808383 
[1,0]<stdout>:DLL 2021-12-17 10:41:18.921215 - Epoch: 1 Iteration: 219  train.loss : 6.605739784240723  train.ips : 379.4063856421283  train.lr : 0.03178922155688623 
[1,0]<stdout>:DLL 2021-12-17 10:41:23.982930 - Epoch: 1 Iteration: 239  train.loss : 6.614276385307312  train.ips : 379.33170036245133  train.lr : 0.032938922155688624 
[1,0]<stdout>:DLL 2021-12-17 10:41:29.927166 - Epoch: 1 Iteration: 259  train.loss : 6.581587600708008  train.ips : 323.01409193486757  train.lr : 0.03408862275449102 
[1,0]<stdout>:DLL 2021-12-17 10:41:35.176700 - Epoch: 1 Iteration: 279  train.loss : 6.599414443969726  train.ips : 365.76227311665826  train.lr : 0.03523832335329342 
[1,0]<stdout>:DLL 2021-12-17 10:41:41.579804 - Epoch: 1 Iteration: 299  train.loss : 6.617825031280518  train.ips : 299.86791021683933  train.lr : 0.03638802395209581 
[1,0]<stdout>:DLL 2021-12-17 10:41:48.018821 - Epoch: 1 Iteration: 319  train.loss : 6.596237826347351  train.ips : 298.1946233857238  train.lr : 0.037537724550898204 
[1,0]<stdout>:DLL 2021-12-17 10:41:53.085665 - Epoch: 1 Iteration: 339  train.loss : 6.590294575691223  train.ips : 378.9601055527075  train.lr : 0.0386874251497006 
[1,0]<stdout>:DLL 2021-12-17 10:41:59.540467 - Epoch: 1 Iteration: 359  train.loss : 6.585986232757568  train.ips : 297.4669952949759  train.lr : 0.039837125748503 
[1,0]<stdout>:DLL 2021-12-17 10:42:05.711355 - Epoch: 1 Iteration: 379  train.loss : 6.584883713722229  train.ips : 311.15334626878195  train.lr : 0.04098682634730539 
[1,0]<stdout>:DLL 2021-12-17 10:42:10.795506 - Epoch: 1 Iteration: 399  train.loss : 6.502374529838562  train.ips : 377.67059515078165  train.lr : 0.042136526946107776 
[1,0]<stdout>:DLL 2021-12-17 10:42:16.332163 - Epoch: 1 Iteration: 419  train.loss : 6.565199089050293  train.ips : 346.79910701981646  train.lr : 0.043286227544910176 
[1,0]<stdout>:DLL 2021-12-17 10:42:22.601444 - Epoch: 1 Iteration: 439  train.loss : 6.57743661403656  train.ips : 306.26941736744936  train.lr : 0.044435928143712576 
[1,0]<stdout>:DLL 2021-12-17 10:42:28.049297 - Epoch: 1 Iteration: 459  train.loss : 6.5917939901351925  train.ips : 352.4517228551296  train.lr : 0.04558562874251497 
[1,0]<stdout>:DLL 2021-12-17 10:42:34.040034 - Epoch: 1 Iteration: 479  train.loss : 6.535533452033997  train.ips : 320.5114515173449  train.lr : 0.04673532934131736 
[1,0]<stderr>:2021-12-17 10:42:40,082:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-12-17 10:42:40.082304 - Epoch: 1 Iteration: 499  train.loss : 6.547101998329163  train.ips : 317.773423855492  train.lr : 0.04788502994011976 
[1,0]<stdout>:DLL 2021-12-17 10:42:40.082678 - Epoch: 1  train.loss : 6.603873184204102  train.ips : 363.0626147943972 
[1,0]<stdout>:DLL 2021-12-17 10:42:45.163969 - Epoch: 2 Iteration: 19  train.loss : 6.550424599647522  train.ips : 377.86543798729616  train.lr : 0.039492215568862274 
[1,0]<stdout>:DLL 2021-12-17 10:42:51.785054 - Epoch: 2 Iteration: 39  train.loss : 6.479319787025451  train.ips : 289.9941529891614  train.lr : 0.040641916167664674 
[1,0]<stdout>:DLL 2021-12-17 10:42:57.358856 - Epoch: 2 Iteration: 59  train.loss : 6.504287123680115  train.ips : 344.48467331236355  train.lr : 0.04179161676646707 
[1,0]<stdout>:DLL 2021-12-17 10:43:03.825983 - Epoch: 2 Iteration: 79  train.loss : 6.4763213157653805  train.ips : 296.8978669091086  train.lr : 0.04294131736526947 
[1,0]<stdout>:DLL 2021-12-17 10:43:09.924789 - Epoch: 2 Iteration: 99  train.loss : 6.483195090293885  train.ips : 314.82931210124246  train.lr : 0.04409101796407185 
[1,0]<stdout>:DLL 2021-12-17 10:43:15.750837 - Epoch: 2 Iteration: 119  train.loss : 6.490644240379334  train.ips : 329.5752319193932  train.lr : 0.045240718562874246 
[1,0]<stdout>:DLL 2021-12-17 10:43:22.512508 - Epoch: 2 Iteration: 139  train.loss : 6.486709213256836  train.ips : 283.96542073959415  train.lr : 0.046390419161676646 
[1,0]<stdout>:DLL 2021-12-17 10:43:27.611508 - Epoch: 2 Iteration: 159  train.loss : 6.464474368095398  train.ips : 376.5629450402942  train.lr : 0.04754011976047904 
[1,0]<stdout>:DLL 2021-12-17 10:43:34.139295 - Epoch: 2 Iteration: 179  train.loss : 6.423434853553772  train.ips : 294.13645208280053  train.lr : 0.04868982035928144 
[1,0]<stdout>:DLL 2021-12-17 10:43:39.199538 - Epoch: 2 Iteration: 199  train.loss : 6.454382038116455  train.ips : 379.44784249585274  train.lr : 0.04983952095808383 
[1,0]<stdout>:DLL 2021-12-17 10:43:44.267611 - Epoch: 2 Iteration: 219  train.loss : 6.454500985145569  train.ips : 378.85819919720143  train.lr : 0.05098922155688623 
[1,0]<stdout>:DLL 2021-12-17 10:43:49.339056 - Epoch: 2 Iteration: 239  train.loss : 6.44044132232666  train.ips : 378.60637847738724  train.lr : 0.052138922155688626 
[1,0]<stdout>:DLL 2021-12-17 10:43:54.409555 - Epoch: 2 Iteration: 259  train.loss : 6.448155927658081  train.ips : 378.67725268040294  train.lr : 0.05328862275449101 
[1,0]<stdout>:DLL 2021-12-17 10:43:59.490804 - Epoch: 2 Iteration: 279  train.loss : 6.443079543113709  train.ips : 377.8796049342906  train.lr : 0.05443832335329342 
[1,0]<stdout>:DLL 2021-12-17 10:44:04.562675 - Epoch: 2 Iteration: 299  train.loss : 6.418426966667175  train.ips : 378.58156720528905  train.lr : 0.05558802395209581 
[1,0]<stdout>:DLL 2021-12-17 10:44:09.637788 - Epoch: 2 Iteration: 319  train.loss : 6.437126278877258  train.ips : 378.3354106459445  train.lr : 0.056737724550898205 
[1,0]<stdout>:DLL 2021-12-17 10:44:14.699590 - Epoch: 2 Iteration: 339  train.loss : 6.45802936553955  train.ips : 379.3299493017026  train.lr : 0.0578874251497006 
[1,0]<stdout>:DLL 2021-12-17 10:44:19.774425 - Epoch: 2 Iteration: 359  train.loss : 6.405314230918885  train.ips : 378.35279472383144  train.lr : 0.05903712574850299 
[1,0]<stdout>:DLL 2021-12-17 10:44:24.836029 - Epoch: 2 Iteration: 379  train.loss : 6.436742496490479  train.ips : 379.3441369324939  train.lr : 0.06018682634730539 
[1,0]<stdout>:DLL 2021-12-17 10:44:29.907493 - Epoch: 2 Iteration: 399  train.loss : 6.415138483047485  train.ips : 378.60365513010476  train.lr : 0.061336526946107785 
[1,0]<stdout>:DLL 2021-12-17 10:44:34.961579 - Epoch: 2 Iteration: 419  train.loss : 6.436981606483459  train.ips : 379.9079076170155  train.lr : 0.06248622754491018 
[1,0]<stdout>:DLL 2021-12-17 10:44:40.033911 - Epoch: 2 Iteration: 439  train.loss : 6.403883266448974  train.ips : 378.5380218529358  train.lr : 0.06363592814371258 
[1,0]<stdout>:DLL 2021-12-17 10:44:45.103149 - Epoch: 2 Iteration: 459  train.loss : 6.375962400436402  train.ips : 378.77273712006496  train.lr : 0.06478562874251496 
[1,0]<stdout>:DLL 2021-12-17 10:44:50.173951 - Epoch: 2 Iteration: 479  train.loss : 6.3820994853973385  train.ips : 378.64958348169887  train.lr : 0.06593532934131736 
[1,0]<stdout>:DLL 2021-12-17 10:44:55.239314 - Epoch: 2 Iteration: 499  train.loss : 6.369349503517151  train.ips : 379.0596044744589  train.lr : 0.06708502994011976 
[1,0]<stdout>:DLL 2021-12-17 10:44:55.239710 - Epoch: 2  train.loss : 6.445536979675293  train.ips : 358.4257996502726 
[1,0]<stdout>:DLL 2021-12-17 10:44:55.409855 - Summary: train.loss : 6.445536979675293  train.ips : 367.7857647384498 
[1,0]<stdout>:DLL 2021-12-17 10:45:01.473709 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 0  fuse_bn_add_relu : 0  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float32  amp : False  batch_size : 768  num_epochs : 3  run_epochs : -1  lr : 0.768  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp32.json-8,96  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [3, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NCHW  batchnorm_layout : NCHW  pooling_layout : NCHW  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,3]<stderr>:[10:45:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,3]<stderr>:CPU
[1,7]<stderr>:[10:45:01[1,7]<stderr>:] ../src/storage/storage.cc:199: [1,7]<stderr>:Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[[1,4]<stderr>:10:45:01] ../src/storage/storage.cc:199[1,4]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:10:45:01] ../src/storage/storage.cc:[1,5]<stderr>:[[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:10:45:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[[1,0]<stderr>:10:45:01] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[10:45:01] ../src/storage/storage.cc:[1,1]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:[10:45:01[1,2]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[10:45:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,4]<stderr>:[10:45:05[1,4]<stderr>:] ../src/storage/storage.cc:[1,4]<stderr>:199: Using [1,4]<stderr>:Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[10:45:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[10:45:05] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[10:45:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:[10:45:05] ../src/storage/storage.cc[1,5]<stderr>::199: Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[[1,6]<stderr>:10:45:05] ../src/storage/storage.cc:199[1,6]<stderr>:: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[[1,1]<stderr>:10:45:05] [1,1]<stderr>:../src/storage/storage.cc:[1,1]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-12-17 10:45:09,379:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-12-17 10:45:09,379:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2021-12-17 10:45:09,860:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2021-12-17 10:45:09,861:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2021-12-17 10:45:09,977:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2021-12-17 10:45:09,978:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2021-12-17 10:45:10,124:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2021-12-17 10:45:10,124:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2021-12-17 10:45:10,298:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2021-12-17 10:45:10,299:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2021-12-17 10:45:10,415:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2021-12-17 10:45:10,415:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2021-12-17 10:45:10,459:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2021-12-17 10:45:10,460:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2021-12-17 10:45:10,607:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2021-12-17 10:45:10,608:INFO: Starting epoch 0
[1,0]<stderr>:[131c8fb9bb8a:18164] Read -1, expected 5649, errno = 1
[1,0]<stderr>:[131c8fb9bb8a:18164] Read -1, expected 27889, errno = 1
[1,0]<stderr>:[131c8fb9bb8a:18164] Read -1, expected 20457, errno = 1
[1,6]<stderr>:[131c8fb9bb8a:18170] Read -1, expected 18577, errno = 1
[1,5]<stderr>:[131c8fb9bb8a:18169] Read -1, expected 18576, errno = 1
[1,2]<stderr>:[131c8fb9bb8a:18166] Read -1, expected 18577, errno = 1
[1,3]<stderr>:[131c8fb9bb8a:18167] Read -1, expected 18576, errno = 1
[1,1]<stderr>:[131c8fb9bb8a:18165] Read -1, expected 18576, errno = 1
[1,7]<stderr>:[131c8fb9bb8a:18171] Read -1, expected 18576, errno = 1
[1,4]<stderr>:[131c8fb9bb8a:18168] Read -1, expected 18577, errno = 1
[1,3]<stderr>:[10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,5]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,4]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)[1,7]<stderr>:
[1,1]<stderr>:[[1,1]<stderr>:10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,1]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,2]<stderr>:[10:45:12] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:[10:45:12] [1,0]<stderr>:../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-12-17 10:45:24.293944 - Epoch: 0 Iteration: 19  train.loss : 7.019954657554626  train.ips : 1029.8787063007187  train.lr : 0.06948571428571429 
[1,0]<stdout>:DLL 2021-12-17 10:45:29.477741 - Epoch: 0 Iteration: 39  train.loss : 6.860283327102661  train.ips : 2963.573980132932  train.lr : 0.14262857142857144 
[1,0]<stdout>:DLL 2021-12-17 10:45:34.638397 - Epoch: 0 Iteration: 59  train.loss : 6.774400448799133  train.ips : 2976.4877823544143  train.lr : 0.21577142857142856 
[1,0]<stdout>:DLL 2021-12-17 10:45:39.816721 - Epoch: 0 Iteration: 79  train.loss : 6.696856164932251  train.ips : 2966.3437224989525  train.lr : 0.28891428571428573 
[1,0]<stdout>:DLL 2021-12-17 10:45:44.980816 - Epoch: 0 Iteration: 99  train.loss : 6.622330617904663  train.ips : 2974.581777312409  train.lr : 0.36205714285714286 
[1,0]<stdout>:DLL 2021-12-17 10:45:50.153276 - Epoch: 0 Iteration: 119  train.loss : 6.6326072931289675  train.ips : 2969.739333034567  train.lr : 0.43520000000000003 
[1,0]<stdout>:DLL 2021-12-17 10:45:55.324195 - Epoch: 0 Iteration: 139  train.loss : 6.489883780479431  train.ips : 2970.6180440379667  train.lr : 0.5083428571428572 
[1,0]<stdout>:DLL 2021-12-17 10:46:00.511617 - Epoch: 0 Iteration: 159  train.loss : 6.475143647193908  train.ips : 2961.159016346274  train.lr : 0.5814857142857143 
[1,0]<stdout>:DLL 2021-12-17 10:46:05.681761 - Epoch: 0 Iteration: 179  train.loss : 6.407799935340881  train.ips : 2971.0043648387013  train.lr : 0.6546285714285714 
[1,0]<stdout>:DLL 2021-12-17 10:46:10.863349 - Epoch: 0 Iteration: 199  train.loss : 6.324965476989746  train.ips : 2964.512476516672  train.lr : 0.7277714285714285 
[1,0]<stdout>:DLL 2021-12-17 10:46:16.048981 - Epoch: 0 Iteration: 219  train.loss : 6.319107580184936  train.ips : 2962.2481162970225  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:21.233851 - Epoch: 0 Iteration: 239  train.loss : 6.3034874439239506  train.ips : 2962.6355328128466  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:26.414845 - Epoch: 0 Iteration: 259  train.loss : 6.3300316572189335  train.ips : 2965.221583939768  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:31.595639 - Epoch: 0 Iteration: 279  train.loss : 6.312304735183716  train.ips : 2965.306339304787  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:36.780376 - Epoch: 0 Iteration: 299  train.loss : 6.278108096122741  train.ips : 2963.1472031908866  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:41.955231 - Epoch: 0 Iteration: 319  train.loss : 6.278162670135498  train.ips : 2968.457186711458  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:47.125261 - Epoch: 0 Iteration: 339  train.loss : 6.30975079536438  train.ips : 2971.4345046570584  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:52.296694 - Epoch: 0 Iteration: 359  train.loss : 6.31382646560669  train.ips : 2970.3235761667997  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:46:57.472285 - Epoch: 0 Iteration: 379  train.loss : 6.315584325790406  train.ips : 2968.3182286213573  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:47:02.649961 - Epoch: 0 Iteration: 399  train.loss : 6.307510852813721  train.ips : 2966.752157364456  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:47:07.841632 - Epoch: 0 Iteration: 419  train.loss : 6.308178186416626  train.ips : 2958.8653926677357  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:47:13.056171 - Epoch: 0 Iteration: 439  train.loss : 6.28952009677887  train.ips : 2945.753617074628  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:47:18.242490 - Epoch: 0 Iteration: 459  train.loss : 6.328402996063232  train.ips : 2962.1620374974636  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:47:23.437080 - Epoch: 0 Iteration: 479  train.loss : 6.334304356575013  train.ips : 2957.0720041155596  train.lr : 0 
[1,7]<stderr>:2021-12-17 10:47:28,635:INFO: Starting epoch 1
[1,3]<stderr>:2021-12-17 10:47:28,635:INFO: Starting epoch 1
[1,1]<stderr>:2021-12-17 10:47:28,635:INFO: Starting epoch 1
[1,2]<stderr>:2021-12-17 10:47:28,635:INFO: Starting epoch 1
[1,4]<stderr>:2021-12-17 10:47:28,635:INFO: Starting epoch 1
[1,6]<stderr>:2021-12-17 10:47:28,636:INFO: Starting epoch 1
[1,0]<stderr>:2021-12-17 10:47:28,637:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-12-17 10:47:28.635898 - Epoch: 0 Iteration: 499  train.loss : 6.326627635955811  train.ips : 2954.6386225872043  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:47:28.637313 - Epoch: 0  train.loss : 6.438365329742432  train.ips : 2964.483063155672 
[1,5]<stderr>:2021-12-17 10:47:28,638:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-12-17 10:47:33.831050 - Epoch: 1 Iteration: 19  train.loss : 6.219894576072693  train.ips : 2957.4632268724154  train.lr : 0.22308571428571428 
[1,0]<stdout>:DLL 2021-12-17 10:47:39.028326 - Epoch: 1 Iteration: 39  train.loss : 6.150635194778443  train.ips : 2961.4410516360654  train.lr : 0.2962285714285714 
[1,0]<stdout>:DLL 2021-12-17 10:47:44.211803 - Epoch: 1 Iteration: 59  train.loss : 6.148677802085876  train.ips : 2963.4349335819834  train.lr : 0.3693714285714286 
[1,0]<stdout>:DLL 2021-12-17 10:47:49.410707 - Epoch: 1 Iteration: 79  train.loss : 6.062019777297974  train.ips : 2958.2121600458  train.lr : 0.44251428571428575 
[1,0]<stdout>:DLL 2021-12-17 10:47:54.599416 - Epoch: 1 Iteration: 99  train.loss : 6.136489605903625  train.ips : 2960.381791755716  train.lr : 0.5156571428571428 
[1,0]<stdout>:DLL 2021-12-17 10:47:59.781508 - Epoch: 1 Iteration: 119  train.loss : 6.130291390419006  train.ips : 2964.1716198731174  train.lr : 0.5888000000000001 
[1,0]<stdout>:DLL 2021-12-17 10:48:04.984028 - Epoch: 1 Iteration: 139  train.loss : 6.1007301807403564  train.ips : 2952.548977282867  train.lr : 0.6619428571428572 
[1,0]<stdout>:DLL 2021-12-17 10:48:10.217054 - Epoch: 1 Iteration: 159  train.loss : 6.058903765678406  train.ips : 2935.3184137377502  train.lr : 0.7350857142857142 
[1,0]<stdout>:DLL 2021-12-17 10:48:15.418027 - Epoch: 1 Iteration: 179  train.loss : 6.012040638923645  train.ips : 2953.456537304056  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:20.620623 - Epoch: 1 Iteration: 199  train.loss : 6.0534303188323975  train.ips : 2952.531115927772  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:25.810632 - Epoch: 1 Iteration: 219  train.loss : 6.048495960235596  train.ips : 2959.6782601948426  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:31.021001 - Epoch: 1 Iteration: 239  train.loss : 6.0460106372833256  train.ips : 2948.0937272599226  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:36.196978 - Epoch: 1 Iteration: 259  train.loss : 6.021267294883728  train.ips : 2967.696495825086  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:41.416191 - Epoch: 1 Iteration: 279  train.loss : 6.0510828495025635  train.ips : 2943.099077461039  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:46.600574 - Epoch: 1 Iteration: 299  train.loss : 6.059840106964112  train.ips : 2962.9117174818134  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:51.795216 - Epoch: 1 Iteration: 319  train.loss : 6.025914001464844  train.ips : 2957.0141846881816  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:48:56.980626 - Epoch: 1 Iteration: 339  train.loss : 6.084084367752075  train.ips : 2962.3292964574134  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:02.195960 - Epoch: 1 Iteration: 359  train.loss : 6.054757237434387  train.ips : 2945.2556103603565  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:07.398508 - Epoch: 1 Iteration: 379  train.loss : 6.079196047782898  train.ips : 2952.531251240256  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:12.620963 - Epoch: 1 Iteration: 399  train.loss : 6.022604393959045  train.ips : 2941.423045965946  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:17.812454 - Epoch: 1 Iteration: 419  train.loss : 6.0413083791732785  train.ips : 2958.8435139451803  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:23.040236 - Epoch: 1 Iteration: 439  train.loss : 6.088097047805786  train.ips : 2938.310267859179  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:28.234515 - Epoch: 1 Iteration: 459  train.loss : 6.083151149749756  train.ips : 2957.2255215945206  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:33.444347 - Epoch: 1 Iteration: 479  train.loss : 6.075991797447204  train.ips : 2948.3893360716684  train.lr : 0 
[1,6]<stderr>:2021-12-17 10:49:38,636:INFO: Starting epoch 2
[1,2]<stderr>:2021-12-17 10:49:38,636:INFO: Starting epoch 2
[1,3]<stderr>:2021-12-17 10:49:38,637:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-12-17 10:49:38.636762 - Epoch: 1 Iteration: 499  train.loss : 6.100403475761413  train.ips : 2958.330747615478  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:49:38.637356 - Epoch: 1  train.loss : 6.078212719917297  train.ips : 2957.5640218708218 
[1,0]<stderr>:2021-12-17 10:49:38,637:INFO: Starting epoch 2
[1,5]<stderr>:2021-12-17 10:49:38,637:INFO: Starting epoch 2
[1,7]<stderr>:2021-12-17 10:49:38,637:INFO: Starting epoch 2
[1,1]<stderr>:2021-12-17 10:49:38,638:INFO: Starting epoch 2
[1,4]<stderr>:2021-12-17 10:49:38,650:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-12-17 10:49:43.847034 - Epoch: 2 Iteration: 19  train.loss : 6.2027127027511595  train.ips : 2948.4097111126853  train.lr : 0.37668571428571435 
[1,0]<stdout>:DLL 2021-12-17 10:49:49.065243 - Epoch: 2 Iteration: 39  train.loss : 5.998226189613343  train.ips : 2943.6576859864376  train.lr : 0.4498285714285715 
[1,0]<stdout>:DLL 2021-12-17 10:49:54.270836 - Epoch: 2 Iteration: 59  train.loss : 5.985575699806214  train.ips : 2950.805267492019  train.lr : 0.5229714285714285 
[1,0]<stdout>:DLL 2021-12-17 10:49:59.473234 - Epoch: 2 Iteration: 79  train.loss : 5.882125902175903  train.ips : 2952.980015655841  train.lr : 0.5961142857142857 
[1,0]<stdout>:DLL 2021-12-17 10:50:04.677783 - Epoch: 2 Iteration: 99  train.loss : 5.889499378204346  train.ips : 2951.3922243450825  train.lr : 0.6692571428571429 
[1,0]<stdout>:DLL 2021-12-17 10:50:09.903806 - Epoch: 2 Iteration: 119  train.loss : 5.928204727172852  train.ips : 2939.2486525204504  train.lr : 0.7424000000000002 
[1,0]<stdout>:DLL 2021-12-17 10:50:15.108101 - Epoch: 2 Iteration: 139  train.loss : 5.952765464782715  train.ips : 2951.9972694332823  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:20.318008 - Epoch: 2 Iteration: 159  train.loss : 5.875123500823975  train.ips : 2948.3560079692484  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:25.532246 - Epoch: 2 Iteration: 179  train.loss : 5.832170796394348  train.ips : 2946.0348807698483  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:30.760364 - Epoch: 2 Iteration: 199  train.loss : 5.92066867351532  train.ips : 2938.1119432594614  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:35.961386 - Epoch: 2 Iteration: 219  train.loss : 5.890444564819336  train.ips : 2953.437311010663  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:41.170167 - Epoch: 2 Iteration: 239  train.loss : 5.905793166160583  train.ips : 2949.0075942845074  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:46.383667 - Epoch: 2 Iteration: 259  train.loss : 5.913823390007019  train.ips : 2946.3411259256804  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:51.597760 - Epoch: 2 Iteration: 279  train.loss : 5.8811540603637695  train.ips : 2946.0067250403426  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:50:56.816158 - Epoch: 2 Iteration: 299  train.loss : 5.932714056968689  train.ips : 2944.0136170063424  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:02.026844 - Epoch: 2 Iteration: 319  train.loss : 5.91661422252655  train.ips : 2947.9234856457797  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:07.234751 - Epoch: 2 Iteration: 339  train.loss : 5.941947054862976  train.ips : 2949.48675060319  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:12.464567 - Epoch: 2 Iteration: 359  train.loss : 5.872161269187927  train.ips : 2937.1647766773526  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:17.664000 - Epoch: 2 Iteration: 379  train.loss : 5.929164791107178  train.ips : 2954.322927999587  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:22.869201 - Epoch: 2 Iteration: 399  train.loss : 5.886165499687195  train.ips : 2951.0347774023357  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:28.075284 - Epoch: 2 Iteration: 419  train.loss : 5.9763614416122435  train.ips : 2950.671741051565  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:33.282283 - Epoch: 2 Iteration: 439  train.loss : 5.891036820411682  train.ips : 2950.0334678522204  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:38.490021 - Epoch: 2 Iteration: 459  train.loss : 5.9012772798538204  train.ips : 2949.6382660619156  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:43.711206 - Epoch: 2 Iteration: 479  train.loss : 5.919171547889709  train.ips : 2941.9695989136753  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:48.911504 - Epoch: 2 Iteration: 499  train.loss : 5.923636841773987  train.ips : 2953.8266245310465  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:51:48.911956 - Epoch: 2  train.loss : 5.925941561698914  train.ips : 2953.072198127676 
[1,0]<stdout>:DLL 2021-12-17 10:51:49.087062 - Summary: train.loss : 5.925941561698914  train.ips : 2958.3730943847236 
train.ips
           |     96    |
------------------------
     1     |   360.73  |
     8     |   2955.3  |

