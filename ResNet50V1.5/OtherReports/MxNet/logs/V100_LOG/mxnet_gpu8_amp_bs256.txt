[1,0]<stdout>:DLL 2023-07-31 06:24:28.055105 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 2048  num_epochs : 3  run_epochs : -1  lr : 2.048  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,256  workspace : ./  logdir : None  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 6  dali_validation_threads : 10  dali_prefetch_queue : 5  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,7]<stderr>:[06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:[[1,5]<stderr>:06:24:28] ../src/storage/storage.cc:[1,0]<stderr>:[[1,5]<stderr>:196: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:[[1,3]<stderr>:06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU[1,3]<stderr>:
[1,2]<stderr>:[[1,2]<stderr>:06:24:28] ../src/storage/storage.cc:196: Using Pooled (Naive)[1,2]<stderr>: StorageManager for CPU
[1,7]<stderr>:2023-07-31 06:24:28,089:INFO: starting epoch 0
[1,0]<stderr>:2023-07-31 06:24:28,089:INFO: starting epoch 0
[1,3]<stderr>:2023-07-31 06:24:28,089:INFO: starting epoch 0
[1,5]<stderr>:2023-07-31 06:24:28,089:INFO: starting epoch 0
[1,4]<stderr>:2023-07-31 06:24:28,090:INFO: starting epoch 0
[1,6]<stderr>:2023-07-31 06:24:28,090:INFO: starting epoch 0
[1,1]<stderr>:2023-07-31 06:24:28,090:INFO: starting epoch 0
[1,2]<stderr>:2023-07-31 06:24:28,090:INFO: starting epoch 0
[1,3]<stderr>:[06:24:32] ../src/storage/storage.cc:[1,3]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[[1,0]<stderr>:06:24:33] ../src/storage/storage.cc:[1,0]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[06:24:33[1,7]<stderr>:] ../src/storage/storage.cc:[1,7]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:[[1,5]<stderr>:06:24:33] ../src/storage/storage.cc:[1,5]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[[1,1]<stderr>:06:24:33] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for [1,1]<stderr>:GPU
[1,2]<stderr>:[06:24:33] [1,2]<stderr>:../src/storage/storage.cc:196: [1,2]<stderr>:Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[[1,6]<stderr>:06:24:33] ../src/storage/storage.cc:[1,6]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,4]<stderr>:[[1,4]<stderr>:06:24:33] ../src/storage/storage.cc:[1,4]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self,
[1,0]<stderr>:2023-07-31 06:25:09,181:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,0]<stderr>:2023-07-31 06:25:09,182:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self,
[1,1]<stderr>:2023-07-31 06:25:09,191:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,1]<stderr>:2023-07-31 06:25:09,191:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self,
[1,3]<stderr>:2023-07-31 06:25:09,315:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,3]<stderr>:2023-07-31 06:25:09,315:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self,
[1,2]<stderr>:2023-07-31 06:25:09,541:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,2]<stderr>:2023-07-31 06:25:09,541:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self,
[1,7]<stderr>:2023-07-31 06:25:09,687:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,7]<stderr>:2023-07-31 06:25:09,688:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self,
[1,4]<stderr>:2023-07-31 06:25:09,693:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,4]<stderr>:2023-07-31 06:25:09,693:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self,
[1,5]<stderr>:2023-07-31 06:25:09,758:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,5]<stderr>:2023-07-31 06:25:09,759:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self,
[1,6]<stderr>:2023-07-31 06:25:09,801:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,6]<stderr>:2023-07-31 06:25:09,801:INFO: Starting epoch 0
[1,0]<stdout>:DLL 2023-07-31 06:25:50.928623 - Epoch: 0 Iteration: 19  train.loss : 6.951127123832703  train.ips : 981.1551882476497 images/s train.lr : 0.4864 
[1,0]<stdout>:DLL 2023-07-31 06:25:54.436868 - Epoch: 0 Iteration: 39  train.loss : 6.67905101776123  train.ips : 11677.433381196674 images/s train.lr : 0.9984 
[1,0]<stdout>:DLL 2023-07-31 06:25:57.946609 - Epoch: 0 Iteration: 59  train.loss : 6.575800657272339  train.ips : 11673.489062577717 images/s train.lr : 1.5104000000000002 
[1,0]<stdout>:DLL 2023-07-31 06:26:01.463673 - Epoch: 0 Iteration: 79  train.loss : 6.433890247344971  train.ips : 11647.725082305906 images/s train.lr : 2.0224 
[1,0]<stdout>:DLL 2023-07-31 06:26:04.985865 - Epoch: 0 Iteration: 99  train.loss : 6.371418476104736  train.ips : 11630.293302253993 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:08.524508 - Epoch: 0 Iteration: 119  train.loss : 6.354049181938171  train.ips : 11576.303775305332 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:12.062509 - Epoch: 0 Iteration: 139  train.loss : 6.36797034740448  train.ips : 11579.03379843256 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:15.609491 - Epoch: 0 Iteration: 159  train.loss : 6.3525712251663204  train.ips : 11552.795793835763 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:19.134660 - Epoch: 0 Iteration: 179  train.loss : 6.353081297874451  train.ips : 11620.362428200764 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:22.654754 - Epoch: 0 Iteration: 199  train.loss : 6.341595387458801  train.ips : 11637.259118756085 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:26.202452 - Epoch: 0 Iteration: 219  train.loss : 6.3500508069992065  train.ips : 11546.684200554393 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:29.703494 - Epoch: 0 Iteration: 239  train.loss : 6.379950332641601  train.ips : 11700.305881559721 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:33.232346 - Epoch: 0 Iteration: 259  train.loss : 6.347925543785095  train.ips : 11607.848738444258 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:36.771307 - Epoch: 0 Iteration: 279  train.loss : 6.361619687080383  train.ips : 11574.889725428455 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:40.313053 - Epoch: 0 Iteration: 299  train.loss : 6.344442200660706  train.ips : 11565.830227264909 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:43.845915 - Epoch: 0 Iteration: 319  train.loss : 6.340886640548706  train.ips : 11594.824338760964 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:47.391694 - Epoch: 0 Iteration: 339  train.loss : 6.339148235321045  train.ips : 11552.729759352385 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:50.923123 - Epoch: 0 Iteration: 359  train.loss : 6.3627265930175785  train.ips : 11599.451016353933 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:54.465978 - Epoch: 0 Iteration: 379  train.loss : 6.373862528800965  train.ips : 11562.065975212168 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:26:57.998423 - Epoch: 0 Iteration: 399  train.loss : 6.351781010627747  train.ips : 11596.024102094387 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:01.535185 - Epoch: 0 Iteration: 419  train.loss : 6.357872271537781  train.ips : 11582.752101732665 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:05.066132 - Epoch: 0 Iteration: 439  train.loss : 6.377409148216247  train.ips : 11601.344242731682 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:08.610440 - Epoch: 0 Iteration: 459  train.loss : 6.354661965370179  train.ips : 11557.382764326352 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:12.156639 - Epoch: 0 Iteration: 479  train.loss : 6.367454409599304  train.ips : 11551.285735129288 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:15.669991 - Epoch: 0 Iteration: 499  train.loss : 6.376170945167542  train.ips : 11659.410144727772 images/s train.lr : 0 
[1,1]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,6]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,2]<stderr>:2023-07-31 06:27:15,674:INFO: Starting epoch 1
[1,4]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,0]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,5]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,7]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,3]<stderr>:2023-07-31 06:27:15,675:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2023-07-31 06:27:15.674897 - Epoch: 0  train.loss : 6.406660691261291  train.ips : 11596.010326494568 images/s
[1,0]<stdout>:DLL 2023-07-31 06:27:19.210118 - Epoch: 1 Iteration: 19  train.loss : 6.282749104499817  train.ips : 11586.829912269899 images/s train.lr : 0.8960000000000001 
[1,0]<stdout>:DLL 2023-07-31 06:27:22.754158 - Epoch: 1 Iteration: 39  train.loss : 6.208302068710327  train.ips : 11558.223300519525 images/s train.lr : 1.408 
[1,0]<stdout>:DLL 2023-07-31 06:27:26.304383 - Epoch: 1 Iteration: 59  train.loss : 6.181911063194275  train.ips : 11538.318917264922 images/s train.lr : 1.92 
[1,0]<stdout>:DLL 2023-07-31 06:27:29.846051 - Epoch: 1 Iteration: 79  train.loss : 6.151396560668945  train.ips : 11566.30755005563 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:33.382939 - Epoch: 1 Iteration: 99  train.loss : 6.159359455108643  train.ips : 11581.58475172311 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:36.930942 - Epoch: 1 Iteration: 119  train.loss : 6.160500836372376  train.ips : 11545.39531049084 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:40.493199 - Epoch: 1 Iteration: 139  train.loss : 6.179363751411438  train.ips : 11499.250792001869 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:44.029472 - Epoch: 1 Iteration: 159  train.loss : 6.163002848625183  train.ips : 11583.59945630836 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:47.570656 - Epoch: 1 Iteration: 179  train.loss : 6.121210646629334  train.ips : 11567.569180044324 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:51.112455 - Epoch: 1 Iteration: 199  train.loss : 6.129575705528259  train.ips : 11565.686960248404 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:54.655149 - Epoch: 1 Iteration: 219  train.loss : 6.166408967971802  train.ips : 11562.563220377402 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:27:58.198169 - Epoch: 1 Iteration: 239  train.loss : 6.167184209823608  train.ips : 11561.848881581134 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:01.737581 - Epoch: 1 Iteration: 259  train.loss : 6.169854187965393  train.ips : 11573.664702856358 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:05.282867 - Epoch: 1 Iteration: 279  train.loss : 6.158426022529602  train.ips : 11554.298476569615 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:08.835522 - Epoch: 1 Iteration: 299  train.loss : 6.132918739318848  train.ips : 11530.24123018812 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:12.379145 - Epoch: 1 Iteration: 319  train.loss : 6.173472476005554  train.ips : 11559.600613430555 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:15.916439 - Epoch: 1 Iteration: 339  train.loss : 6.162057876586914  train.ips : 11580.60342278867 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:19.454421 - Epoch: 1 Iteration: 359  train.loss : 6.1741605520248415  train.ips : 11578.456321221443 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:23.003837 - Epoch: 1 Iteration: 379  train.loss : 6.153045225143432  train.ips : 11540.793039894905 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:26.549215 - Epoch: 1 Iteration: 399  train.loss : 6.1538856506347654  train.ips : 11553.824475490708 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:35.626471 - Epoch: 1 Iteration: 419  train.loss : 6.164701390266418  train.ips : 4512.508328110289 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:43.064868 - Epoch: 1 Iteration: 439  train.loss : 6.165417885780334  train.ips : 5506.794222258279 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:46.614152 - Epoch: 1 Iteration: 459  train.loss : 6.151447296142578  train.ips : 11541.474540072433 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:28:50.145592 - Epoch: 1 Iteration: 479  train.loss : 6.141147446632385  train.ips : 11599.64132933712 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:04.400668 - Epoch: 1 Iteration: 499  train.loss : 6.167523074150085  train.ips : 2873.4075353829885 images/s train.lr : 0 
[1,3]<stderr>:2023-07-31 06:29:04,589:INFO: Starting epoch 2
[1,7]<stderr>:2023-07-31 06:29:04,589:INFO: Starting epoch 2
[1,5]<stderr>:2023-07-31 06:29:04,589:INFO: Starting epoch 2
[1,1]<stderr>:2023-07-31 06:29:04,589:INFO: Starting epoch 2
[1,2]<stderr>:2023-07-31 06:29:04,591:INFO: Starting epoch 2
[1,6]<stderr>:2023-07-31 06:29:04,592:INFO: Starting epoch 2
[1,0]<stderr>:2023-07-31 06:29:04,592:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2023-07-31 06:29:04.591886 - Epoch: 1  train.loss : 6.165560921669006  train.ips : 10213.212860934005 images/s
[1,4]<stderr>:2023-07-31 06:29:04,592:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2023-07-31 06:29:10.810244 - Epoch: 2 Iteration: 19  train.loss : 6.320074248313904  train.ips : 6587.187509861206 images/s train.lr : 1.3056 
[1,0]<stdout>:DLL 2023-07-31 06:29:14.349609 - Epoch: 2 Iteration: 39  train.loss : 6.092155599594117  train.ips : 11573.879121566875 images/s train.lr : 1.8176 
[1,0]<stdout>:DLL 2023-07-31 06:29:17.890792 - Epoch: 2 Iteration: 59  train.loss : 6.060409951210022  train.ips : 11859.447211631514 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:21.441067 - Epoch: 2 Iteration: 79  train.loss : 6.048414015769959  train.ips : 11538.119762431126 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:24.989368 - Epoch: 2 Iteration: 99  train.loss : 6.013015961647033  train.ips : 11544.756016053112 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:28.534552 - Epoch: 2 Iteration: 119  train.loss : 6.036999964714051  train.ips : 11554.704128047004 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:32.090154 - Epoch: 2 Iteration: 139  train.loss : 6.007228398323059  train.ips : 11520.773214735973 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:35.630549 - Epoch: 2 Iteration: 159  train.loss : 6.030879020690918  train.ips : 11570.548341755382 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:39.176425 - Epoch: 2 Iteration: 179  train.loss : 6.023065829277039  train.ips : 11552.185974665284 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:42.718521 - Epoch: 2 Iteration: 199  train.loss : 6.040925645828247  train.ips : 11564.975349518363 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:46.269543 - Epoch: 2 Iteration: 219  train.loss : 6.037574672698975  train.ips : 11535.788534896697 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:49.829912 - Epoch: 2 Iteration: 239  train.loss : 6.0478060960769655  train.ips : 11505.42013486625 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:53.483507 - Epoch: 2 Iteration: 259  train.loss : 6.02668137550354  train.ips : 11211.814643407086 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:29:57.036431 - Epoch: 2 Iteration: 279  train.loss : 6.048459219932556  train.ips : 11529.549449560487 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:00.580628 - Epoch: 2 Iteration: 299  train.loss : 6.048148179054261  train.ips : 11557.7816344375 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:04.128950 - Epoch: 2 Iteration: 319  train.loss : 6.024666476249695  train.ips : 11544.476734879947 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:07.679533 - Epoch: 2 Iteration: 339  train.loss : 6.035988736152649  train.ips : 11537.006326867233 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:11.230938 - Epoch: 2 Iteration: 359  train.loss : 6.0169782638549805  train.ips : 11534.389785850808 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:14.779676 - Epoch: 2 Iteration: 379  train.loss : 6.030162644386292  train.ips : 11543.129393082763 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:18.324718 - Epoch: 2 Iteration: 399  train.loss : 6.033887791633606  train.ips : 11555.133901009953 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:21.872286 - Epoch: 2 Iteration: 419  train.loss : 6.056687879562378  train.ips : 11546.923231665642 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:25.425946 - Epoch: 2 Iteration: 439  train.loss : 6.062163996696472  train.ips : 11527.243340081093 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:28.973791 - Epoch: 2 Iteration: 459  train.loss : 6.039951348304749  train.ips : 11545.98578972691 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:32.934031 - Epoch: 2 Iteration: 479  train.loss : 6.052942609786987  train.ips : 10343.614842754785 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:36.480805 - Epoch: 2 Iteration: 499  train.loss : 6.017586946487427  train.ips : 11549.460831029699 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 06:30:36.574038 - Epoch: 2  train.loss : 6.0501141948699955  train.ips : 10461.071470021281 images/s
[1,0]<stdout>:DLL 2023-07-31 06:30:36.590096 - Summary: train.loss : 6.0501141948699955  train.ips : 10756.764885816618 images/s
train.ips
           |    256    |
------------------------
     8     |   10336   |

