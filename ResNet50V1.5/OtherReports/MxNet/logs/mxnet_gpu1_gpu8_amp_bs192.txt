[1,0]<stdout>:DLL 2021-05-28 09:58:18.884286 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float16  amp : False  batch_size : 192  num_epochs : 3  run_epochs : -1  lr : 0.192  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-1,192  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 3  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[[1,0]<stderr>:09:58:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[09:58:20] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-05-28 09:58:24,631:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-05-28 09:58:24,631:INFO: Starting epoch 0
[1,0]<stderr>:[09:58:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-05-28 09:58:38.270620 - Epoch: 0 Iteration: 19  train.loss : 7.113597726821899  train.ips : 281.5361396480927  train.lr : 0.004368862275449101 
[1,0]<stdout>:DLL 2021-05-28 09:58:40.980837 - Epoch: 0 Iteration: 39  train.loss : 7.0401699304580685  train.ips : 1417.0063132208477  train.lr : 0.008967664670658683 
[1,0]<stdout>:DLL 2021-05-28 09:58:43.692037 - Epoch: 0 Iteration: 59  train.loss : 6.966877722740174  train.ips : 1416.4475256336632  train.lr : 0.013566467065868264 
[1,0]<stdout>:DLL 2021-05-28 09:58:46.411577 - Epoch: 0 Iteration: 79  train.loss : 6.913946318626404  train.ips : 1412.1407335375686  train.lr : 0.018165269461077847 
[1,0]<stdout>:DLL 2021-05-28 09:58:49.135427 - Epoch: 0 Iteration: 99  train.loss : 6.870285010337829  train.ips : 1410.024609138421  train.lr : 0.022764071856287427 
[1,0]<stdout>:DLL 2021-05-28 09:58:51.855715 - Epoch: 0 Iteration: 119  train.loss : 6.863286852836609  train.ips : 1412.032653413338  train.lr : 0.027362874251497006 
[1,0]<stdout>:DLL 2021-05-28 09:58:54.583899 - Epoch: 0 Iteration: 139  train.loss : 6.842371845245362  train.ips : 1407.6785574913629  train.lr : 0.031961676646706585 
[1,0]<stdout>:DLL 2021-05-28 09:58:57.310083 - Epoch: 0 Iteration: 159  train.loss : 6.80492479801178  train.ips : 1408.7732800873841  train.lr : 0.036560479041916165 
[1,0]<stdout>:DLL 2021-05-28 09:59:00.036833 - Epoch: 0 Iteration: 179  train.loss : 6.787103581428528  train.ips : 1408.6415672268565  train.lr : 0.041159281437125744 
[1,0]<stdout>:DLL 2021-05-28 09:59:02.766111 - Epoch: 0 Iteration: 199  train.loss : 6.7872813701629635  train.ips : 1407.392444688455  train.lr : 0.04575808383233533 
[1,0]<stdout>:DLL 2021-05-28 09:59:05.496194 - Epoch: 0 Iteration: 219  train.loss : 6.754218411445618  train.ips : 1406.6945027990869  train.lr : 0.05035688622754492 
[1,0]<stdout>:DLL 2021-05-28 09:59:08.230649 - Epoch: 0 Iteration: 239  train.loss : 6.768594527244568  train.ips : 1404.4507429813552  train.lr : 0.054955688622754496 
[1,0]<stdout>:DLL 2021-05-28 09:59:10.964327 - Epoch: 0 Iteration: 259  train.loss : 6.720275616645813  train.ips : 1404.853777649499  train.lr : 0.059554491017964076 
[1,0]<stdout>:DLL 2021-05-28 09:59:13.700018 - Epoch: 0 Iteration: 279  train.loss : 6.718229007720947  train.ips : 1403.9008330506988  train.lr : 0.06415329341317365 
[1,0]<stdout>:DLL 2021-05-28 09:59:16.430843 - Epoch: 0 Iteration: 299  train.loss : 6.680557227134704  train.ips : 1406.4993062745475  train.lr : 0.06875209580838323 
[1,0]<stdout>:DLL 2021-05-28 09:59:19.165515 - Epoch: 0 Iteration: 319  train.loss : 6.6851826190948485  train.ips : 1404.7172834765265  train.lr : 0.07335089820359282 
[1,0]<stdout>:DLL 2021-05-28 09:59:21.900433 - Epoch: 0 Iteration: 339  train.loss : 6.6774650573730465  train.ips : 1404.211114400888  train.lr : 0.0779497005988024 
[1,0]<stdout>:DLL 2021-05-28 09:59:24.635574 - Epoch: 0 Iteration: 359  train.loss : 6.656642889976501  train.ips : 1404.027009827937  train.lr : 0.08254850299401198 
[1,0]<stdout>:DLL 2021-05-28 09:59:27.374179 - Epoch: 0 Iteration: 379  train.loss : 6.612198209762573  train.ips : 1402.257834920924  train.lr : 0.08714730538922155 
[1,0]<stdout>:DLL 2021-05-28 09:59:30.118545 - Epoch: 0 Iteration: 399  train.loss : 6.627657699584961  train.ips : 1399.3969903036962  train.lr : 0.09174610778443112 
[1,0]<stdout>:DLL 2021-05-28 09:59:32.861328 - Epoch: 0 Iteration: 419  train.loss : 6.602476620674134  train.ips : 1400.2785720297045  train.lr : 0.09634491017964072 
[1,0]<stdout>:DLL 2021-05-28 09:59:35.601592 - Epoch: 0 Iteration: 439  train.loss : 6.597123908996582  train.ips : 1401.455215175971  train.lr : 0.10094371257485031 
[1,0]<stdout>:DLL 2021-05-28 09:59:38.343398 - Epoch: 0 Iteration: 459  train.loss : 6.544668412208557  train.ips : 1400.6644763738227  train.lr : 0.10554251497005988 
[1,0]<stdout>:DLL 2021-05-28 09:59:41.085668 - Epoch: 0 Iteration: 479  train.loss : 6.570110106468201  train.ips : 1400.3938704864152  train.lr : 0.11014131736526947 
[1,0]<stdout>:DLL 2021-05-28 09:59:43.829906 - Epoch: 0 Iteration: 499  train.loss : 6.529603886604309  train.ips : 1399.547654064378  train.lr : 0.11474011976047904 
[1,0]<stdout>:DLL 2021-05-28 09:59:43.830384 - Epoch: 0  train.loss : 6.7493939743041995  train.ips : 1212.133088650056 
[1,0]<stderr>:2021-05-28 09:59:43,830:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 09:59:46.571687 - Epoch: 1 Iteration: 19  train.loss : 6.498813104629517  train.ips : 1400.869144322389  train.lr : 0.0427688622754491 
[1,0]<stdout>:DLL 2021-05-28 09:59:49.317601 - Epoch: 1 Iteration: 39  train.loss : 6.44397509098053  train.ips : 1398.5663080694362  train.lr : 0.047367664670658685 
[1,0]<stdout>:DLL 2021-05-28 09:59:52.066601 - Epoch: 1 Iteration: 59  train.loss : 6.406293749809265  train.ips : 1396.9845945198842  train.lr : 0.05196646706586826 
[1,0]<stdout>:DLL 2021-05-28 09:59:54.815297 - Epoch: 1 Iteration: 79  train.loss : 6.414478349685669  train.ips : 1397.2426113117979  train.lr : 0.05656526946107785 
[1,0]<stdout>:DLL 2021-05-28 09:59:57.563981 - Epoch: 1 Iteration: 99  train.loss : 6.381958055496216  train.ips : 1397.1680687249273  train.lr : 0.06116407185628743 
[1,0]<stdout>:DLL 2021-05-28 10:00:00.312096 - Epoch: 1 Iteration: 119  train.loss : 6.394874858856201  train.ips : 1397.459739187451  train.lr : 0.065762874251497 
[1,0]<stdout>:DLL 2021-05-28 10:00:03.058366 - Epoch: 1 Iteration: 139  train.loss : 6.392037391662598  train.ips : 1398.39582189791  train.lr : 0.07036167664670659 
[1,0]<stdout>:DLL 2021-05-28 10:00:05.805222 - Epoch: 1 Iteration: 159  train.loss : 6.405992722511291  train.ips : 1398.1256063473325  train.lr : 0.07496047904191618 
[1,0]<stdout>:DLL 2021-05-28 10:00:08.557269 - Epoch: 1 Iteration: 179  train.loss : 6.376783323287964  train.ips : 1395.5349784272585  train.lr : 0.07955928143712575 
[1,0]<stdout>:DLL 2021-05-28 10:00:11.307243 - Epoch: 1 Iteration: 199  train.loss : 6.388022184371948  train.ips : 1396.4669094323024  train.lr : 0.08415808383233532 
[1,0]<stdout>:DLL 2021-05-28 10:00:14.057395 - Epoch: 1 Iteration: 219  train.loss : 6.3904561519622805  train.ips : 1396.4193268594183  train.lr : 0.08875688622754492 
[1,0]<stdout>:DLL 2021-05-28 10:00:16.809775 - Epoch: 1 Iteration: 239  train.loss : 6.369477438926697  train.ips : 1395.2412099675882  train.lr : 0.09335568862275448 
[1,0]<stdout>:DLL 2021-05-28 10:00:19.563208 - Epoch: 1 Iteration: 259  train.loss : 6.364132213592529  train.ips : 1394.7401548455882  train.lr : 0.09795449101796408 
[1,0]<stdout>:DLL 2021-05-28 10:00:22.314546 - Epoch: 1 Iteration: 279  train.loss : 6.36862461566925  train.ips : 1395.8363707224032  train.lr : 0.10255329341317365 
[1,0]<stdout>:DLL 2021-05-28 10:00:25.066717 - Epoch: 1 Iteration: 299  train.loss : 6.323534440994263  train.ips : 1395.4695649506841  train.lr : 0.10715209580838322 
[1,0]<stdout>:DLL 2021-05-28 10:00:27.817297 - Epoch: 1 Iteration: 319  train.loss : 6.350658655166626  train.ips : 1396.2153518151392  train.lr : 0.11175089820359282 
[1,0]<stdout>:DLL 2021-05-28 10:00:30.571846 - Epoch: 1 Iteration: 339  train.loss : 6.332156491279602  train.ips : 1394.2084419493278  train.lr : 0.11634970059880241 
[1,0]<stdout>:DLL 2021-05-28 10:00:33.321011 - Epoch: 1 Iteration: 359  train.loss : 6.30895733833313  train.ips : 1396.9529700844878  train.lr : 0.12094850299401198 
[1,0]<stdout>:DLL 2021-05-28 10:00:36.070234 - Epoch: 1 Iteration: 379  train.loss : 6.313812184333801  train.ips : 1396.9699332051387  train.lr : 0.12554730538922154 
[1,0]<stdout>:DLL 2021-05-28 10:00:38.821916 - Epoch: 1 Iteration: 399  train.loss : 6.297147297859192  train.ips : 1395.6475620034014  train.lr : 0.13014610778443114 
[1,0]<stdout>:DLL 2021-05-28 10:00:41.574817 - Epoch: 1 Iteration: 419  train.loss : 6.2582333326339725  train.ips : 1394.978253114057  train.lr : 0.13474491017964071 
[1,0]<stdout>:DLL 2021-05-28 10:00:44.328899 - Epoch: 1 Iteration: 439  train.loss : 6.2886861801147464  train.ips : 1394.3880489093367  train.lr : 0.1393437125748503 
[1,0]<stdout>:DLL 2021-05-28 10:00:47.081164 - Epoch: 1 Iteration: 459  train.loss : 6.291399192810059  train.ips : 1395.3404487682965  train.lr : 0.1439425149700599 
[1,0]<stdout>:DLL 2021-05-28 10:00:49.832974 - Epoch: 1 Iteration: 479  train.loss : 6.280600476264953  train.ips : 1395.5248214039548  train.lr : 0.1485413173652695 
[1,0]<stdout>:DLL 2021-05-28 10:00:52.587838 - Epoch: 1 Iteration: 499  train.loss : 6.254796314239502  train.ips : 1393.9749496737134  train.lr : 0.15314011976047906 
[1,0]<stdout>:DLL 2021-05-28 10:00:52.588032 - Epoch: 1  train.loss : 6.355836046218872  train.ips : 1396.2117594831304 
[1,0]<stderr>:2021-05-28 10:00:52,588:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-05-28 10:00:55.342535 - Epoch: 2 Iteration: 19  train.loss : 6.221621704101563  train.ips : 1394.1503934120033  train.lr : 0.0811688622754491 
[1,0]<stdout>:DLL 2021-05-28 10:00:58.097856 - Epoch: 2 Iteration: 39  train.loss : 6.161274075508118  train.ips : 1393.8663752603743  train.lr : 0.08576766467065869 
[1,0]<stdout>:DLL 2021-05-28 10:01:00.851214 - Epoch: 2 Iteration: 59  train.loss : 6.157929134368897  train.ips : 1394.8308666199418  train.lr : 0.09036646706586826 
[1,0]<stdout>:DLL 2021-05-28 10:01:03.609155 - Epoch: 2 Iteration: 79  train.loss : 6.135848021507263  train.ips : 1392.4758276891794  train.lr : 0.09496526946107783 
[1,0]<stdout>:DLL 2021-05-28 10:01:06.365554 - Epoch: 2 Iteration: 99  train.loss : 6.178349304199219  train.ips : 1393.2310715926185  train.lr : 0.09956407185628743 
[1,0]<stdout>:DLL 2021-05-28 10:01:09.129521 - Epoch: 2 Iteration: 119  train.loss : 6.130604600906372  train.ips : 1389.5290727714587  train.lr : 0.10416287425149702 
[1,0]<stdout>:DLL 2021-05-28 10:01:11.885177 - Epoch: 2 Iteration: 139  train.loss : 6.166579818725586  train.ips : 1393.6316710633007  train.lr : 0.10876167664670659 
[1,0]<stdout>:DLL 2021-05-28 10:01:14.642572 - Epoch: 2 Iteration: 159  train.loss : 6.151913785934449  train.ips : 1392.7489218517171  train.lr : 0.11336047904191618 
[1,0]<stdout>:DLL 2021-05-28 10:01:17.400744 - Epoch: 2 Iteration: 179  train.loss : 6.133416223526001  train.ips : 1392.3175351005004  train.lr : 0.11795928143712575 
[1,0]<stdout>:DLL 2021-05-28 10:01:20.159578 - Epoch: 2 Iteration: 199  train.loss : 6.13217031955719  train.ips : 1391.9973283818977  train.lr : 0.12255808383233532 
[1,0]<stdout>:DLL 2021-05-28 10:01:22.919858 - Epoch: 2 Iteration: 219  train.loss : 6.1189405679702755  train.ips : 1391.2618081613195  train.lr : 0.12715688622754492 
[1,0]<stdout>:DLL 2021-05-28 10:01:25.676821 - Epoch: 2 Iteration: 239  train.loss : 6.132364201545715  train.ips : 1392.9611615471035  train.lr : 0.1317556886227545 
[1,0]<stdout>:DLL 2021-05-28 10:01:28.436152 - Epoch: 2 Iteration: 259  train.loss : 6.112154531478882  train.ips : 1391.7791283172878  train.lr : 0.13635449101796407 
[1,0]<stdout>:DLL 2021-05-28 10:01:31.198042 - Epoch: 2 Iteration: 279  train.loss : 6.117780017852783  train.ips : 1390.495612022158  train.lr : 0.14095329341317367 
[1,0]<stdout>:DLL 2021-05-28 10:01:33.959909 - Epoch: 2 Iteration: 299  train.loss : 6.0777103185653685  train.ips : 1390.4660813045864  train.lr : 0.14555209580838324 
[1,0]<stdout>:DLL 2021-05-28 10:01:36.718163 - Epoch: 2 Iteration: 319  train.loss : 6.082893419265747  train.ips : 1392.347866710156  train.lr : 0.15015089820359281 
[1,0]<stdout>:DLL 2021-05-28 10:01:39.480531 - Epoch: 2 Iteration: 339  train.loss : 6.063480854034424  train.ips : 1390.3142459987348  train.lr : 0.1547497005988024 
[1,0]<stdout>:DLL 2021-05-28 10:01:42.245033 - Epoch: 2 Iteration: 359  train.loss : 6.062674188613892  train.ips : 1389.1920539808887  train.lr : 0.159348502994012 
[1,0]<stdout>:DLL 2021-05-28 10:01:45.008721 - Epoch: 2 Iteration: 379  train.loss : 6.041667222976685  train.ips : 1389.5727102018384  train.lr : 0.16394730538922156 
[1,0]<stdout>:DLL 2021-05-28 10:01:47.768920 - Epoch: 2 Iteration: 399  train.loss : 6.08698673248291  train.ips : 1391.288969021217  train.lr : 0.1685461077844311 
[1,0]<stdout>:DLL 2021-05-28 10:01:50.532127 - Epoch: 2 Iteration: 419  train.loss : 6.079030203819275  train.ips : 1389.8176821448412  train.lr : 0.1731449101796407 
[1,0]<stdout>:DLL 2021-05-28 10:01:53.293596 - Epoch: 2 Iteration: 439  train.loss : 6.04418454170227  train.ips : 1390.7027224176381  train.lr : 0.1777437125748503 
[1,0]<stdout>:DLL 2021-05-28 10:01:56.056296 - Epoch: 2 Iteration: 459  train.loss : 6.054887294769287  train.ips : 1390.0735379853622  train.lr : 0.18234251497005988 
[1,0]<stdout>:DLL 2021-05-28 10:01:58.819820 - Epoch: 2 Iteration: 479  train.loss : 6.0435504674911495  train.ips : 1389.6665879200912  train.lr : 0.18694131736526945 
[1,0]<stdout>:DLL 2021-05-28 10:02:01.579838 - Epoch: 2 Iteration: 499  train.loss : 6.0225510597229  train.ips : 1391.4288762663557  train.lr : 0.19154011976047905 
[1,0]<stdout>:DLL 2021-05-28 10:02:01.580024 - Epoch: 2  train.loss : 6.108422504425048  train.ips : 1391.4674302245078 
[1,0]<stdout>:DLL 2021-05-28 10:02:01.666255 - Summary: train.loss : 6.108422504425048  train.ips : 1333.2707594525646 
[1,0]<stdout>:DLL 2021-05-28 10:02:08.782766 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 1536  num_epochs : 3  run_epochs : -1  lr : 1.536  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,192  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 3  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,2]<stderr>:[10:02:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,2]<stderr>:CPU
[1,4]<stderr>:[[1,4]<stderr>:10:02:08] ../src/storage/storage.cc:[1,4]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:[[1,3]<stderr>:10:02:08] ../src/storage/storage.cc:199: Using Pooled (Naive)[1,3]<stderr>: StorageManager for CPU
[1,5]<stderr>:[10:02:08] ../src/storage/storage.cc:199: [1,5]<stderr>:Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:[10:02:08] ../src/storage/storage.cc:199: Using [1,7]<stderr>:Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[10:02:08[1,6]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[10:02:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[[1,1]<stderr>:10:02:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[10:02:13] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[10:02:13] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[[1,7]<stderr>:10:02:13] ../src/storage/storage.cc:[1,7]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[[1,1]<stderr>:10:02:13] ../src/storage/storage.cc:[1,1]<stderr>:199: Using Pooled (Naive) StorageManager for [1,1]<stderr>:GPU
[1,5]<stderr>:[10:02:13] ../src/storage/storage.cc:199[1,5]<stderr>:: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[[1,0]<stderr>:10:02:13] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive)[1,0]<stderr>: StorageManager for GPU
[1,4]<stderr>:[[1,4]<stderr>:10:02:13] [1,4]<stderr>:../src/storage/storage.cc:[1,4]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[[1,2]<stderr>:10:02:13] ../src/storage/storage.cc:[1,2]<stderr>:199: Using Pooled (Naive) StorageManager for [1,2]<stderr>:GPU
[1,5]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2021-05-28 10:02:17,859:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2021-05-28 10:02:17,859:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2021-05-28 10:02:17,884:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2021-05-28 10:02:17,885:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2021-05-28 10:02:18,123:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2021-05-28 10:02:18,123:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2021-05-28 10:02:18,667:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2021-05-28 10:02:18,668:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-05-28 10:02:18,697:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-05-28 10:02:18,697:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2021-05-28 10:02:19,081:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2021-05-28 10:02:19,090:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2021-05-28 10:02:19,150:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2021-05-28 10:02:19,150:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2021-05-28 10:02:19,261:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2021-05-28 10:02:19,262:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 13609, errno = 1
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 14777, errno = 1
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 13817, errno = 1
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 12713, errno = 1
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 13345, errno = 1
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 14321, errno = 1
[1,0]<stderr>:[6389caacd155:07350] Read -1, expected 13681, errno = 1
[1,5]<stderr>:[6389caacd155:07355] Read -1, expected 8508, errno = 1
[1,1]<stderr>:[6389caacd155:07351] Read -1, expected 8508, errno = 1
[1,6]<stderr>:[6389caacd155:07356] Read -1, expected 8509, errno = 1
[1,7]<stderr>:[6389caacd155:07357] Read -1, expected 8508, errno = 1
[1,2]<stderr>:[6389caacd155:07352] Read -1, expected 8509, errno = 1
[1,3]<stderr>:[6389caacd155:07353] Read -1, expected 8508, errno = 1
[1,4]<stderr>:[6389caacd155:07354] Read -1, expected 8509, errno = 1
[1,4]<stderr>:[10:02:24] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,3]<stderr>:[10:02:24] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,3]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[10:02:24[1,5]<stderr>:] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:[10:02:24] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,0]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[10:02:24] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[10:02:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:[10:02:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[10:02:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,7]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-05-28 10:02:40.443789 - Epoch: 0 Iteration: 19  train.loss : 6.972218990325928  train.ips : 1412.6387131056058  train.lr : 0.27794285714285716 
[1,0]<stdout>:DLL 2021-05-28 10:02:45.026074 - Epoch: 0 Iteration: 39  train.loss : 6.764844346046448  train.ips : 6704.714221673537  train.lr : 0.5705142857142858 
[1,0]<stdout>:DLL 2021-05-28 10:02:49.104232 - Epoch: 0 Iteration: 59  train.loss : 6.624775671958924  train.ips : 7533.4077976071  train.lr : 0.8630857142857142 
[1,0]<stdout>:DLL 2021-05-28 10:02:52.565601 - Epoch: 0 Iteration: 79  train.loss : 6.524515891075135  train.ips : 8875.794341767181  train.lr : 1.155657142857143 
[1,0]<stdout>:DLL 2021-05-28 10:02:56.043799 - Epoch: 0 Iteration: 99  train.loss : 6.4140177249908445  train.ips : 8832.678381188398  train.lr : 1.4482285714285714 
[1,0]<stdout>:DLL 2021-05-28 10:02:59.602932 - Epoch: 0 Iteration: 119  train.loss : 6.346564865112304  train.ips : 8631.973453649065  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:02.964461 - Epoch: 0 Iteration: 139  train.loss : 6.372277092933655  train.ips : 9139.409930801692  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:06.450887 - Epoch: 0 Iteration: 159  train.loss : 6.335426020622253  train.ips : 8811.920980574234  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:10.285633 - Epoch: 0 Iteration: 179  train.loss : 6.3373092889785765  train.ips : 8011.841752702128  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:14.031328 - Epoch: 0 Iteration: 199  train.loss : 6.369361066818238  train.ips : 8202.933844760602  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:17.581859 - Epoch: 0 Iteration: 219  train.loss : 6.34210307598114  train.ips : 8652.804717369108  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:21.391664 - Epoch: 0 Iteration: 239  train.loss : 6.364284777641297  train.ips : 8063.959096734576  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:25.009174 - Epoch: 0 Iteration: 259  train.loss : 6.356788516044617  train.ips : 8492.41225890527  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:28.723708 - Epoch: 0 Iteration: 279  train.loss : 6.351119947433472  train.ips : 8270.610722978197  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:32.446959 - Epoch: 0 Iteration: 299  train.loss : 6.329025483131408  train.ips : 8251.209778728213  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:36.091693 - Epoch: 0 Iteration: 319  train.loss : 6.37897412776947  train.ips : 8429.052635958515  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:39.686177 - Epoch: 0 Iteration: 339  train.loss : 6.345393228530884  train.ips : 8546.987688264011  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:43.121304 - Epoch: 0 Iteration: 359  train.loss : 6.36015784740448  train.ips : 8943.360084490929  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:46.509941 - Epoch: 0 Iteration: 379  train.loss : 6.345262742042541  train.ips : 9066.130050879074  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:50.011097 - Epoch: 0 Iteration: 399  train.loss : 6.353255748748779  train.ips : 8791.109761713058  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:53.434807 - Epoch: 0 Iteration: 419  train.loss : 6.337750768661499  train.ips : 8973.451535401633  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:03:56.871943 - Epoch: 0 Iteration: 439  train.loss : 6.367299723625183  train.ips : 8938.157460248136  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:00.260441 - Epoch: 0 Iteration: 459  train.loss : 6.324632573127746  train.ips : 9066.446467732001  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:03.680154 - Epoch: 0 Iteration: 479  train.loss : 6.367234754562378  train.ips : 8983.733557934193  train.lr : 0 
[1,7]<stderr>:2021-05-28 10:04:07,371:INFO: Starting epoch 1
[1,1]<stderr>:2021-05-28 10:04:07,371:INFO: Starting epoch 1
[1,6]<stderr>:2021-05-28 10:04:07,371:INFO: Starting epoch 1
[1,5]<stderr>:2021-05-28 10:04:07,371:INFO: Starting epoch 1
[1,4]<stderr>:2021-05-28 10:04:07,372:INFO: Starting epoch 1
[1,3]<stderr>:2021-05-28 10:04:07,372:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 10:04:07.373270 - Epoch: 0 Iteration: 499  train.loss : 6.356211566925049  train.ips : 8318.714550288223  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:07.373530 - Epoch: 0  train.loss : 6.41363223361969  train.ips : 7066.857730652437 
[1,0]<stderr>:2021-05-28 10:04:07,374:INFO: Starting epoch 1
[1,2]<stderr>:2021-05-28 10:04:07,373:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 10:04:11.040225 - Epoch: 1 Iteration: 19  train.loss : 6.267800068855285  train.ips : 8379.012503259613  train.lr : 0.5851428571428572 
[1,0]<stdout>:DLL 2021-05-28 10:04:14.620133 - Epoch: 1 Iteration: 39  train.loss : 6.185990953445435  train.ips : 8581.60642901419  train.lr : 0.8777142857142858 
[1,0]<stdout>:DLL 2021-05-28 10:04:18.333560 - Epoch: 1 Iteration: 59  train.loss : 6.181000590324402  train.ips : 8273.063040642526  train.lr : 1.1702857142857144 
[1,0]<stdout>:DLL 2021-05-28 10:04:21.836186 - Epoch: 1 Iteration: 79  train.loss : 6.150933790206909  train.ips : 8770.993031687385  train.lr : 1.4628571428571429 
[1,0]<stdout>:DLL 2021-05-28 10:04:25.238700 - Epoch: 1 Iteration: 99  train.loss : 6.069914531707764  train.ips : 9029.248462283102  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:28.735771 - Epoch: 1 Iteration: 119  train.loss : 6.098176455497741  train.ips : 8785.092493376187  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:32.146708 - Epoch: 1 Iteration: 139  train.loss : 6.084825277328491  train.ips : 9006.747029690616  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:35.878481 - Epoch: 1 Iteration: 159  train.loss : 6.108081412315369  train.ips : 8232.371944271688  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:39.798241 - Epoch: 1 Iteration: 179  train.loss : 6.087055420875549  train.ips : 7837.604979997988  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:43.728543 - Epoch: 1 Iteration: 199  train.loss : 6.112201309204101  train.ips : 7816.6899084278575  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:47.993609 - Epoch: 1 Iteration: 219  train.loss : 6.124231457710266  train.ips : 7203.002670414083  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:52.223147 - Epoch: 1 Iteration: 239  train.loss : 6.095940494537354  train.ips : 7263.6297048356355  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:04:56.377621 - Epoch: 1 Iteration: 259  train.loss : 6.103378200531006  train.ips : 7394.845691897104  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:00.385176 - Epoch: 1 Iteration: 279  train.loss : 6.12193660736084  train.ips : 7665.895245056174  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:04.503456 - Epoch: 1 Iteration: 299  train.loss : 6.0719175100326535  train.ips : 7459.880554157842  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:08.413812 - Epoch: 1 Iteration: 319  train.loss : 6.100039863586426  train.ips : 7856.456829889128  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:12.271135 - Epoch: 1 Iteration: 339  train.loss : 6.100047278404236  train.ips : 7964.4334732018415  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:16.270493 - Epoch: 1 Iteration: 359  train.loss : 6.089406514167786  train.ips : 7681.672574872733  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:19.987174 - Epoch: 1 Iteration: 379  train.loss : 6.098588490486145  train.ips : 8266.007396288564  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:24.093161 - Epoch: 1 Iteration: 399  train.loss : 6.079872512817383  train.ips : 7482.311117387873  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:28.087914 - Epoch: 1 Iteration: 419  train.loss : 6.007092523574829  train.ips : 7690.4750833872295  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:31.899728 - Epoch: 1 Iteration: 439  train.loss : 6.095973086357117  train.ips : 8059.809236592951  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:35.876882 - Epoch: 1 Iteration: 459  train.loss : 6.098314356803894  train.ips : 7724.546444271574  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:39.663952 - Epoch: 1 Iteration: 479  train.loss : 6.108289504051209  train.ips : 8112.284369936079  train.lr : 0 
[1,1]<stderr>:2021-05-28 10:05:43,604:INFO: Starting epoch 2
[1,2]<stderr>:2021-05-28 10:05:43,605:INFO: Starting epoch 2
[1,5]<stderr>:2021-05-28 10:05:43,605:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-05-28 10:05:43.605528 - Epoch: 1 Iteration: 499  train.loss : 6.078736805915833  train.ips : 7794.3039917847345  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:05:43.605744 - Epoch: 1  train.loss : 6.108789800643921  train.ips : 7980.729500198355 
[1,4]<stderr>:2021-05-28 10:05:43,605:INFO: Starting epoch 2
[1,7]<stderr>:2021-05-28 10:05:43,605:INFO: Starting epoch 2
[1,0]<stderr>:2021-05-28 10:05:43,605:INFO: Starting epoch 2
[1,3]<stderr>:2021-05-28 10:05:43,606:INFO: Starting epoch 2
[1,6]<stderr>:2021-05-28 10:05:43,608:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-05-28 10:05:47.588261 - Epoch: 2 Iteration: 19  train.loss : 6.166781234741211  train.ips : 7713.858330695176  train.lr : 0.8923428571428571 
[1,0]<stdout>:DLL 2021-05-28 10:05:51.635706 - Epoch: 2 Iteration: 39  train.loss : 6.046755409240722  train.ips : 7590.286743600223  train.lr : 1.1849142857142856 
[1,0]<stdout>:DLL 2021-05-28 10:05:55.633903 - Epoch: 2 Iteration: 59  train.loss : 5.980692505836487  train.ips : 7683.787114360848  train.lr : 1.4774857142857143 
[1,0]<stdout>:DLL 2021-05-28 10:05:59.659634 - Epoch: 2 Iteration: 79  train.loss : 5.955975341796875  train.ips : 7631.295793231709  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:03.652090 - Epoch: 2 Iteration: 99  train.loss : 5.971961569786072  train.ips : 7694.953528039137  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:07.800516 - Epoch: 2 Iteration: 119  train.loss : 5.923912620544433  train.ips : 7405.531843943191  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:11.689434 - Epoch: 2 Iteration: 139  train.loss : 5.95785162448883  train.ips : 7899.820009032288  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:15.446985 - Epoch: 2 Iteration: 159  train.loss : 5.965392708778381  train.ips : 8176.075287727386  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:19.264904 - Epoch: 2 Iteration: 179  train.loss : 5.925431704521179  train.ips : 8046.753516476798  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:23.151858 - Epoch: 2 Iteration: 199  train.loss : 5.9408265352249146  train.ips : 7904.871062196993  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:27.028472 - Epoch: 2 Iteration: 219  train.loss : 5.952259373664856  train.ips : 7924.945543185193  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:30.835158 - Epoch: 2 Iteration: 239  train.loss : 5.960734152793885  train.ips : 8070.34430474253  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:34.725883 - Epoch: 2 Iteration: 259  train.loss : 5.954180264472962  train.ips : 7896.031840278452  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:38.554717 - Epoch: 2 Iteration: 279  train.loss : 5.950519013404846  train.ips : 8023.698448123328  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:42.411928 - Epoch: 2 Iteration: 299  train.loss : 5.938871073722839  train.ips : 7964.772681431455  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:46.240350 - Epoch: 2 Iteration: 319  train.loss : 5.9281631231307985  train.ips : 8024.742358032912  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:50.171022 - Epoch: 2 Iteration: 339  train.loss : 5.954730272293091  train.ips : 7815.818893874565  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:53.982798 - Epoch: 2 Iteration: 359  train.loss : 5.921607398986817  train.ips : 8059.599007345081  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:06:58.000942 - Epoch: 2 Iteration: 379  train.loss : 5.913143730163574  train.ips : 7645.801917215005  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:02.042522 - Epoch: 2 Iteration: 399  train.loss : 5.90962700843811  train.ips : 7601.492280164172  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:05.939598 - Epoch: 2 Iteration: 419  train.loss : 5.949967956542968  train.ips : 7883.243344573898  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:09.932891 - Epoch: 2 Iteration: 439  train.loss : 5.945303201675415  train.ips : 7693.212235220278  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:13.866983 - Epoch: 2 Iteration: 459  train.loss : 5.965651941299439  train.ips : 7808.993585485646  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:17.863705 - Epoch: 2 Iteration: 479  train.loss : 5.926065611839294  train.ips : 7686.692380643132  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:21.638693 - Epoch: 2 Iteration: 499  train.loss : 5.93994517326355  train.ips : 8138.303250962676  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 10:07:21.638896 - Epoch: 2  train.loss : 5.957854022026062  train.ips : 7834.091842954268 
[1,0]<stdout>:DLL 2021-05-28 10:07:21.729819 - Summary: train.loss : 5.957854022026062  train.ips : 7627.226357935019 
train.ips
           |    192    |
------------------------
     1     |   1393.8  |
     8     |   7906.7  |

