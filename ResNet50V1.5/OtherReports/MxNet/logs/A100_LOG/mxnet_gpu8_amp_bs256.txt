[1,0]<stdout>:DLL 2023-07-31 12:56:58.635725 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 2048  num_epochs : 3  run_epochs : -1  lr : 2.048  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,256  workspace : ./  logdir : None  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 6  dali_validation_threads : 10  dali_prefetch_queue : 5  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,7]<stderr>:[[1,7]<stderr>:12:56:58] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU[1,7]<stderr>:
[1,4]<stderr>:[[1,4]<stderr>:12:56:58] ../src/storage/storage.cc[1,4]<stderr>::196: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:[[1,2]<stderr>:12:56:58] ../src/storage/storage.cc:[1,2]<stderr>:196: Using Pooled (Naive) StorageManager for [1,2]<stderr>:CPU
[1,5]<stderr>:[[1,5]<stderr>:12:56:58] ../src/storage/storage.cc:[1,5]<stderr>:196: Using Pooled (Naive)[1,5]<stderr>: StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:12:56:58] ../src/storage/storage.cc:196: [1,6]<stderr>:Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[[1,0]<stderr>:12:56:58] ../src/storage/storage.cc[1,0]<stderr>::196[1,0]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[[1,1]<stderr>:12:56:58] ../src/storage/storage.cc:[1,1]<stderr>:196: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:[[1,3]<stderr>:12:56:58] ../src/storage/storage.cc:196[1,3]<stderr>:: Using Pooled (Naive) StorageManager for CPU[1,3]<stderr>:
[1,7]<stderr>:2023-07-31 12:56:58,707:INFO: starting epoch 0
[1,4]<stderr>:2023-07-31 12:56:58,709:INFO: starting epoch 0
[1,2]<stderr>:2023-07-31 12:56:58,710:INFO: starting epoch 0
[1,5]<stderr>:2023-07-31 12:56:58,710:INFO: starting epoch 0
[1,0]<stderr>:2023-07-31 12:56:58,711:INFO: starting epoch 0
[1,6]<stderr>:2023-07-31 12:56:58,711:INFO: starting epoch 0
[1,1]<stderr>:2023-07-31 12:56:58,712:INFO: starting epoch 0
[1,3]<stderr>:2023-07-31 12:56:58,715:INFO: starting epoch 0
[1,4]<stderr>:[12:57:08] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[[1,3]<stderr>:12:57:08] ../src/storage/storage.cc:[1,3]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:[[1,5]<stderr>:12:57:08] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU[1,5]<stderr>:
[1,7]<stderr>:[12:57:08] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[[1,6]<stderr>:12:57:08] ../src/storage/storage.cc:[1,6]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[[1,0]<stderr>:12:57:08] ../src/storage/storage.cc:[1,0]<stderr>:196: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[12:57:08] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[12:57:09] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self,
[1,3]<stderr>:2023-07-31 12:57:13,369:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,3]<stderr>:2023-07-31 12:57:13,370:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self,
[1,4]<stderr>:2023-07-31 12:57:13,382:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,4]<stderr>:2023-07-31 12:57:13,383:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self,
[1,0]<stderr>:2023-07-31 12:57:13,876:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,0]<stderr>:2023-07-31 12:57:13,876:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self,
[1,1]<stderr>:2023-07-31 12:57:14,371:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,1]<stderr>:2023-07-31 12:57:14,372:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self,
[1,2]<stderr>:2023-07-31 12:57:14,431:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,2]<stderr>:2023-07-31 12:57:14,431:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self,
[1,5]<stderr>:2023-07-31 12:57:14,579:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,5]<stderr>:2023-07-31 12:57:14,580:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self,
[1,7]<stderr>:2023-07-31 12:57:14,580:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,7]<stderr>:2023-07-31 12:57:14,581:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self,
[1,6]<stderr>:2023-07-31 12:57:14,598:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,6]<stderr>:2023-07-31 12:57:14,598:INFO: Starting epoch 0
[1,0]<stdout>:DLL 2023-07-31 12:57:53.226566 - Epoch: 0 Iteration: 19  train.loss : 6.952979564666748  train.ips : 1040.911122865916 images/s train.lr : 0.4864 
[1,0]<stdout>:DLL 2023-07-31 12:57:54.935614 - Epoch: 0 Iteration: 39  train.loss : 6.680744194984436  train.ips : 23970.57482657478 images/s train.lr : 0.9984 
[1,0]<stdout>:DLL 2023-07-31 12:57:56.662010 - Epoch: 0 Iteration: 59  train.loss : 6.573904061317444  train.ips : 23729.27479165248 images/s train.lr : 1.5104000000000002 
[1,0]<stdout>:DLL 2023-07-31 12:57:58.369879 - Epoch: 0 Iteration: 79  train.loss : 6.423568940162658  train.ips : 23989.972148798726 images/s train.lr : 2.0224 
[1,0]<stdout>:DLL 2023-07-31 12:58:00.091273 - Epoch: 0 Iteration: 99  train.loss : 6.356773710250854  train.ips : 23801.890815545165 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:01.807940 - Epoch: 0 Iteration: 119  train.loss : 6.346080803871155  train.ips : 23871.31676047369 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:03.522488 - Epoch: 0 Iteration: 139  train.loss : 6.360862302780151  train.ips : 23894.730509755813 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:05.242423 - Epoch: 0 Iteration: 159  train.loss : 6.3417621612548825  train.ips : 23819.067411246957 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:08.191249 - Epoch: 0 Iteration: 179  train.loss : 6.344029688835144  train.ips : 13891.836740403663 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:13.776518 - Epoch: 0 Iteration: 199  train.loss : 6.329823660850525  train.ips : 7333.936068508193 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:15.503682 - Epoch: 0 Iteration: 219  train.loss : 6.337713360786438  train.ips : 23720.075004608054 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:19.599431 - Epoch: 0 Iteration: 239  train.loss : 6.363968777656555  train.ips : 10001.277346323062 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:21.314672 - Epoch: 0 Iteration: 259  train.loss : 6.340622472763061  train.ips : 23884.72125845356 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:23.037838 - Epoch: 0 Iteration: 279  train.loss : 6.350749731063843  train.ips : 23776.82221596965 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:24.768438 - Epoch: 0 Iteration: 299  train.loss : 6.334571886062622  train.ips : 23671.9222739328 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:26.492600 - Epoch: 0 Iteration: 319  train.loss : 6.331581377983094  train.ips : 23761.684785435056 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:28.218757 - Epoch: 0 Iteration: 339  train.loss : 6.333264398574829  train.ips : 23734.79874588679 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:29.932714 - Epoch: 0 Iteration: 359  train.loss : 6.360568118095398  train.ips : 23901.10651835996 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:31.659108 - Epoch: 0 Iteration: 379  train.loss : 6.362839555740356  train.ips : 23728.84544061542 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:33.376341 - Epoch: 0 Iteration: 399  train.loss : 6.344239711761475  train.ips : 23856.46958776873 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:35.100659 - Epoch: 0 Iteration: 419  train.loss : 6.348695635795593  train.ips : 23760.63972206202 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:36.827362 - Epoch: 0 Iteration: 439  train.loss : 6.359280943870544  train.ips : 23726.947960661582 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:38.545292 - Epoch: 0 Iteration: 459  train.loss : 6.3400321245193485  train.ips : 23846.30368929279 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:40.269580 - Epoch: 0 Iteration: 479  train.loss : 6.3564318180084225  train.ips : 23759.092014076887 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:41.980966 - Epoch: 0 Iteration: 499  train.loss : 6.3625730037689205  train.ips : 23939.844459500247 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:41.983336 - Epoch: 0  train.loss : 6.39750648021698  train.ips : 19954.479520516044 images/s
[1,3]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,2]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,6]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,4]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,7]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,5]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,0]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,1]<stderr>:2023-07-31 12:58:41,983:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2023-07-31 12:58:43.748027 - Epoch: 1 Iteration: 19  train.loss : 6.261993861198425  train.ips : 23213.859217276215 images/s train.lr : 0.8960000000000001 
[1,0]<stdout>:DLL 2023-07-31 12:58:45.467031 - Epoch: 1 Iteration: 39  train.loss : 6.20210862159729  train.ips : 23831.74546392286 images/s train.lr : 1.408 
[1,0]<stdout>:DLL 2023-07-31 12:58:47.196667 - Epoch: 1 Iteration: 59  train.loss : 6.178462529182434  train.ips : 23685.413925750763 images/s train.lr : 1.92 
[1,0]<stdout>:DLL 2023-07-31 12:58:48.919544 - Epoch: 1 Iteration: 79  train.loss : 6.146393823623657  train.ips : 23782.84571529668 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:50.680350 - Epoch: 1 Iteration: 99  train.loss : 6.145984864234924  train.ips : 23271.51684712163 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:52.400123 - Epoch: 1 Iteration: 119  train.loss : 6.145619487762451  train.ips : 23819.985513789077 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:54.109112 - Epoch: 1 Iteration: 139  train.loss : 6.151393580436706  train.ips : 23971.21030697336 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:55.810177 - Epoch: 1 Iteration: 159  train.loss : 6.14202036857605  train.ips : 24082.741505967813 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:57.558564 - Epoch: 1 Iteration: 179  train.loss : 6.114163088798523  train.ips : 23430.56845610472 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:58:59.259808 - Epoch: 1 Iteration: 199  train.loss : 6.115280961990356  train.ips : 24080.209833014105 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:00.974990 - Epoch: 1 Iteration: 219  train.loss : 6.155274605751037  train.ips : 23884.84080173596 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:02.675433 - Epoch: 1 Iteration: 239  train.loss : 6.148932600021363  train.ips : 24091.1200745344 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:04.374377 - Epoch: 1 Iteration: 259  train.loss : 6.16216766834259  train.ips : 24112.635192841495 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:06.076902 - Epoch: 1 Iteration: 279  train.loss : 6.148835396766662  train.ips : 24061.579602908085 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:07.779235 - Epoch: 1 Iteration: 299  train.loss : 6.119379663467408  train.ips : 24064.92646694213 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:09.528989 - Epoch: 1 Iteration: 319  train.loss : 6.156402993202209  train.ips : 23412.4541085831 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:11.231180 - Epoch: 1 Iteration: 339  train.loss : 6.148821711540222  train.ips : 24066.91884917786 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:12.933313 - Epoch: 1 Iteration: 359  train.loss : 6.165592956542969  train.ips : 24067.640368436634 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:14.647509 - Epoch: 1 Iteration: 379  train.loss : 6.144481372833252  train.ips : 23898.98856150642 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:16.353488 - Epoch: 1 Iteration: 399  train.loss : 6.142250871658325  train.ips : 24015.59989202683 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:18.071752 - Epoch: 1 Iteration: 419  train.loss : 6.148966217041016  train.ips : 23841.601168608173 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:19.798107 - Epoch: 1 Iteration: 439  train.loss : 6.154788970947266  train.ips : 23729.831987918966 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:21.501102 - Epoch: 1 Iteration: 459  train.loss : 6.138448333740234  train.ips : 24055.181696415693 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:23.205664 - Epoch: 1 Iteration: 479  train.loss : 6.122970151901245  train.ips : 24033.036001286433 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:24.915384 - Epoch: 1 Iteration: 499  train.loss : 6.15927484035492  train.ips : 23961.798610288784 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:24.919818 - Epoch: 1  train.loss : 6.1528003816604615  train.ips : 21629.33309874541 images/s
[1,2]<stderr>:2023-07-31 12:59:24,919:INFO: Starting epoch 2
[1,5]<stderr>:2023-07-31 12:59:24,919:INFO: Starting epoch 2
[1,4]<stderr>:2023-07-31 12:59:24,919:INFO: Starting epoch 2
[1,6]<stderr>:2023-07-31 12:59:24,920:INFO: Starting epoch 2
[1,3]<stderr>:2023-07-31 12:59:24,920:INFO: Starting epoch 2
[1,1]<stderr>:2023-07-31 12:59:24,920:INFO: Starting epoch 2
[1,7]<stderr>:2023-07-31 12:59:24,920:INFO: Starting epoch 2
[1,0]<stderr>:2023-07-31 12:59:24,920:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2023-07-31 12:59:26.620109 - Epoch: 2 Iteration: 19  train.loss : 6.1353354215621945  train.ips : 24092.03899854886 images/s train.lr : 1.3056 
[1,0]<stdout>:DLL 2023-07-31 12:59:28.320932 - Epoch: 2 Iteration: 39  train.loss : 6.000222134590149  train.ips : 24086.577160563495 images/s train.lr : 1.8176 
[1,0]<stdout>:DLL 2023-07-31 12:59:30.113571 - Epoch: 2 Iteration: 59  train.loss : 5.998750710487366  train.ips : 22852.01608591998 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:31.824943 - Epoch: 2 Iteration: 79  train.loss : 5.998588109016419  train.ips : 23939.724365000246 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:33.527455 - Epoch: 2 Iteration: 99  train.loss : 5.970118999481201  train.ips : 24061.306636937607 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:35.236016 - Epoch: 2 Iteration: 119  train.loss : 5.98333261013031  train.ips : 23976.19163347353 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:36.947085 - Epoch: 2 Iteration: 139  train.loss : 5.956003308296204  train.ips : 23943.44785487094 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:38.648068 - Epoch: 2 Iteration: 159  train.loss : 5.982219672203064  train.ips : 24087.2019207096 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:40.354294 - Epoch: 2 Iteration: 179  train.loss : 5.978190803527832  train.ips : 24010.179364952473 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:42.072164 - Epoch: 2 Iteration: 199  train.loss : 5.989788246154785  train.ips : 23846.508908362914 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:43.765168 - Epoch: 2 Iteration: 219  train.loss : 5.986357903480529  train.ips : 24196.869346333075 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:45.469879 - Epoch: 2 Iteration: 239  train.loss : 5.993990421295166  train.ips : 24030.655942590074 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:47.177169 - Epoch: 2 Iteration: 259  train.loss : 5.971385526657104  train.ips : 23994.02628553025 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:48.892804 - Epoch: 2 Iteration: 279  train.loss : 5.990348196029663  train.ips : 23877.099524622507 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:50.599278 - Epoch: 2 Iteration: 299  train.loss : 5.990344548225403  train.ips : 24006.418319915207 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:52.345482 - Epoch: 2 Iteration: 319  train.loss : 5.970713210105896  train.ips : 23460.212697533967 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:54.053241 - Epoch: 2 Iteration: 339  train.loss : 5.981358885765076  train.ips : 23987.664248334255 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:55.760552 - Epoch: 2 Iteration: 359  train.loss : 5.9692387342453  train.ips : 23994.515555003098 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:57.462273 - Epoch: 2 Iteration: 379  train.loss : 5.977818202972412  train.ips : 24073.258909310523 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:59:59.168606 - Epoch: 2 Iteration: 399  train.loss : 5.988438248634338  train.ips : 24008.82713191414 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 13:00:00.877205 - Epoch: 2 Iteration: 419  train.loss : 6.002675104141235  train.ips : 23978.186082469118 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 13:00:02.589834 - Epoch: 2 Iteration: 439  train.loss : 6.011355209350586  train.ips : 23920.14173975384 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 13:00:04.308481 - Epoch: 2 Iteration: 459  train.loss : 5.996733021736145  train.ips : 23836.503627255293 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 13:00:06.009105 - Epoch: 2 Iteration: 479  train.loss : 5.99691641330719  train.ips : 24088.958176875432 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 13:00:07.759760 - Epoch: 2 Iteration: 499  train.loss : 5.968322038650513  train.ips : 23400.606982042416 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 13:00:07.766110 - Epoch: 2  train.loss : 5.991541827201844  train.ips : 23860.02619506858 images/s
[1,0]<stdout>:DLL 2023-07-31 13:00:07.812707 - Summary: train.loss : 5.991541827201844  train.ips : 21814.612938110015 images/s
train.ips
           |    256    |
------------------------
     8     |   22690   |

