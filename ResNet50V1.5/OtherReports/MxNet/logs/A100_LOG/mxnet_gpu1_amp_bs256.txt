[1,0]<stdout>:DLL 2023-07-31 12:54:03.115620 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float16  amp : False  batch_size : 256  num_epochs : 3  run_epochs : -1  lr : 0.256  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-1,256  workspace : ./  logdir : None  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 6  dali_validation_threads : 10  dali_prefetch_queue : 5  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[[1,0]<stderr>:12:54:03] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:2023-07-31 12:54:03,190:INFO: starting epoch 0
[1,0]<stderr>:[12:54:06] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self,
[1,0]<stderr>:2023-07-31 12:54:10,441:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,0]<stderr>:2023-07-31 12:54:10,442:INFO: Starting epoch 0
[1,0]<stdout>:DLL 2023-07-31 12:54:45.667858 - Epoch: 0 Iteration: 19  train.loss : 7.104226565361023  train.ips : 145.34703691649955 images/s train.lr : 0.0077824 
[1,0]<stdout>:DLL 2023-07-31 12:54:47.333903 - Epoch: 0 Iteration: 39  train.loss : 7.001699233055115  train.ips : 3073.7771505332094 images/s train.lr : 0.0159744 
[1,0]<stdout>:DLL 2023-07-31 12:54:48.999979 - Epoch: 0 Iteration: 59  train.loss : 6.920290541648865  train.ips : 3073.7406341443584 images/s train.lr : 0.024166399999999998 
[1,0]<stdout>:DLL 2023-07-31 12:54:50.666656 - Epoch: 0 Iteration: 79  train.loss : 6.875957870483399  train.ips : 3072.595427885958 images/s train.lr : 0.032358399999999995 
[1,0]<stdout>:DLL 2023-07-31 12:54:52.332632 - Epoch: 0 Iteration: 99  train.loss : 6.843736553192139  train.ips : 3073.851505862334 images/s train.lr : 0.0405504 
[1,0]<stdout>:DLL 2023-07-31 12:54:54.001831 - Epoch: 0 Iteration: 119  train.loss : 6.8191657066345215  train.ips : 3068.0761608738517 images/s train.lr : 0.0487424 
[1,0]<stdout>:DLL 2023-07-31 12:54:55.667373 - Epoch: 0 Iteration: 139  train.loss : 6.789495587348938  train.ips : 3074.7669430613255 images/s train.lr : 0.05693440000000001 
[1,0]<stdout>:DLL 2023-07-31 12:54:57.333050 - Epoch: 0 Iteration: 159  train.loss : 6.7673215627670285  train.ips : 3074.597898233256 images/s train.lr : 0.0651264 
[1,0]<stdout>:DLL 2023-07-31 12:54:59.000743 - Epoch: 0 Iteration: 179  train.loss : 6.7522964715957645  train.ips : 3070.5955642389213 images/s train.lr : 0.07331839999999999 
[1,0]<stdout>:DLL 2023-07-31 12:55:00.666672 - Epoch: 0 Iteration: 199  train.loss : 6.703423261642456  train.ips : 3073.9368649355533 images/s train.lr : 0.08151040000000001 
[1,0]<stdout>:DLL 2023-07-31 12:55:03.566050 - Epoch: 0 Iteration: 219  train.loss : 6.689585590362549  train.ips : 1766.1524386618196 images/s train.lr : 0.0897024 
[1,0]<stdout>:DLL 2023-07-31 12:55:05.231724 - Epoch: 0 Iteration: 239  train.loss : 6.688582015037537  train.ips : 3074.4077450182044 images/s train.lr : 0.09789439999999999 
[1,0]<stdout>:DLL 2023-07-31 12:55:06.894550 - Epoch: 0 Iteration: 259  train.loss : 6.678930711746216  train.ips : 3079.568257734077 images/s train.lr : 0.1060864 
[1,0]<stdout>:DLL 2023-07-31 12:55:08.557531 - Epoch: 0 Iteration: 279  train.loss : 6.642329359054566  train.ips : 3079.278581550887 images/s train.lr : 0.1142784 
[1,0]<stdout>:DLL 2023-07-31 12:55:10.224471 - Epoch: 0 Iteration: 299  train.loss : 6.617514061927795  train.ips : 3072.154548790406 images/s train.lr : 0.12247040000000001 
[1,0]<stdout>:DLL 2023-07-31 12:55:11.886259 - Epoch: 0 Iteration: 319  train.loss : 6.597941946983338  train.ips : 3081.7624687121593 images/s train.lr : 0.1306624 
[1,0]<stdout>:DLL 2023-07-31 12:55:13.548255 - Epoch: 0 Iteration: 339  train.loss : 6.553247427940368  train.ips : 3081.162451456077 images/s train.lr : 0.13885440000000002 
[1,0]<stdout>:DLL 2023-07-31 12:55:15.213569 - Epoch: 0 Iteration: 359  train.loss : 6.562414622306823  train.ips : 3074.9751931020373 images/s train.lr : 0.1470464 
[1,0]<stdout>:DLL 2023-07-31 12:55:16.876298 - Epoch: 0 Iteration: 379  train.loss : 6.525929093360901  train.ips : 3079.731224539141 images/s train.lr : 0.1552384 
[1,0]<stdout>:DLL 2023-07-31 12:55:18.537734 - Epoch: 0 Iteration: 399  train.loss : 6.515373921394348  train.ips : 3082.3848410101687 images/s train.lr : 0.16343040000000003 
[1,0]<stdout>:DLL 2023-07-31 12:55:20.199058 - Epoch: 0 Iteration: 419  train.loss : 6.482111859321594  train.ips : 3082.340156301313 images/s train.lr : 0.1716224 
[1,0]<stdout>:DLL 2023-07-31 12:55:21.864043 - Epoch: 0 Iteration: 439  train.loss : 6.472812938690185  train.ips : 3075.598791062063 images/s train.lr : 0.17981439999999999 
[1,0]<stdout>:DLL 2023-07-31 12:55:23.528062 - Epoch: 0 Iteration: 459  train.loss : 6.434017705917358  train.ips : 3077.408038895868 images/s train.lr : 0.18800640000000002 
[1,0]<stdout>:DLL 2023-07-31 12:55:25.191757 - Epoch: 0 Iteration: 479  train.loss : 6.4396089792251585  train.ips : 3077.9889478214195 images/s train.lr : 0.1961984 
[1,0]<stdout>:DLL 2023-07-31 12:55:26.853804 - Epoch: 0 Iteration: 499  train.loss : 6.426057744026184  train.ips : 3081.003311440229 images/s train.lr : 0.2043904 
[1,0]<stdout>:DLL 2023-07-31 12:55:26.856059 - Epoch: 0  train.loss : 6.6761628532409665  train.ips : 2977.8337400279133 images/s
[1,0]<stderr>:2023-07-31 12:55:26,856:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2023-07-31 12:55:28.517314 - Epoch: 1 Iteration: 19  train.loss : 6.3829041719436646  train.ips : 3082.427757247241 images/s train.lr : 0.058982400000000004 
[1,0]<stdout>:DLL 2023-07-31 12:55:30.181978 - Epoch: 1 Iteration: 39  train.loss : 6.295212769508362  train.ips : 3076.1574253992126 images/s train.lr : 0.0671744 
[1,0]<stdout>:DLL 2023-07-31 12:55:31.845074 - Epoch: 1 Iteration: 59  train.loss : 6.263811469078064  train.ips : 3079.084317082574 images/s train.lr : 0.0753664 
[1,0]<stdout>:DLL 2023-07-31 12:55:33.509321 - Epoch: 1 Iteration: 79  train.loss : 6.259114861488342  train.ips : 3077.1633023952477 images/s train.lr : 0.0835584 
[1,0]<stdout>:DLL 2023-07-31 12:55:35.173460 - Epoch: 1 Iteration: 99  train.loss : 6.2672340869903564  train.ips : 3077.1284691932315 images/s train.lr : 0.0917504 
[1,0]<stdout>:DLL 2023-07-31 12:55:36.838387 - Epoch: 1 Iteration: 119  train.loss : 6.234682893753051  train.ips : 3075.651209474138 images/s train.lr : 0.0999424 
[1,0]<stdout>:DLL 2023-07-31 12:55:38.502987 - Epoch: 1 Iteration: 139  train.loss : 6.228650736808777  train.ips : 3076.088245944546 images/s train.lr : 0.1081344 
[1,0]<stdout>:DLL 2023-07-31 12:55:40.165688 - Epoch: 1 Iteration: 159  train.loss : 6.230043625831604  train.ips : 3079.6261111834515 images/s train.lr : 0.11632640000000001 
[1,0]<stdout>:DLL 2023-07-31 12:55:41.825988 - Epoch: 1 Iteration: 179  train.loss : 6.192315721511841  train.ips : 3084.129884577266 images/s train.lr : 0.1245184 
[1,0]<stdout>:DLL 2023-07-31 12:55:43.491369 - Epoch: 1 Iteration: 199  train.loss : 6.191383910179138  train.ips : 3074.653364018536 images/s train.lr : 0.1327104 
[1,0]<stdout>:DLL 2023-07-31 12:55:45.155556 - Epoch: 1 Iteration: 219  train.loss : 6.23851261138916  train.ips : 3076.842778512628 images/s train.lr : 0.14090239999999998 
[1,0]<stdout>:DLL 2023-07-31 12:55:46.817361 - Epoch: 1 Iteration: 239  train.loss : 6.211312890052795  train.ips : 3081.465747112978 images/s train.lr : 0.14909440000000002 
[1,0]<stdout>:DLL 2023-07-31 12:55:48.479696 - Epoch: 1 Iteration: 259  train.loss : 6.226442885398865  train.ips : 3080.5016859330385 images/s train.lr : 0.1572864 
[1,0]<stdout>:DLL 2023-07-31 12:55:50.144633 - Epoch: 1 Iteration: 279  train.loss : 6.19687705039978  train.ips : 3075.661340969911 images/s train.lr : 0.1654784 
[1,0]<stdout>:DLL 2023-07-31 12:55:51.812985 - Epoch: 1 Iteration: 299  train.loss : 6.180147910118103  train.ips : 3069.3684670906882 images/s train.lr : 0.1736704 
[1,0]<stdout>:DLL 2023-07-31 12:55:53.481705 - Epoch: 1 Iteration: 319  train.loss : 6.19818913936615  train.ips : 3068.682492757997 images/s train.lr : 0.1818624 
[1,0]<stdout>:DLL 2023-07-31 12:55:55.155030 - Epoch: 1 Iteration: 339  train.loss : 6.182488465309143  train.ips : 3060.217339074093 images/s train.lr : 0.1900544 
[1,0]<stdout>:DLL 2023-07-31 12:55:56.823417 - Epoch: 1 Iteration: 359  train.loss : 6.189957809448242  train.ips : 3069.31363050042 images/s train.lr : 0.1982464 
[1,0]<stdout>:DLL 2023-07-31 12:55:58.490790 - Epoch: 1 Iteration: 379  train.loss : 6.158101272583008  train.ips : 3071.2512079512476 images/s train.lr : 0.2064384 
[1,0]<stdout>:DLL 2023-07-31 12:56:00.157864 - Epoch: 1 Iteration: 399  train.loss : 6.1767806053161625  train.ips : 3071.973486556956 images/s train.lr : 0.21463040000000003 
[1,0]<stdout>:DLL 2023-07-31 12:56:01.826944 - Epoch: 1 Iteration: 419  train.loss : 6.12367045879364  train.ips : 3068.0862425250994 images/s train.lr : 0.22282240000000003 
[1,0]<stdout>:DLL 2023-07-31 12:56:03.498425 - Epoch: 1 Iteration: 439  train.loss : 6.150028824806213  train.ips : 3063.603384241132 images/s train.lr : 0.2310144 
[1,0]<stdout>:DLL 2023-07-31 12:56:05.169502 - Epoch: 1 Iteration: 459  train.loss : 6.1247576713562015  train.ips : 3064.3671081243947 images/s train.lr : 0.23920640000000004 
[1,0]<stdout>:DLL 2023-07-31 12:56:06.838386 - Epoch: 1 Iteration: 479  train.loss : 6.079286360740662  train.ips : 3068.3825849994887 images/s train.lr : 0.24739840000000002 
[1,0]<stdout>:DLL 2023-07-31 12:56:08.507718 - Epoch: 1 Iteration: 499  train.loss : 6.093639755249024  train.ips : 3067.607656349903 images/s train.lr : 0.2555904 
[1,0]<stdout>:DLL 2023-07-31 12:56:08.509813 - Epoch: 1  train.loss : 6.203021918296814  train.ips : 3022.348334253948 images/s
[1,0]<stderr>:2023-07-31 12:56:08,510:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2023-07-31 12:56:10.177352 - Epoch: 2 Iteration: 19  train.loss : 6.004587626457214  train.ips : 3070.9196183708027 images/s train.lr : 0.11018240000000001 
[1,0]<stdout>:DLL 2023-07-31 12:56:11.848009 - Epoch: 2 Iteration: 39  train.loss : 5.968458485603333  train.ips : 3065.12508802935 images/s train.lr : 0.11837439999999999 
[1,0]<stdout>:DLL 2023-07-31 12:56:13.519593 - Epoch: 2 Iteration: 59  train.loss : 5.992914438247681  train.ips : 3063.4491119068293 images/s train.lr : 0.12656640000000002 
[1,0]<stdout>:DLL 2023-07-31 12:56:15.189841 - Epoch: 2 Iteration: 79  train.loss : 5.953410673141479  train.ips : 3065.8672480080636 images/s train.lr : 0.1347584 
[1,0]<stdout>:DLL 2023-07-31 12:56:16.858960 - Epoch: 2 Iteration: 99  train.loss : 5.928263449668885  train.ips : 3067.9455437305214 images/s train.lr : 0.14295039999999998 
[1,0]<stdout>:DLL 2023-07-31 12:56:18.528483 - Epoch: 2 Iteration: 119  train.loss : 5.967742252349853  train.ips : 3067.2948153395905 images/s train.lr : 0.1511424 
[1,0]<stdout>:DLL 2023-07-31 12:56:20.199306 - Epoch: 2 Iteration: 139  train.loss : 5.924743175506592  train.ips : 3064.830249212914 images/s train.lr : 0.15933440000000001 
[1,0]<stdout>:DLL 2023-07-31 12:56:21.869868 - Epoch: 2 Iteration: 159  train.loss : 5.959450149536133  train.ips : 3065.290030030793 images/s train.lr : 0.16752640000000002 
[1,0]<stdout>:DLL 2023-07-31 12:56:23.539792 - Epoch: 2 Iteration: 179  train.loss : 5.930743408203125  train.ips : 3066.463511733614 images/s train.lr : 0.1757184 
[1,0]<stdout>:DLL 2023-07-31 12:56:25.212344 - Epoch: 2 Iteration: 199  train.loss : 5.955743956565857  train.ips : 3061.64968786618 images/s train.lr : 0.1839104 
[1,0]<stdout>:DLL 2023-07-31 12:56:26.881423 - Epoch: 2 Iteration: 219  train.loss : 5.931013226509094  train.ips : 3068.017425614476 images/s train.lr : 0.19210239999999998 
[1,0]<stdout>:DLL 2023-07-31 12:56:28.553500 - Epoch: 2 Iteration: 239  train.loss : 5.9347292423248295  train.ips : 3062.5229305922203 images/s train.lr : 0.20029439999999998 
[1,0]<stdout>:DLL 2023-07-31 12:56:30.224352 - Epoch: 2 Iteration: 259  train.loss : 5.910225033760071  train.ips : 3064.8788018523283 images/s train.lr : 0.20848640000000002 
[1,0]<stdout>:DLL 2023-07-31 12:56:31.892416 - Epoch: 2 Iteration: 279  train.loss : 5.933970093727112  train.ips : 3070.20441926945 images/s train.lr : 0.21667840000000002 
[1,0]<stdout>:DLL 2023-07-31 12:56:33.562153 - Epoch: 2 Iteration: 299  train.loss : 5.933846402168274  train.ips : 3066.8239215515464 images/s train.lr : 0.22487039999999997 
[1,0]<stdout>:DLL 2023-07-31 12:56:35.234397 - Epoch: 2 Iteration: 319  train.loss : 5.907632827758789  train.ips : 3062.238635407591 images/s train.lr : 0.23306239999999998 
[1,0]<stdout>:DLL 2023-07-31 12:56:36.908384 - Epoch: 2 Iteration: 339  train.loss : 5.897144174575805  train.ips : 3059.013772148105 images/s train.lr : 0.2412544 
[1,0]<stdout>:DLL 2023-07-31 12:56:38.579125 - Epoch: 2 Iteration: 359  train.loss : 5.855897402763366  train.ips : 3064.968475185484 images/s train.lr : 0.24944639999999998 
[1,0]<stdout>:DLL 2023-07-31 12:56:40.251468 - Epoch: 2 Iteration: 379  train.loss : 5.897642350196838  train.ips : 3062.053500720212 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:41.921468 - Epoch: 2 Iteration: 399  train.loss : 5.874558401107788  train.ips : 3066.3334696951847 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:43.590939 - Epoch: 2 Iteration: 419  train.loss : 5.8973512887954715  train.ips : 3067.290872372733 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:45.260850 - Epoch: 2 Iteration: 439  train.loss : 5.913785171508789  train.ips : 3066.4665768305304 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:46.936975 - Epoch: 2 Iteration: 459  train.loss : 5.867888998985291  train.ips : 3055.0953445967507 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:48.609524 - Epoch: 2 Iteration: 479  train.loss : 5.879560256004334  train.ips : 3061.616077976498 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:50.278621 - Epoch: 2 Iteration: 499  train.loss : 5.869520950317383  train.ips : 3067.9722798914922 images/s train.lr : 0 
[1,0]<stdout>:DLL 2023-07-31 12:56:50.280595 - Epoch: 2  train.loss : 5.923632937431336  train.ips : 3070.7703271392484 images/s
[1,0]<stdout>:DLL 2023-07-31 12:56:50.330311 - Summary: train.loss : 5.923632937431336  train.ips : 3023.650800473703 images/s
train.ips
           |    256    |
------------------------
     1     |   3046.4  |

