[1,0]<stdout>:DLL 2021-05-28 09:50:09.336759 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float16  amp : False  batch_size : 128  num_epochs : 3  run_epochs : -1  lr : 0.128  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-1,128  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 3  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[[1,0]<stderr>:09:50:09] ../src/storage/storage.cc:199: [1,0]<stderr>:Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[09:50:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-05-28 09:50:15,316:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-05-28 09:50:15,317:INFO: Starting epoch 0
[1,0]<stderr>:[09:50:15] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-05-28 09:50:25.687774 - Epoch: 0 Iteration: 19  train.loss : 7.116805982589722  train.ips : 246.84694428053632  train.lr : 0.0019456 
[1,0]<stdout>:DLL 2021-05-28 09:50:27.600602 - Epoch: 0 Iteration: 39  train.loss : 7.075488948822022  train.ips : 1338.6320802644298  train.lr : 0.0039936 
[1,0]<stdout>:DLL 2021-05-28 09:50:29.517288 - Epoch: 0 Iteration: 59  train.loss : 7.0219789981842045  train.ips : 1335.8508573210845  train.lr : 0.006041599999999999 
[1,0]<stdout>:DLL 2021-05-28 09:50:31.432920 - Epoch: 0 Iteration: 79  train.loss : 6.9810165643692015  train.ips : 1336.5620486929288  train.lr : 0.008089599999999999 
[1,0]<stdout>:DLL 2021-05-28 09:50:33.353654 - Epoch: 0 Iteration: 99  train.loss : 6.937991189956665  train.ips : 1333.002391166897  train.lr : 0.0101376 
[1,0]<stdout>:DLL 2021-05-28 09:50:35.277433 - Epoch: 0 Iteration: 119  train.loss : 6.919995188713074  train.ips : 1330.8901668561637  train.lr : 0.0121856 
[1,0]<stdout>:DLL 2021-05-28 09:50:37.204330 - Epoch: 0 Iteration: 139  train.loss : 6.872754073143005  train.ips : 1328.7397350593449  train.lr : 0.014233600000000003 
[1,0]<stdout>:DLL 2021-05-28 09:50:39.129994 - Epoch: 0 Iteration: 159  train.loss : 6.866753196716308  train.ips : 1329.6346699539902  train.lr : 0.0162816 
[1,0]<stdout>:DLL 2021-05-28 09:50:41.051819 - Epoch: 0 Iteration: 179  train.loss : 6.855830430984497  train.ips : 1332.4173231082323  train.lr : 0.018329599999999998 
[1,0]<stdout>:DLL 2021-05-28 09:50:42.978505 - Epoch: 0 Iteration: 199  train.loss : 6.829170083999633  train.ips : 1328.8721140669193  train.lr : 0.020377600000000003 
[1,0]<stdout>:DLL 2021-05-28 09:50:44.903835 - Epoch: 0 Iteration: 219  train.loss : 6.832203078269958  train.ips : 1329.8439745193143  train.lr : 0.0224256 
[1,0]<stdout>:DLL 2021-05-28 09:50:46.828479 - Epoch: 0 Iteration: 239  train.loss : 6.807438611984253  train.ips : 1330.4658543173714  train.lr : 0.024473599999999998 
[1,0]<stdout>:DLL 2021-05-28 09:50:48.755803 - Epoch: 0 Iteration: 259  train.loss : 6.81001226902008  train.ips : 1328.5764765376248  train.lr : 0.0265216 
[1,0]<stdout>:DLL 2021-05-28 09:50:50.676502 - Epoch: 0 Iteration: 279  train.loss : 6.7791460990905765  train.ips : 1333.0475704518678  train.lr : 0.0285696 
[1,0]<stdout>:DLL 2021-05-28 09:50:52.602537 - Epoch: 0 Iteration: 299  train.loss : 6.7843017578125  train.ips : 1329.3714448715523  train.lr : 0.030617600000000002 
[1,0]<stdout>:DLL 2021-05-28 09:50:54.530981 - Epoch: 0 Iteration: 319  train.loss : 6.755013561248779  train.ips : 1327.8952684273384  train.lr : 0.0326656 
[1,0]<stdout>:DLL 2021-05-28 09:50:56.459365 - Epoch: 0 Iteration: 339  train.loss : 6.7515535116195675  train.ips : 1328.2905009218005  train.lr : 0.034713600000000004 
[1,0]<stdout>:DLL 2021-05-28 09:50:58.387639 - Epoch: 0 Iteration: 359  train.loss : 6.760068893432617  train.ips : 1327.9458503154012  train.lr : 0.0367616 
[1,0]<stdout>:DLL 2021-05-28 09:51:00.313229 - Epoch: 0 Iteration: 379  train.loss : 6.723854374885559  train.ips : 1329.7423605332683  train.lr : 0.0388096 
[1,0]<stdout>:DLL 2021-05-28 09:51:02.238788 - Epoch: 0 Iteration: 399  train.loss : 6.717467498779297  train.ips : 1329.640926727466  train.lr : 0.04085760000000001 
[1,0]<stdout>:DLL 2021-05-28 09:51:04.166862 - Epoch: 0 Iteration: 419  train.loss : 6.713996410369873  train.ips : 1328.0391413065431  train.lr : 0.0429056 
[1,0]<stdout>:DLL 2021-05-28 09:51:06.092922 - Epoch: 0 Iteration: 439  train.loss : 6.662006759643555  train.ips : 1329.3495552974628  train.lr : 0.044953599999999996 
[1,0]<stdout>:DLL 2021-05-28 09:51:08.028633 - Epoch: 0 Iteration: 459  train.loss : 6.721950268745422  train.ips : 1322.7498870649413  train.lr : 0.047001600000000004 
[1,0]<stdout>:DLL 2021-05-28 09:51:09.961456 - Epoch: 0 Iteration: 479  train.loss : 6.661521100997925  train.ips : 1324.7944859505324  train.lr : 0.0490496 
[1,0]<stdout>:DLL 2021-05-28 09:51:11.888658 - Epoch: 0 Iteration: 499  train.loss : 6.665648674964904  train.ips : 1328.5074366669855  train.lr : 0.0510976 
[1,0]<stdout>:DLL 2021-05-28 09:51:11.889352 - Epoch: 0  train.loss : 6.824958701133728  train.ips : 1131.29407984638 
[1,0]<stderr>:2021-05-28 09:51:11,889:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 09:51:13.817067 - Epoch: 1 Iteration: 19  train.loss : 6.630522227287292  train.ips : 1328.1043542364223  train.lr : 0.027545600000000003 
[1,0]<stdout>:DLL 2021-05-28 09:51:15.745685 - Epoch: 1 Iteration: 39  train.loss : 6.5543958187103275  train.ips : 1327.554105582743  train.lr : 0.029593599999999998 
[1,0]<stdout>:DLL 2021-05-28 09:51:17.672684 - Epoch: 1 Iteration: 59  train.loss : 6.542315149307251  train.ips : 1328.6632796992687  train.lr : 0.031641600000000006 
[1,0]<stdout>:DLL 2021-05-28 09:51:19.601565 - Epoch: 1 Iteration: 79  train.loss : 6.549765110015869  train.ips : 1327.3885127325188  train.lr : 0.0336896 
[1,0]<stdout>:DLL 2021-05-28 09:51:21.537934 - Epoch: 1 Iteration: 99  train.loss : 6.566030955314636  train.ips : 1322.3206519302887  train.lr : 0.035737599999999994 
[1,0]<stdout>:DLL 2021-05-28 09:51:23.467164 - Epoch: 1 Iteration: 119  train.loss : 6.54218487739563  train.ips : 1327.1552101760176  train.lr : 0.0377856 
[1,0]<stdout>:DLL 2021-05-28 09:51:25.396923 - Epoch: 1 Iteration: 139  train.loss : 6.546843147277832  train.ips : 1326.848694599552  train.lr : 0.039833600000000004 
[1,0]<stdout>:DLL 2021-05-28 09:51:27.333211 - Epoch: 1 Iteration: 159  train.loss : 6.54277732372284  train.ips : 1322.3856301678886  train.lr : 0.041881600000000005 
[1,0]<stdout>:DLL 2021-05-28 09:51:29.267296 - Epoch: 1 Iteration: 179  train.loss : 6.48272180557251  train.ips : 1323.8308053058186  train.lr : 0.0439296 
[1,0]<stdout>:DLL 2021-05-28 09:51:31.200536 - Epoch: 1 Iteration: 199  train.loss : 6.540404558181763  train.ips : 1324.3221071898133  train.lr : 0.0459776 
[1,0]<stdout>:DLL 2021-05-28 09:51:33.134634 - Epoch: 1 Iteration: 219  train.loss : 6.553574347496033  train.ips : 1323.7320664530268  train.lr : 0.048025599999999995 
[1,0]<stdout>:DLL 2021-05-28 09:51:35.067289 - Epoch: 1 Iteration: 239  train.loss : 6.517245960235596  train.ips : 1324.7694778684393  train.lr : 0.050073599999999996 
[1,0]<stdout>:DLL 2021-05-28 09:51:36.994982 - Epoch: 1 Iteration: 259  train.loss : 6.55046317577362  train.ips : 1328.18337394915  train.lr : 0.052121600000000004 
[1,0]<stdout>:DLL 2021-05-28 09:51:38.930214 - Epoch: 1 Iteration: 279  train.loss : 6.509810090065002  train.ips : 1323.0150606158059  train.lr : 0.054169600000000005 
[1,0]<stdout>:DLL 2021-05-28 09:51:40.863053 - Epoch: 1 Iteration: 299  train.loss : 6.547149920463562  train.ips : 1324.6624277968663  train.lr : 0.05621759999999999 
[1,0]<stdout>:DLL 2021-05-28 09:51:42.792915 - Epoch: 1 Iteration: 319  train.loss : 6.503057050704956  train.ips : 1326.6786878983  train.lr : 0.058265599999999994 
[1,0]<stdout>:DLL 2021-05-28 09:51:44.723625 - Epoch: 1 Iteration: 339  train.loss : 6.5109693050384525  train.ips : 1326.111603685303  train.lr : 0.0603136 
[1,0]<stdout>:DLL 2021-05-28 09:51:46.652534 - Epoch: 1 Iteration: 359  train.loss : 6.522118735313415  train.ips : 1327.3533972594068  train.lr : 0.062361599999999996 
[1,0]<stdout>:DLL 2021-05-28 09:51:48.584734 - Epoch: 1 Iteration: 379  train.loss : 6.4717203140258786  train.ips : 1325.1283443624754  train.lr : 0.0644096 
[1,0]<stdout>:DLL 2021-05-28 09:51:50.519563 - Epoch: 1 Iteration: 399  train.loss : 6.479879546165466  train.ips : 1323.4024995889563  train.lr : 0.0664576 
[1,0]<stdout>:DLL 2021-05-28 09:51:52.454205 - Epoch: 1 Iteration: 419  train.loss : 6.461762380599976  train.ips : 1323.4117969979923  train.lr : 0.06850560000000001 
[1,0]<stdout>:DLL 2021-05-28 09:51:54.386693 - Epoch: 1 Iteration: 439  train.loss : 6.495075798034668  train.ips : 1324.9126741710456  train.lr : 0.07055360000000001 
[1,0]<stdout>:DLL 2021-05-28 09:51:56.319785 - Epoch: 1 Iteration: 459  train.loss : 6.4573835849761965  train.ips : 1324.464389923312  train.lr : 0.07260160000000002 
[1,0]<stdout>:DLL 2021-05-28 09:51:58.256610 - Epoch: 1 Iteration: 479  train.loss : 6.473784303665161  train.ips : 1321.9273361019227  train.lr : 0.07464960000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:00.193645 - Epoch: 1 Iteration: 499  train.loss : 6.465527200698853  train.ips : 1321.7860860504989  train.lr : 0.0766976 
[1,0]<stdout>:DLL 2021-05-28 09:52:00.193983 - Epoch: 1  train.loss : 6.520699307441712  train.ips : 1324.9297944124685 
[1,0]<stderr>:2021-05-28 09:52:00,194:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-05-28 09:52:02.127928 - Epoch: 2 Iteration: 19  train.loss : 6.40711739063263  train.ips : 1323.8097506620024  train.lr : 0.0531456 
[1,0]<stdout>:DLL 2021-05-28 09:52:04.059742 - Epoch: 2 Iteration: 39  train.loss : 6.401987099647522  train.ips : 1325.3506284215598  train.lr : 0.05519360000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:05.996919 - Epoch: 2 Iteration: 59  train.loss : 6.380352258682251  train.ips : 1321.7325556132055  train.lr : 0.05724159999999999 
[1,0]<stdout>:DLL 2021-05-28 09:52:07.936286 - Epoch: 2 Iteration: 79  train.loss : 6.382311701774597  train.ips : 1320.297312930122  train.lr : 0.0592896 
[1,0]<stdout>:DLL 2021-05-28 09:52:09.873779 - Epoch: 2 Iteration: 99  train.loss : 6.356199479103088  train.ips : 1321.4854606570323  train.lr : 0.061337600000000006 
[1,0]<stdout>:DLL 2021-05-28 09:52:11.811622 - Epoch: 2 Iteration: 119  train.loss : 6.3606003522872925  train.ips : 1321.2194366855751  train.lr : 0.0633856 
[1,0]<stdout>:DLL 2021-05-28 09:52:13.744031 - Epoch: 2 Iteration: 139  train.loss : 6.365942478179932  train.ips : 1324.9515844505584  train.lr : 0.06543360000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:15.681292 - Epoch: 2 Iteration: 159  train.loss : 6.349331045150757  train.ips : 1321.7288135259403  train.lr : 0.0674816 
[1,0]<stdout>:DLL 2021-05-28 09:52:17.621502 - Epoch: 2 Iteration: 179  train.loss : 6.374700903892517  train.ips : 1319.6258637086175  train.lr : 0.0695296 
[1,0]<stdout>:DLL 2021-05-28 09:52:19.559863 - Epoch: 2 Iteration: 199  train.loss : 6.3145578622817995  train.ips : 1320.9192314633485  train.lr : 0.0715776 
[1,0]<stdout>:DLL 2021-05-28 09:52:21.497086 - Epoch: 2 Iteration: 219  train.loss : 6.35412871837616  train.ips : 1321.734508014973  train.lr : 0.0736256 
[1,0]<stdout>:DLL 2021-05-28 09:52:23.431058 - Epoch: 2 Iteration: 239  train.loss : 6.3369242429733275  train.ips : 1323.8574101933914  train.lr : 0.0756736 
[1,0]<stdout>:DLL 2021-05-28 09:52:25.368029 - Epoch: 2 Iteration: 259  train.loss : 6.353856253623962  train.ips : 1321.817815863929  train.lr : 0.0777216 
[1,0]<stdout>:DLL 2021-05-28 09:52:27.302744 - Epoch: 2 Iteration: 279  train.loss : 6.2821869373321535  train.ips : 1323.372324687728  train.lr : 0.07976960000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:29.244848 - Epoch: 2 Iteration: 299  train.loss : 6.294334959983826  train.ips : 1318.3476518131085  train.lr : 0.08181759999999999 
[1,0]<stdout>:DLL 2021-05-28 09:52:31.184092 - Epoch: 2 Iteration: 319  train.loss : 6.3056851625442505  train.ips : 1320.3124113508752  train.lr : 0.0838656 
[1,0]<stdout>:DLL 2021-05-28 09:52:33.124995 - Epoch: 2 Iteration: 339  train.loss : 6.297649264335632  train.ips : 1319.2511682910422  train.lr : 0.0859136 
[1,0]<stdout>:DLL 2021-05-28 09:52:35.061504 - Epoch: 2 Iteration: 359  train.loss : 6.282444930076599  train.ips : 1322.138290992571  train.lr : 0.0879616 
[1,0]<stdout>:DLL 2021-05-28 09:52:36.997556 - Epoch: 2 Iteration: 379  train.loss : 6.239026260375977  train.ips : 1322.4574556500738  train.lr : 0.0900096 
[1,0]<stdout>:DLL 2021-05-28 09:52:38.934778 - Epoch: 2 Iteration: 399  train.loss : 6.284176564216613  train.ips : 1321.6484451141532  train.lr : 0.0920576 
[1,0]<stdout>:DLL 2021-05-28 09:52:40.872951 - Epoch: 2 Iteration: 419  train.loss : 6.2821208238601685  train.ips : 1321.0419301593802  train.lr : 0.09410560000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:42.813630 - Epoch: 2 Iteration: 439  train.loss : 6.334330487251282  train.ips : 1319.3884724566112  train.lr : 0.0961536 
[1,0]<stdout>:DLL 2021-05-28 09:52:44.751798 - Epoch: 2 Iteration: 459  train.loss : 6.284038829803467  train.ips : 1321.0375418659823  train.lr : 0.09820160000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:46.689930 - Epoch: 2 Iteration: 479  train.loss : 6.2567157506942745  train.ips : 1321.007637235438  train.lr : 0.10024960000000001 
[1,0]<stdout>:DLL 2021-05-28 09:52:48.630220 - Epoch: 2 Iteration: 499  train.loss : 6.243297815322876  train.ips : 1319.5656970524458  train.lr : 0.10229760000000002 
[1,0]<stdout>:DLL 2021-05-28 09:52:48.630577 - Epoch: 2  train.loss : 6.324960702896118  train.ips : 1321.3193945002079 
[1,0]<stdout>:DLL 2021-05-28 09:52:48.691690 - Summary: train.loss : 6.324960702896118  train.ips : 1259.181089586352 
[1,0]<stdout>:DLL 2021-05-28 09:52:55.235807 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 1024  num_epochs : 3  run_epochs : -1  lr : 1.024  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,128  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 3  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,1]<stderr>:[09:52:55] ../src/storage/storage.cc:[1,1]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[[1,3]<stderr>:[09:52:55] [1,4]<stderr>:09:52:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:[[1,5]<stderr>:09:52:55] ../src/storage/storage.cc:[1,5]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:[[1,7]<stderr>:09:52:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:[[1,2]<stderr>:09:52:55] ../src/storage/storage.cc:[1,2]<stderr>:199: Using Pooled (Naive) StorageManager for [1,2]<stderr>:CPU
[1,0]<stderr>:[[1,0]<stderr>:09:52:55] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[09:52:55[1,6]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:[09:52:59[1,5]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[09:52:59] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,4]<stderr>:[09:52:59] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[09:52:59] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[[1,0]<stderr>:09:52:59] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive) StorageManager for [1,0]<stderr>:GPU
[1,6]<stderr>:[09:52:59] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[09:52:59[1,7]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[09:52:59] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2021-05-28 09:53:03,954:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2021-05-28 09:53:03,954:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 10953, errno = 1
[1,4]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2021-05-28 09:53:04,430:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2021-05-28 09:53:04,431:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 11441, errno = 1
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 4305, errno = 1
[1,7]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2021-05-28 09:53:04,677:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2021-05-28 09:53:04,678:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2021-05-28 09:53:04,722:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2021-05-28 09:53:04,722:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2021-05-28 09:53:04,770:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2021-05-28 09:53:04,771:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-05-28 09:53:04,800:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-05-28 09:53:04,801:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2021-05-28 09:53:04,935:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2021-05-28 09:53:04,936:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2021-05-28 09:53:05,429:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2021-05-28 09:53:05,429:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 16577, errno = 1
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 14977, errno = 1
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 15209, errno = 1
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 14873, errno = 1
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 14089, errno = 1
[1,4]<stderr>:[6389caacd155:05321] Read -1, expected 10117, errno = 1
[1,2]<stderr>:[6389caacd155:05319] Read -1, expected 10117, errno = 1
[1,6]<stderr>:[6389caacd155:05323] Read -1, expected 10117, errno = 1
[1,3]<stderr>:[6389caacd155:05320] Read -1, expected 10116, errno = 1
[1,5]<stderr>:[6389caacd155:05322] Read -1, expected 10116, errno = 1
[1,1]<stderr>:[6389caacd155:05318] Read -1, expected 10116, errno = 1
[1,7]<stderr>:[6389caacd155:05324] Read -1, expected 10116, errno = 1
[1,0]<stderr>:[6389caacd155:05317] Read -1, expected 4049, errno = 1
[1,5]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,3]<stderr>:[09:53:10[1,4]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,3]<stderr>:] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,6]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h[1,2]<stderr>::120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[09:53:10] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,7]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-05-28 09:53:21.939140 - Epoch: 0 Iteration: 19  train.loss : 6.994706034660339  train.ips : 1194.9680294928703  train.lr : 0.1216 
[1,0]<stdout>:DLL 2021-05-28 09:53:24.619033 - Epoch: 0 Iteration: 39  train.loss : 6.823736548423767  train.ips : 7643.014744724478  train.lr : 0.2496 
[1,0]<stdout>:DLL 2021-05-28 09:53:27.336665 - Epoch: 0 Iteration: 59  train.loss : 6.734424567222595  train.ips : 7536.708253118107  train.lr : 0.37760000000000005 
[1,0]<stdout>:DLL 2021-05-28 09:53:30.114574 - Epoch: 0 Iteration: 79  train.loss : 6.619111180305481  train.ips : 7372.923681762278  train.lr : 0.5056 
[1,0]<stdout>:DLL 2021-05-28 09:53:32.750862 - Epoch: 0 Iteration: 99  train.loss : 6.580301952362061  train.ips : 7769.011854661755  train.lr : 0.6336 
[1,0]<stdout>:DLL 2021-05-28 09:53:35.183168 - Epoch: 0 Iteration: 119  train.loss : 6.482834219932556  train.ips : 8420.53614030465  train.lr : 0.7616 
[1,0]<stdout>:DLL 2021-05-28 09:53:37.652796 - Epoch: 0 Iteration: 139  train.loss : 6.42316620349884  train.ips : 8293.328668179753  train.lr : 0.8896000000000001 
[1,0]<stdout>:DLL 2021-05-28 09:53:40.420327 - Epoch: 0 Iteration: 159  train.loss : 6.35820996761322  train.ips : 7400.617600456826  train.lr : 1.0176 
[1,0]<stdout>:DLL 2021-05-28 09:53:43.249598 - Epoch: 0 Iteration: 179  train.loss : 6.308483600616455  train.ips : 7239.238854394791  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:53:45.943874 - Epoch: 0 Iteration: 199  train.loss : 6.325294065475464  train.ips : 7602.22063706209  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:53:48.750431 - Epoch: 0 Iteration: 219  train.loss : 6.333736419677734  train.ips : 7297.8247915707525  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:53:51.472042 - Epoch: 0 Iteration: 239  train.loss : 6.286507177352905  train.ips : 7525.734081812274  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:53:54.370848 - Epoch: 0 Iteration: 259  train.loss : 6.317985677719117  train.ips : 7065.422105431212  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:53:57.397534 - Epoch: 0 Iteration: 279  train.loss : 6.335061407089233  train.ips : 6767.015622550483  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:00.284217 - Epoch: 0 Iteration: 299  train.loss : 6.309514141082763  train.ips : 7095.662561091105  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:03.535704 - Epoch: 0 Iteration: 319  train.loss : 6.308019661903382  train.ips : 6299.019128924818  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:06.709964 - Epoch: 0 Iteration: 339  train.loss : 6.324071836471558  train.ips : 6452.679408764803  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:09.951619 - Epoch: 0 Iteration: 359  train.loss : 6.3458761215209964  train.ips : 6318.283561576629  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:13.293075 - Epoch: 0 Iteration: 379  train.loss : 6.307667827606201  train.ips : 6129.393256089071  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:16.658935 - Epoch: 0 Iteration: 399  train.loss : 6.320886445045471  train.ips : 6085.092191265468  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:19.874293 - Epoch: 0 Iteration: 419  train.loss : 6.3168199300765995  train.ips : 6369.891194904286  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:23.015231 - Epoch: 0 Iteration: 439  train.loss : 6.307296180725098  train.ips : 6520.864832677813  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:26.282430 - Epoch: 0 Iteration: 459  train.loss : 6.34907021522522  train.ips : 6268.962729090734  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:29.538256 - Epoch: 0 Iteration: 479  train.loss : 6.311663126945495  train.ips : 6290.750287168712  train.lr : 0 
[1,5]<stderr>:2021-05-28 09:54:32,694:INFO: Starting epoch 1
[1,6]<stderr>:2021-05-28 09:54:32,694:INFO: Starting epoch 1
[1,4]<stderr>:2021-05-28 09:54:32,695:INFO: Starting epoch 1
[1,1]<stderr>:2021-05-28 09:54:32,695:INFO: Starting epoch 1
[1,7]<stderr>:2021-05-28 09:54:32,696:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 09:54:32.696768 - Epoch: 0 Iteration: 499  train.loss : 6.297106742858887  train.ips : 6484.94092543756  train.lr : 0 
[1,3]<stderr>:2021-05-28 09:54:32,696:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 09:54:32.697112 - Epoch: 0  train.loss : 6.416862050056458  train.ips : 5825.031326972205 
[1,2]<stderr>:2021-05-28 09:54:32,697:INFO: Starting epoch 1
[1,0]<stderr>:2021-05-28 09:54:32,697:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-05-28 09:54:35.772293 - Epoch: 1 Iteration: 19  train.loss : 6.2382303953170775  train.ips : 6660.838008039126  train.lr : 0.3264 
[1,0]<stdout>:DLL 2021-05-28 09:54:38.876600 - Epoch: 1 Iteration: 39  train.loss : 6.1378909826278685  train.ips : 6597.937442934895  train.lr : 0.4544 
[1,0]<stdout>:DLL 2021-05-28 09:54:42.185071 - Epoch: 1 Iteration: 59  train.loss : 6.161902594566345  train.ips : 6190.660529770349  train.lr : 0.5824 
[1,0]<stdout>:DLL 2021-05-28 09:54:45.258685 - Epoch: 1 Iteration: 79  train.loss : 6.15106098651886  train.ips : 6663.820047250645  train.lr : 0.7104 
[1,0]<stdout>:DLL 2021-05-28 09:54:48.507930 - Epoch: 1 Iteration: 99  train.loss : 6.122716665267944  train.ips : 6303.543999769284  train.lr : 0.8384 
[1,0]<stdout>:DLL 2021-05-28 09:54:51.669174 - Epoch: 1 Iteration: 119  train.loss : 6.0770491600036625  train.ips : 6478.949620767371  train.lr : 0.9663999999999999 
[1,0]<stdout>:DLL 2021-05-28 09:54:54.874189 - Epoch: 1 Iteration: 139  train.loss : 6.082894253730774  train.ips : 6390.738367279647  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:54:58.000627 - Epoch: 1 Iteration: 159  train.loss : 6.090170669555664  train.ips : 6551.396241300362  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:01.151149 - Epoch: 1 Iteration: 179  train.loss : 5.997452807426453  train.ips : 6501.221006717576  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:04.462309 - Epoch: 1 Iteration: 199  train.loss : 6.084551072120666  train.ips : 6185.564303823118  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:07.742141 - Epoch: 1 Iteration: 219  train.loss : 6.101794099807739  train.ips : 6244.9088643484965  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:10.981459 - Epoch: 1 Iteration: 239  train.loss : 6.060693144798279  train.ips : 6323.324878122322  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:14.233766 - Epoch: 1 Iteration: 259  train.loss : 6.0937501907348635  train.ips : 6297.666489318923  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:17.364024 - Epoch: 1 Iteration: 279  train.loss : 6.074721026420593  train.ips : 6543.404386308169  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:20.526947 - Epoch: 1 Iteration: 299  train.loss : 6.091363692283631  train.ips : 6475.50581096264  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:23.754398 - Epoch: 1 Iteration: 319  train.loss : 6.0357481956481935  train.ips : 6346.36788615874  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:27.015884 - Epoch: 1 Iteration: 339  train.loss : 6.095177865028381  train.ips : 6280.250597798137  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:30.083979 - Epoch: 1 Iteration: 359  train.loss : 6.101564049720764  train.ips : 6675.7516063698195  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:33.249476 - Epoch: 1 Iteration: 379  train.loss : 6.046779632568359  train.ips : 6470.4607598216735  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:36.564515 - Epoch: 1 Iteration: 399  train.loss : 6.09292323589325  train.ips : 6178.7768920904  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:39.636065 - Epoch: 1 Iteration: 419  train.loss : 6.078276896476746  train.ips : 6668.3164926654945  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:42.679397 - Epoch: 1 Iteration: 439  train.loss : 6.0851421594619755  train.ips : 6730.100837892182  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:45.881815 - Epoch: 1 Iteration: 459  train.loss : 6.0407051086425785  train.ips : 6395.5812466132575  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:48.935053 - Epoch: 1 Iteration: 479  train.loss : 6.091662573814392  train.ips : 6708.181116334178  train.lr : 0 
[1,5]<stderr>:2021-05-28 09:55:52,044:INFO: Starting epoch 2
[1,2]<stderr>:2021-05-28 09:55:52,044:INFO: Starting epoch 2
[1,6]<stderr>:2021-05-28 09:55:52,044:INFO: Starting epoch 2
[1,7]<stderr>:2021-05-28 09:55:52,044:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-05-28 09:55:52.044998 - Epoch: 1 Iteration: 499  train.loss : 6.092739391326904  train.ips : 6585.7534822532525  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:55:52.045323 - Epoch: 1  train.loss : 6.093078433990478  train.ips : 6452.6129641262005 
[1,4]<stderr>:2021-05-28 09:55:52,045:INFO: Starting epoch 2
[1,0]<stderr>:2021-05-28 09:55:52,045:INFO: Starting epoch 2
[1,1]<stderr>:2021-05-28 09:55:52,045:INFO: Starting epoch 2
[1,3]<stderr>:2021-05-28 09:55:52,046:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-05-28 09:55:55.186102 - Epoch: 2 Iteration: 19  train.loss : 6.035699653625488  train.ips : 6520.909384555834  train.lr : 0.5312 
[1,0]<stdout>:DLL 2021-05-28 09:55:58.382671 - Epoch: 2 Iteration: 39  train.loss : 5.9507420539855955  train.ips : 6407.51556724847  train.lr : 0.6592 
[1,0]<stdout>:DLL 2021-05-28 09:56:01.425923 - Epoch: 2 Iteration: 59  train.loss : 5.9386759996414185  train.ips : 6730.155676972632  train.lr : 0.7872 
[1,0]<stdout>:DLL 2021-05-28 09:56:04.704347 - Epoch: 2 Iteration: 79  train.loss : 5.9508168458938595  train.ips : 6247.426892912033  train.lr : 0.9152000000000001 
[1,0]<stdout>:DLL 2021-05-28 09:56:07.725243 - Epoch: 2 Iteration: 99  train.loss : 5.921380257606506  train.ips : 6780.126856429049  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:10.749020 - Epoch: 2 Iteration: 119  train.loss : 5.929296135902405  train.ips : 6773.612165405456  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:13.845123 - Epoch: 2 Iteration: 139  train.loss : 5.886680388450623  train.ips : 6615.391161277225  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:16.834453 - Epoch: 2 Iteration: 159  train.loss : 5.908690309524536  train.ips : 6851.55743866254  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:19.810914 - Epoch: 2 Iteration: 179  train.loss : 5.920180559158325  train.ips : 6881.165683149146  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:22.799435 - Epoch: 2 Iteration: 199  train.loss : 5.89300377368927  train.ips : 6853.8425630853535  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:25.697555 - Epoch: 2 Iteration: 219  train.loss : 5.9403619289398195  train.ips : 7067.101439593511  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:28.915491 - Epoch: 2 Iteration: 239  train.loss : 5.888644337654114  train.ips : 6364.880553474666  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:31.864609 - Epoch: 2 Iteration: 259  train.loss : 5.907872867584229  train.ips : 6944.974356760309  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:34.990808 - Epoch: 2 Iteration: 279  train.loss : 5.92303159236908  train.ips : 6551.72553628837  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:37.954498 - Epoch: 2 Iteration: 299  train.loss : 5.879181170463562  train.ips : 6910.733474150321  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:40.893670 - Epoch: 2 Iteration: 319  train.loss : 5.91572756767273  train.ips : 6968.727691281877  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:43.872482 - Epoch: 2 Iteration: 339  train.loss : 5.869633936882019  train.ips : 6875.664933089425  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:46.795838 - Epoch: 2 Iteration: 359  train.loss : 5.858644413948059  train.ips : 7006.66853295068  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:49.743695 - Epoch: 2 Iteration: 379  train.loss : 5.8344275712966915  train.ips : 6948.568706902772  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:52.660159 - Epoch: 2 Iteration: 399  train.loss : 5.896731114387512  train.ips : 7022.977650736404  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:55.619105 - Epoch: 2 Iteration: 419  train.loss : 5.864383864402771  train.ips : 6921.846433920561  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:56:58.590033 - Epoch: 2 Iteration: 439  train.loss : 5.956654143333435  train.ips : 6893.909463098404  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:57:01.511368 - Epoch: 2 Iteration: 459  train.loss : 5.925893545150757  train.ips : 7011.102350385895  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:57:04.296426 - Epoch: 2 Iteration: 479  train.loss : 5.902825665473938  train.ips : 7354.109571930203  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:57:07.168107 - Epoch: 2 Iteration: 499  train.loss : 5.895043134689331  train.ips : 7132.371675284807  train.lr : 0 
[1,0]<stdout>:DLL 2021-05-28 09:57:07.168323 - Epoch: 2  train.loss : 5.911768913269043  train.ips : 6815.499266004018 
[1,0]<stdout>:DLL 2021-05-28 09:57:07.235109 - Summary: train.loss : 5.911768913269043  train.ips : 6364.381185700808 
train.ips
           |    128    |
------------------------
     1     |   1323.1  |
     8     |   6629.1  |

