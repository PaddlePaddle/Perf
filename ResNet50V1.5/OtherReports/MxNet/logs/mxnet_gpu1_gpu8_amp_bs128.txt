[1,0]<stdout>:DLL 2021-12-17 10:52:28.108923 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float16  amp : False  batch_size : 128  num_epochs : 3  run_epochs : -1  lr : 0.128  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-1,128  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[10:52:28] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[10:52:30] ../src/storage/storage.cc:199: Using [1,0]<stderr>:Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-12-17 10:52:33,940:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-12-17 10:52:33,940:INFO: Starting epoch 0
[1,0]<stderr>:[10:52:34] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-12-17 10:52:43.767715 - Epoch: 0 Iteration: 19  train.loss : 7.116805982589722  train.ips : 260.4854277216634  train.lr : 0.0019456 
[1,0]<stdout>:DLL 2021-12-17 10:52:45.760284 - Epoch: 0 Iteration: 39  train.loss : 7.075488948822022  train.ips : 1284.9859293717288  train.lr : 0.0039936 
[1,0]<stdout>:DLL 2021-12-17 10:52:47.752729 - Epoch: 0 Iteration: 59  train.loss : 7.0219789981842045  train.ips : 1284.948562174991  train.lr : 0.006041599999999999 
[1,0]<stdout>:DLL 2021-12-17 10:52:49.749405 - Epoch: 0 Iteration: 79  train.loss : 6.9810165643692015  train.ips : 1282.2361078287872  train.lr : 0.008089599999999999 
[1,0]<stdout>:DLL 2021-12-17 10:52:51.747107 - Epoch: 0 Iteration: 99  train.loss : 6.937991189956665  train.ips : 1281.6884731431849  train.lr : 0.0101376 
[1,0]<stdout>:DLL 2021-12-17 10:52:53.743046 - Epoch: 0 Iteration: 119  train.loss : 6.919995188713074  train.ips : 1282.7236788472685  train.lr : 0.0121856 
[1,0]<stdout>:DLL 2021-12-17 10:52:55.752719 - Epoch: 0 Iteration: 139  train.loss : 6.872754073143005  train.ips : 1273.9717015360864  train.lr : 0.014233600000000003 
[1,0]<stdout>:DLL 2021-12-17 10:52:57.753549 - Epoch: 0 Iteration: 159  train.loss : 6.866753196716308  train.ips : 1279.5927199647062  train.lr : 0.0162816 
[1,0]<stdout>:DLL 2021-12-17 10:52:59.751369 - Epoch: 0 Iteration: 179  train.loss : 6.855830430984497  train.ips : 1281.5267823532627  train.lr : 0.018329599999999998 
[1,0]<stdout>:DLL 2021-12-17 10:53:01.752960 - Epoch: 0 Iteration: 199  train.loss : 6.829170083999633  train.ips : 1279.1236777572547  train.lr : 0.020377600000000003 
[1,0]<stdout>:DLL 2021-12-17 10:53:03.751478 - Epoch: 0 Iteration: 219  train.loss : 6.832203078269958  train.ips : 1281.1125689822477  train.lr : 0.0224256 
[1,0]<stdout>:DLL 2021-12-17 10:53:05.750482 - Epoch: 0 Iteration: 239  train.loss : 6.807438611984253  train.ips : 1280.7303970121511  train.lr : 0.024473599999999998 
[1,0]<stdout>:DLL 2021-12-17 10:53:07.756779 - Epoch: 0 Iteration: 259  train.loss : 6.81001226902008  train.ips : 1276.0733317241911  train.lr : 0.0265216 
[1,0]<stdout>:DLL 2021-12-17 10:53:09.762448 - Epoch: 0 Iteration: 279  train.loss : 6.7791460990905765  train.ips : 1276.4833818727636  train.lr : 0.0285696 
[1,0]<stdout>:DLL 2021-12-17 10:53:11.766671 - Epoch: 0 Iteration: 299  train.loss : 6.7843017578125  train.ips : 1277.4699157261998  train.lr : 0.030617600000000002 
[1,0]<stdout>:DLL 2021-12-17 10:53:13.765955 - Epoch: 0 Iteration: 319  train.loss : 6.755013561248779  train.ips : 1280.5632971008183  train.lr : 0.0326656 
[1,0]<stdout>:DLL 2021-12-17 10:53:15.768387 - Epoch: 0 Iteration: 339  train.loss : 6.7515535116195675  train.ips : 1278.541245667662  train.lr : 0.034713600000000004 
[1,0]<stdout>:DLL 2021-12-17 10:53:17.771758 - Epoch: 0 Iteration: 359  train.loss : 6.760068893432617  train.ips : 1277.9581269293744  train.lr : 0.0367616 
[1,0]<stdout>:DLL 2021-12-17 10:53:19.772078 - Epoch: 0 Iteration: 379  train.loss : 6.723854374885559  train.ips : 1279.883433467964  train.lr : 0.0388096 
[1,0]<stdout>:DLL 2021-12-17 10:53:21.773056 - Epoch: 0 Iteration: 399  train.loss : 6.717467498779297  train.ips : 1279.4786670108028  train.lr : 0.04085760000000001 
[1,0]<stdout>:DLL 2021-12-17 10:53:23.773066 - Epoch: 0 Iteration: 419  train.loss : 6.713996410369873  train.ips : 1280.1139933053255  train.lr : 0.0429056 
[1,0]<stdout>:DLL 2021-12-17 10:53:25.773310 - Epoch: 0 Iteration: 439  train.loss : 6.662006759643555  train.ips : 1279.93576372188  train.lr : 0.044953599999999996 
[1,0]<stdout>:DLL 2021-12-17 10:53:27.775648 - Epoch: 0 Iteration: 459  train.loss : 6.721950268745422  train.ips : 1278.5828086191962  train.lr : 0.047001600000000004 
[1,0]<stdout>:DLL 2021-12-17 10:53:29.780512 - Epoch: 0 Iteration: 479  train.loss : 6.661521100997925  train.ips : 1276.9788881523286  train.lr : 0.0490496 
[1,0]<stderr>:2021-12-17 10:53:31,784:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-12-17 10:53:31.784120 - Epoch: 0 Iteration: 499  train.loss : 6.665648674964904  train.ips : 1277.7950949669305  train.lr : 0.0510976 
[1,0]<stdout>:DLL 2021-12-17 10:53:31.784569 - Epoch: 0  train.loss : 6.824958701133728  train.ips : 1279.2402176981811 
[1,0]<stdout>:DLL 2021-12-17 10:53:33.785745 - Epoch: 1 Iteration: 19  train.loss : 6.630522227287292  train.ips : 1279.310064466995  train.lr : 0.027545600000000003 
[1,0]<stdout>:DLL 2021-12-17 10:53:35.788548 - Epoch: 1 Iteration: 39  train.loss : 6.5543958187103275  train.ips : 1278.294816137245  train.lr : 0.029593599999999998 
[1,0]<stdout>:DLL 2021-12-17 10:53:37.791364 - Epoch: 1 Iteration: 59  train.loss : 6.542315149307251  train.ips : 1278.3066864133566  train.lr : 0.031641600000000006 
[1,0]<stdout>:DLL 2021-12-17 10:53:39.795479 - Epoch: 1 Iteration: 79  train.loss : 6.549765110015869  train.ips : 1277.4997055333322  train.lr : 0.0336896 
[1,0]<stdout>:DLL 2021-12-17 10:53:41.804620 - Epoch: 1 Iteration: 99  train.loss : 6.566030955314636  train.ips : 1274.2849696720834  train.lr : 0.035737599999999994 
[1,0]<stdout>:DLL 2021-12-17 10:53:43.807412 - Epoch: 1 Iteration: 119  train.loss : 6.54218487739563  train.ips : 1278.2996859674424  train.lr : 0.0377856 
[1,0]<stdout>:DLL 2021-12-17 10:53:45.812042 - Epoch: 1 Iteration: 139  train.loss : 6.546843147277832  train.ips : 1277.1411042623713  train.lr : 0.039833600000000004 
[1,0]<stdout>:DLL 2021-12-17 10:53:47.815949 - Epoch: 1 Iteration: 159  train.loss : 6.54277732372284  train.ips : 1277.59075544353  train.lr : 0.041881600000000005 
[1,0]<stdout>:DLL 2021-12-17 10:53:49.825040 - Epoch: 1 Iteration: 179  train.loss : 6.48272180557251  train.ips : 1274.292531135105  train.lr : 0.0439296 
[1,0]<stdout>:DLL 2021-12-17 10:53:51.830583 - Epoch: 1 Iteration: 199  train.loss : 6.540404558181763  train.ips : 1276.5530392061403  train.lr : 0.0459776 
[1,0]<stdout>:DLL 2021-12-17 10:53:53.834590 - Epoch: 1 Iteration: 219  train.loss : 6.553574347496033  train.ips : 1277.5285847338366  train.lr : 0.048025599999999995 
[1,0]<stdout>:DLL 2021-12-17 10:53:55.837023 - Epoch: 1 Iteration: 239  train.loss : 6.517245960235596  train.ips : 1278.5480965176312  train.lr : 0.050073599999999996 
[1,0]<stdout>:DLL 2021-12-17 10:53:57.839812 - Epoch: 1 Iteration: 259  train.loss : 6.55046317577362  train.ips : 1278.3485385046274  train.lr : 0.052121600000000004 
[1,0]<stdout>:DLL 2021-12-17 10:53:59.841866 - Epoch: 1 Iteration: 279  train.loss : 6.509810090065002  train.ips : 1278.7740634657869  train.lr : 0.054169600000000005 
[1,0]<stdout>:DLL 2021-12-17 10:54:01.845620 - Epoch: 1 Iteration: 299  train.loss : 6.547149920463562  train.ips : 1277.6932211120436  train.lr : 0.05621759999999999 
[1,0]<stdout>:DLL 2021-12-17 10:54:03.848098 - Epoch: 1 Iteration: 319  train.loss : 6.503057050704956  train.ips : 1278.4987720364857  train.lr : 0.058265599999999994 
[1,0]<stdout>:DLL 2021-12-17 10:54:05.852054 - Epoch: 1 Iteration: 339  train.loss : 6.5109693050384525  train.ips : 1277.55700922192  train.lr : 0.0603136 
[1,0]<stdout>:DLL 2021-12-17 10:54:07.857967 - Epoch: 1 Iteration: 359  train.loss : 6.522118735313415  train.ips : 1276.3190571130829  train.lr : 0.062361599999999996 
[1,0]<stdout>:DLL 2021-12-17 10:54:09.866054 - Epoch: 1 Iteration: 379  train.loss : 6.4717203140258786  train.ips : 1274.9349781178528  train.lr : 0.0644096 
[1,0]<stdout>:DLL 2021-12-17 10:54:11.870075 - Epoch: 1 Iteration: 399  train.loss : 6.479879546165466  train.ips : 1277.5402887816294  train.lr : 0.0664576 
[1,0]<stdout>:DLL 2021-12-17 10:54:13.879355 - Epoch: 1 Iteration: 419  train.loss : 6.461762380599976  train.ips : 1274.2182814542066  train.lr : 0.06850560000000001 
[1,0]<stdout>:DLL 2021-12-17 10:54:15.887323 - Epoch: 1 Iteration: 439  train.loss : 6.495075798034668  train.ips : 1275.0018927762444  train.lr : 0.07055360000000001 
[1,0]<stdout>:DLL 2021-12-17 10:54:17.895719 - Epoch: 1 Iteration: 459  train.loss : 6.4573835849761965  train.ips : 1274.7297362432018  train.lr : 0.07260160000000002 
[1,0]<stdout>:DLL 2021-12-17 10:54:19.899053 - Epoch: 1 Iteration: 479  train.loss : 6.473784303665161  train.ips : 1277.9520429000015  train.lr : 0.07464960000000001 
[1,0]<stderr>:2021-12-17 10:54:21,905:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-12-17 10:54:21.904440 - Epoch: 1 Iteration: 499  train.loss : 6.465527200698853  train.ips : 1276.661410170209  train.lr : 0.0766976 
[1,0]<stdout>:DLL 2021-12-17 10:54:21.904833 - Epoch: 1  train.loss : 6.520699307441712  train.ips : 1277.7455378029254 
[1,0]<stdout>:DLL 2021-12-17 10:54:23.909330 - Epoch: 2 Iteration: 19  train.loss : 6.40711739063263  train.ips : 1277.1795378995432  train.lr : 0.0531456 
[1,0]<stdout>:DLL 2021-12-17 10:54:25.915101 - Epoch: 2 Iteration: 39  train.loss : 6.401987099647522  train.ips : 1276.4210154171435  train.lr : 0.05519360000000001 
[1,0]<stdout>:DLL 2021-12-17 10:54:27.921346 - Epoch: 2 Iteration: 59  train.loss : 6.380352258682251  train.ips : 1276.137332557325  train.lr : 0.05724159999999999 
[1,0]<stdout>:DLL 2021-12-17 10:54:29.929543 - Epoch: 2 Iteration: 79  train.loss : 6.382311701774597  train.ips : 1274.8816936399453  train.lr : 0.0592896 
[1,0]<stdout>:DLL 2021-12-17 10:54:31.935936 - Epoch: 2 Iteration: 99  train.loss : 6.356199479103088  train.ips : 1276.0040300049507  train.lr : 0.061337600000000006 
[1,0]<stdout>:DLL 2021-12-17 10:54:33.942993 - Epoch: 2 Iteration: 119  train.loss : 6.3606003522872925  train.ips : 1275.5824677621176  train.lr : 0.0633856 
[1,0]<stdout>:DLL 2021-12-17 10:54:35.948805 - Epoch: 2 Iteration: 139  train.loss : 6.365942478179932  train.ips : 1276.3830825976813  train.lr : 0.06543360000000001 
[1,0]<stdout>:DLL 2021-12-17 10:54:37.954312 - Epoch: 2 Iteration: 159  train.loss : 6.349331045150757  train.ips : 1276.6441060088157  train.lr : 0.0674816 
[1,0]<stdout>:DLL 2021-12-17 10:54:39.965979 - Epoch: 2 Iteration: 179  train.loss : 6.374700903892517  train.ips : 1272.7085518487336  train.lr : 0.0695296 
[1,0]<stdout>:DLL 2021-12-17 10:54:41.970393 - Epoch: 2 Iteration: 199  train.loss : 6.3145578622817995  train.ips : 1277.2808740319654  train.lr : 0.0715776 
[1,0]<stdout>:DLL 2021-12-17 10:54:43.974952 - Epoch: 2 Iteration: 219  train.loss : 6.35412871837616  train.ips : 1277.1696634241277  train.lr : 0.0736256 
[1,0]<stdout>:DLL 2021-12-17 10:54:45.980986 - Epoch: 2 Iteration: 239  train.loss : 6.3369242429733275  train.ips : 1276.2354695251072  train.lr : 0.0756736 
[1,0]<stdout>:DLL 2021-12-17 10:54:47.990311 - Epoch: 2 Iteration: 259  train.loss : 6.353856253623962  train.ips : 1274.147669113761  train.lr : 0.0777216 
[1,0]<stdout>:DLL 2021-12-17 10:54:49.993165 - Epoch: 2 Iteration: 279  train.loss : 6.2821869373321535  train.ips : 1278.2835547970255  train.lr : 0.07976960000000001 
[1,0]<stdout>:DLL 2021-12-17 10:54:51.998333 - Epoch: 2 Iteration: 299  train.loss : 6.294334959983826  train.ips : 1276.8297707480026  train.lr : 0.08181759999999999 
[1,0]<stdout>:DLL 2021-12-17 10:54:54.002387 - Epoch: 2 Iteration: 319  train.loss : 6.3056851625442505  train.ips : 1277.5070012080937  train.lr : 0.0838656 
[1,0]<stdout>:DLL 2021-12-17 10:54:56.010886 - Epoch: 2 Iteration: 339  train.loss : 6.297649264335632  train.ips : 1274.6617909220597  train.lr : 0.0859136 
[1,0]<stdout>:DLL 2021-12-17 10:54:58.014438 - Epoch: 2 Iteration: 359  train.loss : 6.282444930076599  train.ips : 1277.8186651129226  train.lr : 0.0879616 
[1,0]<stdout>:DLL 2021-12-17 10:55:00.022626 - Epoch: 2 Iteration: 379  train.loss : 6.239026260375977  train.ips : 1274.8906245343424  train.lr : 0.0900096 
[1,0]<stdout>:DLL 2021-12-17 10:55:02.028503 - Epoch: 2 Iteration: 399  train.loss : 6.284176564216613  train.ips : 1276.3572895682391  train.lr : 0.0920576 
[1,0]<stdout>:DLL 2021-12-17 10:55:04.034301 - Epoch: 2 Iteration: 419  train.loss : 6.2821208238601685  train.ips : 1276.4475697323119  train.lr : 0.09410560000000001 
[1,0]<stdout>:DLL 2021-12-17 10:55:06.041345 - Epoch: 2 Iteration: 439  train.loss : 6.334330487251282  train.ips : 1275.5998946961251  train.lr : 0.0961536 
[1,0]<stdout>:DLL 2021-12-17 10:55:08.046208 - Epoch: 2 Iteration: 459  train.loss : 6.284038829803467  train.ips : 1276.9962013905242  train.lr : 0.09820160000000001 
[1,0]<stdout>:DLL 2021-12-17 10:55:10.050727 - Epoch: 2 Iteration: 479  train.loss : 6.2567157506942745  train.ips : 1277.2457767896237  train.lr : 0.10024960000000001 
[1,0]<stdout>:DLL 2021-12-17 10:55:12.054223 - Epoch: 2 Iteration: 499  train.loss : 6.243297815322876  train.ips : 1277.8819286422918  train.lr : 0.10229760000000002 
[1,0]<stdout>:DLL 2021-12-17 10:55:12.054680 - Epoch: 2  train.loss : 6.324960702896118  train.ips : 1276.949658682389 
[1,0]<stdout>:DLL 2021-12-17 10:55:12.117142 - Summary: train.loss : 6.324960702896118  train.ips : 1277.9784713944985 
[1,0]<stdout>:DLL 2021-12-17 10:55:18.740015 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 1024  num_epochs : 3  run_epochs : -1  lr : 1.024  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,128  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,6]<stderr>:[10:55:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU[1,6]<stderr>:
[1,7]<stderr>:[[1,7]<stderr>:10:55:18] ../src/storage/storage.cc[1,7]<stderr>::199: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:[10:55:18] ../src/storage/storage.cc:199[1,3]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:[10:55:18] ../src/storage/storage.cc:[1,5]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:[10:55:18] ../src/storage/storage.cc:[1,2]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[10:55:18] ../src/storage/storage.cc:[1,0]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[10:55:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[10:55:18] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:[10:55:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[10:55:22] ../src/storage/storage.cc[1,2]<stderr>::199: Using [1,2]<stderr>:Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[10:55:22] ../src/storage/storage.cc:[1,1]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[[1,0]<stderr>:10:55:22] ../src/storage/storage.cc:199: Using [1,0]<stderr>:Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[[1,3]<stderr>:10:55:22] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,4]<stderr>:[10:55:22] ../src/storage/storage.cc:199: [1,4]<stderr>:Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[[1,6]<stderr>:10:55:22] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive)[1,6]<stderr>: StorageManager for GPU
[1,5]<stderr>:[10:55:22] [1,5]<stderr>:../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,5]<stderr>:GPU
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2021-12-17 10:55:26,331:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2021-12-17 10:55:26,332:INFO: Starting epoch 0
[1,0]<stderr>:[131c8fb9bb8a:21211] Read -1, expected 10153, errno = 1
[1,0]<stderr>:[131c8fb9bb8a:21211] Read -1, expected 4537, errno = 1
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2021-12-17 10:55:26,503:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2021-12-17 10:55:26,503:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2021-12-17 10:55:26,596:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2021-12-17 10:55:26,596:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-12-17 10:55:26,821:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-12-17 10:55:26,821:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2021-12-17 10:55:27,059:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2021-12-17 10:55:27,060:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2021-12-17 10:55:27,069:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2021-12-17 10:55:27,070:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2021-12-17 10:55:27,168:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2021-12-17 10:55:27,168:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2021-12-17 10:55:27,279:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2021-12-17 10:55:27,279:INFO: Starting epoch 0
[1,0]<stderr>:[131c8fb9bb8a:21211] Read -1, expected 22801, errno = 1
[1,0]<stderr>:[131c8fb9bb8a:21211] Read -1, expected 30513, errno = 1
[1,0]<stderr>:[131c8fb9bb8a:21211] Read -1, expected 22681, errno = 1
[1,0]<stderr>:[131c8fb9bb8a:21211] Read -1, expected 28321, errno = 1
[1,6]<stderr>:[131c8fb9bb8a:21217] Read -1, expected 20161, errno = 1
[1,3]<stderr>:[131c8fb9bb8a:21214] Read -1, expected 20160, errno = 1
[1,4]<stderr>:[131c8fb9bb8a:21215] Read -1, expected 20161, errno = 1
[1,5]<stderr>:[131c8fb9bb8a:21216] Read -1, expected 20160, errno = 1
[1,1]<stderr>:[131c8fb9bb8a:21212] Read -1, expected 20160, errno = 1
[1,2]<stderr>:[131c8fb9bb8a:21213] Read -1, expected 20161, errno = 1
[1,7]<stderr>:[131c8fb9bb8a:21218] Read -1, expected 20160, errno = 1
[1,2]<stderr>:[10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[[1,5]<stderr>:10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,5]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[[1,6]<stderr>:10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)[1,6]<stderr>:
[1,0]<stderr>:[[1,0]<stderr>:10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,0]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,7]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,3]<stderr>:[10:55:29[1,3]<stderr>:] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,3]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[10:55:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,4]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-12-17 10:55:38.937342 - Epoch: 0 Iteration: 19  train.loss : 6.99459388256073  train.ips : 1690.335431024747  train.lr : 0.1216 
[1,0]<stdout>:DLL 2021-12-17 10:55:41.095732 - Epoch: 0 Iteration: 39  train.loss : 6.822854948043823  train.ips : 9491.126548949283  train.lr : 0.2496 
[1,0]<stdout>:DLL 2021-12-17 10:55:43.231563 - Epoch: 0 Iteration: 59  train.loss : 6.734313321113587  train.ips : 9589.45071118766  train.lr : 0.37760000000000005 
[1,0]<stdout>:DLL 2021-12-17 10:55:45.391717 - Epoch: 0 Iteration: 79  train.loss : 6.620852470397949  train.ips : 9481.529246546032  train.lr : 0.5056 
[1,0]<stdout>:DLL 2021-12-17 10:55:47.539728 - Epoch: 0 Iteration: 99  train.loss : 6.582784652709961  train.ips : 9535.052843909441  train.lr : 0.6336 
[1,0]<stdout>:DLL 2021-12-17 10:55:49.694297 - Epoch: 0 Iteration: 119  train.loss : 6.4757567882537845  train.ips : 9506.053921758494  train.lr : 0.7616 
[1,0]<stdout>:DLL 2021-12-17 10:55:51.878409 - Epoch: 0 Iteration: 139  train.loss : 6.42384946346283  train.ips : 9377.517598262995  train.lr : 0.8896000000000001 
[1,0]<stdout>:DLL 2021-12-17 10:55:54.034607 - Epoch: 0 Iteration: 159  train.loss : 6.364898419380188  train.ips : 9499.362732776246  train.lr : 1.0176 
[1,0]<stdout>:DLL 2021-12-17 10:55:56.195390 - Epoch: 0 Iteration: 179  train.loss : 6.320368409156799  train.ips : 9479.817372521144  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:55:58.353461 - Epoch: 0 Iteration: 199  train.loss : 6.329521560668946  train.ips : 9490.826634091927  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:00.513337 - Epoch: 0 Iteration: 219  train.loss : 6.330917716026306  train.ips : 9483.149608698423  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:02.666668 - Epoch: 0 Iteration: 239  train.loss : 6.288989520072937  train.ips : 9511.76227721517  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:04.825298 - Epoch: 0 Iteration: 259  train.loss : 6.313541126251221  train.ips : 9493.584257638608  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:06.978739 - Epoch: 0 Iteration: 279  train.loss : 6.3387147188186646  train.ips : 9511.24621194296  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:09.166287 - Epoch: 0 Iteration: 299  train.loss : 6.312555909156799  train.ips : 9366.87367578768  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:11.317630 - Epoch: 0 Iteration: 319  train.loss : 6.317908453941345  train.ips : 9521.265772695395  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:13.484554 - Epoch: 0 Iteration: 339  train.loss : 6.320508360862732  train.ips : 9452.067082678157  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:15.658959 - Epoch: 0 Iteration: 359  train.loss : 6.341689896583557  train.ips : 9419.469601966808  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:17.824649 - Epoch: 0 Iteration: 379  train.loss : 6.306016063690185  train.ips : 9460.515858654631  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:19.992081 - Epoch: 0 Iteration: 399  train.loss : 6.327701878547669  train.ips : 9449.806505212724  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:22.148687 - Epoch: 0 Iteration: 419  train.loss : 6.322960543632507  train.ips : 9497.077378773418  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:24.301503 - Epoch: 0 Iteration: 439  train.loss : 6.307485842704773  train.ips : 9514.207502569077  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:26.468778 - Epoch: 0 Iteration: 459  train.loss : 6.348615550994873  train.ips : 9450.805642757046  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:28.647489 - Epoch: 0 Iteration: 479  train.loss : 6.312559914588928  train.ips : 9400.695713687868  train.lr : 0 
[1,2]<stderr>:2021-12-17 10:56:30,803:INFO: Starting epoch 1
[1,3]<stderr>:2021-12-17 10:56:30,803:INFO: Starting epoch 1
[1,7]<stderr>:2021-12-17 10:56:30,804:INFO: Starting epoch 1
[1,6]<stderr>:2021-12-17 10:56:30,804:INFO: Starting epoch 1
[1,0]<stderr>:2021-12-17 10:56:30,804:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-12-17 10:56:30.803542 - Epoch: 0 Iteration: 499  train.loss : 6.297530245780945  train.ips : 9499.847041344667  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:30.803999 - Epoch: 0  train.loss : 6.418299586296081  train.ips : 9475.35287740309 
[1,4]<stderr>:2021-12-17 10:56:30,804:INFO: Starting epoch 1
[1,1]<stderr>:2021-12-17 10:56:30,805:INFO: Starting epoch 1
[1,5]<stderr>:2021-12-17 10:56:30,805:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-12-17 10:56:32.960962 - Epoch: 1 Iteration: 19  train.loss : 6.235501098632812  train.ips : 9495.797598904626  train.lr : 0.3264 
[1,0]<stdout>:DLL 2021-12-17 10:56:35.149487 - Epoch: 1 Iteration: 39  train.loss : 6.147218704223633  train.ips : 9358.931814160487  train.lr : 0.4544 
[1,0]<stdout>:DLL 2021-12-17 10:56:37.318565 - Epoch: 1 Iteration: 59  train.loss : 6.159476089477539  train.ips : 9442.552722878094  train.lr : 0.5824 
[1,0]<stdout>:DLL 2021-12-17 10:56:39.504654 - Epoch: 1 Iteration: 79  train.loss : 6.14938895702362  train.ips : 9369.19897865137  train.lr : 0.7104 
[1,0]<stdout>:DLL 2021-12-17 10:56:41.671092 - Epoch: 1 Iteration: 99  train.loss : 6.103641533851624  train.ips : 9463.667713664032  train.lr : 0.8384 
[1,0]<stdout>:DLL 2021-12-17 10:56:43.829365 - Epoch: 1 Iteration: 119  train.loss : 6.0762909889221195  train.ips : 9490.043379440123  train.lr : 0.9663999999999999 
[1,0]<stdout>:DLL 2021-12-17 10:56:45.984057 - Epoch: 1 Iteration: 139  train.loss : 6.089504432678223  train.ips : 9506.099157447765  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:48.145410 - Epoch: 1 Iteration: 159  train.loss : 6.10437240600586  train.ips : 9476.675662773845  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:50.315112 - Epoch: 1 Iteration: 179  train.loss : 6.0267997741699215  train.ips : 9440.801975307773  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:52.470786 - Epoch: 1 Iteration: 199  train.loss : 6.102340674400329  train.ips : 9501.303416203618  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:54.643358 - Epoch: 1 Iteration: 219  train.loss : 6.117246103286743  train.ips : 9427.454572273458  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:56.807726 - Epoch: 1 Iteration: 239  train.loss : 6.07518470287323  train.ips : 9463.733399642402  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:56:58.975852 - Epoch: 1 Iteration: 259  train.loss : 6.109243583679199  train.ips : 9446.808281889627  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:01.150667 - Epoch: 1 Iteration: 279  train.loss : 6.087483954429627  train.ips : 9424.650434420446  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:03.311377 - Epoch: 1 Iteration: 299  train.loss : 6.101004266738892  train.ips : 9480.932741044617  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:05.463762 - Epoch: 1 Iteration: 319  train.loss : 6.048845338821411  train.ips : 9519.882400296481  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:07.627879 - Epoch: 1 Iteration: 339  train.loss : 6.108281111717224  train.ips : 9466.180069715256  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:09.863428 - Epoch: 1 Iteration: 359  train.loss : 6.10975079536438  train.ips : 9162.237249780488  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:12.061278 - Epoch: 1 Iteration: 379  train.loss : 6.0548913955688475  train.ips : 9319.101137101728  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:14.225005 - Epoch: 1 Iteration: 399  train.loss : 6.10706524848938  train.ips : 9466.137299487722  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:16.386503 - Epoch: 1 Iteration: 419  train.loss : 6.086500120162964  train.ips : 9476.017046370289  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:18.573895 - Epoch: 1 Iteration: 439  train.loss : 6.0953041315078735  train.ips : 9363.960503625754  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:20.751821 - Epoch: 1 Iteration: 459  train.loss : 6.0573160409927365  train.ips : 9405.275065878486  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:22.912720 - Epoch: 1 Iteration: 479  train.loss : 6.108905220031739  train.ips : 9479.032795827252  train.lr : 0 
[1,7]<stderr>:2021-12-17 10:57:25,075:INFO: Starting epoch 2
[1,2]<stderr>:2021-12-17 10:57:25,075:INFO: Starting epoch 2
[1,5]<stderr>:2021-12-17 10:57:25,076:INFO: Starting epoch 2
[1,6]<stderr>:2021-12-17 10:57:25,075:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-12-17 10:57:25.075638 - Epoch: 1 Iteration: 499  train.loss : 6.106791424751282  train.ips : 9474.587223063372  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:25.076334 - Epoch: 1  train.loss : 6.102733923912048  train.ips : 9449.022766878037 
[1,0]<stderr>:2021-12-17 10:57:25,076:INFO: Starting epoch 2
[1,3]<stderr>:2021-12-17 10:57:25,075:INFO: Starting epoch 2
[1,1]<stderr>:2021-12-17 10:57:25,076:INFO: Starting epoch 2
[1,4]<stderr>:2021-12-17 10:57:25,076:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-12-17 10:57:27.250157 - Epoch: 2 Iteration: 19  train.loss : 6.2270584344863895  train.ips : 9421.671250489047  train.lr : 0.5312 
[1,0]<stdout>:DLL 2021-12-17 10:57:29.414594 - Epoch: 2 Iteration: 39  train.loss : 6.050371265411377  train.ips : 9463.237128164383  train.lr : 0.6592 
[1,0]<stdout>:DLL 2021-12-17 10:57:31.579496 - Epoch: 2 Iteration: 59  train.loss : 5.997329616546631  train.ips : 9461.600635242825  train.lr : 0.7872 
[1,0]<stdout>:DLL 2021-12-17 10:57:33.745168 - Epoch: 2 Iteration: 79  train.loss : 6.0061880350112915  train.ips : 9457.699310694725  train.lr : 0.9152000000000001 
[1,0]<stdout>:DLL 2021-12-17 10:57:35.907877 - Epoch: 2 Iteration: 99  train.loss : 5.961705470085144  train.ips : 9470.717995041452  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:38.072312 - Epoch: 2 Iteration: 119  train.loss : 5.960036659240723  train.ips : 9471.576389947879  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:40.231147 - Epoch: 2 Iteration: 139  train.loss : 5.903887748718262  train.ips : 9487.682863777816  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:42.381566 - Epoch: 2 Iteration: 159  train.loss : 5.934854960441589  train.ips : 9525.019046856576  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:44.540603 - Epoch: 2 Iteration: 179  train.loss : 5.943405866622925  train.ips : 9486.418186143275  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:46.697202 - Epoch: 2 Iteration: 199  train.loss : 5.911576843261718  train.ips : 9502.606756349538  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:48.868667 - Epoch: 2 Iteration: 219  train.loss : 5.954740571975708  train.ips : 9432.736381891029  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:51.047593 - Epoch: 2 Iteration: 239  train.loss : 5.917846035957337  train.ips : 9400.047615597938  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:53.198258 - Epoch: 2 Iteration: 259  train.loss : 5.930620002746582  train.ips : 9523.756011708876  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:55.373277 - Epoch: 2 Iteration: 279  train.loss : 5.952268385887146  train.ips : 9416.80957377814  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:57.527833 - Epoch: 2 Iteration: 299  train.loss : 5.910509181022644  train.ips : 9506.357955947047  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:57:59.700563 - Epoch: 2 Iteration: 319  train.loss : 5.942125821113587  train.ips : 9429.744838382932  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:01.860078 - Epoch: 2 Iteration: 339  train.loss : 5.901716113090515  train.ips : 9485.806400174213  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:04.018261 - Epoch: 2 Iteration: 359  train.loss : 5.8759945154190065  train.ips : 9490.48269912709  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:06.185067 - Epoch: 2 Iteration: 379  train.loss : 5.8737828731536865  train.ips : 9452.860724847358  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:08.370112 - Epoch: 2 Iteration: 399  train.loss : 5.92384147644043  train.ips : 9373.717001727768  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:10.561684 - Epoch: 2 Iteration: 419  train.loss : 5.895032525062561  train.ips : 9347.69420553897  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:12.716789 - Epoch: 2 Iteration: 439  train.loss : 5.968495416641235  train.ips : 9507.884733010143  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:14.890648 - Epoch: 2 Iteration: 459  train.loss : 5.954780077934265  train.ips : 9421.78595864605  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:17.050002 - Epoch: 2 Iteration: 479  train.loss : 5.9289244413375854  train.ips : 9489.897647525946  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:19.210055 - Epoch: 2 Iteration: 499  train.loss : 5.940825510025024  train.ips : 9486.550191411106  train.lr : 0 
[1,0]<stdout>:DLL 2021-12-17 10:58:19.210872 - Epoch: 2  train.loss : 5.950716713905335  train.ips : 9449.493566119021 
[1,0]<stdout>:DLL 2021-12-17 10:58:19.281378 - Summary: train.loss : 5.950716713905335  train.ips : 9457.956403466716 
train.ips
           |    128    |
------------------------
     1     |   1277.3  |
     8     |   9449.3  |

