[1,0]<stdout>:DLL 2021-06-01 05:25:22.579910 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0]  kv_store : horovod  dtype : float16  amp : False  batch_size : 128  num_epochs : 3  run_epochs : -1  lr : 0.128  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-1,128  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 3  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,0]<stderr>:[[1,0]<stderr>:05:25:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,0]<stderr>:CPU
[1,0]<stderr>:[05:25:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-06-01 05:25:28,599:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-06-01 05:25:28,599:INFO: Starting epoch 0
[1,0]<stderr>:[05:25:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-06-01 05:25:38.981219 - Epoch: 0 Iteration: 19  train.loss : 7.116805982589722  train.ips : 246.57747264835064  train.lr : 0.0019456 
[1,0]<stdout>:DLL 2021-06-01 05:25:40.905960 - Epoch: 0 Iteration: 39  train.loss : 7.075488948822022  train.ips : 1330.6595895898563  train.lr : 0.0039936 
[1,0]<stdout>:DLL 2021-06-01 05:25:42.832008 - Epoch: 0 Iteration: 59  train.loss : 7.0219789981842045  train.ips : 1329.3459345351414  train.lr : 0.006041599999999999 
[1,0]<stdout>:DLL 2021-06-01 05:25:44.757125 - Epoch: 0 Iteration: 79  train.loss : 6.9810165643692015  train.ips : 1329.968007445648  train.lr : 0.008089599999999999 
[1,0]<stdout>:DLL 2021-06-01 05:25:46.689783 - Epoch: 0 Iteration: 99  train.loss : 6.937991189956665  train.ips : 1324.7433266356434  train.lr : 0.0101376 
[1,0]<stdout>:DLL 2021-06-01 05:25:48.621288 - Epoch: 0 Iteration: 119  train.loss : 6.919995188713074  train.ips : 1325.5587499518535  train.lr : 0.0121856 
[1,0]<stdout>:DLL 2021-06-01 05:25:50.558410 - Epoch: 0 Iteration: 139  train.loss : 6.872754073143005  train.ips : 1321.7317421141713  train.lr : 0.014233600000000003 
[1,0]<stdout>:DLL 2021-06-01 05:25:52.488238 - Epoch: 0 Iteration: 159  train.loss : 6.866753196716308  train.ips : 1326.7506526303719  train.lr : 0.0162816 
[1,0]<stdout>:DLL 2021-06-01 05:25:54.415090 - Epoch: 0 Iteration: 179  train.loss : 6.855830430984497  train.ips : 1328.827546263352  train.lr : 0.018329599999999998 
[1,0]<stdout>:DLL 2021-06-01 05:25:56.347197 - Epoch: 0 Iteration: 199  train.loss : 6.829170083999633  train.ips : 1325.1720101793733  train.lr : 0.020377600000000003 
[1,0]<stdout>:DLL 2021-06-01 05:25:58.274366 - Epoch: 0 Iteration: 219  train.loss : 6.832203078269958  train.ips : 1328.556750128093  train.lr : 0.0224256 
[1,0]<stdout>:DLL 2021-06-01 05:26:00.201100 - Epoch: 0 Iteration: 239  train.loss : 6.807438611984253  train.ips : 1328.9017179503903  train.lr : 0.024473599999999998 
[1,0]<stdout>:DLL 2021-06-01 05:26:02.132428 - Epoch: 0 Iteration: 259  train.loss : 6.81001226902008  train.ips : 1325.7762675165857  train.lr : 0.0265216 
[1,0]<stdout>:DLL 2021-06-01 05:26:04.065847 - Epoch: 0 Iteration: 279  train.loss : 6.7791460990905765  train.ips : 1324.2732709114362  train.lr : 0.0285696 
[1,0]<stdout>:DLL 2021-06-01 05:26:06.000684 - Epoch: 0 Iteration: 299  train.loss : 6.7843017578125  train.ips : 1323.267783375563  train.lr : 0.030617600000000002 
[1,0]<stdout>:DLL 2021-06-01 05:26:07.940752 - Epoch: 0 Iteration: 319  train.loss : 6.755013561248779  train.ips : 1319.7126366074297  train.lr : 0.0326656 
[1,0]<stdout>:DLL 2021-06-01 05:26:09.878897 - Epoch: 0 Iteration: 339  train.loss : 6.7515535116195675  train.ips : 1321.030553162611  train.lr : 0.034713600000000004 
[1,0]<stdout>:DLL 2021-06-01 05:26:11.821034 - Epoch: 0 Iteration: 359  train.loss : 6.760068893432617  train.ips : 1318.3024922890227  train.lr : 0.0367616 
[1,0]<stdout>:DLL 2021-06-01 05:26:13.753156 - Epoch: 0 Iteration: 379  train.loss : 6.723854374885559  train.ips : 1325.1294891224397  train.lr : 0.0388096 
[1,0]<stdout>:DLL 2021-06-01 05:26:15.691755 - Epoch: 0 Iteration: 399  train.loss : 6.717467498779297  train.ips : 1320.734007742051  train.lr : 0.04085760000000001 
[1,0]<stdout>:DLL 2021-06-01 05:26:17.629662 - Epoch: 0 Iteration: 419  train.loss : 6.713996410369873  train.ips : 1321.2586180864732  train.lr : 0.0429056 
[1,0]<stdout>:DLL 2021-06-01 05:26:19.568100 - Epoch: 0 Iteration: 439  train.loss : 6.662006759643555  train.ips : 1320.8357118808217  train.lr : 0.044953599999999996 
[1,0]<stdout>:DLL 2021-06-01 05:26:21.507771 - Epoch: 0 Iteration: 459  train.loss : 6.721950268745422  train.ips : 1319.993145203425  train.lr : 0.047001600000000004 
[1,0]<stdout>:DLL 2021-06-01 05:26:23.443161 - Epoch: 0 Iteration: 479  train.loss : 6.661521100997925  train.ips : 1323.0209292107256  train.lr : 0.0490496 
[1,0]<stdout>:DLL 2021-06-01 05:26:25.375788 - Epoch: 0 Iteration: 499  train.loss : 6.665648674964904  train.ips : 1324.8431972130638  train.lr : 0.0510976 
[1,0]<stdout>:DLL 2021-06-01 05:26:25.376279 - Epoch: 0  train.loss : 6.824958701133728  train.ips : 1127.2097799827225 
[1,0]<stderr>:2021-06-01 05:26:25,376:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-06-01 05:26:27.312200 - Epoch: 1 Iteration: 19  train.loss : 6.630522227287292  train.ips : 1322.4843311356012  train.lr : 0.027545600000000003 
[1,0]<stdout>:DLL 2021-06-01 05:26:29.254005 - Epoch: 1 Iteration: 39  train.loss : 6.5543958187103275  train.ips : 1318.5678285665797  train.lr : 0.029593599999999998 
[1,0]<stdout>:DLL 2021-06-01 05:26:31.202579 - Epoch: 1 Iteration: 59  train.loss : 6.542315149307251  train.ips : 1313.9972940321857  train.lr : 0.031641600000000006 
[1,0]<stdout>:DLL 2021-06-01 05:26:33.142344 - Epoch: 1 Iteration: 79  train.loss : 6.549765110015869  train.ips : 1320.0356618263556  train.lr : 0.0336896 
[1,0]<stdout>:DLL 2021-06-01 05:26:35.090063 - Epoch: 1 Iteration: 99  train.loss : 6.566030955314636  train.ips : 1314.5819052896363  train.lr : 0.035737599999999994 
[1,0]<stdout>:DLL 2021-06-01 05:26:37.032992 - Epoch: 1 Iteration: 119  train.loss : 6.54218487739563  train.ips : 1317.8051329683174  train.lr : 0.0377856 
[1,0]<stdout>:DLL 2021-06-01 05:26:38.975136 - Epoch: 1 Iteration: 139  train.loss : 6.546843147277832  train.ips : 1318.3029778588484  train.lr : 0.039833600000000004 
[1,0]<stdout>:DLL 2021-06-01 05:26:40.923014 - Epoch: 1 Iteration: 159  train.loss : 6.54277732372284  train.ips : 1314.4319223745376  train.lr : 0.041881600000000005 
[1,0]<stdout>:DLL 2021-06-01 05:26:42.865522 - Epoch: 1 Iteration: 179  train.loss : 6.48272180557251  train.ips : 1318.0757702623393  train.lr : 0.0439296 
[1,0]<stdout>:DLL 2021-06-01 05:26:44.811542 - Epoch: 1 Iteration: 199  train.loss : 6.540404558181763  train.ips : 1315.877333195423  train.lr : 0.0459776 
[1,0]<stdout>:DLL 2021-06-01 05:26:46.757535 - Epoch: 1 Iteration: 219  train.loss : 6.553574347496033  train.ips : 1316.2525346098905  train.lr : 0.048025599999999995 
[1,0]<stdout>:DLL 2021-06-01 05:26:48.698754 - Epoch: 1 Iteration: 239  train.loss : 6.517245960235596  train.ips : 1318.973891304177  train.lr : 0.050073599999999996 
[1,0]<stdout>:DLL 2021-06-01 05:26:50.639100 - Epoch: 1 Iteration: 259  train.loss : 6.55046317577362  train.ips : 1319.5781840204654  train.lr : 0.052121600000000004 
[1,0]<stdout>:DLL 2021-06-01 05:26:52.585900 - Epoch: 1 Iteration: 279  train.loss : 6.509810090065002  train.ips : 1315.2503245125451  train.lr : 0.054169600000000005 
[1,0]<stdout>:DLL 2021-06-01 05:26:54.527411 - Epoch: 1 Iteration: 299  train.loss : 6.547149920463562  train.ips : 1318.7359247280067  train.lr : 0.05621759999999999 
[1,0]<stdout>:DLL 2021-06-01 05:26:56.469815 - Epoch: 1 Iteration: 319  train.loss : 6.503057050704956  train.ips : 1318.1540865420322  train.lr : 0.058265599999999994 
[1,0]<stdout>:DLL 2021-06-01 05:26:58.418478 - Epoch: 1 Iteration: 339  train.loss : 6.5109693050384525  train.ips : 1313.9694760272016  train.lr : 0.0603136 
[1,0]<stdout>:DLL 2021-06-01 05:27:00.364111 - Epoch: 1 Iteration: 359  train.loss : 6.522118735313415  train.ips : 1315.98167771875  train.lr : 0.062361599999999996 
[1,0]<stdout>:DLL 2021-06-01 05:27:02.313919 - Epoch: 1 Iteration: 379  train.loss : 6.4717203140258786  train.ips : 1313.1759532201277  train.lr : 0.0644096 
[1,0]<stdout>:DLL 2021-06-01 05:27:04.257539 - Epoch: 1 Iteration: 399  train.loss : 6.479879546165466  train.ips : 1317.4099725166864  train.lr : 0.0664576 
[1,0]<stdout>:DLL 2021-06-01 05:27:06.208456 - Epoch: 1 Iteration: 419  train.loss : 6.461762380599976  train.ips : 1312.367027026961  train.lr : 0.06850560000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:08.156056 - Epoch: 1 Iteration: 439  train.loss : 6.495075798034668  train.ips : 1314.6017017288966  train.lr : 0.07055360000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:10.112352 - Epoch: 1 Iteration: 459  train.loss : 6.4573835849761965  train.ips : 1308.7906840453452  train.lr : 0.07260160000000002 
[1,0]<stdout>:DLL 2021-06-01 05:27:12.064057 - Epoch: 1 Iteration: 479  train.loss : 6.473784303665161  train.ips : 1311.9417778104146  train.lr : 0.07464960000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:14.016003 - Epoch: 1 Iteration: 499  train.loss : 6.465527200698853  train.ips : 1311.701534473428  train.lr : 0.0766976 
[1,0]<stdout>:DLL 2021-06-01 05:27:14.016413 - Epoch: 1  train.loss : 6.520699307441712  train.ips : 1315.7930955328573 
[1,0]<stderr>:2021-06-01 05:27:14,017:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-06-01 05:27:15.966227 - Epoch: 2 Iteration: 19  train.loss : 6.40711739063263  train.ips : 1313.0400995411203  train.lr : 0.0531456 
[1,0]<stdout>:DLL 2021-06-01 05:27:17.915783 - Epoch: 2 Iteration: 39  train.loss : 6.401987099647522  train.ips : 1313.3111924809655  train.lr : 0.05519360000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:19.866295 - Epoch: 2 Iteration: 59  train.loss : 6.380352258682251  train.ips : 1312.7243403380064  train.lr : 0.05724159999999999 
[1,0]<stdout>:DLL 2021-06-01 05:27:21.818606 - Epoch: 2 Iteration: 79  train.loss : 6.382311701774597  train.ips : 1311.592420300075  train.lr : 0.0592896 
[1,0]<stdout>:DLL 2021-06-01 05:27:23.769648 - Epoch: 2 Iteration: 99  train.loss : 6.356199479103088  train.ips : 1312.2813777574465  train.lr : 0.061337600000000006 
[1,0]<stdout>:DLL 2021-06-01 05:27:25.721348 - Epoch: 2 Iteration: 119  train.loss : 6.3606003522872925  train.ips : 1311.8550620947422  train.lr : 0.0633856 
[1,0]<stdout>:DLL 2021-06-01 05:27:27.672641 - Epoch: 2 Iteration: 139  train.loss : 6.365942478179932  train.ips : 1312.1769777575296  train.lr : 0.06543360000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:29.628834 - Epoch: 2 Iteration: 159  train.loss : 6.349331045150757  train.ips : 1309.0177336527584  train.lr : 0.0674816 
[1,0]<stdout>:DLL 2021-06-01 05:27:31.587602 - Epoch: 2 Iteration: 179  train.loss : 6.374700903892517  train.ips : 1307.126837249996  train.lr : 0.0695296 
[1,0]<stdout>:DLL 2021-06-01 05:27:33.542367 - Epoch: 2 Iteration: 199  train.loss : 6.3145578622817995  train.ips : 1309.7166087113924  train.lr : 0.0715776 
[1,0]<stdout>:DLL 2021-06-01 05:27:35.493133 - Epoch: 2 Iteration: 219  train.loss : 6.35412871837616  train.ips : 1312.4773931305235  train.lr : 0.0736256 
[1,0]<stdout>:DLL 2021-06-01 05:27:37.447288 - Epoch: 2 Iteration: 239  train.loss : 6.3369242429733275  train.ips : 1310.228344490849  train.lr : 0.0756736 
[1,0]<stdout>:DLL 2021-06-01 05:27:39.400044 - Epoch: 2 Iteration: 259  train.loss : 6.353856253623962  train.ips : 1311.2402063807053  train.lr : 0.0777216 
[1,0]<stdout>:DLL 2021-06-01 05:27:41.352731 - Epoch: 2 Iteration: 279  train.loss : 6.2821869373321535  train.ips : 1311.1996954940669  train.lr : 0.07976960000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:43.303605 - Epoch: 2 Iteration: 299  train.loss : 6.294334959983826  train.ips : 1312.4159515702297  train.lr : 0.08181759999999999 
[1,0]<stdout>:DLL 2021-06-01 05:27:45.251747 - Epoch: 2 Iteration: 319  train.loss : 6.3056851625442505  train.ips : 1314.242561514058  train.lr : 0.0838656 
[1,0]<stdout>:DLL 2021-06-01 05:27:47.206705 - Epoch: 2 Iteration: 339  train.loss : 6.297649264335632  train.ips : 1309.6482370872275  train.lr : 0.0859136 
[1,0]<stdout>:DLL 2021-06-01 05:27:49.158859 - Epoch: 2 Iteration: 359  train.loss : 6.282444930076599  train.ips : 1311.54692136827  train.lr : 0.0879616 
[1,0]<stdout>:DLL 2021-06-01 05:27:51.112168 - Epoch: 2 Iteration: 379  train.loss : 6.239026260375977  train.ips : 1310.8139267303457  train.lr : 0.0900096 
[1,0]<stdout>:DLL 2021-06-01 05:27:53.063683 - Epoch: 2 Iteration: 399  train.loss : 6.284176564216613  train.ips : 1312.0665018409395  train.lr : 0.0920576 
[1,0]<stdout>:DLL 2021-06-01 05:27:55.011929 - Epoch: 2 Iteration: 419  train.loss : 6.2821208238601685  train.ips : 1314.1801503494737  train.lr : 0.09410560000000001 
[1,0]<stdout>:DLL 2021-06-01 05:27:56.963998 - Epoch: 2 Iteration: 439  train.loss : 6.334330487251282  train.ips : 1311.602834231928  train.lr : 0.0961536 
[1,0]<stdout>:DLL 2021-06-01 05:27:58.910028 - Epoch: 2 Iteration: 459  train.loss : 6.284038829803467  train.ips : 1315.6757870803146  train.lr : 0.09820160000000001 
[1,0]<stdout>:DLL 2021-06-01 05:28:00.863879 - Epoch: 2 Iteration: 479  train.loss : 6.2567157506942745  train.ips : 1310.433342706283  train.lr : 0.10024960000000001 
[1,0]<stdout>:DLL 2021-06-01 05:28:02.818449 - Epoch: 2 Iteration: 499  train.loss : 6.243297815322876  train.ips : 1310.0088660367107  train.lr : 0.10229760000000002 
[1,0]<stdout>:DLL 2021-06-01 05:28:02.818817 - Epoch: 2  train.loss : 6.324960702896118  train.ips : 1311.415203739451 
[1,0]<stdout>:DLL 2021-06-01 05:28:02.880226 - Summary: train.loss : 6.324960702896118  train.ips : 1251.4726930850104 
[1,0]<stdout>:DLL 2021-06-01 05:28:09.753809 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 1024  num_epochs : 3  run_epochs : -1  lr : 1.024  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,128  workspace : ./  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 3  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,2]<stderr>:[[1,2]<stderr>:05:28:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:[05:28:09[1,5]<stderr>:] ../src/storage/storage.cc:199: Using [1,5]<stderr>:Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:05:28:09] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:[[1,7]<stderr>:05:28:09] [1,7]<stderr>:../src/storage/storage.cc:199[1,7]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:[05:28:09] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:[05:28:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[05:28:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[[1,4]<stderr>:05:28:09[1,4]<stderr>:] [1,4]<stderr>:../src/storage/storage.cc[1,4]<stderr>::[1,4]<stderr>:199[1,4]<stderr>:: [1,4]<stderr>:Using [1,4]<stderr>:Pooled (Naive)[1,4]<stderr>: StorageManager for [1,4]<stderr>:CPU[1,4]<stderr>:
[1,2]<stderr>:[05:28:14] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[[1,6]<stderr>:05:28:14] ../src/storage/storage.cc[1,6]<stderr>::[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for [1,6]<stderr>:GPU
[1,4]<stderr>:[05:28:14] ../src/storage/storage.cc:[1,4]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[05:28:14] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[05:28:14] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU[1,0]<stderr>:
[1,5]<stderr>:[05:28:14[1,5]<stderr>:] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[05:28:14] ../src/storage/storage.cc:199: Using Pooled (Naive)[1,3]<stderr>: StorageManager for GPU
[1,1]<stderr>:[05:28:14] ../src/storage/storage.cc[1,1]<stderr>::199: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,2]<stderr>:2021-06-01 05:28:19,291:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,2]<stderr>:2021-06-01 05:28:19,292:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 12697, errno = 1
[1,7]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,7]<stderr>:2021-06-01 05:28:19,532:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,7]<stderr>:2021-06-01 05:28:19,532:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 4681, errno = 1
[1,4]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,4]<stderr>:2021-06-01 05:28:19,806:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,4]<stderr>:2021-06-01 05:28:19,807:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,1]<stderr>:2021-06-01 05:28:19,913:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,1]<stderr>:2021-06-01 05:28:19,914:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,5]<stderr>:2021-06-01 05:28:20,159:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,5]<stderr>:2021-06-01 05:28:20,159:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,3]<stderr>:2021-06-01 05:28:20,170:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,3]<stderr>:2021-06-01 05:28:20,171:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,6]<stderr>:2021-06-01 05:28:20,175:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,6]<stderr>:2021-06-01 05:28:20,176:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:65: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:100: DeprecationWarning: Argument 'image_type' for operator 'CropMirrorNormalize' is now deprecated. The argument is no longer used and should be removed.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:176: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:156: Warning: Please set `reader_name` and don't set last_batch_padded and size manually  whenever possible. This may lead, in some situations, to miss some  samples or return duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:84: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self, pipelines, size, reader_name, auto_reset,
[1,0]<stderr>:2021-06-01 05:28:20,245:WARNING: DALI iterator does not support resetting while epoch is not finished. Ignoring...
[1,0]<stderr>:2021-06-01 05:28:20,245:INFO: Starting epoch 0
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 20345, errno = 1
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 19097, errno = 1
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 22449, errno = 1
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 20153, errno = 1
[1,0]<stderr>:[6389caacd155:11460] Read -1, expected 20025, errno = 1
[1,1]<stderr>:[6389caacd155:11461] Read -1, expected 12900, errno = 1
[1,5]<stderr>:[6389caacd155:11465] Read -1, expected 12900, errno = 1
[1,3]<stderr>:[6389caacd155:11463] Read -1, expected 12900, errno = 1
[1,7]<stderr>:[6389caacd155:11467] Read -1, expected 12900, errno = 1
[1,2]<stderr>:[6389caacd155:11462] Read -1, expected 12901, errno = 1
[1,4]<stderr>:[6389caacd155:11464] Read -1, expected 12901, errno = 1
[1,6]<stderr>:[6389caacd155:11466] Read -1, expected 12901, errno = 1
[1,7]<stderr>:[05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[05:28:25] [1,6]<stderr>:../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,3]<stderr>:[05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,3]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[[1,4]<stderr>:05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)[1,4]<stderr>:
[1,0]<stderr>:[05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,2]<stderr>:[05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[05:28:25] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,1]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2021-06-01 05:28:37.382448 - Epoch: 0 Iteration: 19  train.loss : 6.994497346878052  train.ips : 1195.0988209557763  train.lr : 0.1216 
[1,0]<stdout>:DLL 2021-06-01 05:28:40.446662 - Epoch: 0 Iteration: 39  train.loss : 6.824832606315613  train.ips : 6684.284514262418  train.lr : 0.2496 
[1,0]<stdout>:DLL 2021-06-01 05:28:43.473371 - Epoch: 0 Iteration: 59  train.loss : 6.741907954216003  train.ips : 6766.963912743472  train.lr : 0.37760000000000005 
[1,0]<stdout>:DLL 2021-06-01 05:28:46.335659 - Epoch: 0 Iteration: 79  train.loss : 6.620160555839538  train.ips : 7156.088467254981  train.lr : 0.5056 
[1,0]<stdout>:DLL 2021-06-01 05:28:49.094634 - Epoch: 0 Iteration: 99  train.loss : 6.579967260360718  train.ips : 7423.542411781243  train.lr : 0.6336 
[1,0]<stdout>:DLL 2021-06-01 05:28:51.906077 - Epoch: 0 Iteration: 119  train.loss : 6.47692084312439  train.ips : 7285.038496505868  train.lr : 0.7616 
[1,0]<stdout>:DLL 2021-06-01 05:28:54.675964 - Epoch: 0 Iteration: 139  train.loss : 6.424225521087647  train.ips : 7394.333050183026  train.lr : 0.8896000000000001 
[1,0]<stdout>:DLL 2021-06-01 05:28:57.240611 - Epoch: 0 Iteration: 159  train.loss : 6.3611867189407345  train.ips : 7986.205414390992  train.lr : 1.0176 
[1,0]<stdout>:DLL 2021-06-01 05:28:59.838945 - Epoch: 0 Iteration: 179  train.loss : 6.320669388771057  train.ips : 7883.024380663959  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:02.403621 - Epoch: 0 Iteration: 199  train.loss : 6.326156520843506  train.ips : 7987.212358905842  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:04.955557 - Epoch: 0 Iteration: 219  train.loss : 6.334349513053894  train.ips : 8025.8790245091095  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:07.471223 - Epoch: 0 Iteration: 239  train.loss : 6.294660067558288  train.ips : 8141.824064931873  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:10.072589 - Epoch: 0 Iteration: 259  train.loss : 6.318560934066772  train.ips : 7873.325741030871  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:12.796541 - Epoch: 0 Iteration: 279  train.loss : 6.340417075157165  train.ips : 7518.967454965068  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:15.608254 - Epoch: 0 Iteration: 299  train.loss : 6.304705810546875  train.ips : 7284.27863637944  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:18.420516 - Epoch: 0 Iteration: 319  train.loss : 6.310375642776489  train.ips : 7282.942161468211  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:21.334079 - Epoch: 0 Iteration: 339  train.loss : 6.327571153640747  train.ips : 7029.760740803301  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:24.070781 - Epoch: 0 Iteration: 359  train.loss : 6.346747159957886  train.ips : 7484.052783971215  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:26.943594 - Epoch: 0 Iteration: 379  train.loss : 6.307689237594604  train.ips : 7129.4331401814925  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:29.976616 - Epoch: 0 Iteration: 399  train.loss : 6.323723816871643  train.ips : 6752.938743303907  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:32.690672 - Epoch: 0 Iteration: 419  train.loss : 6.325166511535644  train.ips : 7546.386331360921  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:35.498139 - Epoch: 0 Iteration: 439  train.loss : 6.305113697052002  train.ips : 7295.406323679175  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:37.941310 - Epoch: 0 Iteration: 459  train.loss : 6.34975037574768  train.ips : 8383.47394090982  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:29:40.493902 - Epoch: 0 Iteration: 479  train.loss : 6.313159918785095  train.ips : 8023.769399408347  train.lr : 0 
[1,1]<stderr>:2021-06-01 05:29:43,035:INFO: Starting epoch 1
[1,6]<stderr>:2021-06-01 05:29:43,035:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-06-01 05:29:43.036234 - Epoch: 0 Iteration: 499  train.loss : 6.2976309061050415  train.ips : 8056.275616384807  train.lr : 0 
[1,4]<stderr>:2021-06-01 05:29:43,035:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-06-01 05:29:43.036515 - Epoch: 0  train.loss : 6.418805861473084  train.ips : 6184.26507557912 
[1,3]<stderr>:2021-06-01 05:29:43,036:INFO: Starting epoch 1
[1,7]<stderr>:2021-06-01 05:29:43,036:INFO: Starting epoch 1
[1,2]<stderr>:2021-06-01 05:29:43,036:INFO: Starting epoch 1
[1,5]<stderr>:2021-06-01 05:29:43,036:INFO: Starting epoch 1
[1,0]<stderr>:2021-06-01 05:29:43,037:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2021-06-01 05:29:45.586706 - Epoch: 1 Iteration: 19  train.loss : 6.22244610786438  train.ips : 8031.9712215739455  train.lr : 0.3264 
[1,0]<stdout>:DLL 2021-06-01 05:29:48.135023 - Epoch: 1 Iteration: 39  train.loss : 6.141509389877319  train.ips : 8037.157392037652  train.lr : 0.4544 
[1,0]<stdout>:DLL 2021-06-01 05:29:50.853113 - Epoch: 1 Iteration: 59  train.loss : 6.162794828414917  train.ips : 7535.194928380453  train.lr : 0.5824 
[1,0]<stdout>:DLL 2021-06-01 05:29:53.344126 - Epoch: 1 Iteration: 79  train.loss : 6.146025562286377  train.ips : 8222.24248582777  train.lr : 0.7104 
[1,0]<stdout>:DLL 2021-06-01 05:29:55.868991 - Epoch: 1 Iteration: 99  train.loss : 6.115356278419495  train.ips : 8112.14544932562  train.lr : 0.8384 
[1,0]<stdout>:DLL 2021-06-01 05:29:58.471746 - Epoch: 1 Iteration: 119  train.loss : 6.071452403068543  train.ips : 7869.351456981666  train.lr : 0.9663999999999999 
[1,0]<stdout>:DLL 2021-06-01 05:30:01.002278 - Epoch: 1 Iteration: 139  train.loss : 6.0775484323501585  train.ips : 8093.9700990072515  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:03.490331 - Epoch: 1 Iteration: 159  train.loss : 6.084423351287842  train.ips : 8232.123689414846  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:05.982938 - Epoch: 1 Iteration: 179  train.loss : 5.986030244827271  train.ips : 8217.10561108229  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:08.521296 - Epoch: 1 Iteration: 199  train.loss : 6.090969395637512  train.ips : 8068.802888634643  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:11.071691 - Epoch: 1 Iteration: 219  train.loss : 6.094101238250732  train.ips : 8030.801294960208  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:13.605621 - Epoch: 1 Iteration: 239  train.loss : 6.055645275115967  train.ips : 8083.181361152236  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:16.243068 - Epoch: 1 Iteration: 259  train.loss : 6.083450603485107  train.ips : 7765.677786105027  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:18.823048 - Epoch: 1 Iteration: 279  train.loss : 6.078276038169861  train.ips : 7938.730822943976  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:21.421664 - Epoch: 1 Iteration: 299  train.loss : 6.0811927795410154  train.ips : 7881.898885936952  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:23.966477 - Epoch: 1 Iteration: 319  train.loss : 6.0283743143081665  train.ips : 8048.407173424725  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:26.564334 - Epoch: 1 Iteration: 339  train.loss : 6.081483674049378  train.ips : 7884.233415838472  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:29.056918 - Epoch: 1 Iteration: 359  train.loss : 6.0896151304245  train.ips : 8217.251818212342  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:31.705491 - Epoch: 1 Iteration: 379  train.loss : 6.03126323223114  train.ips : 7732.96090485874  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:34.167453 - Epoch: 1 Iteration: 399  train.loss : 6.088328075408936  train.ips : 8319.209221666679  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:36.698736 - Epoch: 1 Iteration: 419  train.loss : 6.069353771209717  train.ips : 8091.300892338817  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:39.276582 - Epoch: 1 Iteration: 439  train.loss : 6.079422807693481  train.ips : 7945.118323043756  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:41.940091 - Epoch: 1 Iteration: 459  train.loss : 6.026411986351013  train.ips : 7689.5484472991575  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:44.460754 - Epoch: 1 Iteration: 479  train.loss : 6.079007816314697  train.ips : 8125.462823359701  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:30:46.992891 - Epoch: 1 Iteration: 499  train.loss : 6.079587793350219  train.ips : 8088.881753961652  train.lr : 0 
[1,6]<stderr>:2021-06-01 05:30:46,992:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-06-01 05:30:46.993143 - Epoch: 1  train.loss : 6.08576282119751  train.ips : 8005.474735163086 
[1,7]<stderr>:2021-06-01 05:30:46,992:INFO: Starting epoch 2
[1,4]<stderr>:2021-06-01 05:30:46,992:INFO: Starting epoch 2
[1,5]<stderr>:2021-06-01 05:30:46,992:INFO: Starting epoch 2
[1,3]<stderr>:2021-06-01 05:30:46,992:INFO: Starting epoch 2
[1,1]<stderr>:2021-06-01 05:30:46,993:INFO: Starting epoch 2
[1,0]<stderr>:2021-06-01 05:30:46,993:INFO: Starting epoch 2
[1,2]<stderr>:2021-06-01 05:30:46,993:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2021-06-01 05:30:49.575958 - Epoch: 2 Iteration: 19  train.loss : 6.071289658546448  train.ips : 7929.575410928681  train.lr : 0.5312 
[1,0]<stdout>:DLL 2021-06-01 05:30:52.192094 - Epoch: 2 Iteration: 39  train.loss : 5.99253146648407  train.ips : 7828.917609721202  train.lr : 0.6592 
[1,0]<stdout>:DLL 2021-06-01 05:30:54.712906 - Epoch: 2 Iteration: 59  train.loss : 5.955430912971496  train.ips : 8125.034729822093  train.lr : 0.7872 
[1,0]<stdout>:DLL 2021-06-01 05:30:57.286148 - Epoch: 2 Iteration: 79  train.loss : 5.95700614452362  train.ips : 7959.575235284148  train.lr : 0.9152000000000001 
[1,0]<stdout>:DLL 2021-06-01 05:30:59.928231 - Epoch: 2 Iteration: 99  train.loss : 5.921080899238587  train.ips : 7752.053151874346  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:02.562371 - Epoch: 2 Iteration: 119  train.loss : 5.912864828109742  train.ips : 7775.497141826781  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:05.195859 - Epoch: 2 Iteration: 139  train.loss : 5.872839450836182  train.ips : 7777.678212275732  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:07.818170 - Epoch: 2 Iteration: 159  train.loss : 5.902894973754883  train.ips : 7810.469993837047  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:10.389334 - Epoch: 2 Iteration: 179  train.loss : 5.9119665145874025  train.ips : 7965.772504521932  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:12.960953 - Epoch: 2 Iteration: 199  train.loss : 5.884853839874268  train.ips : 7965.346299544553  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:15.490285 - Epoch: 2 Iteration: 219  train.loss : 5.927039742469788  train.ips : 8097.711169694533  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:18.119120 - Epoch: 2 Iteration: 239  train.loss : 5.881436419487  train.ips : 7791.27866468621  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:20.733235 - Epoch: 2 Iteration: 259  train.loss : 5.895351099967956  train.ips : 7834.948030822683  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:23.316906 - Epoch: 2 Iteration: 279  train.loss : 5.917836856842041  train.ips : 7927.401972175438  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:25.869569 - Epoch: 2 Iteration: 299  train.loss : 5.872366642951965  train.ips : 8023.773896363064  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:28.490734 - Epoch: 2 Iteration: 319  train.loss : 5.916078090667725  train.ips : 7814.316766976937  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:31.211333 - Epoch: 2 Iteration: 339  train.loss : 5.858832120895386  train.ips : 7528.411945217985  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:33.749586 - Epoch: 2 Iteration: 359  train.loss : 5.84558687210083  train.ips : 8069.358488630525  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:36.302498 - Epoch: 2 Iteration: 379  train.loss : 5.821974396705627  train.ips : 8022.786935665258  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:38.863368 - Epoch: 2 Iteration: 399  train.loss : 5.886651563644409  train.ips : 7997.956261739813  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:41.432189 - Epoch: 2 Iteration: 419  train.loss : 5.855472278594971  train.ips : 7973.30767994101  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:44.091246 - Epoch: 2 Iteration: 439  train.loss : 5.934726333618164  train.ips : 7702.448466506155  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:46.653624 - Epoch: 2 Iteration: 459  train.loss : 5.911784911155701  train.ips : 7993.249692969404  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:49.224100 - Epoch: 2 Iteration: 479  train.loss : 5.8988580226898195  train.ips : 7968.18581765294  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:51.958913 - Epoch: 2 Iteration: 499  train.loss : 5.888820743560791  train.ips : 7489.136390505202  train.lr : 0 
[1,0]<stdout>:DLL 2021-06-01 05:31:51.959232 - Epoch: 2  train.loss : 5.907822991371154  train.ips : 7881.049162318649 
[1,0]<stdout>:DLL 2021-06-01 05:31:52.041583 - Summary: train.loss : 5.907822991371154  train.ips : 7356.929657686952 
train.ips
           |    128    |
------------------------
     1     |   1313.6  |
     8     |   7942.8  |

