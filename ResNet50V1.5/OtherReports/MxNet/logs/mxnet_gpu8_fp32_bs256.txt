[1,0]<stdout>:DLL 2022-11-30 03:14:36.778434 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 0  fuse_bn_add_relu : 0  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float32  amp : False  batch_size : 2048  num_epochs : 3  run_epochs : -1  lr : 2.048  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp32.json-8,256  workspace : ./  logdir : None  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [3, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NCHW  batchnorm_layout : NCHW  pooling_layout : NCHW  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,4]<stderr>:[03:14:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,4]<stderr>:GPU
[1,4]<stderr>:[03:14:40] [1,4]<stderr>:../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,4]<stderr>:CPU
[1,4]<stderr>:2022-11-30 03:14:40,949:INFO: starting epoch 0
[1,3]<stderr>:[[1,3]<stderr>:03:14:40] ../src/storage/storage.cc:199: Using [1,3]<stderr>:Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[[1,3]<stderr>:03:14:40] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:2022-11-30 03:14:40,992:INFO: starting epoch 0
[1,0]<stderr>:[03:14:41] ../src/storage/storage.cc[1,0]<stderr>::199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[03:14:41] ../src/storage/storage.cc:199[1,0]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,0]<stderr>:2022-11-30 03:14:41,043:INFO: starting epoch 0
[1,6]<stderr>:[03:14:41] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,6]<stderr>:[03:14:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:2022-11-30 03:14:41,073:INFO: starting epoch 0
[1,5]<stderr>:[03:14:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for [1,5]<stderr>:GPU
[1,5]<stderr>:[[1,5]<stderr>:03:14:41] ../src/storage/storage.cc:199[1,5]<stderr>:: Using Pooled (Naive) StorageManager for CPU
[1,5]<stderr>:2022-11-30 03:14:41,150:INFO: starting epoch 0
[1,2]<stderr>:[03:14:41[1,2]<stderr>:] ../src/storage/storage.cc:199: Using [1,2]<stderr>:Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[[1,2]<stderr>:03:14:41] ../src/storage/storage.cc[1,2]<stderr>::199: Using Pooled (Naive) StorageManager for CPU
[1,2]<stderr>:2022-11-30 03:14:41,174:INFO: starting epoch 0
[1,7]<stderr>:[03:14:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[03:14:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:2022-11-30 03:14:41,228:INFO: starting epoch 0
[1,1]<stderr>:[03:14:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[03:14:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:2022-11-30 03:14:41,305:INFO: starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self,
[1,6]<stderr>:2022-11-30 03:14:43,410:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,6]<stderr>:2022-11-30 03:14:43,410:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self,
[1,4]<stderr>:2022-11-30 03:14:43,525:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,4]<stderr>:2022-11-30 03:14:43,525:INFO: Starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self,
[1,3]<stderr>:2022-11-30 03:14:43,567:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,3]<stderr>:2022-11-30 03:14:43,567:INFO: Starting epoch 0
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self,
[1,0]<stderr>:2022-11-30 03:14:43,755:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,0]<stderr>:2022-11-30 03:14:43,755:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self,
[1,5]<stderr>:2022-11-30 03:14:44,102:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,5]<stderr>:2022-11-30 03:14:44,102:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self,
[1,1]<stderr>:2022-11-30 03:14:44,220:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,1]<stderr>:2022-11-30 03:14:44,220:INFO: Starting epoch 0
[1,0]<stderr>:[92d7ce6a21c5:15446] Read -1, expected 30577, errno = 1
[1,0]<stderr>:[92d7ce6a21c5:15446] Read -1, expected 30577, errno = 1
[1,0]<stderr>:[92d7ce6a21c5:15446] Read -1, expected 18761, errno = 1
[1,0]<stderr>:[92d7ce6a21c5:15446] Read -1, expected 30577, errno = 1
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self,
[1,2]<stderr>:2022-11-30 03:14:44,387:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,2]<stderr>:2022-11-30 03:14:44,387:INFO: Starting epoch 0
[1,0]<stderr>:[92d7ce6a21c5:15446] Read -1, expected 5921, errno = 1
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self,
[1,7]<stderr>:2022-11-30 03:14:44,450:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,7]<stderr>:2022-11-30 03:14:44,451:INFO: Starting epoch 0
[1,3]<stderr>:[03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:[[1,0]<stderr>:03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,0]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[[1,6]<stderr>:[03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,4]<stderr>:03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[[1,5]<stderr>:03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,5]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:[03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,1]<stderr>:[03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[[1,7]<stderr>:03:14:45] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,7]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2022-11-30 03:15:14.840225 - Epoch: 0 Iteration: 19  train.loss : 6.943831276893616  train.ips : 1317.670017695262 images/s train.lr : 0.4864 
[1,0]<stdout>:DLL 2022-11-30 03:15:28.474580 - Epoch: 0 Iteration: 39  train.loss : 6.696640944480896  train.ips : 3004.266455282211 images/s train.lr : 0.9984 
[1,0]<stdout>:DLL 2022-11-30 03:15:42.073663 - Epoch: 0 Iteration: 59  train.loss : 6.578142046928406  train.ips : 3012.0578932454737 images/s train.lr : 1.5104000000000002 
[1,0]<stdout>:DLL 2022-11-30 03:15:55.653789 - Epoch: 0 Iteration: 79  train.loss : 6.411099195480347  train.ips : 3016.2456409827123 images/s train.lr : 2.0224 
[1,0]<stdout>:DLL 2022-11-30 03:16:09.295863 - Epoch: 0 Iteration: 99  train.loss : 6.3616478681564335  train.ips : 3002.587712712807 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:16:22.987067 - Epoch: 0 Iteration: 119  train.loss : 6.349622201919556  train.ips : 2991.845449630514 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:16:36.670850 - Epoch: 0 Iteration: 139  train.loss : 6.363842844963074  train.ips : 2993.393329198307 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:16:50.386128 - Epoch: 0 Iteration: 159  train.loss : 6.349073982238769  train.ips : 2986.529880006991 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:17:04.115416 - Epoch: 0 Iteration: 179  train.loss : 6.353481984138488  train.ips : 2983.4753254378998 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:17:17.846714 - Epoch: 0 Iteration: 199  train.loss : 6.339221096038818  train.ips : 2983.0499111632985 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:17:31.596035 - Epoch: 0 Iteration: 219  train.loss : 6.340978193283081  train.ips : 2979.2142357998046 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:17:45.345810 - Epoch: 0 Iteration: 239  train.loss : 6.376607847213745  train.ips : 2979.2982429792987 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:17:59.100430 - Epoch: 0 Iteration: 259  train.loss : 6.34131269454956  train.ips : 2977.975086327267 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:18:12.844321 - Epoch: 0 Iteration: 279  train.loss : 6.349832916259766  train.ips : 2980.350904121832 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:18:26.598458 - Epoch: 0 Iteration: 299  train.loss : 6.331903886795044  train.ips : 2978.1155007273037 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:18:40.397300 - Epoch: 0 Iteration: 319  train.loss : 6.34453239440918  train.ips : 2968.458639959044 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:18:54.140594 - Epoch: 0 Iteration: 339  train.loss : 6.334935736656189  train.ips : 2980.4333725378383 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:19:07.880248 - Epoch: 0 Iteration: 359  train.loss : 6.365215206146241  train.ips : 2981.229595471134 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:19:21.644688 - Epoch: 0 Iteration: 379  train.loss : 6.365912413597107  train.ips : 2975.8759736909083 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:19:35.369190 - Epoch: 0 Iteration: 399  train.loss : 6.357069301605224  train.ips : 2984.516371682269 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:19:49.141943 - Epoch: 0 Iteration: 419  train.loss : 6.3522072553634645  train.ips : 2974.098586613802 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:20:02.863571 - Epoch: 0 Iteration: 439  train.loss : 6.370309329032898  train.ips : 2985.190541836539 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:20:16.603670 - Epoch: 0 Iteration: 459  train.loss : 6.349960613250732  train.ips : 2981.151117974019 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:20:30.346996 - Epoch: 0 Iteration: 479  train.loss : 6.360091590881348  train.ips : 2980.439111889 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:20:44.121929 - Epoch: 0 Iteration: 499  train.loss : 6.372010111808777  train.ips : 2973.6018792060754 images/s train.lr : 0 
[1,5]<stderr>:2022-11-30 03:20:44,177:INFO: Starting epoch 1
[1,1]<stderr>:2022-11-30 03:20:44,179:INFO: Starting epoch 1
[1,6]<stderr>:2022-11-30 03:20:44,184:INFO: Starting epoch 1
[1,3]<stderr>:2022-11-30 03:20:44,192:INFO: Starting epoch 1
[1,4]<stderr>:2022-11-30 03:20:44,196:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-11-30 03:20:44.198881 - Epoch: 0  train.loss : 6.40237931728363  train.ips : 2983.9778893791517 images/s
[1,2]<stderr>:2022-11-30 03:20:44,199:INFO: Starting epoch 1
[1,0]<stderr>:2022-11-30 03:20:44,199:INFO: Starting epoch 1
[1,7]<stderr>:2022-11-30 03:20:44,202:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-11-30 03:20:57.914450 - Epoch: 1 Iteration: 19  train.loss : 6.277478313446045  train.ips : 2986.45423810722 images/s train.lr : 0.8960000000000001 
[1,0]<stdout>:DLL 2022-11-30 03:21:11.700078 - Epoch: 1 Iteration: 39  train.loss : 6.2102546215057375  train.ips : 2971.2734445723395 images/s train.lr : 1.408 
[1,0]<stdout>:DLL 2022-11-30 03:21:25.455837 - Epoch: 1 Iteration: 59  train.loss : 6.17818591594696  train.ips : 2977.7318187505666 images/s train.lr : 1.92 
[1,0]<stdout>:DLL 2022-11-30 03:21:39.242924 - Epoch: 1 Iteration: 79  train.loss : 6.126635551452637  train.ips : 2970.9748563860803 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:21:53.010076 - Epoch: 1 Iteration: 99  train.loss : 6.132278275489807  train.ips : 2975.2693286951567 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:22:06.759729 - Epoch: 1 Iteration: 119  train.loss : 6.1300253629684445  train.ips : 2979.0538293462205 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:22:20.524777 - Epoch: 1 Iteration: 139  train.loss : 6.147644972801208  train.ips : 2975.721905411854 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:22:34.288253 - Epoch: 1 Iteration: 159  train.loss : 6.13467493057251  train.ips : 2976.0958411325078 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:22:48.050927 - Epoch: 1 Iteration: 179  train.loss : 6.089709186553955  train.ips : 2976.2282927924816 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:23:01.813212 - Epoch: 1 Iteration: 199  train.loss : 6.10156614780426  train.ips : 2976.3501855460095 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:23:15.549933 - Epoch: 1 Iteration: 219  train.loss : 6.143631458282471  train.ips : 2981.858599327386 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:23:29.307116 - Epoch: 1 Iteration: 239  train.loss : 6.139070701599121  train.ips : 2977.421714096362 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:23:43.054265 - Epoch: 1 Iteration: 259  train.loss : 6.139621663093567  train.ips : 2979.5926671562047 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:23:56.801880 - Epoch: 1 Iteration: 279  train.loss : 6.130132174491882  train.ips : 2979.4927796350707 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:24:10.534817 - Epoch: 1 Iteration: 299  train.loss : 6.109908580780029  train.ips : 2982.6857219952194 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:24:24.273864 - Epoch: 1 Iteration: 319  train.loss : 6.143225383758545  train.ips : 2981.3682991610335 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:24:38.043938 - Epoch: 1 Iteration: 339  train.loss : 6.12823531627655  train.ips : 2974.636045227625 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:24:51.801177 - Epoch: 1 Iteration: 359  train.loss : 6.152551054954529  train.ips : 2977.426151816892 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:25:05.555989 - Epoch: 1 Iteration: 379  train.loss : 6.109326982498169  train.ips : 2977.9571224991123 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:25:19.325331 - Epoch: 1 Iteration: 399  train.loss : 6.1389864683151245  train.ips : 2974.79937595922 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:25:33.076380 - Epoch: 1 Iteration: 419  train.loss : 6.1310972452163695  train.ips : 2978.752384277103 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:25:46.833391 - Epoch: 1 Iteration: 439  train.loss : 6.137580823898316  train.ips : 2977.496331481679 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:26:00.623412 - Epoch: 1 Iteration: 459  train.loss : 6.113897657394409  train.ips : 2970.3289685129075 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:26:14.366886 - Epoch: 1 Iteration: 479  train.loss : 6.109760689735412  train.ips : 2980.384718205602 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:26:28.135982 - Epoch: 1 Iteration: 499  train.loss : 6.134632658958435  train.ips : 2974.845220983852 images/s train.lr : 0 
[1,3]<stderr>:2022-11-30 03:26:28,199:INFO: Starting epoch 2
[1,5]<stderr>:2022-11-30 03:26:28,200:INFO: Starting epoch 2
[1,1]<stderr>:2022-11-30 03:26:28,209:INFO: Starting epoch 2
[1,4]<stderr>:2022-11-30 03:26:28,210:INFO: Starting epoch 2
[1,0]<stderr>:2022-11-30 03:26:28,212:INFO: Starting epoch 2
[1,6]<stderr>:2022-11-30 03:26:28,214:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-11-30 03:26:28.212364 - Epoch: 1  train.loss : 6.1396044855117795  train.ips : 2978.1925809170366 images/s
[1,7]<stderr>:2022-11-30 03:26:28,215:INFO: Starting epoch 2
[1,2]<stderr>:2022-11-30 03:26:28,220:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-11-30 03:26:41.917754 - Epoch: 2 Iteration: 19  train.loss : 6.201772832870484  train.ips : 2988.6795652193123 images/s train.lr : 1.3056 
[1,0]<stdout>:DLL 2022-11-30 03:26:55.652178 - Epoch: 2 Iteration: 39  train.loss : 6.051142287254334  train.ips : 2982.355635875699 images/s train.lr : 1.8176 
[1,0]<stdout>:DLL 2022-11-30 03:27:09.435855 - Epoch: 2 Iteration: 59  train.loss : 6.041530299186706  train.ips : 2971.703371028761 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:27:23.221506 - Epoch: 2 Iteration: 79  train.loss : 6.010853719711304  train.ips : 2971.265479386291 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:27:36.957418 - Epoch: 2 Iteration: 99  train.loss : 5.989133620262146  train.ips : 2982.0776435477746 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:27:50.714388 - Epoch: 2 Iteration: 119  train.loss : 6.003304815292358  train.ips : 2977.465575868411 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:28:04.412437 - Epoch: 2 Iteration: 139  train.loss : 5.978552842140198  train.ips : 2990.277726160186 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:28:18.201505 - Epoch: 2 Iteration: 159  train.loss : 6.0086575746536255  train.ips : 2970.5464247636733 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:28:31.988299 - Epoch: 2 Iteration: 179  train.loss : 5.978929805755615  train.ips : 2971.0515144998535 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:28:45.713604 - Epoch: 2 Iteration: 199  train.loss : 6.009044027328491  train.ips : 2984.343988599511 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:28:59.493238 - Epoch: 2 Iteration: 219  train.loss : 6.007640552520752  train.ips : 2972.5659632203588 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:29:13.222316 - Epoch: 2 Iteration: 239  train.loss : 6.014443755149841  train.ips : 2983.519624814167 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:29:27.001375 - Epoch: 2 Iteration: 259  train.loss : 5.996040463447571  train.ips : 2972.726186127645 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:29:40.775432 - Epoch: 2 Iteration: 279  train.loss : 6.0169764995574955  train.ips : 2973.79232672997 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:29:54.534558 - Epoch: 2 Iteration: 299  train.loss : 6.0090007305145265  train.ips : 2976.9959092680288 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:30:08.303336 - Epoch: 2 Iteration: 319  train.loss : 5.993120861053467  train.ips : 2974.912651795511 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:30:22.062525 - Epoch: 2 Iteration: 339  train.loss : 6.011250853538513  train.ips : 2976.9908537930955 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:30:35.826394 - Epoch: 2 Iteration: 359  train.loss : 5.985396671295166  train.ips : 2975.978196411137 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:30:49.592849 - Epoch: 2 Iteration: 379  train.loss : 6.00080361366272  train.ips : 2975.4319044622066 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:31:03.334689 - Epoch: 2 Iteration: 399  train.loss : 6.005255174636841  train.ips : 2980.7543447948433 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:31:17.110036 - Epoch: 2 Iteration: 419  train.loss : 6.024401450157166  train.ips : 2973.491430818798 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:31:30.887580 - Epoch: 2 Iteration: 439  train.loss : 6.025481390953064  train.ips : 2973.0276474640727 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:31:44.651428 - Epoch: 2 Iteration: 459  train.loss : 6.009514045715332  train.ips : 2975.988970672237 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:31:58.403370 - Epoch: 2 Iteration: 479  train.loss : 6.019359540939331  train.ips : 2978.575347312679 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:32:12.149026 - Epoch: 2 Iteration: 499  train.loss : 5.987351584434509  train.ips : 2979.93707983196 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:32:12.221643 - Epoch: 2  train.loss : 6.015158360481262  train.ips : 2977.535625808556 images/s
[1,0]<stdout>:DLL 2022-11-30 03:32:12.618250 - Summary: train.loss : 6.015158360481262  train.ips : 2979.902032034915 images/s
Traceback (most recent call last):
  File "benchmark.py", line 84, in <module>
    epochs_report = list(filter(lambda x: len(x['step']) == 1, log_data))
  File "benchmark.py", line 84, in <lambda>
    epochs_report = list(filter(lambda x: len(x['step']) == 1, log_data))
KeyError: 'step'
train.ips
           |    256    |
------------------------
     8     |    nan    |

