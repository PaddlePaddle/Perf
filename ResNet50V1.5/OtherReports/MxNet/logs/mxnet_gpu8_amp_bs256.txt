[1,0]<stdout>:DLL 2022-11-30 03:37:19.195847 - PARAMETER arch : resnetv15  num_layers : 50  num_groups : 32  num_classes : 1000  batchnorm_eps : 1e-05  batchnorm_mom : 0.9  fuse_bn_relu : 1  fuse_bn_add_relu : 1  mode : train  seed : None  gpus : [0, 1, 2, 3, 4, 5, 6, 7]  kv_store : horovod  dtype : float16  amp : False  batch_size : 2048  num_epochs : 3  run_epochs : -1  lr : 2.048  lr_schedule : cosine  lr_factor : 0.256  lr_steps : []  warmup_epochs : 5  optimizer : sgd  mom : 0.875  wd : 3.0517578125e-05  label_smoothing : 0.1  mixup : 0  disp_batches : 20  model_prefix : model  save_frequency : -1  begin_epoch : 0  load : None  test_io : False  test_io_mode : train  log : log.log  dllogger_log : benchmark_report_fp16.json-8,256  workspace : ./  logdir : None  no_metrics : True  benchmark_iters : 500  data_train : /data/imagenet/train-val-recordio-passthrough/train.rec  data_train_idx : /data/imagenet/train-val-recordio-passthrough/train.idx  data_val : /data/imagenet/train-val-recordio-passthrough/val.rec  data_val_idx : /data/imagenet/train-val-recordio-passthrough/val.idx  data_pred : None  data_backend : dali-gpu  image_shape : [4, 224, 224]  rgb_mean : [123.68, 116.779, 103.939]  rgb_std : [58.393, 57.12, 57.375]  input_layout : NCHW  conv_layout : NHWC  batchnorm_layout : NHWC  pooling_layout : NHWC  num_examples : 32000  data_val_resize : 256  dali_separ_val : False  dali_threads : 4  dali_validation_threads : 10  dali_prefetch_queue : 2  dali_nvjpeg_memory_padding : 64  dali_fuse_decoder : 1  dali_nvjpeg_width_hint : 5980  dali_nvjpeg_height_hint : 6430  dali_dont_use_mmap : False  data_mxnet_threads : 40  random_crop : 0  random_mirror : 1  max_random_h : 0  max_random_s : 0  max_random_l : 0  min_random_aspect_ratio : 0.75  max_random_aspect_ratio : 1.33  max_random_rotate_angle : 0  max_random_shear_ratio : 0  max_random_scale : 1  min_random_scale : 1  max_random_area : 1  min_random_area : 0.05  min_crop_size : -1  max_crop_size : -1  brightness : 0  contrast : 0  saturation : 0  pca_noise : 0  random_resized_crop : 1 
[1,3]<stderr>:[03:37:23] ../src/storage/storage.cc:[1,3]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,3]<stderr>:[03:37:23] [1,3]<stderr>:../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,3]<stderr>:2022-11-30 03:37:23,278:INFO: starting epoch 0
[1,5]<stderr>:[[1,5]<stderr>:03:37:23] ../src/storage/storage.cc:[1,5]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,1]<stderr>:[[1,1]<stderr>:03:37:23] ../src/storage/storage.cc:199[1,1]<stderr>:: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:[03:37:23] ../src/storage/storage.cc[1,5]<stderr>::199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:[03:37:23] [1,1]<stderr>:../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,6]<stderr>:[[1,6]<stderr>:03:37:23] ../src/storage/storage.cc:[1,6]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,5]<stderr>:2022-11-30 03:37:23,381:INFO: starting epoch 0
[1,6]<stderr>:[03:37:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,1]<stderr>:2022-11-30 03:37:23,386:INFO: starting epoch 0
[1,6]<stderr>:2022-11-30 03:37:23,399:INFO: starting epoch 0
[1,4]<stderr>:[03:37:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[1,4]<stderr>:[03:37:23] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,4]<stderr>:2022-11-30 03:37:23,450:INFO: starting epoch 0
[1,7]<stderr>:[03:37:24] ../src/storage/storage.cc:[1,7]<stderr>:199: Using Pooled (Naive) StorageManager for GPU
[1,2]<stderr>:[[1,2]<stderr>:03:37:24] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1,0]<stderr>:[[1,0]<stderr>:03:37:24] ../src/storage/storage.cc[1,0]<stderr>::199: Using [1,0]<stderr>:Pooled (Naive) StorageManager for GPU
[1,7]<stderr>:[[1,7]<stderr>:03:37:24] ../src/storage/storage.cc:[1,7]<stderr>:199: Using Pooled (Naive)[1,7]<stderr>: StorageManager for CPU
[1,2]<stderr>:[[1,2]<stderr>:03:37:24] ../src/storage/storage.cc[1,2]<stderr>::199: Using Pooled (Naive)[1,2]<stderr>: StorageManager for CPU
[1,0]<stderr>:[[1,0]<stderr>:03:37:24] ../src/storage/storage.cc[1,0]<stderr>::199: Using Pooled (Naive) StorageManager for CPU
[1,7]<stderr>:2022-11-30 03:37:24,049:INFO: starting epoch 0
[1,2]<stderr>:2022-11-30 03:37:24,052:INFO: starting epoch 0
[1,0]<stderr>:2022-11-30 03:37:24,056:INFO: starting epoch 0
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,3]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,3]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,3]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,3]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,3]<stderr>:functionality to allow for backward compatibility.
[1,3]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,3]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,3]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,3]<stderr>:  _iterator_deprecation_warning()
[1,3]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,3]<stderr>:  _DaliBaseIterator.__init__(self,
[1,3]<stderr>:2022-11-30 03:37:26,528:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,3]<stderr>:2022-11-30 03:37:26,529:INFO: Starting epoch 0
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,1]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,1]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,1]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,1]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,1]<stderr>:functionality to allow for backward compatibility.
[1,1]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,1]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,1]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,1]<stderr>:  _iterator_deprecation_warning()
[1,1]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,1]<stderr>:  _DaliBaseIterator.__init__(self,
[1,1]<stderr>:2022-11-30 03:37:26,910:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,1]<stderr>:2022-11-30 03:37:26,910:INFO: Starting epoch 0
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,5]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,5]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,5]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,5]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,5]<stderr>:functionality to allow for backward compatibility.
[1,5]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,5]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,5]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,5]<stderr>:  _iterator_deprecation_warning()
[1,5]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,5]<stderr>:  _DaliBaseIterator.__init__(self,
[1,5]<stderr>:2022-11-30 03:37:26,960:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,5]<stderr>:2022-11-30 03:37:26,961:INFO: Starting epoch 0
[1,0]<stderr>:[92d7ce6a21c5:18051] Read -1, expected 8609, errno = 1
[1,0]<stderr>:[92d7ce6a21c5:18051] Read -1, expected 31009, errno = 1
[1,0]<stderr>:[92d7ce6a21c5:18051] Read -1, expected 7761, errno = 1
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,0]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,0]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,0]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,0]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,0]<stderr>:functionality to allow for backward compatibility.
[1,0]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,0]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,0]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,0]<stderr>:  _iterator_deprecation_warning()
[1,0]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,0]<stderr>:  _DaliBaseIterator.__init__(self,
[1,0]<stderr>:2022-11-30 03:37:27,320:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,0]<stderr>:2022-11-30 03:37:27,320:INFO: Starting epoch 0
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,7]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,7]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,7]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,7]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,7]<stderr>:functionality to allow for backward compatibility.
[1,7]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,7]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,7]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,7]<stderr>:  _iterator_deprecation_warning()
[1,7]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,7]<stderr>:  _DaliBaseIterator.__init__(self,
[1,7]<stderr>:2022-11-30 03:37:27,342:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,7]<stderr>:2022-11-30 03:37:27,343:INFO: Starting epoch 0
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,4]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,4]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,4]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,4]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,4]<stderr>:functionality to allow for backward compatibility.
[1,4]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,4]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,4]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,4]<stderr>:  _iterator_deprecation_warning()
[1,4]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,4]<stderr>:  _DaliBaseIterator.__init__(self,
[1,4]<stderr>:2022-11-30 03:37:27,371:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,4]<stderr>:2022-11-30 03:37:27,371:INFO: Starting epoch 0
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,2]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,2]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,2]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,2]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,2]<stderr>:functionality to allow for backward compatibility.
[1,2]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,2]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,2]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,2]<stderr>:  _iterator_deprecation_warning()
[1,2]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,2]<stderr>:  _DaliBaseIterator.__init__(self,
[1,2]<stderr>:2022-11-30 03:37:27,385:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,2]<stderr>:2022-11-30 03:37:27,385:INFO: Starting epoch 0
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:83: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``output_dtype`` is a deprecated alias for ``dtype``. Use ``dtype`` instead.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/workspace/rn50/dali.py:128: DeprecationWarning: The argument ``image_type`` is no longer used and will be removed in a future release.
[1,6]<stderr>:  self.cmnp = ops.CropMirrorNormalize(device="gpu",
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder_random_crop` is now deprecated. Use `decoders.image_random_crop` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
[1,6]<stderr>:In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:649: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
[1,6]<stderr>:In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
[1,6]<stderr>:submodule and renamed to follow a common pattern. This is a placeholder operator with identical
[1,6]<stderr>:functionality to allow for backward compatibility.
[1,6]<stderr>:  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
[1,6]<stderr>:/workspace/rn50/dali.py:209: UserWarning: 32000 training examples will be used, although full training set contains 1281167 examples
[1,6]<stderr>:  warnings.warn("{} training examples will be used, although full training set contains {} examples".format(args.num_examples, trainpipes[0].epoch_size("Reader")))
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/base_iterator.py:192: Warning: Please set `reader_name` and don't set last_batch_padded and size manually whenever possible. This may lead, in some situations, to missing some samples or returning duplicated ones. Check the Sharding section of the documentation for more details.
[1,6]<stderr>:  _iterator_deprecation_warning()
[1,6]<stderr>:/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:95: Warning: Please do not use `fill_last_batch` and use `last_batch_policy`                            instead.
[1,6]<stderr>:  _DaliBaseIterator.__init__(self,
[1,6]<stderr>:2022-11-30 03:37:28,141:WARNING: DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
[1,6]<stderr>:2022-11-30 03:37:28,142:INFO: Starting epoch 0
[1,3]<stderr>:[03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,1]<stderr>:[03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,5]<stderr>:[03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,6]<stderr>:[[1,6]<stderr>:03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,6]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,4]<stderr>:[[1,4]<stderr>:03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:[1,4]<stderr>:120: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,2]<stderr>:[[1,2]<stderr>:03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,2]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stderr>:[03:37:29[1,0]<stderr>:] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120: [1,0]<stderr>:Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,7]<stderr>:[[1,7]<stderr>:03:37:29] ../src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:120[1,7]<stderr>:: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
[1,0]<stdout>:DLL 2022-11-30 03:37:50.029699 - Epoch: 0 Iteration: 19  train.loss : 6.9515848636627195  train.ips : 1803.6903096010747 images/s train.lr : 0.4864 
[1,0]<stdout>:DLL 2022-11-30 03:37:54.030684 - Epoch: 0 Iteration: 39  train.loss : 6.682845091819763  train.ips : 10240.11779920669 images/s train.lr : 0.9984 
[1,0]<stdout>:DLL 2022-11-30 03:37:57.902641 - Epoch: 0 Iteration: 59  train.loss : 6.572544431686401  train.ips : 10579.969774803812 images/s train.lr : 1.5104000000000002 
[1,0]<stdout>:DLL 2022-11-30 03:38:01.769638 - Epoch: 0 Iteration: 79  train.loss : 6.435230684280396  train.ips : 10593.576669683413 images/s train.lr : 2.0224 
[1,0]<stdout>:DLL 2022-11-30 03:38:05.646601 - Epoch: 0 Iteration: 99  train.loss : 6.371240210533142  train.ips : 10566.14044303463 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:09.516986 - Epoch: 0 Iteration: 119  train.loss : 6.352793622016907  train.ips : 10583.778162813383 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:13.391068 - Epoch: 0 Iteration: 139  train.loss : 6.373638868331909  train.ips : 10573.852635315878 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:17.269429 - Epoch: 0 Iteration: 159  train.loss : 6.355153894424438  train.ips : 10561.79668472637 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:21.137496 - Epoch: 0 Iteration: 179  train.loss : 6.353488802909851  train.ips : 10590.000795797156 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:25.013535 - Epoch: 0 Iteration: 199  train.loss : 6.346474528312683  train.ips : 10568.075399793706 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:28.886550 - Epoch: 0 Iteration: 219  train.loss : 6.35200788974762  train.ips : 10576.703902119309 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:32.759979 - Epoch: 0 Iteration: 239  train.loss : 6.379503583908081  train.ips : 10575.362703846593 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:36.654717 - Epoch: 0 Iteration: 259  train.loss : 6.343221545219421  train.ips : 10517.328676125151 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:40.542399 - Epoch: 0 Iteration: 279  train.loss : 6.361024689674378  train.ips : 10536.580479480619 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:44.417109 - Epoch: 0 Iteration: 299  train.loss : 6.353654980659485  train.ips : 10572.181648448284 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:48.297981 - Epoch: 0 Iteration: 319  train.loss : 6.346896123886109  train.ips : 10556.31152047682 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:52.177464 - Epoch: 0 Iteration: 339  train.loss : 6.349183797836304  train.ips : 10558.797050078272 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:56.070183 - Epoch: 0 Iteration: 359  train.loss : 6.366442108154297  train.ips : 10523.027342438823 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:38:59.940947 - Epoch: 0 Iteration: 379  train.loss : 6.3744466543197635  train.ips : 10582.81847488351 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:03.812566 - Epoch: 0 Iteration: 399  train.loss : 6.3560981273651125  train.ips : 10580.356159178298 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:07.684049 - Epoch: 0 Iteration: 419  train.loss : 6.363793134689331  train.ips : 10582.295022834032 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:11.557465 - Epoch: 0 Iteration: 439  train.loss : 6.378264737129212  train.ips : 10575.315182187045 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:15.436599 - Epoch: 0 Iteration: 459  train.loss : 6.351651978492737  train.ips : 10559.882849562444 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:19.314802 - Epoch: 0 Iteration: 479  train.loss : 6.367743372917175  train.ips : 10562.087586071219 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:23.190412 - Epoch: 0 Iteration: 499  train.loss : 6.378785800933838  train.ips : 10569.313311776199 images/s train.lr : 0 
[1,1]<stderr>:2022-11-30 03:39:23,247:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-11-30 03:39:23.251841 - Epoch: 0  train.loss : 6.408708540916443  train.ips : 10566.255178850708 images/s
[1,0]<stderr>:2022-11-30 03:39:23,252:INFO: Starting epoch 1
[1,3]<stderr>:2022-11-30 03:39:23,255:INFO: Starting epoch 1
[1,5]<stderr>:2022-11-30 03:39:23,256:INFO: Starting epoch 1
[1,4]<stderr>:2022-11-30 03:39:23,257:INFO: Starting epoch 1
[1,6]<stderr>:2022-11-30 03:39:23,263:INFO: Starting epoch 1
[1,2]<stderr>:2022-11-30 03:39:23,268:INFO: Starting epoch 1
[1,7]<stderr>:2022-11-30 03:39:23,277:INFO: Starting epoch 1
[1,0]<stdout>:DLL 2022-11-30 03:39:27.085883 - Epoch: 1 Iteration: 19  train.loss : 6.3072614669799805  train.ips : 10683.668702756433 images/s train.lr : 0.8960000000000001 
[1,0]<stdout>:DLL 2022-11-30 03:39:30.966279 - Epoch: 1 Iteration: 39  train.loss : 6.2005698680877686  train.ips : 10557.19828750862 images/s train.lr : 1.408 
[1,0]<stdout>:DLL 2022-11-30 03:39:34.849653 - Epoch: 1 Iteration: 59  train.loss : 6.172195315361023  train.ips : 10550.03446227545 images/s train.lr : 1.92 
[1,0]<stdout>:DLL 2022-11-30 03:39:38.731556 - Epoch: 1 Iteration: 79  train.loss : 6.1254096031188965  train.ips : 10552.268143160112 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:42.622680 - Epoch: 1 Iteration: 99  train.loss : 6.14039556980133  train.ips : 10527.163802996907 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:46.514564 - Epoch: 1 Iteration: 119  train.loss : 6.1295182466506954  train.ips : 10527.111553059804 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:50.400689 - Epoch: 1 Iteration: 139  train.loss : 6.158298492431641  train.ips : 10540.769641566927 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:54.286310 - Epoch: 1 Iteration: 159  train.loss : 6.132337069511413  train.ips : 10542.093669608637 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:39:58.176315 - Epoch: 1 Iteration: 179  train.loss : 6.092454028129578  train.ips : 10530.443040197606 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:02.050016 - Epoch: 1 Iteration: 199  train.loss : 6.100133156776428  train.ips : 10574.76122832142 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:05.935016 - Epoch: 1 Iteration: 219  train.loss : 6.14153151512146  train.ips : 10543.897521864485 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:09.818160 - Epoch: 1 Iteration: 239  train.loss : 6.140571975708008  train.ips : 10549.104202916697 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:13.690645 - Epoch: 1 Iteration: 259  train.loss : 6.145832467079162  train.ips : 10577.80771603382 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:17.574841 - Epoch: 1 Iteration: 279  train.loss : 6.131717944145203  train.ips : 10546.59474628248 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:21.459396 - Epoch: 1 Iteration: 299  train.loss : 6.105327129364014  train.ips : 10545.065049367915 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:25.336705 - Epoch: 1 Iteration: 319  train.loss : 6.149136805534363  train.ips : 10565.18719956942 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:29.218512 - Epoch: 1 Iteration: 339  train.loss : 6.12890202999115  train.ips : 10552.469071755248 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:33.090801 - Epoch: 1 Iteration: 359  train.loss : 6.1465744972229  train.ips : 10578.414749057834 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:36.963858 - Epoch: 1 Iteration: 379  train.loss : 6.115824341773987  train.ips : 10576.268952011815 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:40.848397 - Epoch: 1 Iteration: 399  train.loss : 6.121575355529785  train.ips : 10544.920712395226 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:44.751637 - Epoch: 1 Iteration: 419  train.loss : 6.136258387565613  train.ips : 10494.517387800659 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:48.646239 - Epoch: 1 Iteration: 439  train.loss : 6.141197562217712  train.ips : 10517.68216681575 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:52.531699 - Epoch: 1 Iteration: 459  train.loss : 6.1214051961898805  train.ips : 10542.880999791842 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:40:56.416296 - Epoch: 1 Iteration: 479  train.loss : 6.112003469467163  train.ips : 10544.743371031589 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:00.306237 - Epoch: 1 Iteration: 499  train.loss : 6.138586139678955  train.ips : 10530.490159433326 images/s train.lr : 0 
[1,5]<stderr>:2022-11-30 03:41:00,369:INFO: Starting epoch 2
[1,2]<stderr>:2022-11-30 03:41:00,370:INFO: Starting epoch 2
[1,7]<stderr>:2022-11-30 03:41:00,370:INFO: Starting epoch 2
[1,1]<stderr>:2022-11-30 03:41:00,371:INFO: Starting epoch 2
[1,6]<stderr>:2022-11-30 03:41:00,374:INFO: Starting epoch 2
[1,4]<stderr>:2022-11-30 03:41:00,375:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-11-30 03:41:00.375232 - Epoch: 1  train.loss : 6.141400705337524  train.ips : 10555.792314408858 images/s
[1,0]<stderr>:2022-11-30 03:41:00,375:INFO: Starting epoch 2
[1,3]<stderr>:2022-11-30 03:41:00,392:INFO: Starting epoch 2
[1,0]<stdout>:DLL 2022-11-30 03:41:04.244216 - Epoch: 2 Iteration: 19  train.loss : 6.2970618724823  train.ips : 10587.249356825867 images/s train.lr : 1.3056 
[1,0]<stdout>:DLL 2022-11-30 03:41:08.130162 - Epoch: 2 Iteration: 39  train.loss : 6.05406129360199  train.ips : 10541.227548180157 images/s train.lr : 1.8176 
[1,0]<stdout>:DLL 2022-11-30 03:41:12.012352 - Epoch: 2 Iteration: 59  train.loss : 6.0081504583358765  train.ips : 10551.553288298699 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:15.901109 - Epoch: 2 Iteration: 79  train.loss : 5.993859338760376  train.ips : 10534.19582605985 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:19.777294 - Epoch: 2 Iteration: 99  train.loss : 5.963993167877197  train.ips : 10567.793269260934 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:23.655131 - Epoch: 2 Iteration: 119  train.loss : 5.979020977020264  train.ips : 10563.293569014219 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:27.537446 - Epoch: 2 Iteration: 139  train.loss : 5.949321746826172  train.ips : 10551.14697245491 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:31.418727 - Epoch: 2 Iteration: 159  train.loss : 5.980791354179383  train.ips : 10553.786964106346 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:35.300916 - Epoch: 2 Iteration: 179  train.loss : 5.970989537239075  train.ips : 10551.539031072676 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:39.201326 - Epoch: 2 Iteration: 199  train.loss : 5.994131350517273  train.ips : 10502.199172361718 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:43.088226 - Epoch: 2 Iteration: 219  train.loss : 5.992140746116638  train.ips : 10538.544057767856 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:46.961186 - Epoch: 2 Iteration: 239  train.loss : 5.992428112030029  train.ips : 10576.677205049287 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:50.853997 - Epoch: 2 Iteration: 259  train.loss : 5.9696025371551515  train.ips : 10522.660602105345 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:54.741813 - Epoch: 2 Iteration: 279  train.loss : 5.994166564941406  train.ips : 10536.223132656414 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:41:58.626199 - Epoch: 2 Iteration: 299  train.loss : 5.991926288604736  train.ips : 10546.079403129103 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:02.521716 - Epoch: 2 Iteration: 319  train.loss : 5.972769165039063  train.ips : 10515.497858751673 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:06.407982 - Epoch: 2 Iteration: 339  train.loss : 5.984532523155212  train.ips : 10540.55169716752 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:10.298007 - Epoch: 2 Iteration: 359  train.loss : 5.962660932540894  train.ips : 10530.630874181417 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:14.171631 - Epoch: 2 Iteration: 379  train.loss : 5.98241708278656  train.ips : 10574.726079270424 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:18.063308 - Epoch: 2 Iteration: 399  train.loss : 5.987703156471253  train.ips : 10525.779032439497 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:21.938765 - Epoch: 2 Iteration: 419  train.loss : 5.997846102714538  train.ips : 10569.786057410864 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:25.837931 - Epoch: 2 Iteration: 439  train.loss : 6.010141801834107  train.ips : 10505.405698559458 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:29.727566 - Epoch: 2 Iteration: 459  train.loss : 5.997159314155579  train.ips : 10531.3125548178 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:33.613396 - Epoch: 2 Iteration: 479  train.loss : 5.99868369102478  train.ips : 10541.448754608544 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:37.489087 - Epoch: 2 Iteration: 499  train.loss : 5.969565367698669  train.ips : 10569.254790498919 images/s train.lr : 0 
[1,0]<stdout>:DLL 2022-11-30 03:42:37.554795 - Epoch: 2  train.loss : 5.999804979324341  train.ips : 10550.8743468182 images/s
[1,0]<stdout>:DLL 2022-11-30 03:42:37.657686 - Summary: train.loss : 5.999804979324341  train.ips : 10557.640613359255 images/s
Traceback (most recent call last):
  File "benchmark.py", line 84, in <module>
    epochs_report = list(filter(lambda x: len(x['step']) == 1, log_data))
  File "benchmark.py", line 84, in <lambda>
    epochs_report = list(filter(lambda x: len(x['step']) == 1, log_data))
KeyError: 'step'
train.ips
           |    256    |
------------------------
     8     |    nan    |

