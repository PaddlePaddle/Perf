------------Environment Information-------------
platform: Linux-4.14.0_1-0-0-32-x86_64-with-Ubuntu-18.04-bionic
Python: 3.7.10 (default, Feb 20 2021, 21:17:23) [GCC 7.5.0]
Paddle compiled with cuda: True
NVCC: Build cuda_11.0_bu.TC445_37.28845127_0
cudnn: 8.0
GPUs used: 1
CUDA_VISIBLE_DEVICES: 0
GPU: ['GPU 0: Tesla V100-SXM2-32GB']
GCC: gcc (GCC) 8.2.0
PaddlePaddle: 0.0.0
OpenCV: 4.0.0
------------------------------------------------
2021-05-31 15:37:58 [INFO]	
---------------Config Information---------------
batch_size: 4
iters: 20
learning_rate:
  decay:
    end_lr: 0.0
    power: 0.9
    type: poly
  value: 0.01
loss:
  coef:
  - 1
  types:
  - ignore_index: 255
    type: CrossEntropyLoss
model:
  aspp_ratios:
  - 1
  - 12
  - 24
  - 36
  backbone:
    multi_grid:
    - 1
    - 2
    - 4
    output_stride: 8
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
    type: ResNet50_vd
  backbone_indices:
  - 0
  - 3
  num_classes: 19
  type: DeepLabV3P
optimizer:
  type: sgd
  weight_decay: 4.0e-05
train_dataset:
  dataset_root: data/cityscapes
  mode: train
  transforms:
  - max_scale_factor: 2.0
    min_scale_factor: 0.5
    scale_step_size: 0.25
    type: ResizeStepScaling
  - crop_size:
    - 1024
    - 512
    type: RandomPaddingCrop
  - type: RandomHorizontalFlip
  - type: RandomDistort
  - type: Normalize
  type: Cityscapes
val_dataset:
  dataset_root: data/cityscapes
  mode: val
  transforms:
  - type: Normalize
  type: Cityscapes
------------------------------------------------
W0531 15:37:58.285946  4048 device_context.cc:430] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 11.0
W0531 15:37:58.285980  4048 device_context.cc:448] device: 0, cuDNN Version: 8.0.
2021-05-31 15:38:00 [INFO]	Loading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
Connecting to https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
Downloading resnet50_vd_ssld_v2.tar.gz

[                                                  ] 0.00%
[                                                  ] 0.55%
[                                                  ] 1.34%
[=                                                 ] 2.54%
[==                                                ] 4.34%
[===                                               ] 7.04%
[=====                                             ] 11.15%
[========                                          ] 17.37%
[=============                                     ] 27.07%
[====================                              ] 40.74%
[===========================                       ] 54.79%
[==================================                ] 68.43%
[=========================================         ] 82.50%
[================================================  ] 96.56%
[==================================================] 100.00%
Uncompress resnet50_vd_ssld_v2.tar.gz

[                                                  ] 0.00%
[=========================                         ] 50.00%
[==================================================] 100.00%
2021-05-31 15:38:06 [INFO]	There are 275/275 variables loaded into ResNet_vd.
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/cvlibs/param_init.py:89: DeprecationWarning: invalid escape sequence \s
  """
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/models/losses/binary_cross_entropy_loss.py:82: DeprecationWarning: invalid escape sequence \|
  """
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/models/losses/lovasz_loss.py:50: DeprecationWarning: invalid escape sequence \i
  """
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/models/losses/lovasz_loss.py:77: DeprecationWarning: invalid escape sequence \i
  """
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/models/losses/lovasz_loss.py:120: DeprecationWarning: invalid escape sequence \i
  """
/usr/local/lib/python3.7/dist-packages/scipy/linalg/__init__.py:212: DeprecationWarning: The module numpy.dual is deprecated.  Instead of using dual, use the functions directly from numpy or scipy.
  from numpy.dual import register_func
/usr/local/lib/python3.7/dist-packages/scipy/special/orthogonal.py:81: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  from numpy import (exp, inf, pi, sqrt, floor, sin, cos, around, int,
2021-05-31 15:38:12 [INFO]	[TRAIN] epoch: 1, iter: 1/20, loss: 3.2190, lr: 0.010000, batch_cost: 5.1140, reader_cost: 1.43108, ips: 0.7822 samples/sec | ETA 00:01:37
2021-05-31 15:38:12 [INFO]	[TRAIN] epoch: 1, iter: 2/20, loss: 3.3329, lr: 0.009549, batch_cost: 0.6309, reader_cost: 0.00128, ips: 6.3397 samples/sec | ETA 00:00:11
2021-05-31 15:38:13 [INFO]	[TRAIN] epoch: 1, iter: 3/20, loss: 3.0657, lr: 0.009095, batch_cost: 0.6282, reader_cost: 0.00152, ips: 6.3672 samples/sec | ETA 00:00:10
2021-05-31 15:38:13 [INFO]	[TRAIN] epoch: 1, iter: 4/20, loss: 2.6452, lr: 0.008639, batch_cost: 0.6291, reader_cost: 0.00133, ips: 6.3583 samples/sec | ETA 00:00:10
2021-05-31 15:38:14 [INFO]	[TRAIN] epoch: 1, iter: 5/20, loss: 2.1962, lr: 0.008181, batch_cost: 0.6353, reader_cost: 0.00160, ips: 6.2967 samples/sec | ETA 00:00:09
2021-05-31 15:38:15 [INFO]	[TRAIN] epoch: 1, iter: 6/20, loss: 1.8020, lr: 0.007719, batch_cost: 0.6308, reader_cost: 0.00153, ips: 6.3410 samples/sec | ETA 00:00:08
2021-05-31 15:38:15 [INFO]	[TRAIN] epoch: 1, iter: 7/20, loss: 2.0807, lr: 0.007254, batch_cost: 0.6307, reader_cost: 0.00157, ips: 6.3424 samples/sec | ETA 00:00:08
2021-05-31 15:38:16 [INFO]	[TRAIN] epoch: 1, iter: 8/20, loss: 1.1934, lr: 0.006786, batch_cost: 0.6343, reader_cost: 0.00138, ips: 6.3061 samples/sec | ETA 00:00:07
2021-05-31 15:38:17 [INFO]	[TRAIN] epoch: 1, iter: 9/20, loss: 2.4125, lr: 0.006314, batch_cost: 0.6350, reader_cost: 0.00137, ips: 6.2994 samples/sec | ETA 00:00:06
2021-05-31 15:38:17 [INFO]	[TRAIN] epoch: 1, iter: 10/20, loss: 2.0026, lr: 0.005839, batch_cost: 0.6322, reader_cost: 0.00017, ips: 6.3276 samples/sec | ETA 00:00:06
2021-05-31 15:38:18 [INFO]	[TRAIN] epoch: 1, iter: 11/20, loss: 1.5808, lr: 0.005359, batch_cost: 0.6290, reader_cost: 0.00015, ips: 6.3592 samples/sec | ETA 00:00:05
2021-05-31 15:38:18 [INFO]	[TRAIN] epoch: 1, iter: 12/20, loss: 1.7126, lr: 0.004874, batch_cost: 0.6318, reader_cost: 0.00148, ips: 6.3315 samples/sec | ETA 00:00:05
2021-05-31 15:38:19 [INFO]	[TRAIN] epoch: 1, iter: 13/20, loss: 1.9027, lr: 0.004384, batch_cost: 0.6381, reader_cost: 0.00140, ips: 6.2685 samples/sec | ETA 00:00:04
2021-05-31 15:38:20 [INFO]	[TRAIN] epoch: 1, iter: 14/20, loss: 1.7622, lr: 0.003887, batch_cost: 0.6318, reader_cost: 0.00146, ips: 6.3313 samples/sec | ETA 00:00:03
2021-05-31 15:38:20 [INFO]	[TRAIN] epoch: 1, iter: 15/20, loss: 1.6299, lr: 0.003384, batch_cost: 0.6290, reader_cost: 0.00135, ips: 6.3592 samples/sec | ETA 00:00:03
2021-05-31 15:38:21 [INFO]	[TRAIN] epoch: 1, iter: 16/20, loss: 1.4962, lr: 0.002872, batch_cost: 0.6337, reader_cost: 0.00133, ips: 6.3124 samples/sec | ETA 00:00:02
2021-05-31 15:38:22 [INFO]	[TRAIN] epoch: 1, iter: 17/20, loss: 1.9170, lr: 0.002349, batch_cost: 0.6337, reader_cost: 0.00135, ips: 6.3116 samples/sec | ETA 00:00:01
2021-05-31 15:38:22 [INFO]	[TRAIN] epoch: 1, iter: 18/20, loss: 1.6249, lr: 0.001813, batch_cost: 0.6354, reader_cost: 0.00150, ips: 6.2950 samples/sec | ETA 00:00:01
2021-05-31 15:38:23 [INFO]	[TRAIN] epoch: 1, iter: 19/20, loss: 1.6303, lr: 0.001259, batch_cost: 0.6306, reader_cost: 0.00146, ips: 6.3428 samples/sec | ETA 00:00:00
2021-05-31 15:38:24 [INFO]	[TRAIN] epoch: 1, iter: 20/20, loss: 1.7657, lr: 0.000675, batch_cost: 0.6338, reader_cost: 0.00145, ips: 6.3116 samples/sec | ETA 00:00:00
/usr/local/lib/python3.7/dist-packages/paddle/nn/layer/norm.py:641: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/models/losses/cross_entropy_loss.py:60: DeprecationWarning: [93m
Warning:
API "paddle.nn.functional.loss.softmax_with_cross_entropy" is deprecated since 2.0.0, and will be removed in future versions. Please use "paddle.nn.functional.cross_entropy" instead.
reason: Please notice that behavior of "paddle.nn.functional.softmax_with_cross_entropy" and "paddle.nn.functional.cross_entropy" is different. [0m
  logit, label, ignore_index=self.ignore_index, axis=axis)
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:135: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
<class 'paddle.nn.layer.pooling.AvgPool2D'>'s flops has been counted
<class 'paddle.nn.layer.conv.Conv2D'>'s flops has been counted
<class 'paddle.nn.layer.norm.BatchNorm2D'>'s flops has been counted
<class 'paddle.nn.layer.activation.ReLU'>'s flops has been counted
Cannot find suitable count function for <class 'paddle.nn.layer.pooling.MaxPool2D'>. Treat it as zero FLOPs.
Cannot find suitable count function for <class 'paddleseg.models.layers.activation.Activation'>. Treat it as zero FLOPs.
<class 'paddle.nn.layer.pooling.AdaptiveAvgPool2D'>'s flops has been counted
<class 'paddle.nn.layer.common.Dropout'>'s flops has been counted
Total Flops: 645499392     Total Params: 26794243
