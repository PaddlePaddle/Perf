-----------  Configuration Arguments -----------
gpus: 0,1,2,3,4,5,6,7
heter_worker_num: None
heter_workers: 
http_port: None
ips: 127.0.0.1
log_dir: log
nproc_per_node: None
run_mode: None
server_num: None
servers: 
training_script: train.py
training_script_args: ['--config', 'benchmark/deeplabv3p.yml', '--iters', '20', '--log_iters', '1', '--batch_size', '4', '--num_workers', '8', '--data_format', 'NCHW']
worker_num: None
workers: 
------------------------------------------------
launch train in GPU mode!
launch proc_id:4111 idx:0
launch proc_id:4114 idx:1
launch proc_id:4117 idx:2
launch proc_id:4120 idx:3
launch proc_id:4123 idx:4
launch proc_id:4126 idx:5
launch proc_id:4129 idx:6
launch proc_id:4134 idx:7
------------Environment Information-------------
platform: Linux-4.14.0_1-0-0-32-x86_64-with-Ubuntu-18.04-bionic
Python: 3.7.10 (default, Feb 20 2021, 21:17:23) [GCC 7.5.0]
Paddle compiled with cuda: True
NVCC: Build cuda_11.0_bu.TC445_37.28845127_0
cudnn: 8.0
GPUs used: 8
CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
GPU: ['GPU 0: Tesla V100-SXM2-32GB', 'GPU 1: Tesla V100-SXM2-32GB', 'GPU 2: Tesla V100-SXM2-32GB', 'GPU 3: Tesla V100-SXM2-32GB', 'GPU 4: Tesla V100-SXM2-32GB', 'GPU 5: Tesla V100-SXM2-32GB', 'GPU 6: Tesla V100-SXM2-32GB', 'GPU 7: Tesla V100-SXM2-32GB']
GCC: gcc (GCC) 8.2.0
PaddlePaddle: 0.0.0
OpenCV: 4.0.0
------------------------------------------------
2021-05-31 15:37:56 [INFO]	
---------------Config Information---------------
batch_size: 4
iters: 20
learning_rate:
  decay:
    end_lr: 0.0
    power: 0.9
    type: poly
  value: 0.01
loss:
  coef:
  - 1
  types:
  - ignore_index: 255
    type: CrossEntropyLoss
model:
  aspp_ratios:
  - 1
  - 12
  - 24
  - 36
  backbone:
    multi_grid:
    - 1
    - 2
    - 4
    output_stride: 8
    pretrained: https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
    type: ResNet50_vd
  backbone_indices:
  - 0
  - 3
  num_classes: 19
  type: DeepLabV3P
optimizer:
  type: sgd
  weight_decay: 4.0e-05
train_dataset:
  dataset_root: data/cityscapes
  mode: train
  transforms:
  - max_scale_factor: 2.0
    min_scale_factor: 0.5
    scale_step_size: 0.25
    type: ResizeStepScaling
  - crop_size:
    - 1024
    - 512
    type: RandomPaddingCrop
  - type: RandomHorizontalFlip
  - type: RandomDistort
  - type: Normalize
  type: Cityscapes
val_dataset:
  dataset_root: data/cityscapes
  mode: val
  transforms:
  - type: Normalize
  type: Cityscapes
------------------------------------------------
W0531 15:37:56.761261  4111 device_context.cc:430] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 11.0
W0531 15:37:56.761301  4111 device_context.cc:448] device: 0, cuDNN Version: 8.0.
2021-05-31 15:38:00 [INFO]	Loading pretrained model from https://bj.bcebos.com/paddleseg/dygraph/resnet50_vd_ssld_v2.tar.gz
2021-05-31 15:38:06 [INFO]	There are 275/275 variables loaded into ResNet_vd.
I0531 15:38:06.310380  4111 nccl_context.cc:74] init nccl context nranks: 8 local rank: 0 gpu id: 0 ring id: 0
I0531 15:38:07.365227  4111 nccl_context.cc:107] init nccl context nranks: 8 local rank: 0 gpu id: 0 ring id: 10
2021-05-31 15:38:07,974-INFO: [topology.py:152:__init__] HybridParallelInfo: rank_id: 0, dp_degree: 8, mp_degree: 1, pp_degree: 1, dp_group: [0, 1, 2, 3, 4, 5, 6, 7], mp_group: [0], pp_group: [0], check/clip group: [0]
/root/paddlejob/workspace/env_run/PaddleSeg/paddleseg/models/losses/cross_entropy_loss.py:60: DeprecationWarning: [93m
Warning:
API "paddle.nn.functional.loss.softmax_with_cross_entropy" is deprecated since 2.0.0, and will be removed in future versions. Please use "paddle.nn.functional.cross_entropy" instead.
reason: Please notice that behavior of "paddle.nn.functional.softmax_with_cross_entropy" and "paddle.nn.functional.cross_entropy" is different. [0m
  logit, label, ignore_index=self.ignore_index, axis=axis)
2021-05-31 15:38:16 [INFO]	[TRAIN] epoch: 1, iter: 1/20, loss: 3.4813, lr: 0.010000, batch_cost: 8.2600, reader_cost: 3.59467, ips: 0.4843 samples/sec | ETA 00:02:36
2021-05-31 15:38:16 [INFO]	[TRAIN] epoch: 1, iter: 2/20, loss: 3.3993, lr: 0.009549, batch_cost: 0.7079, reader_cost: 0.00012, ips: 5.6501 samples/sec | ETA 00:00:12
2021-05-31 15:38:17 [INFO]	[TRAIN] epoch: 1, iter: 3/20, loss: 3.3391, lr: 0.009095, batch_cost: 0.6926, reader_cost: 0.00013, ips: 5.7750 samples/sec | ETA 00:00:11
2021-05-31 15:38:18 [INFO]	[TRAIN] epoch: 1, iter: 4/20, loss: 2.6310, lr: 0.008639, batch_cost: 0.6948, reader_cost: 0.00015, ips: 5.7575 samples/sec | ETA 00:00:11
2021-05-31 15:38:19 [INFO]	[TRAIN] epoch: 1, iter: 5/20, loss: 2.0874, lr: 0.008181, batch_cost: 0.6977, reader_cost: 0.00363, ips: 5.7333 samples/sec | ETA 00:00:10
2021-05-31 15:38:19 [INFO]	[TRAIN] epoch: 1, iter: 6/20, loss: 2.2114, lr: 0.007719, batch_cost: 0.6939, reader_cost: 0.00012, ips: 5.7647 samples/sec | ETA 00:00:09
2021-05-31 15:38:20 [INFO]	[TRAIN] epoch: 1, iter: 7/20, loss: 1.6661, lr: 0.007254, batch_cost: 0.6985, reader_cost: 0.00017, ips: 5.7269 samples/sec | ETA 00:00:09
2021-05-31 15:38:21 [INFO]	[TRAIN] epoch: 1, iter: 8/20, loss: 1.6490, lr: 0.006786, batch_cost: 0.7037, reader_cost: 0.00013, ips: 5.6843 samples/sec | ETA 00:00:08
2021-05-31 15:38:21 [INFO]	[TRAIN] epoch: 1, iter: 9/20, loss: 1.3492, lr: 0.006314, batch_cost: 0.6987, reader_cost: 0.00016, ips: 5.7246 samples/sec | ETA 00:00:07
2021-05-31 15:38:22 [INFO]	[TRAIN] epoch: 1, iter: 10/20, loss: 1.0710, lr: 0.005839, batch_cost: 0.6950, reader_cost: 0.00014, ips: 5.7552 samples/sec | ETA 00:00:06
2021-05-31 15:38:23 [INFO]	[TRAIN] epoch: 1, iter: 11/20, loss: 1.0519, lr: 0.005359, batch_cost: 0.6954, reader_cost: 0.00015, ips: 5.7519 samples/sec | ETA 00:00:06
2021-05-31 15:38:23 [INFO]	[TRAIN] epoch: 1, iter: 12/20, loss: 0.8380, lr: 0.004874, batch_cost: 0.7019, reader_cost: 0.00344, ips: 5.6986 samples/sec | ETA 00:00:05
2021-05-31 15:38:24 [INFO]	[TRAIN] epoch: 1, iter: 13/20, loss: 1.0028, lr: 0.004384, batch_cost: 0.6938, reader_cost: 0.00216, ips: 5.7651 samples/sec | ETA 00:00:04
2021-05-31 15:38:25 [INFO]	[TRAIN] epoch: 1, iter: 14/20, loss: 0.9988, lr: 0.003887, batch_cost: 0.6947, reader_cost: 0.00012, ips: 5.7581 samples/sec | ETA 00:00:04
2021-05-31 15:38:26 [INFO]	[TRAIN] epoch: 1, iter: 15/20, loss: 0.7866, lr: 0.003384, batch_cost: 0.6942, reader_cost: 0.00305, ips: 5.7619 samples/sec | ETA 00:00:03
2021-05-31 15:38:26 [INFO]	[TRAIN] epoch: 1, iter: 16/20, loss: 0.9386, lr: 0.002872, batch_cost: 0.6914, reader_cost: 0.00015, ips: 5.7852 samples/sec | ETA 00:00:02
2021-05-31 15:38:27 [INFO]	[TRAIN] epoch: 1, iter: 17/20, loss: 0.7824, lr: 0.002349, batch_cost: 0.6953, reader_cost: 0.00416, ips: 5.7533 samples/sec | ETA 00:00:02
INFO 2021-05-31 15:38:34,244 launch.py:268] Local processes completed.
2021-05-31 15:38:28 [INFO]	[TRAIN] epoch: 1, iter: 18/20, loss: 0.6524, lr: 0.001813, batch_cost: 0.6988, reader_cost: 0.00013, ips: 5.7238 samples/sec | ETA 00:00:01
2021-05-31 15:38:28 [INFO]	[TRAIN] epoch: 1, iter: 19/20, loss: 0.6903, lr: 0.001259, batch_cost: 0.6973, reader_cost: 0.00425, ips: 5.7368 samples/sec | ETA 00:00:00
2021-05-31 15:38:29 [INFO]	[TRAIN] epoch: 1, iter: 20/20, loss: 0.5636, lr: 0.000675, batch_cost: 0.6906, reader_cost: 0.00365, ips: 5.7918 samples/sec | ETA 00:00:00
<class 'paddle.nn.layer.pooling.AvgPool2D'>'s flops has been counted
<class 'paddle.nn.layer.conv.Conv2D'>'s flops has been counted
Customize Function has been applied to <class 'paddle.nn.layer.norm.SyncBatchNorm'>
<class 'paddle.nn.layer.activation.ReLU'>'s flops has been counted
Cannot find suitable count function for <class 'paddle.nn.layer.pooling.MaxPool2D'>. Treat it as zero FLOPs.
Cannot find suitable count function for <class 'paddleseg.models.layers.activation.Activation'>. Treat it as zero FLOPs.
<class 'paddle.nn.layer.pooling.AdaptiveAvgPool2D'>'s flops has been counted
<class 'paddle.nn.layer.common.Dropout'>'s flops has been counted
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:135: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Total Flops: 645499392     Total Params: 26794243
