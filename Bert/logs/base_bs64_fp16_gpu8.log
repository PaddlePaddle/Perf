Namespace(adam_epsilon=1e-06, batch_size=64, device='gpu', enable_addto=False, gradient_merge_steps=1, input_dir='./wikicorpus_en_seqlen128', learning_rate=0.0001, logging_steps=10, max_grad_norm=1.0, max_predictions_per_seq=20, max_steps=400, model_name_or_path='bert-base-uncased', model_type='bert', output_dir='./tmp2/', save_steps=20000, scale_loss=32768, seed=42, use_amp=1, use_pure_fp16=False, warmup_steps=10000, weight_decay=0.01)
[32m[2021-12-27 14:57:15,901] [    INFO][0m - Already cached /root/.paddlenlp/models/bert-base-uncased/bert-base-uncased-vocab.txt[0m
server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:32833', '127.0.0.1:37794', '127.0.0.1:37442', '127.0.0.1:52521', '127.0.0.1:53552', '127.0.0.1:39633', '127.0.0.1:46106']
server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:32833', '127.0.0.1:37794', '127.0.0.1:37442', '127.0.0.1:52521', '127.0.0.1:53552', '127.0.0.1:39633', '127.0.0.1:46106']
W1227 14:57:24.284035 34429 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W1227 14:57:24.288491 34429 device_context.cc:465] device: 0, cuDNN Version: 8.1.
W1227 14:57:36.486490 34429 build_strategy.cc:110] Currently, fuse_broadcast_ops only works under Reduce mode.
W1227 14:57:36.618818 34429 fuse_all_reduce_op_pass.cc:76] Find all_reduce operators: 206. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 20.
tobal step: 10, epoch: 0, batch: 9, loss: 11.191424, avg_reader_cost: 0.07494 sec, avg_batch_cost: 0.45257 sec, avg_samples: 64.00000, ips: 141.41574 sequences/sec
tobal step: 20, epoch: 0, batch: 19, loss: 11.153821, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11985 sec, avg_samples: 64.00000, ips: 533.98706 sequences/sec
tobal step: 30, epoch: 0, batch: 29, loss: 11.169550, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.11857 sec, avg_samples: 64.00000, ips: 539.78348 sequences/sec
tobal step: 40, epoch: 0, batch: 39, loss: 11.071603, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11893 sec, avg_samples: 64.00000, ips: 538.11622 sequences/sec
tobal step: 50, epoch: 0, batch: 49, loss: 10.991778, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11855 sec, avg_samples: 64.00000, ips: 539.87662 sequences/sec
tobal step: 60, epoch: 0, batch: 59, loss: 10.867575, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11985 sec, avg_samples: 64.00000, ips: 533.98802 sequences/sec
tobal step: 70, epoch: 0, batch: 69, loss: 10.792622, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11874 sec, avg_samples: 64.00000, ips: 538.98102 sequences/sec
tobal step: 80, epoch: 0, batch: 79, loss: 10.668679, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11755 sec, avg_samples: 64.00000, ips: 544.43044 sequences/sec
tobal step: 90, epoch: 0, batch: 89, loss: 10.576186, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11794 sec, avg_samples: 64.00000, ips: 542.63412 sequences/sec
tobal step: 100, epoch: 0, batch: 99, loss: 10.410854, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.11871 sec, avg_samples: 64.00000, ips: 539.11655 sequences/sec
tobal step: 110, epoch: 0, batch: 109, loss: 10.405623, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11748 sec, avg_samples: 64.00000, ips: 544.77085 sequences/sec
tobal step: 120, epoch: 0, batch: 119, loss: 10.176094, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11725 sec, avg_samples: 64.00000, ips: 545.82695 sequences/sec
tobal step: 130, epoch: 0, batch: 129, loss: 10.174833, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.11772 sec, avg_samples: 64.00000, ips: 543.64098 sequences/sec
tobal step: 140, epoch: 0, batch: 139, loss: 10.126228, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11807 sec, avg_samples: 64.00000, ips: 542.06487 sequences/sec
tobal step: 150, epoch: 0, batch: 149, loss: 10.030186, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11754 sec, avg_samples: 64.00000, ips: 544.48333 sequences/sec
tobal step: 160, epoch: 0, batch: 159, loss: 10.141376, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11786 sec, avg_samples: 64.00000, ips: 543.03688 sequences/sec
tobal step: 170, epoch: 0, batch: 169, loss: 9.988031, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11750 sec, avg_samples: 64.00000, ips: 544.68253 sequences/sec
tobal step: 180, epoch: 0, batch: 179, loss: 9.957123, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11768 sec, avg_samples: 64.00000, ips: 543.82987 sequences/sec
tobal step: 190, epoch: 0, batch: 189, loss: 9.884649, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11769 sec, avg_samples: 64.00000, ips: 543.77952 sequences/sec
tobal step: 200, epoch: 0, batch: 199, loss: 9.782442, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11773 sec, avg_samples: 64.00000, ips: 543.60850 sequences/sec
tobal step: 210, epoch: 0, batch: 209, loss: 9.899711, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11724 sec, avg_samples: 64.00000, ips: 545.88944 sequences/sec
tobal step: 220, epoch: 0, batch: 2, loss: 9.794777, avg_reader_cost: 0.01708 sec, avg_batch_cost: 0.16006 sec, avg_samples: 19.20000, ips: 119.95501 sequences/sec
tobal step: 230, epoch: 0, batch: 12, loss: 9.922103, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11703 sec, avg_samples: 64.00000, ips: 546.86264 sequences/sec
tobal step: 240, epoch: 0, batch: 22, loss: 9.713834, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11683 sec, avg_samples: 64.00000, ips: 547.81214 sequences/sec
tobal step: 250, epoch: 0, batch: 32, loss: 9.750424, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11722 sec, avg_samples: 64.00000, ips: 545.97749 sequences/sec
tobal step: 260, epoch: 0, batch: 42, loss: 9.645266, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11707 sec, avg_samples: 64.00000, ips: 546.68945 sequences/sec
tobal step: 270, epoch: 0, batch: 52, loss: 9.587447, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11675 sec, avg_samples: 64.00000, ips: 548.18501 sequences/sec
tobal step: 280, epoch: 0, batch: 62, loss: 9.556598, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11714 sec, avg_samples: 64.00000, ips: 546.34508 sequences/sec
tobal step: 290, epoch: 0, batch: 72, loss: 9.600490, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11699 sec, avg_samples: 64.00000, ips: 547.07741 sequences/sec
tobal step: 300, epoch: 0, batch: 82, loss: 9.641647, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11737 sec, avg_samples: 64.00000, ips: 545.30160 sequences/sec
tobal step: 310, epoch: 0, batch: 92, loss: 9.579043, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11750 sec, avg_samples: 64.00000, ips: 544.69999 sequences/sec
tobal step: 320, epoch: 0, batch: 102, loss: 9.532844, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11759 sec, avg_samples: 64.00000, ips: 544.28296 sequences/sec
tobal step: 330, epoch: 0, batch: 112, loss: 9.432921, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11679 sec, avg_samples: 64.00000, ips: 547.97418 sequences/sec
tobal step: 340, epoch: 0, batch: 122, loss: 9.620481, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11711 sec, avg_samples: 64.00000, ips: 546.47755 sequences/sec
tobal step: 350, epoch: 0, batch: 132, loss: 9.405901, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11778 sec, avg_samples: 64.00000, ips: 543.38413 sequences/sec
tobal step: 360, epoch: 0, batch: 142, loss: 9.404545, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11769 sec, avg_samples: 64.00000, ips: 543.80255 sequences/sec
tobal step: 370, epoch: 0, batch: 152, loss: 9.244171, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11738 sec, avg_samples: 64.00000, ips: 545.25176 sequences/sec
tobal step: 380, epoch: 0, batch: 162, loss: 9.356332, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.11823 sec, avg_samples: 64.00000, ips: 541.30114 sequences/sec
tobal step: 390, epoch: 0, batch: 172, loss: 9.260743, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.11811 sec, avg_samples: 64.00000, ips: 541.86507 sequences/sec
tobal step: 400, epoch: 0, batch: 182, loss: 9.300541, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.11778 sec, avg_samples: 64.00000, ips: 543.39172 sequences/sec
