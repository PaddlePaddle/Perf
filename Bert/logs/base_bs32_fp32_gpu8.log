Namespace(adam_epsilon=1e-06, batch_size=32, device='gpu', enable_addto=False, gradient_merge_steps=1, input_dir='./wikicorpus_en_seqlen128', learning_rate=0.0001, logging_steps=10, max_grad_norm=1.0, max_predictions_per_seq=20, max_steps=400, model_name_or_path='bert-base-uncased', model_type='bert', output_dir='./tmp2/', save_steps=20000, scale_loss=32768, seed=42, use_amp=0, use_pure_fp16=False, warmup_steps=10000, weight_decay=0.01)
[32m[2021-12-27 14:46:38,280] [    INFO][0m - Already cached /root/.paddlenlp/models/bert-base-uncased/bert-base-uncased-vocab.txt[0m
server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:56519', '127.0.0.1:48746', '127.0.0.1:41268', '127.0.0.1:53972', '127.0.0.1:47130', '127.0.0.1:49404', '127.0.0.1:41118']
server not ready, wait 3 sec to retry...
not ready endpoints:['127.0.0.1:56519', '127.0.0.1:48746', '127.0.0.1:41268', '127.0.0.1:53972', '127.0.0.1:47130', '127.0.0.1:49404', '127.0.0.1:41118']
W1227 14:46:45.817998 33089 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W1227 14:46:45.823014 33089 device_context.cc:465] device: 0, cuDNN Version: 8.1.
W1227 14:46:57.937512 33089 build_strategy.cc:110] Currently, fuse_broadcast_ops only works under Reduce mode.
W1227 14:46:58.031052 33089 fuse_all_reduce_op_pass.cc:76] Find all_reduce operators: 206. To make the speed faster, some all_reduce ops are fused during training, after fusion, the number of all_reduce ops is 19.
tobal step: 10, epoch: 0, batch: 9, loss: 11.212529, avg_reader_cost: 0.07153 sec, avg_batch_cost: 0.50728 sec, avg_samples: 32.00000, ips: 63.08146 sequences/sec
tobal step: 20, epoch: 0, batch: 19, loss: 11.213636, avg_reader_cost: 0.00009 sec, avg_batch_cost: 0.21368 sec, avg_samples: 32.00000, ips: 149.75821 sequences/sec
tobal step: 30, epoch: 0, batch: 29, loss: 11.088994, avg_reader_cost: 0.00016 sec, avg_batch_cost: 0.21451 sec, avg_samples: 32.00000, ips: 149.17879 sequences/sec
tobal step: 40, epoch: 0, batch: 39, loss: 11.043439, avg_reader_cost: 0.00011 sec, avg_batch_cost: 0.21393 sec, avg_samples: 32.00000, ips: 149.58183 sequences/sec
tobal step: 50, epoch: 0, batch: 49, loss: 10.961557, avg_reader_cost: 0.00010 sec, avg_batch_cost: 0.21440 sec, avg_samples: 32.00000, ips: 149.25137 sequences/sec
tobal step: 60, epoch: 0, batch: 59, loss: 10.941221, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21442 sec, avg_samples: 32.00000, ips: 149.23740 sequences/sec
tobal step: 70, epoch: 0, batch: 69, loss: 10.837517, avg_reader_cost: 0.00009 sec, avg_batch_cost: 0.21420 sec, avg_samples: 32.00000, ips: 149.39537 sequences/sec
tobal step: 80, epoch: 0, batch: 79, loss: 10.598081, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21453 sec, avg_samples: 32.00000, ips: 149.16384 sequences/sec
tobal step: 90, epoch: 0, batch: 89, loss: 10.548759, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21498 sec, avg_samples: 32.00000, ips: 148.84831 sequences/sec
tobal step: 100, epoch: 0, batch: 99, loss: 10.458643, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.21521 sec, avg_samples: 32.00000, ips: 148.68989 sequences/sec
tobal step: 110, epoch: 0, batch: 109, loss: 10.432853, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21497 sec, avg_samples: 32.00000, ips: 148.85957 sequences/sec
tobal step: 120, epoch: 0, batch: 119, loss: 10.359174, avg_reader_cost: 0.00011 sec, avg_batch_cost: 0.21597 sec, avg_samples: 32.00000, ips: 148.16942 sequences/sec
tobal step: 130, epoch: 0, batch: 129, loss: 10.290360, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21431 sec, avg_samples: 32.00000, ips: 149.31325 sequences/sec
tobal step: 140, epoch: 0, batch: 139, loss: 10.189514, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.21538 sec, avg_samples: 32.00000, ips: 148.57754 sequences/sec
tobal step: 150, epoch: 0, batch: 149, loss: 10.101098, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21463 sec, avg_samples: 32.00000, ips: 149.09609 sequences/sec
tobal step: 160, epoch: 0, batch: 159, loss: 10.087432, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21518 sec, avg_samples: 32.00000, ips: 148.71019 sequences/sec
tobal step: 170, epoch: 0, batch: 169, loss: 10.167763, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21456 sec, avg_samples: 32.00000, ips: 149.14294 sequences/sec
tobal step: 180, epoch: 0, batch: 179, loss: 9.936742, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21580 sec, avg_samples: 32.00000, ips: 148.28296 sequences/sec
tobal step: 190, epoch: 0, batch: 189, loss: 10.094395, avg_reader_cost: 0.00009 sec, avg_batch_cost: 0.21557 sec, avg_samples: 32.00000, ips: 148.44448 sequences/sec
tobal step: 200, epoch: 0, batch: 199, loss: 9.834146, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21499 sec, avg_samples: 32.00000, ips: 148.84288 sequences/sec
tobal step: 210, epoch: 0, batch: 209, loss: 9.944005, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21553 sec, avg_samples: 32.00000, ips: 148.47128 sequences/sec
tobal step: 220, epoch: 0, batch: 219, loss: 9.958980, avg_reader_cost: 0.00009 sec, avg_batch_cost: 0.21655 sec, avg_samples: 32.00000, ips: 147.77418 sequences/sec
tobal step: 230, epoch: 0, batch: 229, loss: 9.795728, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21577 sec, avg_samples: 32.00000, ips: 148.30455 sequences/sec
tobal step: 240, epoch: 0, batch: 239, loss: 9.772112, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21514 sec, avg_samples: 32.00000, ips: 148.74098 sequences/sec
tobal step: 250, epoch: 0, batch: 249, loss: 9.753963, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21553 sec, avg_samples: 32.00000, ips: 148.47306 sequences/sec
tobal step: 260, epoch: 0, batch: 259, loss: 10.006562, avg_reader_cost: 0.00009 sec, avg_batch_cost: 0.21578 sec, avg_samples: 32.00000, ips: 148.30149 sequences/sec
tobal step: 270, epoch: 0, batch: 269, loss: 9.732470, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21582 sec, avg_samples: 32.00000, ips: 148.27061 sequences/sec
tobal step: 280, epoch: 0, batch: 279, loss: 9.514539, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21537 sec, avg_samples: 32.00000, ips: 148.58099 sequences/sec
tobal step: 290, epoch: 0, batch: 289, loss: 9.739794, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21557 sec, avg_samples: 32.00000, ips: 148.44345 sequences/sec
tobal step: 300, epoch: 0, batch: 299, loss: 9.830888, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21608 sec, avg_samples: 32.00000, ips: 148.09441 sequences/sec
tobal step: 310, epoch: 0, batch: 309, loss: 9.506464, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21624 sec, avg_samples: 32.00000, ips: 147.98602 sequences/sec
tobal step: 320, epoch: 0, batch: 319, loss: 9.364569, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21581 sec, avg_samples: 32.00000, ips: 148.28008 sequences/sec
tobal step: 330, epoch: 0, batch: 329, loss: 9.691610, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21551 sec, avg_samples: 32.00000, ips: 148.48764 sequences/sec
tobal step: 340, epoch: 0, batch: 339, loss: 9.392197, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21591 sec, avg_samples: 32.00000, ips: 148.20877 sequences/sec
tobal step: 350, epoch: 0, batch: 349, loss: 9.313383, avg_reader_cost: 0.00008 sec, avg_batch_cost: 0.21643 sec, avg_samples: 32.00000, ips: 147.85264 sequences/sec
tobal step: 360, epoch: 0, batch: 359, loss: 9.340073, avg_reader_cost: 0.00009 sec, avg_batch_cost: 0.21667 sec, avg_samples: 32.00000, ips: 147.68822 sequences/sec
tobal step: 370, epoch: 0, batch: 369, loss: 9.346942, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21722 sec, avg_samples: 32.00000, ips: 147.31551 sequences/sec
tobal step: 380, epoch: 0, batch: 379, loss: 9.457917, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21569 sec, avg_samples: 32.00000, ips: 148.36218 sequences/sec
tobal step: 390, epoch: 0, batch: 389, loss: 9.310940, avg_reader_cost: 0.00006 sec, avg_batch_cost: 0.21577 sec, avg_samples: 32.00000, ips: 148.30662 sequences/sec
tobal step: 400, epoch: 0, batch: 399, loss: 9.368101, avg_reader_cost: 0.00007 sec, avg_batch_cost: 0.21635 sec, avg_samples: 32.00000, ips: 147.90786 sequences/sec
