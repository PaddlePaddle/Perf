+ batch_size=96
+ num_gpus=1
+ precision=fp16
++ expr 67584 / 96 / 1
+ num_accumulation_steps_phase1=704
+ train_steps=100
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 96 64 8 7.5e-4 5e-4 fp16 true 1 2000 200 100 200 704 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738
Logs written to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768.210526225738.log
Container nvidia build =  13409399
XLA activated
2021-05-26 22:57:39.195938: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0526 22:57:40.796368 140256144648000 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0526 22:57:41.476454 140256144648000 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8e45ae6198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0526 22:57:41.477040 140256144648000 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8e45ae6198>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8e45adf488>) includes params argument, but params are not passed to Estimator.
W0526 22:57:41.477711 140256144648000 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8e45adf488>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0526 22:57:41.478122 140256144648000 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0526 22:57:41.478192 140256144648000 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0526 22:57:41.586054 140256144648000 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I0526 22:57:41.709652 140256144648000 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0526 22:57:41.709786 140256144648000 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0526 22:57:41.709888 140256144648000 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0526 22:57:41.709969 140256144648000 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0526 22:57:41.710043 140256144648000 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0526 22:57:41.710113 140256144648000 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0526 22:57:41.710182 140256144648000 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0526 22:57:41.710249 140256144648000 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0526 22:57:41.710314 140256144648000 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0526 22:57:41.710510 140256144648000 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0526 22:57:41.711634 140256144648000 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0526 22:57:43.520756 140256144648000 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0526 22:57:46.884167 140256144648000 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0526 22:57:47.134094 140256144648000 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I0526 22:57:56.662047 140256144648000 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0526 22:57:56.664306 140256144648000 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0526 22:58:00.896451 140256144648000 monitored_session.py:240] Graph was finalized.
2021-05-26 22:58:00.917431: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2021-05-26 22:58:00.921069: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x664d300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-05-26 22:58:00.921121: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-05-26 22:58:00.927413: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-05-26 22:58:02.871683: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x147c6f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-05-26 22:58:02.871730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871744: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871753: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871769: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871777: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.871793: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla V100-SXM2-16GB, Compute Capability 7.0
2021-05-26 22:58:02.924281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:3f:00.0
2021-05-26 22:58:02.925999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 1 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:40:00.0
2021-05-26 22:58:02.927697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 2 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:41:00.0
2021-05-26 22:58:02.929368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 3 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:42:00.0
2021-05-26 22:58:02.931049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 4 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:62:00.0
2021-05-26 22:58:02.932736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 5 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:63:00.0
2021-05-26 22:58:02.934341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 6 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:64:00.0
2021-05-26 22:58:02.935944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 7 with properties: 
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:65:00.0
2021-05-26 22:58:02.935984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 22:58:02.939958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-05-26 22:58:02.941744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-05-26 22:58:02.942098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-05-26 22:58:02.945744: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-05-26 22:58:02.946573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-05-26 22:58:02.946749: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-05-26 22:58:02.970551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2021-05-26 22:58:02.970585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-05-26 22:58:05.590063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-05-26 22:58:05.590103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 1 2 3 4 5 6 7 
2021-05-26 22:58:05.590116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N Y Y Y Y Y Y Y 
2021-05-26 22:58:05.590120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   Y N Y Y Y Y Y Y 
2021-05-26 22:58:05.590124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   Y Y N Y Y Y Y Y 
2021-05-26 22:58:05.590128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   Y Y Y N Y Y Y Y 
2021-05-26 22:58:05.590132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   Y Y Y Y N Y Y Y 
2021-05-26 22:58:05.590136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   Y Y Y Y Y N Y Y 
2021-05-26 22:58:05.590140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   Y Y Y Y Y Y N Y 
2021-05-26 22:58:05.590144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   Y Y Y Y Y Y Y N 
2021-05-26 22:58:05.602502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14797 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:3f:00.0, compute capability: 7.0)
2021-05-26 22:58:05.604187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 14797 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-16GB, pci bus id: 0000:40:00.0, compute capability: 7.0)
2021-05-26 22:58:05.605789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 14797 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-16GB, pci bus id: 0000:41:00.0, compute capability: 7.0)
2021-05-26 22:58:05.607365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 14797 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-16GB, pci bus id: 0000:42:00.0, compute capability: 7.0)
2021-05-26 22:58:05.608916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 14797 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-16GB, pci bus id: 0000:62:00.0, compute capability: 7.0)
2021-05-26 22:58:05.610469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 14797 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-16GB, pci bus id: 0000:63:00.0, compute capability: 7.0)
2021-05-26 22:58:05.611978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 14797 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-16GB, pci bus id: 0000:64:00.0, compute capability: 7.0)
2021-05-26 22:58:05.613477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 14797 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-16GB, pci bus id: 0000:65:00.0, compute capability: 7.0)
2021-05-26 22:58:08.734773: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:08.747352: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:10.998528: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-05-26 22:58:13.973846: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:13.981381: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I0526 22:58:14.672321 140256144648000 session_manager.py:500] Running local_init_op.
2021-05-26 22:58:15.075831: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:15.076087: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I0526 22:58:15.177107 140256144648000 session_manager.py:502] Done running local_init_op.
2021-05-26 22:58:15.781365: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:15.790752: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:16.875872: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:16.876194: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/phase_1/model.ckpt.
I0526 22:58:26.147984 140256144648000 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/phase_1/model.ckpt.
2021-05-26 22:58:26.903645: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:26.913111: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:32.908324: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:32.908723: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:32.913524: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:32.915686: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:32.919201: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W0526 22:58:33.102428 140256144648000 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2021-05-26 22:58:33.573040: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:33.573325: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-05-26 22:58:48.193106: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:58:48.344311: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 24313
Recognized nodes available for conversion: 15663
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-05-26 22:58:59.619808: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-05-26 22:59:00.231458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-05-26 22:59:34.974667: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.205363, step = 0
I0526 22:59:37.135730 140256144648000 basic_session_run_hooks.py:262] loss = 11.205363, step = 0
2021-05-26 22:59:51.042204: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 22:59:51.184233: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 24313
Recognized nodes available for conversion: 15663
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0526 23:00:35.530431 140256144648000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0526 23:00:35.718967 140256144648000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0526 23:00:35.900197 140256144648000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0526 23:00:36.080625 140256144648000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0526 23:00:36.260920 140256144648000 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
2021-05-26 23:31:54.404678: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-05-26 23:31:54.553729: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 24313
Recognized nodes available for conversion: 15663
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:loss = 11.180525, step = 9 (1985.679 sec)
I0526 23:32:42.814864 140256144648000 basic_session_run_hooks.py:260] loss = 11.180525, step = 9 (1985.679 sec)
INFO:tensorflow:loss = 11.169107, step = 23 (1840.923 sec)
I0527 00:03:23.738085 140256144648000 basic_session_run_hooks.py:260] loss = 11.169107, step = 23 (1840.923 sec)
decayed_learning_rate_at_crossover_point = 7.500000e-04, adjusted_init_lr = 7.500000e-04
Initializing LAMB Optimizer
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:02:48.156241 - Iteration: 1  throughput_train : 265.779 seq/s mlm_loss : 10.4537  nsp_loss : 0.7261  total_loss : 11.1798  avg_loss_step : 11.2028  learning_rate : 0.0  loss_scaler : 4294967296 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:04:54.492526 - Iteration: 1  throughput_train : 535.565 seq/s mlm_loss : 10.4647  nsp_loss : 0.7529  total_loss : 11.2175  avg_loss_step : 11.2039  learning_rate : 0.0  loss_scaler : 2147483648 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:07:00.878172 - Iteration: 1  throughput_train : 535.364 seq/s mlm_loss : 10.4769  nsp_loss : 0.7782  total_loss : 11.2552  avg_loss_step : 11.2044  learning_rate : 0.0  loss_scaler : 1073741824 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:09:07.745137 - Iteration: 1  throughput_train : 533.321 seq/s mlm_loss : 10.4833  nsp_loss : 0.7305  total_loss : 11.2138  avg_loss_step : 11.2037  learning_rate : 0.0  loss_scaler : 536870912 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:11:19.687360 - Iteration: 1  throughput_train : 512.781 seq/s mlm_loss : 10.4541  nsp_loss : 0.6972  total_loss : 11.1513  avg_loss_step : 11.2038  learning_rate : 0.0  loss_scaler : 268435456 
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:13:58.918422 - Iteration: 2  throughput_train : 424.820 seq/s mlm_loss : 10.4490  nsp_loss : 0.7458  total_loss : 11.1948  avg_loss_step : 11.2051  learning_rate : 0.0  loss_scaler : 134217728 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:16:07.842775 - Iteration: 3  throughput_train : 524.800 seq/s mlm_loss : 10.4459  nsp_loss : 0.7184  total_loss : 11.1643  avg_loss_step : 11.2036  learning_rate : 3.75e-07  loss_scaler : 134217728 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:18:17.114934 - Iteration: 4  throughput_train : 523.380 seq/s mlm_loss : 10.4688  nsp_loss : 0.7466  total_loss : 11.2155  avg_loss_step : 11.2026  learning_rate : 7.5e-07  loss_scaler : 134217728 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:20:26.531979 - Iteration: 5  throughput_train : 522.791 seq/s mlm_loss : 10.4677  nsp_loss : 0.7364  total_loss : 11.2041  avg_loss_step : 11.2049  learning_rate : 1.125e-06  loss_scaler : 134217728 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2021-05-26 23:22:35.872969 - Iteration: 6  throughput_train : 523.106 seq/s mlm_loss : 10.4832  nsp_loss : 0.7485  total_loss : 11.2318  avg_loss_step : 11.2027  learning_rate : 1.5e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:24:45.262646 - Iteration: 7  throughput_train : 522.904 seq/s mlm_loss : 10.4624  nsp_loss : 0.7385  total_loss : 11.2009  avg_loss_step : 11.2018  learning_rate : 1.8750001e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:26:54.833255 - Iteration: 8  throughput_train : 522.179 seq/s mlm_loss : 10.4880  nsp_loss : 0.6941  total_loss : 11.1821  avg_loss_step : 11.2012  learning_rate : 2.25e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:29:04.098447 - Iteration: 9  throughput_train : 523.418 seq/s mlm_loss : 10.4558  nsp_loss : 0.7240  total_loss : 11.1797  avg_loss_step : 11.2000  learning_rate : 2.625e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:31:13.640836 - Iteration: 10  throughput_train : 522.287 seq/s mlm_loss : 10.4527  nsp_loss : 0.7405  total_loss : 11.1932  avg_loss_step : 11.1995  learning_rate : 3e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:34:25.307830 - Iteration: 11  throughput_train : 352.880 seq/s mlm_loss : 10.4643  nsp_loss : 0.7349  total_loss : 11.1993  avg_loss_step : 11.1979  learning_rate : 3.3750002e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:36:35.467432 - Iteration: 12  throughput_train : 519.825 seq/s mlm_loss : 10.4714  nsp_loss : 0.7080  total_loss : 11.1794  avg_loss_step : 11.1972  learning_rate : 3.7500001e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:38:45.536457 - Iteration: 13  throughput_train : 520.182 seq/s mlm_loss : 10.4751  nsp_loss : 0.6912  total_loss : 11.1664  avg_loss_step : 11.1961  learning_rate : 4.125e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:40:55.573329 - Iteration: 14  throughput_train : 520.304 seq/s mlm_loss : 10.4550  nsp_loss : 0.7044  total_loss : 11.1594  avg_loss_step : 11.1908  learning_rate : 4.5e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:43:05.352989 - Iteration: 15  throughput_train : 521.337 seq/s mlm_loss : 10.4691  nsp_loss : 0.7204  total_loss : 11.1895  avg_loss_step : 11.1923  learning_rate : 4.8750003e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:45:14.715434 - Iteration: 16  throughput_train : 523.021 seq/s mlm_loss : 10.4714  nsp_loss : 0.7235  total_loss : 11.1949  avg_loss_step : 11.1891  learning_rate : 5.25e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:47:24.453805 - Iteration: 17  throughput_train : 521.518 seq/s mlm_loss : 10.4620  nsp_loss : 0.7000  total_loss : 11.1620  avg_loss_step : 11.1850  learning_rate : 5.625e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:49:33.940158 - Iteration: 18  throughput_train : 522.520 seq/s mlm_loss : 10.4423  nsp_loss : 0.7382  total_loss : 11.1805  avg_loss_step : 11.1829  learning_rate : 6e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:51:43.620799 - Iteration: 19  throughput_train : 521.732 seq/s mlm_loss : 10.4698  nsp_loss : 0.7049  total_loss : 11.1747  avg_loss_step : 11.1804  learning_rate : 6.3750003e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:53:53.105339 - Iteration: 20  throughput_train : 522.528 seq/s mlm_loss : 10.4327  nsp_loss : 0.7180  total_loss : 11.1507  avg_loss_step : 11.1774  learning_rate : 6.7500005e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:56:03.044428 - Iteration: 21  throughput_train : 520.697 seq/s mlm_loss : 10.4550  nsp_loss : 0.7169  total_loss : 11.1720  avg_loss_step : 11.1759  learning_rate : 7.125e-06  loss_scaler : 134217728 
DLL 2021-05-26 23:58:12.375156 - Iteration: 22  throughput_train : 523.146 seq/s mlm_loss : 10.4338  nsp_loss : 0.7220  total_loss : 11.1558  avg_loss_step : 11.1705  learning_rate : 7.5000003e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:00:21.548607 - Iteration: 23  throughput_train : 523.782 seq/s mlm_loss : 10.4428  nsp_loss : 0.7186  total_loss : 11.1614  avg_loss_step : 11.1674  learning_rate : 7.875e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:02:30.671505 - Iteration: 24  throughput_train : 523.978 seq/s mlm_loss : 10.4503  nsp_loss : 0.7060  total_loss : 11.1563  avg_loss_step : 11.1641  learning_rate : 8.25e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:04:40.254290 - Iteration: 25  throughput_train : 522.125 seq/s mlm_loss : 10.4686  nsp_loss : 0.7313  total_loss : 11.1999  avg_loss_step : 11.1623  learning_rate : 8.625e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:06:49.671064 - Iteration: 26  throughput_train : 522.799 seq/s mlm_loss : 10.4469  nsp_loss : 0.6978  total_loss : 11.1447  avg_loss_step : 11.1584  learning_rate : 9e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:08:59.154815 - Iteration: 27  throughput_train : 522.530 seq/s mlm_loss : 10.4415  nsp_loss : 0.7003  total_loss : 11.1418  avg_loss_step : 11.1540  learning_rate : 9.375e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:11:08.492238 - Iteration: 28  throughput_train : 523.118 seq/s mlm_loss : 10.4625  nsp_loss : 0.6892  total_loss : 11.1518  avg_loss_step : 11.1507  learning_rate : 9.750001e-06  loss_scaler : 134217728 
DLL 2021-05-27 00:13:17.822114 - Iteration: 29  throughput_train : 523.148 seq/s mlm_loss : 10.4218  nsp_loss : 0.7173  total_loss : 11.1391  avg_loss_step : 11.1463  learning_rate : 1.0125001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:15:27.234055 - Iteration: 30  throughput_train : 522.813 seq/s mlm_loss : 10.4438  nsp_loss : 0.7039  total_loss : 11.1477  avg_loss_step : 11.1430  learning_rate : 1.05e-05  loss_scaler : 134217728 INFO:tensorflow:loss = 11.091254, step = 37 (1840.605 sec)
I0527 00:34:04.343238 140256144648000 basic_session_run_hooks.py:260] loss = 11.091254, step = 37 (1840.605 sec)
INFO:tensorflow:loss = 11.019852, step = 51 (1838.691 sec)
I0527 01:04:43.034263 140256144648000 basic_session_run_hooks.py:260] loss = 11.019852, step = 51 (1838.691 sec)
INFO:tensorflow:loss = 10.954004, step = 66 (1841.616 sec)
I0527 01:35:24.650587 140256144648000 basic_session_run_hooks.py:260] loss = 10.954004, step = 66 (1841.616 sec)

DLL 2021-05-27 00:17:36.607923 - Iteration: 31  throughput_train : 522.972 seq/s mlm_loss : 10.4551  nsp_loss : 0.7025  total_loss : 11.1576  avg_loss_step : 11.1390  learning_rate : 1.0875e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:19:45.873008 - Iteration: 32  throughput_train : 523.403 seq/s mlm_loss : 10.4364  nsp_loss : 0.6988  total_loss : 11.1352  avg_loss_step : 11.1348  learning_rate : 1.125e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:21:55.367668 - Iteration: 33  throughput_train : 522.474 seq/s mlm_loss : 10.4137  nsp_loss : 0.7017  total_loss : 11.1153  avg_loss_step : 11.1305  learning_rate : 1.1625e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:24:05.842610 - Iteration: 34  throughput_train : 518.557 seq/s mlm_loss : 10.4508  nsp_loss : 0.7068  total_loss : 11.1577  avg_loss_step : 11.1255  learning_rate : 1.2e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:26:15.646757 - Iteration: 35  throughput_train : 521.229 seq/s mlm_loss : 10.4151  nsp_loss : 0.7066  total_loss : 11.1217  avg_loss_step : 11.1218  learning_rate : 1.2375001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:28:25.560006 - Iteration: 36  throughput_train : 520.788 seq/s mlm_loss : 10.4023  nsp_loss : 0.6916  total_loss : 11.0939  avg_loss_step : 11.1176  learning_rate : 1.2750001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:30:35.127728 - Iteration: 37  throughput_train : 522.178 seq/s mlm_loss : 10.4122  nsp_loss : 0.6894  total_loss : 11.1016  avg_loss_step : 11.1125  learning_rate : 1.3125001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:32:44.756660 - Iteration: 38  throughput_train : 521.924 seq/s mlm_loss : 10.4253  nsp_loss : 0.6839  total_loss : 11.1092  avg_loss_step : 11.1085  learning_rate : 1.3500001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:34:54.153579 - Iteration: 39  throughput_train : 522.878 seq/s mlm_loss : 10.4226  nsp_loss : 0.6887  total_loss : 11.1113  avg_loss_step : 11.1036  learning_rate : 1.3875e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:37:03.768523 - Iteration: 40  throughput_train : 522.006 seq/s mlm_loss : 10.4091  nsp_loss : 0.7010  total_loss : 11.1101  avg_loss_step : 11.0985  learning_rate : 1.425e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:39:13.077352 - Iteration: 41  throughput_train : 523.234 seq/s mlm_loss : 10.4307  nsp_loss : 0.6781  total_loss : 11.1088  avg_loss_step : 11.0932  learning_rate : 1.4625e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:41:22.694934 - Iteration: 42  throughput_train : 521.981 seq/s mlm_loss : 10.3846  nsp_loss : 0.6934  total_loss : 11.0780  avg_loss_step : 11.0883  learning_rate : 1.50000005e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:43:32.105033 - Iteration: 43  throughput_train : 522.821 seq/s mlm_loss : 10.3949  nsp_loss : 0.6849  total_loss : 11.0797  avg_loss_step : 11.0832  learning_rate : 1.5375e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:45:41.687350 - Iteration: 44  throughput_train : 522.129 seq/s mlm_loss : 10.3832  nsp_loss : 0.6837  total_loss : 11.0669  avg_loss_step : 11.0780  learning_rate : 1.575e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:47:51.129062 - Iteration: 45  throughput_train : 522.694 seq/s mlm_loss : 10.3757  nsp_loss : 0.7074  total_loss : 11.0830  avg_loss_step : 11.0722  learning_rate : 1.6125001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:50:00.407990 - Iteration: 46  throughput_train : 523.357 seq/s mlm_loss : 10.3904  nsp_loss : 0.6802  total_loss : 11.0705  avg_loss_step : 11.0691  learning_rate : 1.65e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:52:10.022131 - Iteration: 47  throughput_train : 521.995 seq/s mlm_loss : 10.3766  nsp_loss : 0.6999  total_loss : 11.0764  avg_loss_step : 11.0618  learning_rate : 1.6875001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:54:19.426506 - Iteration: 48  throughput_train : 522.846 seq/s mlm_loss : 10.3842  nsp_loss : 0.6812  total_loss : 11.0654  avg_loss_step : 11.0572  learning_rate : 1.725e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:56:28.946291 - Iteration: 49  throughput_train : 522.379 seq/s mlm_loss : 10.3727  nsp_loss : 0.6859  total_loss : 11.0586  avg_loss_step : 11.0529  learning_rate : 1.7625001e-05  loss_scaler : 134217728 
DLL 2021-05-27 00:58:38.304142 - Iteration: 50  throughput_train : 523.034 seq/s mlm_loss : 10.3699  nsp_loss : 0.6986  total_loss : 11.0685  avg_loss_step : 11.0478  learning_rate : 1.8e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:00:47.532384 - Iteration: 51  throughput_train : 523.557 seq/s mlm_loss : 10.3748  nsp_loss : 0.6812  total_loss : 11.0560  avg_loss_step : 11.0413  learning_rate : 1.8375e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:02:56.735235 - Iteration: 52  throughput_train : 523.669 seq/s mlm_loss : 10.3666  nsp_loss : 0.6900  total_loss : 11.0567  avg_loss_step : 11.0359  learning_rate : 1.875e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:05:06.370072 - Iteration: 53  throughput_train : 521.922 seq/s mlm_loss : 10.3298  nsp_loss : 0.6842  total_loss : 11.0140  avg_loss_step : 11.0301  learning_rate : 1.9125e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:07:16.209621 - Iteration: 54  throughput_train : 521.098 seq/s mlm_loss : 10.3224  nsp_loss : 0.6896  total_loss : 11.0120  avg_loss_step : 11.0240  learning_rate : 1.9500001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:09:25.675646 - Iteration: 55  throughput_train : 522.590 seq/s mlm_loss : 10.3577  nsp_loss : 0.6859  total_loss : 11.0436  avg_loss_step : 11.0188  learning_rate : 1.9875e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:11:35.646198 - Iteration: 56  throughput_train : 520.567 seq/s mlm_loss : 10.3271  nsp_loss : 0.6666  total_loss : 10.9937  avg_loss_step : 11.0127  learning_rate : 2.0250001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:13:45.823963 - Iteration: 57  throughput_train : 519.730 seq/s mlm_loss : 10.3248  nsp_loss : 0.6869  total_loss : 11.0117  avg_loss_step : 11.0052  learning_rate : 2.0625e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:15:55.710920 - Iteration: 58  throughput_train : 520.897 seq/s mlm_loss : 10.3231  nsp_loss : 0.7184  total_loss : 11.0414  avg_loss_step : 10.9991  learning_rate : 2.1e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:18:05.710533 - Iteration: 59  throughput_train : 520.453 seq/s mlm_loss : 10.3181  nsp_loss : 0.6734  total_loss : 10.9915  avg_loss_step : 10.9966  learning_rate : 2.1375e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:20:15.226129 - Iteration: 60  throughput_train : 522.395 seq/s mlm_loss : 10.2979  nsp_loss : 0.6695  total_loss : 10.9674  avg_loss_step : 10.9871  learning_rate : 2.175e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:22:24.780077 - Iteration: 61  throughput_train : 522.242 seq/s mlm_loss : 10.3068  nsp_loss : 0.6870  total_loss : 10.9938  avg_loss_step : 10.9819  learning_rate : 2.2125001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:24:34.237322 - Iteration: 62  throughput_train : 522.636 seq/s mlm_loss : 10.2720  nsp_loss : 0.6836  total_loss : 10.9556  avg_loss_step : 10.9751  learning_rate : 2.25e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:26:43.892581 - Iteration: 63  throughput_train : 521.834 seq/s mlm_loss : 10.2975  nsp_loss : 0.7216  total_loss : 11.0191  avg_loss_step : 10.9677  learning_rate : 2.2875001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:28:53.219412 - Iteration: 64  throughput_train : 523.154 seq/s mlm_loss : 10.2674  nsp_loss : 0.6709  total_loss : 10.9383  avg_loss_step : 10.9615  learning_rate : 2.325e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:31:02.637710 - Iteration: 65  throughput_train : 522.797 seq/s mlm_loss : 10.2543  nsp_loss : 0.6647  total_loss : 10.9190  avg_loss_step : 10.9532  learning_rate : 2.3625002e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:33:12.001036 - Iteration: 66  throughput_train : 523.009 seq/s mlm_loss : 10.2685  nsp_loss : 0.6705  total_loss : 10.9389  avg_loss_step : 10.9473  learning_rate : 2.4e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:35:21.513065 - Iteration: 67  throughput_train : 522.414 seq/s mlm_loss : 10.2547  nsp_loss : 0.6765  total_loss : 10.9312  avg_loss_step : 10.9405  learning_rate : 2.4375e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:37:31.182376 - Iteration: 68  throughput_train : 521.792 seq/s mlm_loss : 10.2748  nsp_loss : 0.6842  total_loss : 10.9590  avg_loss_step : 10.9330  learning_rate : 2.4750001e-05  loss_scaler : 134217728 INFO:tensorflow:loss = 10.850141, step = 80 (1842.452 sec)
I0527 02:06:07.102836 140256144648000 basic_session_run_hooks.py:260] loss = 10.850141, step = 80 (1842.452 sec)
INFO:tensorflow:Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/phase_1/model.ckpt.
I0527 02:27:13.811990 140256144648000 basic_session_run_hooks.py:606] Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_210526225738/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 10.760812.
I0527 02:27:18.533545 140256144648000 estimator.py:371] Loss for final step: 10.760812.
INFO:tensorflow:-----------------------------
I0527 02:27:18.534918 140256144648000 run_pretraining.py:644] -----------------------------
INFO:tensorflow:Total Training Time = 12577.06 for Sentences = 6082560
I0527 02:27:18.535000 140256144648000 run_pretraining.py:646] Total Training Time = 12577.06 for Sentences = 6082560
INFO:tensorflow:Total Training Time W/O Overhead = 11065.35 for Sentences = 5406720
I0527 02:27:18.535074 140256144648000 run_pretraining.py:648] Total Training Time W/O Overhead = 11065.35 for Sentences = 5406720
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 483.62
I0527 02:27:18.535131 140256144648000 run_pretraining.py:649] Throughput Average (sentences/sec) with overhead = 483.62
INFO:tensorflow:Throughput Average (sentences/sec) = 488.62
I0527 02:27:18.535197 140256144648000 run_pretraining.py:650] Throughput Average (sentences/sec) = 488.62
INFO:tensorflow:-----------------------------
I0527 02:27:18.535367 140256144648000 run_pretraining.py:652] -----------------------------

DLL 2021-05-27 01:39:40.549549 - Iteration: 69  throughput_train : 522.998 seq/s mlm_loss : 10.2291  nsp_loss : 0.6683  total_loss : 10.8974  avg_loss_step : 10.9273  learning_rate : 2.5125e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:41:50.041618 - Iteration: 70  throughput_train : 522.495 seq/s mlm_loss : 10.2351  nsp_loss : 0.7106  total_loss : 10.9456  avg_loss_step : 10.9191  learning_rate : 2.5500001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:43:59.357653 - Iteration: 71  throughput_train : 523.201 seq/s mlm_loss : 10.2071  nsp_loss : 0.6720  total_loss : 10.8791  avg_loss_step : 10.9114  learning_rate : 2.5875e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:46:09.127672 - Iteration: 72  throughput_train : 521.381 seq/s mlm_loss : 10.1917  nsp_loss : 0.6992  total_loss : 10.8910  avg_loss_step : 10.9075  learning_rate : 2.6250002e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:48:18.578366 - Iteration: 73  throughput_train : 522.655 seq/s mlm_loss : 10.2073  nsp_loss : 0.6868  total_loss : 10.8941  avg_loss_step : 10.8973  learning_rate : 2.6625e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:50:28.026011 - Iteration: 74  throughput_train : 522.662 seq/s mlm_loss : 10.2125  nsp_loss : 0.6732  total_loss : 10.8857  avg_loss_step : 10.8901  learning_rate : 2.7000002e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:52:37.700543 - Iteration: 75  throughput_train : 521.750 seq/s mlm_loss : 10.1825  nsp_loss : 0.6829  total_loss : 10.8654  avg_loss_step : 10.8833  learning_rate : 2.7375001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:54:47.023358 - Iteration: 76  throughput_train : 523.167 seq/s mlm_loss : 10.1900  nsp_loss : 0.6719  total_loss : 10.8619  avg_loss_step : 10.8740  learning_rate : 2.775e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:56:56.588126 - Iteration: 77  throughput_train : 522.197 seq/s mlm_loss : 10.1622  nsp_loss : 0.7071  total_loss : 10.8693  avg_loss_step : 10.8662  learning_rate : 2.8125001e-05  loss_scaler : 134217728 
DLL 2021-05-27 01:59:06.516756 - Iteration: 78  throughput_train : 520.728 seq/s mlm_loss : 10.1772  nsp_loss : 0.6859  total_loss : 10.8631  avg_loss_step : 10.8568  learning_rate : 2.85e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:01:16.245155 - Iteration: 79  throughput_train : 521.537 seq/s mlm_loss : 10.1820  nsp_loss : 0.6688  total_loss : 10.8508  avg_loss_step : 10.8506  learning_rate : 2.8875002e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:03:26.296140 - Iteration: 80  throughput_train : 520.241 seq/s mlm_loss : 10.1476  nsp_loss : 0.6441  total_loss : 10.7917  avg_loss_step : 10.8408  learning_rate : 2.925e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:05:37.001152 - Iteration: 81  throughput_train : 517.646 seq/s mlm_loss : 10.1492  nsp_loss : 0.6658  total_loss : 10.8150  avg_loss_step : 10.8350  learning_rate : 2.9625002e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:07:47.548403 - Iteration: 82  throughput_train : 518.268 seq/s mlm_loss : 10.1435  nsp_loss : 0.6685  total_loss : 10.8120  avg_loss_step : 10.8256  learning_rate : 3.0000001e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:09:57.278706 - Iteration: 83  throughput_train : 521.525 seq/s mlm_loss : 10.1068  nsp_loss : 0.6938  total_loss : 10.8006  avg_loss_step : 10.8159  learning_rate : 3.0375e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:12:07.094119 - Iteration: 84  throughput_train : 521.188 seq/s mlm_loss : 10.1253  nsp_loss : 0.6902  total_loss : 10.8155  avg_loss_step : 10.8081  learning_rate : 3.075e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:14:16.355543 - Iteration: 85  throughput_train : 523.418 seq/s mlm_loss : 10.1216  nsp_loss : 0.7052  total_loss : 10.8268  avg_loss_step : 10.8019  learning_rate : 3.1125e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:16:26.081758 - Iteration: 86  throughput_train : 521.541 seq/s mlm_loss : 10.1170  nsp_loss : 0.6803  total_loss : 10.7973  avg_loss_step : 10.7910  learning_rate : 3.15e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:18:35.346068 - Iteration: 87  throughput_train : 523.403 seq/s mlm_loss : 10.0943  nsp_loss : 0.6875  total_loss : 10.7817  avg_loss_step : 10.7810  learning_rate : 3.1875003e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:20:45.053006 - Iteration: 88  throughput_train : 521.620 seq/s mlm_loss : 10.1097  nsp_loss : 0.6820  total_loss : 10.7917  avg_loss_step : 10.7744  learning_rate : 3.2250002e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:22:54.364542 - Iteration: 89  throughput_train : 523.223 seq/s mlm_loss : 10.0606  nsp_loss : 0.6971  total_loss : 10.7577  avg_loss_step : 10.7668  learning_rate : 3.2625e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:25:03.798608 - Iteration: 90  throughput_train : 522.727 seq/s mlm_loss : 10.1163  nsp_loss : 0.6917  total_loss : 10.8080  avg_loss_step : 10.7573  learning_rate : 3.3e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:27:13.810054 - Iteration: 91  throughput_train : 522.237 seq/s mlm_loss : 10.0790  nsp_loss : 0.6818  total_loss : 10.7608  avg_loss_step : 10.7465  learning_rate : 3.3375e-05  loss_scaler : 134217728 
DLL 2021-05-27 02:27:18.535253 -  throughput_train : 488.617 seq/s
