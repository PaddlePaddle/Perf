+ batch_size=96
+ num_gpus=1
+ precision=fp32
++ expr 67584 / 96 / 1
+ num_accumulation_steps_phase1=704
+ train_steps=200
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 96 64 8 7.5e-4 5e-4 fp32 true 1 2000 200 200 200 704 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_230731030909
Logs written to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_230731030909/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768.230731030909.log
Container nvidia build =  13409399
XLA activated
2023-07-31 03:09:09.314975: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0731 03:09:10.730360 140150236432192 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_230731030909/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f74dd122400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0731 03:09:11.311642 140150236432192 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_230731030909/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f74dd122400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f74dd08a048>) includes params argument, but params are not passed to Estimator.
W0731 03:09:11.312227 140150236432192 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f74dd08a048>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0731 03:09:11.312594 140150236432192 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0731 03:09:11.312657 140150236432192 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0731 03:09:11.403264 140150236432192 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I0731 03:09:11.505126 140150236432192 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0731 03:09:11.505258 140150236432192 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0731 03:09:11.505348 140150236432192 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0731 03:09:11.505418 140150236432192 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0731 03:09:11.505484 140150236432192 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0731 03:09:11.505548 140150236432192 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0731 03:09:11.505610 140150236432192 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0731 03:09:11.505671 140150236432192 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0731 03:09:11.505732 140150236432192 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0731 03:09:11.505916 140150236432192 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0731 03:09:11.506879 140150236432192 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0731 03:09:12.928457 140150236432192 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0731 03:09:15.742743 140150236432192 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I0731 03:09:22.846503 140150236432192 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0731 03:09:22.847584 140150236432192 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0731 03:09:26.675019 140150236432192 monitored_session.py:240] Graph was finalized.
2023-07-31 03:09:26.685875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2023-07-31 03:09:26.690061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b87d90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2023-07-31 03:09:26.690083: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2023-07-31 03:09:26.692741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2023-07-31 03:09:27.713166: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11978c40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2023-07-31 03:09:27.713204: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713212: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713217: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713229: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713235: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713240: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.713246: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0
2023-07-31 03:09:27.724279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:41:00.0
2023-07-31 03:09:27.724761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 1 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:42:00.0
2023-07-31 03:09:27.725225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 2 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:43:00.0
2023-07-31 03:09:27.725669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 3 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:44:00.0
2023-07-31 03:09:27.726117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 4 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:61:00.0
2023-07-31 03:09:27.726568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 5 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:62:00.0
2023-07-31 03:09:27.727018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 6 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:63:00.0
2023-07-31 03:09:27.727471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 7 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:64:00.0
2023-07-31 03:09:27.727509: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2023-07-31 03:09:27.730492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2023-07-31 03:09:27.731809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2023-07-31 03:09:27.732129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2023-07-31 03:09:27.734731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2023-07-31 03:09:27.735308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2023-07-31 03:09:27.735496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2023-07-31 03:09:27.742222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7
2023-07-31 03:09:27.742269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2023-07-31 03:09:29.985216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2023-07-31 03:09:29.985261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 1 2 3 4 5 6 7 
2023-07-31 03:09:29.985276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N Y Y Y N N N Y 
2023-07-31 03:09:29.985282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   Y N Y Y N N Y N 
2023-07-31 03:09:29.985289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   Y Y N Y N Y N N 
2023-07-31 03:09:29.985295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   Y Y Y N Y N N N 
2023-07-31 03:09:29.985302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N N N Y N Y Y Y 
2023-07-31 03:09:29.985309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N N Y N Y N Y Y 
2023-07-31 03:09:29.985316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N Y N N Y Y N Y 
2023-07-31 03:09:29.985327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   Y N N N Y Y Y N 
2023-07-31 03:09:29.989763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30156 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:41:00.0, compute capability: 7.0)
2023-07-31 03:09:29.990630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30156 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:42:00.0, compute capability: 7.0)
2023-07-31 03:09:29.991405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30156 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:43:00.0, compute capability: 7.0)
2023-07-31 03:09:29.992102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30156 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:44:00.0, compute capability: 7.0)
2023-07-31 03:09:29.992786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 30156 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0)
2023-07-31 03:09:29.993478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 30156 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)
2023-07-31 03:09:29.994161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 30156 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:63:00.0, compute capability: 7.0)
2023-07-31 03:09:29.994858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 30156 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:64:00.0, compute capability: 7.0)
2023-07-31 03:09:34.992948: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I0731 03:09:39.293946 140150236432192 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0731 03:09:39.729590 140150236432192 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_230731030909/phase_1/model.ckpt.
I0731 03:09:49.091651 140150236432192 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_230731030909/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W0731 03:09:55.200503 140150236432192 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2023-07-31 03:10:16.254408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2023-07-31 03:10:16.787740: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2023-07-31 03:10:45.853839: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.19014, step = 0
I0731 03:10:51.352142 140150236432192 basic_session_run_hooks.py:262] loss = 11.19014, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0731 03:11:38.212299 140150236432192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0731 03:11:38.829472 140150236432192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0731 03:11:39.434633 140150236432192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0731 03:11:40.042755 140150236432192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0731 03:11:40.644782 140150236432192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:loss = 11.170619, step = 14 (6280.270 sec)
I0731 04:55:31.622253 140150236432192 basic_session_run_hooks.py:260] loss = 11.170619, step = 14 (6280.270 sec)
INFO:tensorflow:loss = 11.108782, step = 28 (6166.651 sec)
I0731 06:38:18.272851 140150236432192 basic_session_run_hooks.py:260] loss = 11.108782, step = 28 (6166.651 sec)
decayed_learning_rate_at_crossover_point = 7.500000e-04, adjusted_init_lr = 7.500000e-04
Initializing LAMB Optimizer
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2023-07-31 03:19:13.633573 - Iteration: 2  throughput_train : 121.161 sequences/s mlm_loss : 10.4683  nsp_loss : 0.7005  total_loss : 11.1688  avg_loss_step : 11.1687  learning_rate : 0.0 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2023-07-31 03:26:26.682805 - Iteration: 3  throughput_train : 156.094 sequences/s mlm_loss : 10.4936  nsp_loss : 0.6847  total_loss : 11.1783  avg_loss_step : 11.1699  learning_rate : 3.75e-07 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2023-07-31 03:33:40.612924 - Iteration: 4  throughput_train : 155.776 sequences/s mlm_loss : 10.4560  nsp_loss : 0.6978  total_loss : 11.1538  avg_loss_step : 11.1676  learning_rate : 7.5e-07 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2023-07-31 03:40:54.779424 - Iteration: 5  throughput_train : 155.692 sequences/s mlm_loss : 10.4638  nsp_loss : 0.6953  total_loss : 11.1591  avg_loss_step : 11.1677  learning_rate : 1.125e-06 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2023-07-31 03:48:08.903503 - Iteration: 6  throughput_train : 155.707 sequences/s mlm_loss : 10.4836  nsp_loss : 0.6928  total_loss : 11.1764  avg_loss_step : 11.1678  learning_rate : 1.5e-06 
DLL 2023-07-31 03:55:23.062949 - Iteration: 7  throughput_train : 155.694 sequences/s mlm_loss : 10.4586  nsp_loss : 0.6943  total_loss : 11.1529  avg_loss_step : 11.1675  learning_rate : 1.8750001e-06 
DLL 2023-07-31 04:02:37.143217 - Iteration: 8  throughput_train : 155.722 sequences/s mlm_loss : 10.4569  nsp_loss : 0.6911  total_loss : 11.1480  avg_loss_step : 11.1681  learning_rate : 2.25e-06 
DLL 2023-07-31 04:09:51.349300 - Iteration: 9  throughput_train : 155.677 sequences/s mlm_loss : 10.4600  nsp_loss : 0.6949  total_loss : 11.1549  avg_loss_step : 11.1673  learning_rate : 2.625e-06 
DLL 2023-07-31 04:17:05.543157 - Iteration: 10  throughput_train : 155.682 sequences/s mlm_loss : 10.4501  nsp_loss : 0.6926  total_loss : 11.1427  avg_loss_step : 11.1658  learning_rate : 3e-06 
DLL 2023-07-31 04:24:19.709813 - Iteration: 11  throughput_train : 155.691 sequences/s mlm_loss : 10.4727  nsp_loss : 0.6995  total_loss : 11.1723  avg_loss_step : 11.1639  learning_rate : 3.3750002e-06 
DLL 2023-07-31 04:31:33.895891 - Iteration: 12  throughput_train : 155.685 sequences/s mlm_loss : 10.4757  nsp_loss : 0.6995  total_loss : 11.1752  avg_loss_step : 11.1629  learning_rate : 3.7500001e-06 
DLL 2023-07-31 04:38:48.087343 - Iteration: 13  throughput_train : 155.682 sequences/s mlm_loss : 10.4689  nsp_loss : 0.6968  total_loss : 11.1658  avg_loss_step : 11.1613  learning_rate : 4.125e-06 
DLL 2023-07-31 04:46:02.248130 - Iteration: 14  throughput_train : 155.694 sequences/s mlm_loss : 10.4582  nsp_loss : 0.6910  total_loss : 11.1492  avg_loss_step : 11.1609  learning_rate : 4.5e-06 
DLL 2023-07-31 04:53:16.355735 - Iteration: 15  throughput_train : 155.712 sequences/s mlm_loss : 10.4723  nsp_loss : 0.6932  total_loss : 11.1655  avg_loss_step : 11.1591  learning_rate : 4.8750003e-06 
DLL 2023-07-31 05:01:15.398402 - Iteration: 16  throughput_train : 141.105 sequences/s mlm_loss : 10.4786  nsp_loss : 0.6965  total_loss : 11.1751  avg_loss_step : 11.1579  learning_rate : 5.25e-06 
DLL 2023-07-31 05:08:29.642873 - Iteration: 17  throughput_train : 155.663 sequences/s mlm_loss : 10.4687  nsp_loss : 0.7014  total_loss : 11.1702  avg_loss_step : 11.1552  learning_rate : 5.625e-06 
DLL 2023-07-31 05:15:43.898688 - Iteration: 18  throughput_train : 155.660 sequences/s mlm_loss : 10.4670  nsp_loss : 0.7000  total_loss : 11.1670  avg_loss_step : 11.1541  learning_rate : 6e-06 
DLL 2023-07-31 05:22:58.048242 - Iteration: 19  throughput_train : 155.697 sequences/s mlm_loss : 10.4743  nsp_loss : 0.6926  total_loss : 11.1669  avg_loss_step : 11.1511  learning_rate : 6.3750003e-06 
DLL 2023-07-31 05:30:12.254932 - Iteration: 20  throughput_train : 155.677 sequences/s mlm_loss : 10.4420  nsp_loss : 0.7043  total_loss : 11.1463  avg_loss_step : 11.1488  learning_rate : 6.7500005e-06 
DLL 2023-07-31 05:37:26.558728 - Iteration: 21  throughput_train : 155.642 sequences/s mlm_loss : 10.4741  nsp_loss : 0.6822  total_loss : 11.1563  avg_loss_step : 11.1479  learning_rate : 7.125e-06 
DLL 2023-07-31 05:44:40.784260 - Iteration: 22  throughput_train : 155.670 sequences/s mlm_loss : 10.4426  nsp_loss : 0.6778  total_loss : 11.1204  avg_loss_step : 11.1448  learning_rate : 7.5000003e-06 
DLL 2023-07-31 05:51:54.964828 - Iteration: 23  throughput_train : 155.687 sequences/s mlm_loss : 10.4241  nsp_loss : 0.6889  total_loss : 11.1130  avg_loss_step : 11.1417  learning_rate : 7.875e-06 
DLL 2023-07-31 05:59:09.108160 - Iteration: 24  throughput_train : 155.700 sequences/s mlm_loss : 10.4562  nsp_loss : 0.6901  total_loss : 11.1463  avg_loss_step : 11.1387  learning_rate : 8.25e-06 
DLL 2023-07-31 06:06:23.321343 - Iteration: 25  throughput_train : 155.675 sequences/s mlm_loss : 10.4531  nsp_loss : 0.6991  total_loss : 11.1522  avg_loss_step : 11.1361  learning_rate : 8.625e-06 
DLL 2023-07-31 06:13:37.373333 - Iteration: 26  throughput_train : 155.732 sequences/s mlm_loss : 10.4522  nsp_loss : 0.6905  total_loss : 11.1427  avg_loss_step : 11.1321  learning_rate : 9e-06 
DLL 2023-07-31 06:20:51.490739 - Iteration: 27  throughput_train : 155.710 sequences/s mlm_loss : 10.4212  nsp_loss : 0.6780  total_loss : 11.0992  avg_loss_step : 11.1312  learning_rate : 9.375e-06 
DLL 2023-07-31 06:28:05.738161 - Iteration: 28  throughput_train : 155.664 sequences/s mlm_loss : 10.4369  nsp_loss : 0.6740  total_loss : 11.1109  avg_loss_step : 11.1270  learning_rate : 9.750001e-06 
DLL 2023-07-31 06:35:20.074158 - Iteration: 29  throughput_train : 155.632 sequences/s mlm_loss : 10.4535  nsp_loss : 0.6877  total_loss : 11.1412  avg_loss_step : 11.1248  learning_rate : 1.0125001e-05 
DLL 2023-07-31 06:42:34.221972 - Iteration: 30  throughput_train : 155.698 sequences/s mlm_loss : 10.4224  nsp_loss : 0.6854  total_loss : 11.1079  avg_loss_step : 11.1208  learning_rate : 1.05e-05 
DLL 2023-07-31 06:49:48.443083 - Iteration: 31  throughput_train : 155.672 sequences/s mlm_loss : 10.4224  nsp_loss : 0.6709  total_loss : 11.0933  avg_loss_step : 11.1173  learning_rate : 1.0875e-05 
DLL 2023-07-31 06:57:02.776185 - Iteration: 32  throughput_train : 155.633 sequences/s mlm_loss : 10.4312  nsp_loss : 0.6776  total_loss : 11.1088  avg_loss_step : 11.1136  learning_rate : 1.125e-05 
DLL 2023-07-31 07:04:17.061448 - Iteration: 33  throughput_train : 155.651 sequences/s mlm_loss : 10.4114  nsp_loss : 0.6995  total_loss : 11.1109  avg_loss_step : 11.1106  learning_rate : 1.1625e-05 
DLL 2023-07-31 07:11:31.210685 - Iteration: 34  throughput_train : 155.698 sequences/s mlm_loss : 10.4122  nsp_loss : 0.6850  total_loss : 11.0971  avg_loss_step : 11.1073  learning_rate : 1.2e-05 
DLL 2023-07-31 07:18:45.316315 - Iteration: 35  throughput_train : 155.713 sequences/s mlm_loss : 10.4272  nsp_loss : 0.6966  total_loss : 11.1238  avg_loss_step : 11.1036  learning_rate : 1.2375001e-05 
DLL 2023-07-31 07:25:59.507353 - Iteration: 36  throughput_train : 155.683 sequences/s mlm_loss : 10.3929  nsp_loss : 0.6992  total_loss : 11.0921  avg_loss_step : 11.1017  learning_rate : 1.2750001e-05 
DLL 2023-07-31 07:33:13.605808 - Iteration: 37  throughput_train : 155.716 sequences/s mlm_loss : 10.4198  nsp_loss : 0.6632  total_loss : 11.0830  avg_loss_step : 11.0960  learning_rate : 1.3125001e-05 
DLL 2023-07-31 07:40:27.734542 - Iteration: 38  throughput_train : 155.705 sequences/s mlm_loss : 10.4125  nsp_loss : 0.6969  total_loss : 11.1094  avg_loss_step : 11.0926  learning_rate : 1.3500001e-05 
DLL 2023-07-31 07:47:42.005680 - Iteration: 39  throughput_train : 155.654 sequences/s mlm_loss : 10.3976  nsp_loss : 0.6838  total_loss : 11.0814  avg_loss_step : 11.0880  learning_rate : 1.3875e-05 
DLL 2023-07-31 07:54:56.256560 - Iteration: 40  throughput_train : 155.661 sequences/s mlm_loss : 10.3783  nsp_loss : 0.6806  total_loss : 11.0589  avg_loss_step : 11.0839  learning_rate : 1.425e-05 INFO:tensorflow:loss = 11.079266, step = 42 (6167.723 sec)
I0731 08:21:05.995985 140150236432192 basic_session_run_hooks.py:260] loss = 11.079266, step = 42 (6167.723 sec)
INFO:tensorflow:loss = 11.032311, step = 56 (6167.604 sec)
I0731 10:03:53.600063 140150236432192 basic_session_run_hooks.py:260] loss = 11.032311, step = 56 (6167.604 sec)
INFO:tensorflow:loss = 10.913841, step = 71 (6167.423 sec)
I0731 11:46:41.023340 140150236432192 basic_session_run_hooks.py:260] loss = 10.913841, step = 71 (6167.423 sec)

DLL 2023-07-31 08:02:10.505563 - Iteration: 41  throughput_train : 155.662 sequences/s mlm_loss : 10.3891  nsp_loss : 0.6971  total_loss : 11.0862  avg_loss_step : 11.0805  learning_rate : 1.4625e-05 
DLL 2023-07-31 08:09:24.736143 - Iteration: 42  throughput_train : 155.668 sequences/s mlm_loss : 10.3898  nsp_loss : 0.6674  total_loss : 11.0572  avg_loss_step : 11.0773  learning_rate : 1.50000005e-05 
DLL 2023-07-31 08:16:38.916192 - Iteration: 43  throughput_train : 155.687 sequences/s mlm_loss : 10.3822  nsp_loss : 0.6989  total_loss : 11.0811  avg_loss_step : 11.0700  learning_rate : 1.5375e-05 
DLL 2023-07-31 08:23:53.212524 - Iteration: 44  throughput_train : 155.645 sequences/s mlm_loss : 10.3917  nsp_loss : 0.6853  total_loss : 11.0771  avg_loss_step : 11.0651  learning_rate : 1.575e-05 
DLL 2023-07-31 08:31:07.449255 - Iteration: 45  throughput_train : 155.666 sequences/s mlm_loss : 10.3531  nsp_loss : 0.6862  total_loss : 11.0393  avg_loss_step : 11.0610  learning_rate : 1.6125001e-05 
DLL 2023-07-31 08:38:21.684434 - Iteration: 46  throughput_train : 155.667 sequences/s mlm_loss : 10.3765  nsp_loss : 0.7045  total_loss : 11.0810  avg_loss_step : 11.0553  learning_rate : 1.65e-05 
DLL 2023-07-31 08:45:35.964314 - Iteration: 47  throughput_train : 155.651 sequences/s mlm_loss : 10.3838  nsp_loss : 0.6901  total_loss : 11.0739  avg_loss_step : 11.0517  learning_rate : 1.6875001e-05 
DLL 2023-07-31 08:52:50.131826 - Iteration: 48  throughput_train : 155.691 sequences/s mlm_loss : 10.3621  nsp_loss : 0.6738  total_loss : 11.0359  avg_loss_step : 11.0471  learning_rate : 1.725e-05 
DLL 2023-07-31 09:00:04.351437 - Iteration: 49  throughput_train : 155.672 sequences/s mlm_loss : 10.3596  nsp_loss : 0.6972  total_loss : 11.0568  avg_loss_step : 11.0420  learning_rate : 1.7625001e-05 
DLL 2023-07-31 09:07:18.434035 - Iteration: 50  throughput_train : 155.722 sequences/s mlm_loss : 10.3476  nsp_loss : 0.6760  total_loss : 11.0236  avg_loss_step : 11.0352  learning_rate : 1.8e-05 
DLL 2023-07-31 09:14:32.690346 - Iteration: 51  throughput_train : 155.659 sequences/s mlm_loss : 10.3447  nsp_loss : 0.6699  total_loss : 11.0146  avg_loss_step : 11.0298  learning_rate : 1.8375e-05 
DLL 2023-07-31 09:21:46.833184 - Iteration: 52  throughput_train : 155.700 sequences/s mlm_loss : 10.3451  nsp_loss : 0.6894  total_loss : 11.0345  avg_loss_step : 11.0250  learning_rate : 1.875e-05 
DLL 2023-07-31 09:29:01.010193 - Iteration: 53  throughput_train : 155.688 sequences/s mlm_loss : 10.3348  nsp_loss : 0.6783  total_loss : 11.0131  avg_loss_step : 11.0189  learning_rate : 1.9125e-05 
DLL 2023-07-31 09:36:15.155401 - Iteration: 54  throughput_train : 155.699 sequences/s mlm_loss : 10.3276  nsp_loss : 0.6647  total_loss : 10.9923  avg_loss_step : 11.0145  learning_rate : 1.9500001e-05 
DLL 2023-07-31 09:43:29.333226 - Iteration: 55  throughput_train : 155.687 sequences/s mlm_loss : 10.3083  nsp_loss : 0.6686  total_loss : 10.9768  avg_loss_step : 11.0080  learning_rate : 1.9875e-05 
DLL 2023-07-31 09:50:43.507010 - Iteration: 56  throughput_train : 155.689 sequences/s mlm_loss : 10.3377  nsp_loss : 0.6852  total_loss : 11.0229  avg_loss_step : 11.0012  learning_rate : 2.0250001e-05 
DLL 2023-07-31 09:57:57.715430 - Iteration: 57  throughput_train : 155.677 sequences/s mlm_loss : 10.3147  nsp_loss : 0.6726  total_loss : 10.9873  avg_loss_step : 10.9964  learning_rate : 2.0625e-05 
DLL 2023-07-31 10:05:11.917718 - Iteration: 58  throughput_train : 155.679 sequences/s mlm_loss : 10.3243  nsp_loss : 0.6713  total_loss : 10.9956  avg_loss_step : 10.9892  learning_rate : 2.1e-05 
DLL 2023-07-31 10:12:26.162922 - Iteration: 59  throughput_train : 155.663 sequences/s mlm_loss : 10.2910  nsp_loss : 0.6697  total_loss : 10.9607  avg_loss_step : 10.9835  learning_rate : 2.1375e-05 
DLL 2023-07-31 10:19:40.402487 - Iteration: 60  throughput_train : 155.666 sequences/s mlm_loss : 10.3067  nsp_loss : 0.6711  total_loss : 10.9777  avg_loss_step : 10.9771  learning_rate : 2.175e-05 
DLL 2023-07-31 10:26:54.678874 - Iteration: 61  throughput_train : 155.652 sequences/s mlm_loss : 10.2892  nsp_loss : 0.7069  total_loss : 10.9961  avg_loss_step : 10.9711  learning_rate : 2.2125001e-05 
DLL 2023-07-31 10:34:08.827945 - Iteration: 62  throughput_train : 155.698 sequences/s mlm_loss : 10.2971  nsp_loss : 0.6462  total_loss : 10.9432  avg_loss_step : 10.9652  learning_rate : 2.25e-05 
DLL 2023-07-31 10:41:23.008190 - Iteration: 63  throughput_train : 155.687 sequences/s mlm_loss : 10.2632  nsp_loss : 0.6528  total_loss : 10.9160  avg_loss_step : 10.9575  learning_rate : 2.2875001e-05 
DLL 2023-07-31 10:48:37.157910 - Iteration: 64  throughput_train : 155.698 sequences/s mlm_loss : 10.2724  nsp_loss : 0.6857  total_loss : 10.9580  avg_loss_step : 10.9515  learning_rate : 2.325e-05 
DLL 2023-07-31 10:55:51.401754 - Iteration: 65  throughput_train : 155.664 sequences/s mlm_loss : 10.2510  nsp_loss : 0.7012  total_loss : 10.9522  avg_loss_step : 10.9439  learning_rate : 2.3625002e-05 
DLL 2023-07-31 11:03:05.608370 - Iteration: 66  throughput_train : 155.677 sequences/s mlm_loss : 10.2634  nsp_loss : 0.6939  total_loss : 10.9573  avg_loss_step : 10.9387  learning_rate : 2.4e-05 
DLL 2023-07-31 11:10:19.786297 - Iteration: 67  throughput_train : 155.687 sequences/s mlm_loss : 10.2577  nsp_loss : 0.6702  total_loss : 10.9280  avg_loss_step : 10.9313  learning_rate : 2.4375e-05 
DLL 2023-07-31 11:17:33.992325 - Iteration: 68  throughput_train : 155.677 sequences/s mlm_loss : 10.2426  nsp_loss : 0.6717  total_loss : 10.9143  avg_loss_step : 10.9236  learning_rate : 2.4750001e-05 
DLL 2023-07-31 11:24:48.197598 - Iteration: 69  throughput_train : 155.678 sequences/s mlm_loss : 10.2248  nsp_loss : 0.6758  total_loss : 10.9006  avg_loss_step : 10.9164  learning_rate : 2.5125e-05 
DLL 2023-07-31 11:32:02.214574 - Iteration: 70  throughput_train : 155.745 sequences/s mlm_loss : 10.2344  nsp_loss : 0.6931  total_loss : 10.9275  avg_loss_step : 10.9092  learning_rate : 2.5500001e-05 
DLL 2023-07-31 11:39:16.364281 - Iteration: 71  throughput_train : 155.697 sequences/s mlm_loss : 10.2328  nsp_loss : 0.6980  total_loss : 10.9308  avg_loss_step : 10.9013  learning_rate : 2.5875e-05 
DLL 2023-07-31 11:46:30.553666 - Iteration: 72  throughput_train : 155.684 sequences/s mlm_loss : 10.1929  nsp_loss : 0.6904  total_loss : 10.8833  avg_loss_step : 10.8936  learning_rate : 2.6250002e-05 
DLL 2023-07-31 11:53:44.660744 - Iteration: 73  throughput_train : 155.713 sequences/s mlm_loss : 10.1943  nsp_loss : 0.7109  total_loss : 10.9051  avg_loss_step : 10.8872  learning_rate : 2.6625e-05 
DLL 2023-07-31 12:00:58.801784 - Iteration: 74  throughput_train : 155.701 sequences/s mlm_loss : 10.2239  nsp_loss : 0.6671  total_loss : 10.8910  avg_loss_step : 10.8794  learning_rate : 2.7000002e-05 
DLL 2023-07-31 12:08:12.976297 - Iteration: 75  throughput_train : 155.689 sequences/s mlm_loss : 10.1980  nsp_loss : 0.6721  total_loss : 10.8701  avg_loss_step : 10.8729  learning_rate : 2.7375001e-05 
DLL 2023-07-31 12:15:27.100146 - Iteration: 76  throughput_train : 155.707 sequences/s mlm_loss : 10.1608  nsp_loss : 0.6789  total_loss : 10.8397  avg_loss_step : 10.8631  learning_rate : 2.775e-05 
DLL 2023-07-31 12:22:41.155570 - Iteration: 77  throughput_train : 155.731 sequences/s mlm_loss : 10.1903  nsp_loss : 0.6923  total_loss : 10.8825  avg_loss_step : 10.8564  learning_rate : 2.8125001e-05 
DLL 2023-07-31 12:29:55.284415 - Iteration: 78  throughput_train : 155.705 sequences/s mlm_loss : 10.1534  nsp_loss : 0.6602  total_loss : 10.8136  avg_loss_step : 10.8474  learning_rate : 2.85e-05 
DLL 2023-07-31 12:37:09.386123 - Iteration: 79  throughput_train : 155.714 sequences/s mlm_loss : 10.1671  nsp_loss : 0.6777  total_loss : 10.8449  avg_loss_step : 10.8385  learning_rate : 2.8875002e-05 
DLL 2023-07-31 12:44:23.575935 - Iteration: 80  throughput_train : 155.683 sequences/s mlm_loss : 10.1334  nsp_loss : 0.6717  total_loss : 10.8050  avg_loss_step : 10.8329  learning_rate : 2.925e-05 
