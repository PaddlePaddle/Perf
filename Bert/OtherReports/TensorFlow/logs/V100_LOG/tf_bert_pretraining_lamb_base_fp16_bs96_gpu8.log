+ batch_size=96
+ num_gpus=8
+ precision=fp16
++ expr 67584 / 96 / 8
+ num_accumulation_steps_phase1=88
+ train_steps=200
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 96 64 8 7.5e-4 5e-4 fp16 true 8 2000 200 200 200 88 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230
Logs written to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144.221126183230.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2022-11-26 18:32:31.363056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.363062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.363061: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.363051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.363065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.363062: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.363056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:31.368355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

--------------------------------------------------------------------------
[[13866,1],6]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.960456 140058966173504 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.960556 139671492257600 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.960975 139767222495040 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.961030 139713062618944 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.961017 139659189745472 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.961108 139662769284928 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.961340 140580483716928 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 18:32:32.961612 140620976506688 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:***** Configuaration *****
I1126 18:32:33.780637 139662769284928 run_pretraining.py:581] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1126 18:32:33.780908 139662769284928 run_pretraining.py:583]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1126 18:32:33.781010 139662769284928 run_pretraining.py:583]   alsologtostderr: False
INFO:tensorflow:  log_dir: 
I1126 18:32:33.781110 139662769284928 run_pretraining.py:583]   log_dir: 
INFO:tensorflow:  v: 0
I1126 18:32:33.781187 139662769284928 run_pretraining.py:583]   v: 0
INFO:tensorflow:  verbosity: 0
I1126 18:32:33.781266 139662769284928 run_pretraining.py:583]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1126 18:32:33.781345 139662769284928 run_pretraining.py:583]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1126 18:32:33.781458 139662769284928 run_pretraining.py:583]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1126 18:32:33.781548 139662769284928 run_pretraining.py:583]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1126 18:32:33.781618 139662769284928 run_pretraining.py:583]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1126 18:32:33.781696 139662769284928 run_pretraining.py:583]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1126 18:32:33.781778 139662769284928 run_pretraining.py:583]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1126 18:32:33.781846 139662769284928 run_pretraining.py:583]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1126 18:32:33.781926 139662769284928 run_pretraining.py:583]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1126 18:32:33.781998 139662769284928 run_pretraining.py:583]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1126 18:32:33.782079 139662769284928 run_pretraining.py:583]   test_random_seed: 301
INFO:tensorflow:  test_srcdir: 
I1126 18:32:33.782161 139662769284928 run_pretraining.py:583]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1126 18:32:33.782227 139662769284928 run_pretraining.py:583]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed: 
I1126 18:32:33.782304 139662769284928 run_pretraining.py:583]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I1126 18:32:33.782376 139662769284928 run_pretraining.py:583]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1126 18:32:33.782463 139662769284928 run_pretraining.py:583]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1126 18:32:33.782525 139662769284928 run_pretraining.py:583]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1126 18:32:33.782589 139662769284928 run_pretraining.py:583]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1
I1126 18:32:33.782649 139662769284928 run_pretraining.py:583]   output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1126 18:32:33.782709 139662769284928 run_pretraining.py:583]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1126 18:32:33.782768 139662769284928 run_pretraining.py:583]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1126 18:32:33.782831 139662769284928 run_pretraining.py:583]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1126 18:32:33.782891 139662769284928 run_pretraining.py:583]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1126 18:32:33.782953 139662769284928 run_pretraining.py:583]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1126 18:32:33.783025 139662769284928 run_pretraining.py:583]   do_train: True
INFO:tensorflow:  do_eval: True
I1126 18:32:33.783095 139662769284928 run_pretraining.py:583]   do_eval: True
INFO:tensorflow:  train_batch_size: 96
I1126 18:32:33.783157 139662769284928 run_pretraining.py:583]   train_batch_size: 96
INFO:tensorflow:  eval_batch_size: 8
I1126 18:32:33.783219 139662769284928 run_pretraining.py:583]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1126 18:32:33.783287 139662769284928 run_pretraining.py:583]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 180
I1126 18:32:33.783348 139662769284928 run_pretraining.py:583]   num_train_steps: 180
INFO:tensorflow:  num_warmup_steps: 2000
I1126 18:32:33.783421 139662769284928 run_pretraining.py:583]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1126 18:32:33.783483 139662769284928 run_pretraining.py:583]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1126 18:32:33.783551 139662769284928 run_pretraining.py:583]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1126 18:32:33.783617 139662769284928 run_pretraining.py:583]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1126 18:32:33.783680 139662769284928 run_pretraining.py:583]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 88
I1126 18:32:33.783738 139662769284928 run_pretraining.py:583]   num_accumulation_steps: 88
INFO:tensorflow:  allreduce_post_accumulation: True
I1126 18:32:33.783796 139662769284928 run_pretraining.py:583]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1126 18:32:33.783856 139662769284928 run_pretraining.py:583]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1126 18:32:33.783916 139662769284928 run_pretraining.py:583]   horovod: True
INFO:tensorflow:  report_loss: True
I1126 18:32:33.783976 139662769284928 run_pretraining.py:583]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1126 18:32:33.784034 139662769284928 run_pretraining.py:583]   manual_fp16: False
INFO:tensorflow:  amp: True
I1126 18:32:33.784101 139662769284928 run_pretraining.py:583]   amp: True
INFO:tensorflow:  use_xla: True
I1126 18:32:33.784172 139662769284928 run_pretraining.py:583]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1126 18:32:33.784237 139662769284928 run_pretraining.py:583]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1126 18:32:33.784307 139662769284928 run_pretraining.py:583]   ?: False
INFO:tensorflow:  help: False
I1126 18:32:33.784368 139662769284928 run_pretraining.py:583]   help: False
INFO:tensorflow:  helpshort: False
I1126 18:32:33.784446 139662769284928 run_pretraining.py:583]   helpshort: False
INFO:tensorflow:  helpfull: False
I1126 18:32:33.784511 139662769284928 run_pretraining.py:583]   helpfull: False
INFO:tensorflow:  helpxml: False
I1126 18:32:33.784572 139662769284928 run_pretraining.py:583]   helpxml: False
INFO:tensorflow:**************************
I1126 18:32:33.784626 139662769284928 run_pretraining.py:584] **************************
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.784799 139662769284928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f041d999780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.785424 139662769284928 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f041d999780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f041d9a3268>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.786191 139662769284928 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f041d9a3268>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.786757 139662769284928 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.786839 139662769284928 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.805761 140620976506688 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe337336780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.806370 140620976506688 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe337336780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe337340158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.806984 140620976506688 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe337340158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.807327 140620976506688 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.807388 140620976506688 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.811753 140058966173504 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f605ccae780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.812332 140058966173504 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f605ccae780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f605ccb8158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.812948 140058966173504 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f605ccb8158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.813286 140058966173504 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.813347 140058966173504 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.814778 139713062618944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0fd354e780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.815621 139713062618944 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0fd354e780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0fd3558158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.816531 139713062618944 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0fd3558158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.817169 139713062618944 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.817292 139713062618944 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.829924 140580483716928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd9c9a47780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.830591 140580483716928 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd9c9a47780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd9c9a51158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.831245 140580483716928 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd9c9a51158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.831637 140580483716928 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.831700 140580483716928 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.834445 139671492257600 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f06258777f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.835044 139671492257600 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f06258777f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0625881158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.835701 139671492257600 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0625881158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.836048 139671492257600 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.836120 139671492257600 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.837491 139767222495040 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c6f7ee710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.838131 139767222495040 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1c6f7ee710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1c6f7f9158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.838791 139767222495040 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1c6f7f9158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.839156 139767222495040 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.839219 139767222495040 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1126 18:32:33.855266 139659189745472 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:591: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03483eb710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 18:32:33.856149 139659189745472 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f03483eb710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f03483f6158>) includes params argument, but params are not passed to Estimator.
W1126 18:32:33.857084 139659189745472 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f03483f6158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 18:32:33.857712 139659189745472 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 18:32:33.857823 139659189745472 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.903876 140620976506688 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.907532 140058966173504 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.928963 140580483716928 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.932996 139671492257600 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.935755 139662769284928 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.954747 139713062618944 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.971303 139767222495040 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 18:32:33.983175 139659189745472 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.007450 140620976506688 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.007603 140620976506688 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.007697 140620976506688 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.007769 140620976506688 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.007835 140620976506688 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.007896 140620976506688 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.007955 140620976506688 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.008013 140620976506688 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.008070 140620976506688 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.008249 140620976506688 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.009230 140620976506688 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.009969 140058966173504 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.010132 140058966173504 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.010222 140058966173504 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.010294 140058966173504 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.010356 140058966173504 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.010429 140058966173504 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.010488 140058966173504 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.010545 140058966173504 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.010603 140058966173504 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.010775 140058966173504 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.011740 140058966173504 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.032413 140580483716928 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.032593 140580483716928 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.032685 140580483716928 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.032758 140580483716928 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.032823 140580483716928 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.032886 140580483716928 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.032944 140580483716928 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.033003 140580483716928 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.033060 140580483716928 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.033259 140580483716928 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.034264 140580483716928 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.035577 139671492257600 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.035746 139671492257600 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.035838 139671492257600 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.035908 139671492257600 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.035973 139671492257600 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.036036 139671492257600 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.036102 139671492257600 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.036161 139671492257600 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.036220 139671492257600 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.036412 139671492257600 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.037420 139671492257600 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.049198 139662769284928 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.049366 139662769284928 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.049502 139662769284928 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.049584 139662769284928 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.049650 139662769284928 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.049712 139662769284928 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.049771 139662769284928 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.049830 139662769284928 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.049887 139662769284928 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.050061 139662769284928 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.051136 139662769284928 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.055826 139713062618944 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.055981 139713062618944 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.056071 139713062618944 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.056150 139713062618944 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.056214 139713062618944 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.056276 139713062618944 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.056335 139713062618944 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.056406 139713062618944 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.056466 139713062618944 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.056637 139713062618944 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.057611 139713062618944 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.073863 139767222495040 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.074042 139767222495040 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.074145 139767222495040 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.074216 139767222495040 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.074280 139767222495040 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.074343 139767222495040 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.074417 139767222495040 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.074478 139767222495040 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.074536 139767222495040 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.074719 139767222495040 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.075714 139767222495040 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 18:32:34.085988 139659189745472 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 18:32:34.086178 139659189745472 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 18:32:34.086264 139659189745472 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 18:32:34.086334 139659189745472 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 18:32:34.086411 139659189745472 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 18:32:34.086477 139659189745472 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 18:32:34.086534 139659189745472 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 18:32:34.086591 139659189745472 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 18:32:34.086647 139659189745472 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 18:32:34.086834 139659189745472 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 18:32:34.087834 139659189745472 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.540805 140058966173504 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.547125 140620976506688 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.585690 139713062618944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.604807 139671492257600 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.627202 140580483716928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.630561 139767222495040 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.631019 139659189745472 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 18:32:35.715228 139662769284928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.429716 140058966173504 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.436387 140620976506688 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.467969 139713062618944 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.521898 139659189745472 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.538989 139671492257600 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.546411 139767222495040 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.617177 140580483716928 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.645586 140058966173504 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.653607 140620976506688 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.684382 139713062618944 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.738052 139659189745472 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.758497 139671492257600 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.765289 139767222495040 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:38.841877 140580483716928 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1126 18:32:38.860723 139662769284928 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 18:32:39.099207 139662769284928 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.416103 140058966173504 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.430222 139713062618944 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.518884 139659189745472 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.555459 139767222495040 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.635478 139671492257600 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.681945 140620976506688 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:47.884877 140580483716928 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 18:32:48.695118 139662769284928 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1126 18:32:48.696994 139662769284928 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1126 18:32:52.740816 139713062618944 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:52.752901: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:52.758276: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5441340 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:52.758313: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:52.761367: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 18:32:52.776863 139659189745472 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:52.788948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:52.793062: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6959380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:52.793092: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:52.795902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 18:32:52.800498 140058966173504 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:52.813719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:52.818834: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaa98df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:52.818872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:52.821979: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 18:32:52.901525 139767222495040 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:52.913170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:52.918715: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x694c4b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:52.918739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:52.921659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 18:32:53.017091 139671492257600 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:53.028751: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:53.034946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f54950 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.034971: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:53.037982: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 18:32:53.297338 140580483716928 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:53.308875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:53.314116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13256770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.314141: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:53.317104: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 18:32:53.464817 140620976506688 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:53.476520: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:53.481197: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9e5a570 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.481223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:53.484145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-11-26 18:32:53.759755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.766343: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x695d0b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.766380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:53.772449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.781019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0a:00.0
2022-11-26 18:32:53.781093: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.782922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.784777: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:53.786443: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:53.786841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:53.788377: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x68ea120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.788422: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:53.789496: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:53.789459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.790118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:53.790366: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:53.790533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.796850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
2022-11-26 18:32:53.796906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.797921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.800078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:53.801549: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:53.801953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:53.803934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.804764: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:53.805475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:53.805700: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:53.805836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.806353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2022-11-26 18:32:53.806421: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.814431: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x186bead0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.814464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:53.815158: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.816200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.818481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.824891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2022-11-26 18:32:53.824945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.827008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
2022-11-26 18:32:53.827067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.830516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e58840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.830540: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:53.831057: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:53.832704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.832732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:53.833166: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:53.836477: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:53.837260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:53.837571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:53.837720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.841252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:09:00.0
2022-11-26 18:32:53.841301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.844237: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:53.845485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:53.845846: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:53.847142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.848608: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:53.849248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:53.849473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:53.849586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.856817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.858828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2022-11-26 18:32:53.858902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.860468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.870368: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1447b660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:53.870403: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:53.873268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2022-11-26 18:32:53.873322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.873588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.886168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:06:00.0
2022-11-26 18:32:53.886207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:53.889299: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:53.890718: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:53.891051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:53.893905: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:53.894593: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:53.894802: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:53.894914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.905028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:53.915228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2022-11-26 18:32:53.915306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:54.198726: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.201842: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17eac440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:54.201872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:54.202818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.205056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
2022-11-26 18:32:54.205121: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:54.208378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:54.209761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:54.210098: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:54.212696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:54.213266: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:54.213480: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:54.213644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.215742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.218008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2022-11-26 18:32:54.218065: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:54.229901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.235413: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x521a480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:54.235458: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:54.237837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.243030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:05:00.0
2022-11-26 18:32:54.243099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:54.247889: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:54.249852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:54.250335: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:54.254494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:54.255562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:54.255862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:54.256080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.258565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.261522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2022-11-26 18:32:54.261574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:54.398070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.398117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2022-11-26 18:32:54.398128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2022-11-26 18:32:54.398548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.400675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.403460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2022-11-26 18:32:54.412800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.412843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2022-11-26 18:32:54.412852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2022-11-26 18:32:54.413139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.415814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.418125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2022-11-26 18:32:54.431047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.431092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2022-11-26 18:32:54.431102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2022-11-26 18:32:54.431468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.433597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.435839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
2022-11-26 18:32:54.437141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.437184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2022-11-26 18:32:54.437194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2022-11-26 18:32:54.437570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.439690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.441986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
2022-11-26 18:32:54.453888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.453926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2022-11-26 18:32:54.453936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2022-11-26 18:32:54.454218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.456317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.458849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
2022-11-26 18:32:54.622381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.622440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2022-11-26 18:32:54.622450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2022-11-26 18:32:54.622763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.624888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.627160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1126 18:32:54.650305 139662769284928 monitored_session.py:240] Graph was finalized.
2022-11-26 18:32:54.663467: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 18:32:54.668056: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x152ceac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:54.668092: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 18:32:54.672038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-11-26 18:32:54.687456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:54.687493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2022-11-26 18:32:54.687503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2022-11-26 18:32:54.687850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.690695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.693507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2022-11-26 18:32:54.854507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.857050: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1595afc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 18:32:54.857095: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 18:32:54.857957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.859972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2022-11-26 18:32:54.860018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:54.863630: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:32:54.865619: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 18:32:54.866036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 18:32:54.869820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 18:32:54.870542: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 18:32:54.870769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:32:54.870918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.873015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:54.874973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2022-11-26 18:32:54.875014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 18:32:55.324382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 18:32:55.324447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-11-26 18:32:55.324459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-11-26 18:32:55.324766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:55.326882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 18:32:55.328891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
2022-11-26 18:32:57.838263: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:57.849662: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:57.863530: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:57.879262: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:57.916622: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:57.928585: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:57.938146: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:57.955879: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:57.977410: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:57.992668: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:58.002809: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:58.018243: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:58.260346: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:58.277753: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:32:59.351637: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:32:59.373764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:00.228271: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:00.401509: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:00.629190: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:00.640319: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:00.652058: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:00.723367: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:00.925342: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:02.045046: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 18:33:04.171717: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.178629: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:04.192891: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.199428: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:04.304165: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.311117: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:04.384925: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.392007: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:04.498376: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.505325: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:04.555676: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.562088: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:04.680263: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:04.687268: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1126 18:33:04.874136 139713062618944 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 18:33:04.875497 140620976506688 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 18:33:05.020195 139767222495040 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 18:33:05.097225 139659189745472 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 18:33:05.200582 139671492257600 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 18:33:05.259887 140058966173504 session_manager.py:500] Running local_init_op.
2022-11-26 18:33:05.365694: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.365930: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1126 18:33:05.379899 140580483716928 session_manager.py:500] Running local_init_op.
2022-11-26 18:33:05.380224: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.380464: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 18:33:05.491686 139713062618944 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 18:33:05.512181 140620976506688 session_manager.py:502] Done running local_init_op.
2022-11-26 18:33:05.525304: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.525580: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:05.608844: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.609079: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 18:33:05.656613 139767222495040 session_manager.py:502] Done running local_init_op.
2022-11-26 18:33:05.714065: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.714296: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 18:33:05.740222 139659189745472 session_manager.py:502] Done running local_init_op.
2022-11-26 18:33:05.755805: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.756052: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 18:33:05.844824 139671492257600 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 18:33:05.879933 140058966173504 session_manager.py:502] Done running local_init_op.
2022-11-26 18:33:05.881536: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.888410: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:05.888638: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:05.888727: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 18:33:06.016528 140580483716928 session_manager.py:502] Done running local_init_op.
2022-11-26 18:33:06.141218: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.147795: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:06.193944: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.201784: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:06.318375: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.325509: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:06.406327: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.413443: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:06.509504: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.516454: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:06.521913: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.528672: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1126 18:33:06.605290 139662769284928 session_manager.py:500] Running local_init_op.
2022-11-26 18:33:06.687412: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:06.694854: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.198838: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.199068: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.291197: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.291579: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.296151: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.298045: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.300645: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 18:33:07.352536 139662769284928 session_manager.py:502] Done running local_init_op.
2022-11-26 18:33:07.499989: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.500347: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.504873: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.506702: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.509226: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.524131: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.524488: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.529202: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.531140: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.533733: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.660035: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.660368: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.664871: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.666678: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.669158: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.708684: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.709021: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.713578: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.715375: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.717907: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.724734: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.725071: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.730003: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.731977: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.734683: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.894502: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:07.894835: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.899383: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.901267: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:07.903852: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.114647: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.121807: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.188208: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.202831: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.417855: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.432016: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.487695: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.505308: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.648358: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.663779: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.665318: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.677266: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.703006: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.719920: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:08.876066: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:08.893384: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:09.446726: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:09.447022: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt.
I1126 18:33:18.733996 139662769284928 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt.
2022-11-26 18:33:19.768182: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:19.776955: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:26.433409: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:26.433785: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:26.438857: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:26.440925: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:26.443752: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:27.514175: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:27.528046: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1126 18:33:30.382202 139662769284928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2022-11-26 18:33:31.083549: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:31.083835: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:33:46.846486: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:46.942182: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:46.975896: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:47.029508: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:47.136212: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:47.160683: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:47.255436: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:47.260591: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:47.438511: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:47.448253: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:47.460102: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:47.623000: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:48.167441: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:48.339132: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:49.918962: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:33:50.106267: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:33:58.008634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:33:58.021633: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:33:58.067200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:33:58.370578: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:33:58.475523: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:33:58.615374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:33:58.642890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:33:58.678569: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:33:58.717276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:33:59.029010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:33:59.104272: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:33:59.376836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:33:59.714255: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:34:00.363923: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:34:02.224493: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 18:34:02.872445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 18:34:31.852697: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:32.427111: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:32.663790: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:32.851610: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:32.910043: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:33.234950: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:34.411637: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 18:34:36.549824: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.146881, step = 0
I1126 18:34:38.548530 139662769284928 basic_session_run_hooks.py:262] loss = 11.146881, step = 0
2022-11-26 18:34:39.194029: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.194354: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:34:39.212591: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.212908: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:34:39.213220: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.213567: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:34:39.219131: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.219432: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:34:39.239335: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.239661: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:34:39.241076: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.241383: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 18:34:39.261912: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:39.262205: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:loss = 11.155923, step = 0
I1126 18:34:39.353070 140620976506688 basic_session_run_hooks.py:262] loss = 11.155923, step = 0
INFO:tensorflow:loss = 11.177107, step = 0
I1126 18:34:39.368777 139713062618944 basic_session_run_hooks.py:262] loss = 11.177107, step = 0
INFO:tensorflow:loss = 11.167147, step = 0
I1126 18:34:39.375414 140580483716928 basic_session_run_hooks.py:262] loss = 11.167147, step = 0
INFO:tensorflow:loss = 11.140417, step = 0
I1126 18:34:39.379964 139671492257600 basic_session_run_hooks.py:262] loss = 11.140417, step = 0
INFO:tensorflow:loss = 11.130865, step = 0
I1126 18:34:39.399215 140058966173504 basic_session_run_hooks.py:262] loss = 11.130865, step = 0
INFO:tensorflow:loss = 11.164957, step = 0
I1126 18:34:39.405016 139767222495040 basic_session_run_hooks.py:262] loss = 11.164957, step = 0
INFO:tensorflow:loss = 11.163591, step = 0
I1126 18:34:39.429331 139659189745472 basic_session_run_hooks.py:262] loss = 11.163591, step = 0
2022-11-26 18:34:58.537452: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:58.728424: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:34:59.103720: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:59.300192: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:34:59.387042: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:34:59.576757: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:35:00.894017: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:35:01.081645: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:35:01.607520: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:35:01.776128: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:35:01.790041: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:35:01.839503: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:35:01.959184: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:35:02.021891: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-11-26 18:35:02.415384: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 18:35:02.585479: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:45.195799 139659189745472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:45.195844 139767222495040 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:45.196639 139713062618944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:45.199791 139671492257600 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:45.200493 140580483716928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.195952 140058966173504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.196614 140620976506688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.513457 139662769284928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691602 140620976506688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691630 139767222495040 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691658 139671492257600 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691655 139659189745472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691655 139713062618944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691690 140580483716928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.691947 140058966173504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.698049 139662769284928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.873661 140620976506688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.873664 139713062618944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.873732 139659189745472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.873735 139671492257600 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.873725 140580483716928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.873807 140058966173504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.874406 139767222495040 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:46.876466 139662769284928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.051307 139659189745472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.051655 140580483716928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.051761 140058966173504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.052577 139671492257600 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.052980 140620976506688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.053485 139767222495040 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.053782 139713062618944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.054299 139662769284928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.227926 139659189745472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.228002 140580483716928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.228978 139767222495040 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.229781 139662769284928 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.230521 140058966173504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.232461 139671492257600 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.232882 139713062618944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 18:35:47.234828 140620976506688 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:36:10.157121 - Iteration: 1  throughput_train : 425.529 sequences/s mlm_loss : 10.4555  nsp_loss : 0.6903  total_loss : 11.1458  avg_loss_step : 11.1521  learning_rate : 0.0  loss_scaler : 4294967296 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:36:26.314377 - Iteration: 1  throughput_train : 4186.856 sequences/s mlm_loss : 10.4407  nsp_loss : 0.6927  total_loss : 11.1334  avg_loss_step : 11.1467  learning_rate : 0.0  loss_scaler : 2147483648 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:36:42.247020 - Iteration: 1  throughput_train : 4245.971 sequences/s mlm_loss : 10.4513  nsp_loss : 0.6932  total_loss : 11.1444  avg_loss_step : 11.1460  learning_rate : 0.0  loss_scaler : 1073741824 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:36:58.323234 - Iteration: 1  throughput_train : 4207.964 sequences/s mlm_loss : 10.4624  nsp_loss : 0.6776  total_loss : 11.1401  avg_loss_step : 11.1460  learning_rate : 0.0  loss_scaler : 536870912 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:37:14.388512 - Iteration: 1  throughput_train : 4210.804 sequences/s mlm_loss : 10.4676  nsp_loss : 0.6999  total_loss : 11.1675  avg_loss_step : 11.1477  learning_rate : 0.0  loss_scaler : 268435456 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:37:30.469914 - Iteration: 1  throughput_train : 4206.759 sequences/s mlm_loss : 10.4454  nsp_loss : 0.6839  total_loss : 11.1293  avg_loss_step : 11.1497  learning_rate : 0.0  loss_scaler : 134217728 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:37:46.551800 - Iteration: 1  throughput_train : 4206.378 sequences/s mlm_loss : 10.4327  nsp_loss : 0.6879  total_loss : 11.1206  avg_loss_step : 11.1507  learning_rate : 0.0  loss_scaler : 67108864 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:38:07.266770 - Iteration: 1  throughput_train : 3264.988 sequences/s mlm_loss : 10.4436  nsp_loss : 0.6942  total_loss : 11.1378  avg_loss_step : 11.1451  learning_rate : 0.0  loss_scaler : 33554432 
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:38:51.312968 - Iteration: 2  throughput_train : 1534.876 sequences/s mlm_loss : 10.4631  nsp_loss : 0.6892  total_loss : 11.1523  avg_loss_step : 11.1484  learning_rate : 0.0  loss_scaler : 16777216 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:39:08.816123 - Iteration: 3  throughput_train : 3864.377 sequences/s mlm_loss : 10.4954  nsp_loss : 0.6963  total_loss : 11.1918  avg_loss_step : 11.1467  learning_rate : 3e-06  loss_scaler : 16777216 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:39:25.100971 - Iteration: 4  throughput_train : 4153.698 sequences/s mlm_loss : 10.4563  nsp_loss : 0.6745  total_loss : 11.1308  avg_loss_step : 11.1461  learning_rate : 6e-06  loss_scaler : 16777216 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:39:41.446392 - Iteration: 5  throughput_train : 4138.393 sequences/s mlm_loss : 10.4486  nsp_loss : 0.7052  total_loss : 11.1538  avg_loss_step : 11.1468  learning_rate : 9e-06  loss_scaler : 16777216 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 18:39:57.840354 - Iteration: 6  throughput_train : 4126.208 sequences/s mlm_loss : 10.4491  nsp_loss : 0.6848  total_loss : 11.1339  avg_loss_step : 11.1407  learning_rate : 1.2e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:40:14.141232 - Iteration: 7  throughput_train : 4149.627 sequences/s mlm_loss : 10.4353  nsp_loss : 0.6984  total_loss : 11.1337  avg_loss_step : 11.1425  learning_rate : 1.50000005e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:40:30.500228 - Iteration: 8  throughput_train : 4134.907 sequences/s mlm_loss : 10.4063  nsp_loss : 0.6900  total_loss : 11.0962  avg_loss_step : 11.1331  learning_rate : 1.8e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:40:46.898264 - Iteration: 9  throughput_train : 4124.949 sequences/s mlm_loss : 10.4710  nsp_loss : 0.6756  total_loss : 11.1466  avg_loss_step : 11.1257  learning_rate : 2.1e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:41:03.248972 - Iteration: 10  throughput_train : 4136.613 sequences/s mlm_loss : 10.4328  nsp_loss : 0.6857  total_loss : 11.1185  avg_loss_step : 11.1221  learning_rate : 2.4e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:41:19.629334 - Iteration: 11  throughput_train : 4129.421 sequences/s mlm_loss : 10.4335  nsp_loss : 0.6736  total_loss : 11.1070  avg_loss_step : 11.1138  learning_rate : 2.7000002e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:41:36.041729 - Iteration: 12  throughput_train : 4121.391 sequences/s mlm_loss : 10.4219  nsp_loss : 0.7122  total_loss : 11.1340  avg_loss_step : 11.1033  learning_rate : 3.0000001e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:41:52.376650 - Iteration: 13  throughput_train : 4141.063 sequences/s mlm_loss : 10.3902  nsp_loss : 0.6894  total_loss : 11.0796  avg_loss_step : 11.0979  learning_rate : 3.3e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:42:08.696820 - Iteration: 14  throughput_train : 4144.776 sequences/s mlm_loss : 10.4023  nsp_loss : 0.6836  total_loss : 11.0859  avg_loss_step : 11.0915  learning_rate : 3.6e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:42:25.045220 - Iteration: 15  throughput_train : 4137.555 sequences/s mlm_loss : 10.3883  nsp_loss : 0.7221  total_loss : 11.1104  avg_loss_step : 11.0794  learning_rate : 3.9000002e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:42:41.382045 - Iteration: 16  throughput_train : 4140.447 sequences/s mlm_loss : 10.3851  nsp_loss : 0.6824  total_loss : 11.0675  avg_loss_step : 11.0572  learning_rate : 4.2e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:42:57.752059 - Iteration: 17  throughput_train : 4131.893 sequences/s mlm_loss : 10.3930  nsp_loss : 0.6874  total_loss : 11.0804  avg_loss_step : 11.0606  learning_rate : 4.5e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:43:14.089957 - Iteration: 18  throughput_train : 4140.191 sequences/s mlm_loss : 10.3452  nsp_loss : 0.7118  total_loss : 11.0569  avg_loss_step : 11.0418  learning_rate : 4.8e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:43:30.382584 - Iteration: 19  throughput_train : 4151.635 sequences/s mlm_loss : 10.3330  nsp_loss : 0.7281  total_loss : 11.0610  avg_loss_step : 11.0333  learning_rate : 5.1000003e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:43:46.730677 - Iteration: 20  throughput_train : 4137.336 sequences/s mlm_loss : 10.3328  nsp_loss : 0.7154  total_loss : 11.0482  avg_loss_step : 11.0230  learning_rate : 5.4000004e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:44:03.069719 - Iteration: 21  throughput_train : 4139.852 sequences/s mlm_loss : 10.3256  nsp_loss : 0.6714  total_loss : 10.9970  avg_loss_step : 10.9999  learning_rate : 5.7e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:44:19.436419 - Iteration: 22  throughput_train : 4132.970 sequences/s mlm_loss : 10.2758  nsp_loss : 0.6916  total_loss : 10.9674  avg_loss_step : 10.9804  learning_rate : 6.0000002e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:44:35.790004 - Iteration: 23  throughput_train : 4136.260 sequences/s mlm_loss : 10.2828  nsp_loss : 0.6950  total_loss : 10.9778  avg_loss_step : 10.9635  learning_rate : 6.3e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:44:52.090800 - Iteration: 24  throughput_train : 4149.614 sequences/s mlm_loss : 10.2648  nsp_loss : 0.6803  total_loss : 10.9451  avg_loss_step : 10.9386  learning_rate : 6.6e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:45:08.416030 - Iteration: 25  throughput_train : 4143.358 sequences/s mlm_loss : 10.2560  nsp_loss : 0.6697  total_loss : 10.9257  avg_loss_step : 10.9327  learning_rate : 6.9e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:45:24.787269 - Iteration: 26  throughput_train : 4131.609 sequences/s mlm_loss : 10.2548  nsp_loss : 0.6841  total_loss : 10.9389  avg_loss_step : 10.9084  learning_rate : 7.2e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:45:41.159898 - Iteration: 27  throughput_train : 4131.419 sequences/s mlm_loss : 10.2028  nsp_loss : 0.7104  total_loss : 10.9132  avg_loss_step : 10.8921  learning_rate : 7.5e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:45:57.510017 - Iteration: 28  throughput_train : 4137.129 sequences/s mlm_loss : 10.1939  nsp_loss : 0.6581  total_loss : 10.8520  avg_loss_step : 10.8698  learning_rate : 7.8000005e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:46:13.855560 - Iteration: 29  throughput_train : 4138.237 sequences/s mlm_loss : 10.1620  nsp_loss : 0.7018  total_loss : 10.8638  avg_loss_step : 10.8487  learning_rate : 8.1000006e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:46:30.174476 - Iteration: 30  throughput_train : 4145.203 sequences/s mlm_loss : 10.1611  nsp_loss : 0.6868  total_loss : 10.8478  avg_loss_step : 10.8327  learning_rate : 8.4e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:46:46.495950 - Iteration: 31  throughput_train : 4144.389 sequences/s mlm_loss : 10.1074  nsp_loss : 0.6652  total_loss : 10.7726  avg_loss_step : 10.8065  learning_rate : 8.7e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:47:02.820434 - Iteration: 32  throughput_train : 4143.504 sequences/s mlm_loss : 10.1426  nsp_loss : 0.6703  total_loss : 10.8129  avg_loss_step : 10.7866  learning_rate : 9e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:47:19.156467 - Iteration: 33  throughput_train : 4140.556 sequences/s mlm_loss : 10.0670  nsp_loss : 0.6712  total_loss : 10.7382  avg_loss_step : 10.7583  learning_rate : 9.3e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:47:35.525182 - Iteration: 34  throughput_train : 4132.386 sequences/s mlm_loss : 10.0504  nsp_loss : 0.6751  total_loss : 10.7255  avg_loss_step : 10.7448  learning_rate : 9.6e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:47:51.895405 - Iteration: 35  throughput_train : 4132.179 sequences/s mlm_loss : 10.0202  nsp_loss : 0.6996  total_loss : 10.7198  avg_loss_step : 10.7159  learning_rate : 9.9000004e-05  loss_scaler : 16777216 
DLL 2022-11-26 18:48:08.232654 - Iteration: 36  throughput_train : 4140.124 sequences/s mlm_loss : 9.9546  nsp_loss : 0.7048  total_loss : 10.6595  avg_loss_step : 10.6945  learning_rate : 0.000102000005  loss_scaler : 16777216 
DLL 2022-11-26 18:48:24.582587 - Iteration: 37  throughput_train : 4136.887 sequences/s mlm_loss : 9.9865  nsp_loss : 0.7176  total_loss : 10.7042  avg_loss_step : 10.6703  learning_rate : 0.00010500001  loss_scaler : 16777216 
DLL 2022-11-26 18:48:40.925302 - Iteration: 38  throughput_train : 4138.910 sequences/s mlm_loss : 9.9389  nsp_loss : 0.6858  total_loss : 10.6246  avg_loss_step : 10.6506  learning_rate : 0.00010800001  loss_scaler : 16777216 
DLL 2022-11-26 18:48:57.263730 - Iteration: 39  throughput_train : 4140.104 sequences/s mlm_loss : 9.9518  nsp_loss : 0.6587  total_loss : 10.6105  avg_loss_step : 10.6251  learning_rate : 0.000111  loss_scaler : 16777216 
DLL 2022-11-26 18:49:13.604175 - Iteration: 40  throughput_train : 4139.353 sequences/s mlm_loss : 9.9286  nsp_loss : 0.6655  total_loss : 10.5941  avg_loss_step : 10.6014  learning_rate : 0.000114  loss_scaler : 16777216 
DLL 2022-11-26 18:49:29.924546 - Iteration: 41  throughput_train : 4144.810 sequences/s mlm_loss : 9.8277  nsp_loss : 0.6781  total_loss : 10.5058  avg_loss_step : 10.5801  learning_rate : 0.000117  loss_scaler : 16777216 
DLL 2022-11-26 18:49:46.270664 - Iteration: 42  throughput_train : 4138.060 sequences/s mlm_loss : 9.8714  nsp_loss : 0.6991  total_loss : 10.5705  avg_loss_step : 10.5459  learning_rate : 0.000120000004  loss_scaler : 16777216 
DLL 2022-11-26 18:50:02.586353 - Iteration: 43  throughput_train : 4145.695 sequences/s mlm_loss : 9.8421  nsp_loss : 0.6583  total_loss : 10.5003  avg_loss_step : 10.5341  learning_rate : 0.000123  loss_scaler : 16777216 
DLL 2022-11-26 18:50:18.924642 - Iteration: 44  throughput_train : 4140.189 sequences/s mlm_loss : 9.7817  nsp_loss : 0.7027  total_loss : 10.4844  avg_loss_step : 10.5020  learning_rate : 0.000126  loss_scaler : 16777216 
DLL 2022-11-26 18:50:35.283849 - Iteration: 45  throughput_train : 4134.858 sequences/s mlm_loss : 9.7608  nsp_loss : 0.6867  total_loss : 10.4475  avg_loss_step : 10.4787  learning_rate : 0.00012900001  loss_scaler : 16777216 
DLL 2022-11-26 18:50:51.586261 - Iteration: 46  throughput_train : 4149.031 sequences/s mlm_loss : 9.8291  nsp_loss : 0.6870  total_loss : 10.5160  avg_loss_step : 10.4677  learning_rate : 0.000132  loss_scaler : 16777216 
DLL 2022-11-26 18:51:07.911005 - Iteration: 47  throughput_train : 4143.474 sequences/s mlm_loss : 9.7624  nsp_loss : 0.6730  total_loss : 10.4354  avg_loss_step : 10.4428  learning_rate : 0.00013500001  loss_scaler : 16777216 
DLL 2022-11-26 18:51:24.181181 - Iteration: 48  throughput_train : 4157.239 sequences/s mlm_loss : 9.7460  nsp_loss : 0.6833  total_loss : 10.4293  avg_loss_step : 10.4155  learning_rate : 0.000138  loss_scaler : 16777216 
DLL 2022-11-26 18:51:40.502653 - Iteration: 49  throughput_train : 4145.269 sequences/s mlm_loss : 9.7559  nsp_loss : 0.6769  total_loss : 10.4328  avg_loss_step : 10.3960  learning_rate : 0.00014100001  loss_scaler : 16777216 
DLL 2022-11-26 18:51:56.802441 - Iteration: 50  throughput_train : 4149.872 sequences/s mlm_loss : 9.6552  nsp_loss : 0.6874  total_loss : 10.3426  avg_loss_step : 10.3780  learning_rate : 0.000144  loss_scaler : 16777216 
DLL 2022-11-26 18:52:13.157052 - Iteration: 51  throughput_train : 4135.928 sequences/s mlm_loss : 9.6736  nsp_loss : 0.6446  total_loss : 10.3182  avg_loss_step : 10.3547  learning_rate : 0.000147  loss_scaler : 16777216 
DLL 2022-11-26 18:52:29.486419 - Iteration: 52  throughput_train : 4142.139 sequences/s mlm_loss : 9.6996  nsp_loss : 0.6597  total_loss : 10.3593  avg_loss_step : 10.3280  learning_rate : 0.00015  loss_scaler : 16777216 
DLL 2022-11-26 18:52:45.881632 - Iteration: 53  throughput_train : 4125.885 sequences/s mlm_loss : 9.5821  nsp_loss : 0.6858  total_loss : 10.2678  avg_loss_step : 10.3215  learning_rate : 0.000153  loss_scaler : 16777216 
DLL 2022-11-26 18:53:02.239660 - Iteration: 54  throughput_train : 4134.997 sequences/s mlm_loss : 9.6055  nsp_loss : 0.6636  total_loss : 10.2691  avg_loss_step : 10.2930  learning_rate : 0.00015600001  loss_scaler : 16777216 
DLL 2022-11-26 18:53:18.612571 - Iteration: 55  throughput_train : 4131.113 sequences/s mlm_loss : 9.6109  nsp_loss : 0.6543  total_loss : 10.2652  avg_loss_step : 10.2772  learning_rate : 0.000159  loss_scaler : 16777216 
DLL 2022-11-26 18:53:34.958155 - Iteration: 56  throughput_train : 4138.329 sequences/s mlm_loss : 9.4896  nsp_loss : 0.6543  total_loss : 10.1439  avg_loss_step : 10.2431  learning_rate : 0.00016200001  loss_scaler : 16777216 
DLL 2022-11-26 18:53:51.277146 - Iteration: 57  throughput_train : 4144.918 sequences/s mlm_loss : 9.5742  nsp_loss : 0.6855  total_loss : 10.2597  avg_loss_step : 10.2357  learning_rate : 0.000165  loss_scaler : 16777216 
DLL 2022-11-26 18:54:07.621678 - Iteration: 58  throughput_train : 4138.661 sequences/s mlm_loss : 9.5678  nsp_loss : 0.6748  total_loss : 10.2426  avg_loss_step : 10.2265  learning_rate : 0.000168  loss_scaler : 16777216 
DLL 2022-11-26 18:54:23.965319 - Iteration: 59  throughput_train : 4139.050 sequences/s mlm_loss : 9.5060  nsp_loss : 0.7019  total_loss : 10.2080  avg_loss_step : 10.2117  learning_rate : 0.000171  loss_scaler : 16777216 
DLL 2022-11-26 18:54:40.326754 - Iteration: 60  throughput_train : 4134.225 sequences/s mlm_loss : 9.4264  nsp_loss : 0.6971  total_loss : 10.1235  avg_loss_step : 10.1897  learning_rate : 0.000174  loss_scaler : 16777216 
DLL 2022-11-26 18:54:56.674963 - Iteration: 61  throughput_train : 4137.354 sequences/s mlm_loss : 9.4812  nsp_loss : 0.7038  total_loss : 10.1851  avg_loss_step : 10.1721  learning_rate : 0.00017700001  loss_scaler : 16777216 
DLL 2022-11-26 18:55:13.007554 - Iteration: 62  throughput_train : 4141.515 sequences/s mlm_loss : 9.5165  nsp_loss : 0.6551  total_loss : 10.1716  avg_loss_step : 10.1639  learning_rate : 0.00018  loss_scaler : 16777216 
DLL 2022-11-26 18:55:29.375720 - Iteration: 63  throughput_train : 4132.500 sequences/s mlm_loss : 9.4126  nsp_loss : 0.6736  total_loss : 10.0862  avg_loss_step : 10.1305  learning_rate : 0.00018300001  loss_scaler : 16777216 
DLL 2022-11-26 18:55:45.665771 - Iteration: 64  throughput_train : 4152.269 sequences/s mlm_loss : 9.4166  nsp_loss : 0.6887  total_loss : 10.1053  avg_loss_step : 10.1052  learning_rate : 0.000186  loss_scaler : 16777216 
DLL 2022-11-26 18:56:02.002138 - Iteration: 65  throughput_train : 4140.596 sequences/s mlm_loss : 9.4397  nsp_loss : 0.6604  total_loss : 10.1001  avg_loss_step : 10.1072  learning_rate : 0.00018900001  loss_scaler : 16777216 
DLL 2022-11-26 18:56:18.298555 - Iteration: 66  throughput_train : 4150.762 sequences/s mlm_loss : 9.3986  nsp_loss : 0.6678  total_loss : 10.0664  avg_loss_step : 10.0922  learning_rate : 0.000192  loss_scaler : 16777216 
DLL 2022-11-26 18:56:34.657502 - Iteration: 67  throughput_train : 4134.625 sequences/s mlm_loss : 9.3839  nsp_loss : 0.6639  total_loss : 10.0479  avg_loss_step : 10.0771  learning_rate : 0.000195  loss_scaler : 16777216 
DLL 2022-11-26 18:56:50.980988 - Iteration: 68  throughput_train : 4143.756 sequences/s mlm_loss : 9.4905  nsp_loss : 0.6474  total_loss : 10.1379  avg_loss_step : 10.0530  learning_rate : 0.00019800001  loss_scaler : 16777216 
DLL 2022-11-26 18:57:07.301331 - Iteration: 69  throughput_train : 4144.503 sequences/s mlm_loss : 9.4265  nsp_loss : 0.6986  total_loss : 10.1251  avg_loss_step : 10.0484  learning_rate : 0.000201  loss_scaler : 16777216 
DLL 2022-11-26 18:57:23.683409 - Iteration: 70  throughput_train : 4128.780 sequences/s mlm_loss : 9.3752  nsp_loss : 0.6406  total_loss : 10.0158  avg_loss_step : 10.0324  learning_rate : 0.00020400001  loss_scaler : 16777216 
DLL 2022-11-26 18:57:40.081511 - Iteration: 71  throughput_train : 4125.056 sequences/s mlm_loss : 9.3292  nsp_loss : 0.6786  total_loss : 10.0078  avg_loss_step : 10.0205  learning_rate : 0.000207  loss_scaler : 16777216 
DLL 2022-11-26 18:57:56.393898 - Iteration: 72  throughput_train : 4146.705 sequences/s mlm_loss : 9.2828  nsp_loss : 0.6731  total_loss : 9.9558  avg_loss_step : 10.0140  learning_rate : 0.00021000001  loss_scaler : 16777216 
DLL 2022-11-26 18:58:12.716844 - Iteration: 73  throughput_train : 4144.118 sequences/s mlm_loss : 9.2545  nsp_loss : 0.6865  total_loss : 9.9411  avg_loss_step : 9.9933  learning_rate : 0.000213  loss_scaler : 16777216 
DLL 2022-11-26 18:58:29.089682 - Iteration: 74  throughput_train : 4131.402 sequences/s mlm_loss : 9.3632  nsp_loss : 0.6532  total_loss : 10.0164  avg_loss_step : 9.9981  learning_rate : 0.00021600001  loss_scaler : 16777216 
DLL 2022-11-26 18:58:45.467491 - Iteration: 75  throughput_train : 4130.120 sequences/s mlm_loss : 9.2942  nsp_loss : 0.6634  total_loss : 9.9576  avg_loss_step : 9.9849  learning_rate : 0.00021900001  loss_scaler : 16777216 
DLL 2022-11-26 18:59:01.814005 - Iteration: 76  throughput_train : 4138.092 sequences/s mlm_loss : 9.2601  nsp_loss : 0.6741  total_loss : 9.9342  avg_loss_step : 9.9587  learning_rate : 0.000222  loss_scaler : 16777216 
DLL 2022-11-26 18:59:18.152917 - Iteration: 77  throughput_train : 4139.877 sequences/s mlm_loss : 9.2609  nsp_loss : 0.6627  total_loss : 9.9236  avg_loss_step : 9.9485  learning_rate : 0.00022500001  loss_scaler : 16777216 
DLL 2022-11-26 18:59:34.503973 - Iteration: 78  throughput_train : 4136.923 sequences/s mlm_loss : 9.2138  nsp_loss : 0.6792  total_loss : 9.8930  avg_loss_step : 9.9500  learning_rate : 0.000228  loss_scaler : 16777216 
DLL 2022-11-26 18:59:50.839840 - Iteration: 79  throughput_train : 4140.550 sequences/s mlm_loss : 9.2813  nsp_loss : 0.6713  total_loss : 9.9526  avg_loss_step : 9.9386  learning_rate : 0.00023100001  loss_scaler : 16777216 
DLL 2022-11-26 19:00:07.191381 - Iteration: 80  throughput_train : 4136.948 sequences/s mlm_loss : 9.2826  nsp_loss : 0.6540  total_loss : 9.9366  avg_loss_step : 9.9335  learning_rate : 0.000234  loss_scaler : 16777216 
DLL 2022-11-26 19:00:23.509025 - Iteration: 81  throughput_train : 4145.106 sequences/s mlm_loss : 9.2224  nsp_loss : 0.6684  total_loss : 9.8908  avg_loss_step : 9.9176  learning_rate : 0.00023700001  loss_scaler : 16777216 
DLL 2022-11-26 19:00:39.874218 - Iteration: 82  throughput_train : 4133.110 sequences/s mlm_loss : 9.2764  nsp_loss : 0.6888  total_loss : 9.9652  avg_loss_step : 9.9083  learning_rate : 0.00024000001  loss_scaler : 16777216 
DLL 2022-11-26 19:00:56.236204 - Iteration: 83  throughput_train : 4134.027 sequences/s mlm_loss : 9.2124  nsp_loss : 0.7222  total_loss : 9.9346  avg_loss_step : 9.9015  learning_rate : 0.000243  loss_scaler : 16777216 
DLL 2022-11-26 19:01:12.565672 - Iteration: 84  throughput_train : 4142.352 sequences/s mlm_loss : 9.1234  nsp_loss : 0.6885  total_loss : 9.8119  avg_loss_step : 9.8801  learning_rate : 0.000246  loss_scaler : 16777216 
DLL 2022-11-26 19:01:28.905574 - Iteration: 85  throughput_train : 4139.609 sequences/s mlm_loss : 9.1833  nsp_loss : 0.6989  total_loss : 9.8822  avg_loss_step : 9.8720  learning_rate : 0.000249  loss_scaler : 16777216 
DLL 2022-11-26 19:01:45.266505 - Iteration: 86  throughput_train : 4134.314 sequences/s mlm_loss : 9.2140  nsp_loss : 0.6881  total_loss : 9.9021  avg_loss_step : 9.8729  learning_rate : 0.000252  loss_scaler : 16777216 
DLL 2022-11-26 19:02:01.573204 - Iteration: 87  throughput_train : 4147.904 sequences/s mlm_loss : 9.2635  nsp_loss : 0.6872  total_loss : 9.9507  avg_loss_step : 9.8609  learning_rate : 0.00025500002  loss_scaler : 16777216 
DLL 2022-11-26 19:02:17.862837 - Iteration: 88  throughput_train : 4152.270 sequences/s mlm_loss : 9.1100  nsp_loss : 0.6731  total_loss : 9.7831  avg_loss_step : 9.8415  learning_rate : 0.00025800001  loss_scaler : 16777216 
DLL 2022-11-26 19:02:34.209092 - Iteration: 89  throughput_train : 4138.131 sequences/s mlm_loss : 9.1397  nsp_loss : 0.7156  total_loss : 9.8553  avg_loss_step : 9.8435  learning_rate : 0.000261  loss_scaler : 16777216 
DLL 2022-11-26 19:02:50.588890 - Iteration: 90  throughput_train : 4129.732 sequences/s mlm_loss : 9.1293  nsp_loss : 0.6523  total_loss : 9.7816  avg_loss_step : 9.8432  learning_rate : 0.000264  loss_scaler : 16777216 
DLL 2022-11-26 19:03:06.893311 - Iteration: 91  throughput_train : 4148.524 sequences/s mlm_loss : 9.1023  nsp_loss : 0.6995  total_loss : 9.8018  avg_loss_step : 9.8319  learning_rate : 0.000267  loss_scaler : 16777216 
DLL 2022-11-26 19:03:23.202095 - Iteration: 92  throughput_train : 4147.583 sequences/s mlm_loss : 9.2020  nsp_loss : 0.6834  total_loss : 9.8853  avg_loss_step : 9.8268  learning_rate : 0.00027000002  loss_scaler : 16777216 
DLL 2022-11-26 19:03:39.516413 - Iteration: 93  throughput_train : 4146.044 sequences/s mlm_loss : 9.1984  nsp_loss : 0.6948  total_loss : 9.8932  avg_loss_step : 9.8173  learning_rate : 0.000273  loss_scaler : 16777216 
DLL 2022-11-26 19:03:55.843016 - Iteration: 94  throughput_train : 4143.000 sequences/s mlm_loss : 9.0927  nsp_loss : 0.6728  total_loss : 9.7655  avg_loss_step : 9.7939  learning_rate : 0.000276  loss_scaler : 16777216 
DLL 2022-11-26 19:04:12.205506 - Iteration: 95  throughput_train : 4133.900 sequences/s mlm_loss : 9.1826  nsp_loss : 0.6797  total_loss : 9.8623  avg_loss_step : 9.7947  learning_rate : 0.000279  loss_scaler : 16777216 
DLL 2022-11-26 19:04:28.544737 - Iteration: 96  throughput_train : 4140.060 sequences/s mlm_loss : 9.0866  nsp_loss : 0.6746  total_loss : 9.7611  avg_loss_step : 9.7825  learning_rate : 0.00028200002  loss_scaler : 16777216 
DLL 2022-11-26 19:04:44.939476 - Iteration: 97  throughput_train : 4125.997 sequences/s mlm_loss : 9.0919  nsp_loss : 0.6482  total_loss : 9.7401  avg_loss_step : 9.7657  learning_rate : 0.00028500002  loss_scaler : 16777216 
DLL 2022-11-26 19:05:01.301575 - Iteration: 98  throughput_train : 4134.124 sequences/s mlm_loss : 9.0321  nsp_loss : 0.6827  total_loss : 9.7149  avg_loss_step : 9.7590  learning_rate : 0.000288  loss_scaler : 16777216 
DLL 2022-11-26 19:05:17.618696 - Iteration: 99  throughput_train : 4145.273 sequences/s mlm_loss : 9.1403  nsp_loss : 0.6711  total_loss : 9.8114  avg_loss_step : 9.7589  learning_rate : 0.000291  loss_scaler : 16777216 
DLL 2022-11-26 19:05:33.994516 - Iteration: 100  throughput_train : 4130.538 sequences/s mlm_loss : 9.1395  nsp_loss : 0.6735  total_loss : 9.8131  avg_loss_step : 9.7509  learning_rate : 0.000294  loss_scaler : 16777216 
DLL 2022-11-26 19:05:50.358878 - Iteration: 101  throughput_train : 4133.590 sequences/s mlm_loss : 9.0497  nsp_loss : 0.6666  total_loss : 9.7163  avg_loss_step : 9.7440  learning_rate : 0.00029700002  loss_scaler : 16777216 
DLL 2022-11-26 19:06:06.691196 - Iteration: 102  throughput_train : 4141.906 sequences/s mlm_loss : 8.9616  nsp_loss : 0.6538  total_loss : 9.6154  avg_loss_step : 9.7274  learning_rate : 0.0003  loss_scaler : 16777216 
DLL 2022-11-26 19:06:23.000560 - Iteration: 103  throughput_train : 4147.298 sequences/s mlm_loss : 9.0137  nsp_loss : 0.6796  total_loss : 9.6933  avg_loss_step : 9.7280  learning_rate : 0.000303  loss_scaler : 16777216 
DLL 2022-11-26 19:06:39.345054 - Iteration: 104  throughput_train : 4138.505 sequences/s mlm_loss : 8.9923  nsp_loss : 0.6965  total_loss : 9.6889  avg_loss_step : 9.7064  learning_rate : 0.000306  loss_scaler : 16777216 
DLL 2022-11-26 19:06:55.668158 - Iteration: 105  throughput_train : 4143.851 sequences/s mlm_loss : 9.0155  nsp_loss : 0.6906  total_loss : 9.7061  avg_loss_step : 9.7303  learning_rate : 0.00030900002  loss_scaler : 16777216 
DLL 2022-11-26 19:07:12.020975 - Iteration: 106  throughput_train : 4136.456 sequences/s mlm_loss : 9.1050  nsp_loss : 0.6816  total_loss : 9.7866  avg_loss_step : 9.7044  learning_rate : 0.00031200002  loss_scaler : 16777216 
2022-11-26 19:07:40.017148: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:07:40.180445: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:loss = 9.736258, step = 105 (2022.692 sec)
I1126 19:08:22.096582 139767222495040 basic_session_run_hooks.py:260] loss = 9.736258, step = 105 (2022.692 sec)
INFO:tensorflow:loss = 9.773617, step = 105 (2022.717 sec)
INFO:tensorflow:loss = 9.63107, step = 105 (2022.722 sec)
INFO:tensorflow:loss = 9.657412, step = 105 (2022.668 sec)
I1126 19:08:22.096882 139671492257600 basic_session_run_hooks.py:260] loss = 9.773617, step = 105 (2022.717 sec)
I1126 19:08:22.096994 140580483716928 basic_session_run_hooks.py:260] loss = 9.63107, step = 105 (2022.722 sec)
I1126 19:08:22.097094 139659189745472 basic_session_run_hooks.py:260] loss = 9.657412, step = 105 (2022.668 sec)
INFO:tensorflow:loss = 9.759846, step = 105 (2022.746 sec)
I1126 19:08:22.098610 140620976506688 basic_session_run_hooks.py:260] loss = 9.759846, step = 105 (2022.746 sec)
INFO:tensorflow:loss = 9.760368, step = 105 (2022.730 sec)
INFO:tensorflow:loss = 9.672676, step = 105 (2022.700 sec)
I1126 19:08:22.098849 140058966173504 basic_session_run_hooks.py:260] loss = 9.672676, step = 105 (2022.700 sec)
I1126 19:08:22.099032 139713062618944 basic_session_run_hooks.py:260] loss = 9.760368, step = 105 (2022.730 sec)
INFO:tensorflow:loss = 9.727438, step = 105 (2027.883 sec)
I1126 19:08:26.431071 139662769284928 basic_session_run_hooks.py:260] loss = 9.727438, step = 105 (2027.883 sec)
DLL 2022-11-26 19:08:32.221302 - Iteration: 107  throughput_train : 842.870 sequences/s mlm_loss : 8.9941  nsp_loss : 0.6887  total_loss : 9.6828  avg_loss_step : 9.7013  learning_rate : 0.000315  loss_scaler : 16777216 
DLL 2022-11-26 19:08:48.555057 - Iteration: 108  throughput_train : 4141.257 sequences/s mlm_loss : 8.9330  nsp_loss : 0.6874  total_loss : 9.6204  avg_loss_step : 9.6822  learning_rate : 0.000318  loss_scaler : 16777216 
DLL 2022-11-26 19:09:04.889737 - Iteration: 109  throughput_train : 4141.708 sequences/s mlm_loss : 8.9658  nsp_loss : 0.6832  total_loss : 9.6490  avg_loss_step : 9.6615  learning_rate : 0.000321  loss_scaler : 16777216 
DLL 2022-11-26 19:09:21.276887 - Iteration: 110  throughput_train : 4128.406 sequences/s mlm_loss : 8.9690  nsp_loss : 0.6822  total_loss : 9.6512  avg_loss_step : 9.6659  learning_rate : 0.00032400002  loss_scaler : 16777216 
DLL 2022-11-26 19:09:37.644145 - Iteration: 111  throughput_train : 4132.920 sequences/s mlm_loss : 9.0079  nsp_loss : 0.7253  total_loss : 9.7332  avg_loss_step : 9.6536  learning_rate : 0.00032700002  loss_scaler : 16777216 
DLL 2022-11-26 19:09:53.953258 - Iteration: 112  throughput_train : 4147.449 sequences/s mlm_loss : 8.8955  nsp_loss : 0.6593  total_loss : 9.5549  avg_loss_step : 9.6431  learning_rate : 0.00033  loss_scaler : 16777216 
DLL 2022-11-26 19:10:10.248641 - Iteration: 113  throughput_train : 4151.200 sequences/s mlm_loss : 8.8664  nsp_loss : 0.6590  total_loss : 9.5254  avg_loss_step : 9.6224  learning_rate : 0.000333  loss_scaler : 16777216 
DLL 2022-11-26 19:10:26.581018 - Iteration: 114  throughput_train : 4141.649 sequences/s mlm_loss : 9.0541  nsp_loss : 0.7143  total_loss : 9.7684  avg_loss_step : 9.6249  learning_rate : 0.000336  loss_scaler : 16777216 
DLL 2022-11-26 19:10:42.951511 - Iteration: 115  throughput_train : 4132.050 sequences/s mlm_loss : 9.0063  nsp_loss : 0.6631  total_loss : 9.6694  avg_loss_step : 9.5975  learning_rate : 0.00033900002  loss_scaler : 16777216 
DLL 2022-11-26 19:10:59.275371 - Iteration: 116  throughput_train : 4144.587 sequences/s mlm_loss : 8.8740  nsp_loss : 0.6882  total_loss : 9.5622  avg_loss_step : 9.5732  learning_rate : 0.000342  loss_scaler : 16777216 
DLL 2022-11-26 19:11:15.600594 - Iteration: 117  throughput_train : 4143.477 sequences/s mlm_loss : 8.9260  nsp_loss : 0.6498  total_loss : 9.5759  avg_loss_step : 9.5694  learning_rate : 0.000345  loss_scaler : 16777216 
DLL 2022-11-26 19:11:31.916945 - Iteration: 118  throughput_train : 4145.423 sequences/s mlm_loss : 8.9092  nsp_loss : 0.6091  total_loss : 9.5182  avg_loss_step : 9.5640  learning_rate : 0.000348  loss_scaler : 16777216 
DLL 2022-11-26 19:11:48.272444 - Iteration: 119  throughput_train : 4135.580 sequences/s mlm_loss : 8.8496  nsp_loss : 0.6417  total_loss : 9.4913  avg_loss_step : 9.5535  learning_rate : 0.00035100002  loss_scaler : 16777216 
DLL 2022-11-26 19:12:04.578506 - Iteration: 120  throughput_train : 4148.391 sequences/s mlm_loss : 8.9536  nsp_loss : 0.6514  total_loss : 9.6050  avg_loss_step : 9.5356  learning_rate : 0.00035400002  loss_scaler : 16777216 
DLL 2022-11-26 19:12:20.900494 - Iteration: 121  throughput_train : 4144.392 sequences/s mlm_loss : 8.8013  nsp_loss : 0.6901  total_loss : 9.4914  avg_loss_step : 9.5268  learning_rate : 0.000357  loss_scaler : 16777216 
DLL 2022-11-26 19:12:37.247036 - Iteration: 122  throughput_train : 4137.945 sequences/s mlm_loss : 8.9350  nsp_loss : 0.6897  total_loss : 9.6248  avg_loss_step : 9.5504  learning_rate : 0.00036  loss_scaler : 16777216 
DLL 2022-11-26 19:12:53.578173 - Iteration: 123  throughput_train : 4141.875 sequences/s mlm_loss : 8.9442  nsp_loss : 0.6599  total_loss : 9.6041  avg_loss_step : 9.5235  learning_rate : 0.000363  loss_scaler : 16777216 
DLL 2022-11-26 19:13:09.924014 - Iteration: 124  throughput_train : 4138.151 sequences/s mlm_loss : 8.8287  nsp_loss : 0.6239  total_loss : 9.4527  avg_loss_step : 9.5149  learning_rate : 0.00036600002  loss_scaler : 16777216 
DLL 2022-11-26 19:13:26.272256 - Iteration: 125  throughput_train : 4137.737 sequences/s mlm_loss : 8.9533  nsp_loss : 0.7025  total_loss : 9.6557  avg_loss_step : 9.5007  learning_rate : 0.00036900002  loss_scaler : 16777216 
DLL 2022-11-26 19:13:42.640821 - Iteration: 126  throughput_train : 4132.434 sequences/s mlm_loss : 8.8338  nsp_loss : 0.5957  total_loss : 9.4295  avg_loss_step : 9.4846  learning_rate : 0.000372  loss_scaler : 16777216 
DLL 2022-11-26 19:13:58.964536 - Iteration: 127  throughput_train : 4143.981 sequences/s mlm_loss : 8.8017  nsp_loss : 0.6391  total_loss : 9.4408  avg_loss_step : 9.4763  learning_rate : 0.000375  loss_scaler : 16777216 
DLL 2022-11-26 19:14:15.285019 - Iteration: 128  throughput_train : 4144.563 sequences/s mlm_loss : 8.9177  nsp_loss : 0.6511  total_loss : 9.5689  avg_loss_step : 9.4594  learning_rate : 0.00037800003  loss_scaler : 16777216 
DLL 2022-11-26 19:14:31.608441 - Iteration: 129  throughput_train : 4143.825 sequences/s mlm_loss : 8.7162  nsp_loss : 0.7290  total_loss : 9.4452  avg_loss_step : 9.4445  learning_rate : 0.00038100002  loss_scaler : 16777216 
DLL 2022-11-26 19:14:47.940447 - Iteration: 130  throughput_train : 4141.675 sequences/s mlm_loss : 8.7569  nsp_loss : 0.6716  total_loss : 9.4286  avg_loss_step : 9.4469  learning_rate : 0.000384  loss_scaler : 16777216 
DLL 2022-11-26 19:15:04.251205 - Iteration: 131  throughput_train : 4147.023 sequences/s mlm_loss : 8.7691  nsp_loss : 0.6088  total_loss : 9.3778  avg_loss_step : 9.4353  learning_rate : 0.000387  loss_scaler : 16777216 
DLL 2022-11-26 19:15:20.582805 - Iteration: 132  throughput_train : 4141.901 sequences/s mlm_loss : 8.8730  nsp_loss : 0.6437  total_loss : 9.5166  avg_loss_step : 9.4181  learning_rate : 0.00039  loss_scaler : 16777216 
DLL 2022-11-26 19:15:36.881756 - Iteration: 133  throughput_train : 4149.843 sequences/s mlm_loss : 8.7895  nsp_loss : 0.6096  total_loss : 9.3991  avg_loss_step : 9.3928  learning_rate : 0.00039300002  loss_scaler : 16777216 
DLL 2022-11-26 19:15:53.175766 - Iteration: 134  throughput_train : 4151.234 sequences/s mlm_loss : 8.7424  nsp_loss : 0.6120  total_loss : 9.3544  avg_loss_step : 9.3968  learning_rate : 0.00039600002  loss_scaler : 16777216 
DLL 2022-11-26 19:16:09.502531 - Iteration: 135  throughput_train : 4142.881 sequences/s mlm_loss : 8.8844  nsp_loss : 0.6324  total_loss : 9.5168  avg_loss_step : 9.3940  learning_rate : 0.000399  loss_scaler : 16777216 
DLL 2022-11-26 19:16:25.782842 - Iteration: 136  throughput_train : 4154.927 sequences/s mlm_loss : 8.7636  nsp_loss : 0.6688  total_loss : 9.4325  avg_loss_step : 9.3654  learning_rate : 0.000402  loss_scaler : 16777216 
DLL 2022-11-26 19:16:42.103420 - Iteration: 137  throughput_train : 4144.478 sequences/s mlm_loss : 8.8272  nsp_loss : 0.6691  total_loss : 9.4962  avg_loss_step : 9.3594  learning_rate : 0.00040500003  loss_scaler : 16777216 
DLL 2022-11-26 19:16:58.432741 - Iteration: 138  throughput_train : 4142.307 sequences/s mlm_loss : 8.6914  nsp_loss : 0.6397  total_loss : 9.3311  avg_loss_step : 9.3234  learning_rate : 0.00040800002  loss_scaler : 16777216 
DLL 2022-11-26 19:17:14.820211 - Iteration: 139  throughput_train : 4127.757 sequences/s mlm_loss : 8.7294  nsp_loss : 0.6524  total_loss : 9.3818  avg_loss_step : 9.3430  learning_rate : 0.00041100002  loss_scaler : 16777216 
DLL 2022-11-26 19:17:31.145774 - Iteration: 140  throughput_train : 4143.399 sequences/s mlm_loss : 8.5876  nsp_loss : 0.6808  total_loss : 9.2684  avg_loss_step : 9.3257  learning_rate : 0.000414  loss_scaler : 16777216 
DLL 2022-11-26 19:17:47.461166 - Iteration: 141  throughput_train : 4146.014 sequences/s mlm_loss : 8.6112  nsp_loss : 0.6602  total_loss : 9.2714  avg_loss_step : 9.3083  learning_rate : 0.000417  loss_scaler : 16777216 
DLL 2022-11-26 19:18:03.819385 - Iteration: 142  throughput_train : 4135.047 sequences/s mlm_loss : 8.7186  nsp_loss : 0.5759  total_loss : 9.2945  avg_loss_step : 9.2981  learning_rate : 0.00042000003  loss_scaler : 16777216 
DLL 2022-11-26 19:18:20.153975 - Iteration: 143  throughput_train : 4141.121 sequences/s mlm_loss : 8.7662  nsp_loss : 0.6248  total_loss : 9.3910  avg_loss_step : 9.3026  learning_rate : 0.00042300002  loss_scaler : 16777216 
DLL 2022-11-26 19:18:36.504887 - Iteration: 144  throughput_train : 4136.913 sequences/s mlm_loss : 8.6981  nsp_loss : 0.6234  total_loss : 9.3215  avg_loss_step : 9.2993  learning_rate : 0.000426  loss_scaler : 16777216 
DLL 2022-11-26 19:18:52.805094 - Iteration: 145  throughput_train : 4149.677 sequences/s mlm_loss : 8.5036  nsp_loss : 0.6081  total_loss : 9.1117  avg_loss_step : 9.2562  learning_rate : 0.000429  loss_scaler : 16777216 
DLL 2022-11-26 19:19:09.075357 - Iteration: 146  throughput_train : 4157.427 sequences/s mlm_loss : 8.6033  nsp_loss : 0.6152  total_loss : 9.2184  avg_loss_step : 9.2431  learning_rate : 0.00043200003  loss_scaler : 16777216 
DLL 2022-11-26 19:19:25.396984 - Iteration: 147  throughput_train : 4144.183 sequences/s mlm_loss : 8.5629  nsp_loss : 0.6658  total_loss : 9.2286  avg_loss_step : 9.2505  learning_rate : 0.00043500002  loss_scaler : 16777216 
DLL 2022-11-26 19:19:41.728495 - Iteration: 148  throughput_train : 4141.605 sequences/s mlm_loss : 8.6389  nsp_loss : 0.6557  total_loss : 9.2946  avg_loss_step : 9.2450  learning_rate : 0.00043800002  loss_scaler : 16777216 
DLL 2022-11-26 19:19:57.988977 - Iteration: 149  throughput_train : 4159.710 sequences/s mlm_loss : 8.6257  nsp_loss : 0.6471  total_loss : 9.2728  avg_loss_step : 9.2331  learning_rate : 0.000441  loss_scaler : 16777216 
DLL 2022-11-26 19:20:14.322522 - Iteration: 150  throughput_train : 4141.247 sequences/s mlm_loss : 8.5238  nsp_loss : 0.6823  total_loss : 9.2061  avg_loss_step : 9.2202  learning_rate : 0.000444  loss_scaler : 16777216 
DLL 2022-11-26 19:20:30.626459 - Iteration: 151  throughput_train : 4148.687 sequences/s mlm_loss : 8.6277  nsp_loss : 0.6550  total_loss : 9.2827  avg_loss_step : 9.1829  learning_rate : 0.00044700003  loss_scaler : 16777216 
DLL 2022-11-26 19:20:46.900460 - Iteration: 152  throughput_train : 4156.240 sequences/s mlm_loss : 8.4584  nsp_loss : 0.5915  total_loss : 9.0498  avg_loss_step : 9.1856  learning_rate : 0.00045000002  loss_scaler : 16777216 
DLL 2022-11-26 19:21:03.210419 - Iteration: 153  throughput_train : 4147.597 sequences/s mlm_loss : 8.6471  nsp_loss : 0.6381  total_loss : 9.2852  avg_loss_step : 9.1742  learning_rate : 0.00045300002  loss_scaler : 16777216 
DLL 2022-11-26 19:21:19.552472 - Iteration: 154  throughput_train : 4139.104 sequences/s mlm_loss : 8.5560  nsp_loss : 0.6657  total_loss : 9.2217  avg_loss_step : 9.1826  learning_rate : 0.000456  loss_scaler : 16777216 
DLL 2022-11-26 19:21:35.893559 - Iteration: 155  throughput_train : 4139.221 sequences/s mlm_loss : 8.5546  nsp_loss : 0.6328  total_loss : 9.1875  avg_loss_step : 9.1617  learning_rate : 0.000459  loss_scaler : 16777216 
DLL 2022-11-26 19:21:52.263859 - Iteration: 156  throughput_train : 4131.834 sequences/s mlm_loss : 8.4889  nsp_loss : 0.6141  total_loss : 9.1031  avg_loss_step : 9.1395  learning_rate : 0.00046200003  loss_scaler : 16777216 
DLL 2022-11-26 19:22:08.595202 - Iteration: 157  throughput_train : 4141.936 sequences/s mlm_loss : 8.4314  nsp_loss : 0.6620  total_loss : 9.0934  avg_loss_step : 9.1362  learning_rate : 0.00046500002  loss_scaler : 16777216 
DLL 2022-11-26 19:22:24.882011 - Iteration: 158  throughput_train : 4153.135 sequences/s mlm_loss : 8.5020  nsp_loss : 0.6686  total_loss : 9.1706  avg_loss_step : 9.1396  learning_rate : 0.000468  loss_scaler : 16777216 
DLL 2022-11-26 19:22:41.192454 - Iteration: 159  throughput_train : 4147.156 sequences/s mlm_loss : 8.5183  nsp_loss : 0.6439  total_loss : 9.1622  avg_loss_step : 9.1323  learning_rate : 0.000471  loss_scaler : 16777216 
DLL 2022-11-26 19:22:57.547838 - Iteration: 160  throughput_train : 4135.684 sequences/s mlm_loss : 8.4285  nsp_loss : 0.6680  total_loss : 9.0965  avg_loss_step : 9.1216  learning_rate : 0.00047400003  loss_scaler : 16777216 
DLL 2022-11-26 19:23:13.833535 - Iteration: 161  throughput_train : 4153.465 sequences/s mlm_loss : 8.5182  nsp_loss : 0.6485  total_loss : 9.1668  avg_loss_step : 9.0885  learning_rate : 0.00047700002  loss_scaler : 16777216 
DLL 2022-11-26 19:23:30.128196 - Iteration: 162  throughput_train : 4151.097 sequences/s mlm_loss : 8.4579  nsp_loss : 0.6706  total_loss : 9.1285  avg_loss_step : 9.0801  learning_rate : 0.00048000002  loss_scaler : 16777216 
DLL 2022-11-26 19:23:46.461261 - Iteration: 163  throughput_train : 4141.412 sequences/s mlm_loss : 8.4889  nsp_loss : 0.6062  total_loss : 9.0950  avg_loss_step : 9.0697  learning_rate : 0.000483  loss_scaler : 16777216 
DLL 2022-11-26 19:24:02.769554 - Iteration: 164  throughput_train : 4148.036 sequences/s mlm_loss : 8.5527  nsp_loss : 0.6152  total_loss : 9.1679  avg_loss_step : 9.0562  learning_rate : 0.000486  loss_scaler : 16777216 
DLL 2022-11-26 19:24:19.089373 - Iteration: 165  throughput_train : 4144.590 sequences/s mlm_loss : 8.3312  nsp_loss : 0.6484  total_loss : 8.9796  avg_loss_step : 9.0339  learning_rate : 0.000489  loss_scaler : 16777216 
DLL 2022-11-26 19:24:35.445063 - Iteration: 166  throughput_train : 4135.672 sequences/s mlm_loss : 8.4886  nsp_loss : 0.6312  total_loss : 9.1198  avg_loss_step : 9.0486  learning_rate : 0.000492  loss_scaler : 16777216 
DLL 2022-11-26 19:24:51.757198 - Iteration: 167  throughput_train : 4146.691 sequences/s mlm_loss : 8.3299  nsp_loss : 0.6537  total_loss : 8.9835  avg_loss_step : 9.0335  learning_rate : 0.00049500004  loss_scaler : 16777216 
DLL 2022-11-26 19:25:08.074044 - Iteration: 168  throughput_train : 4145.436 sequences/s mlm_loss : 8.1706  nsp_loss : 0.6720  total_loss : 8.8426  avg_loss_step : 9.0042  learning_rate : 0.000498  loss_scaler : 16777216 
DLL 2022-11-26 19:25:24.418247 - Iteration: 169  throughput_train : 4138.387 sequences/s mlm_loss : 8.3327  nsp_loss : 0.6589  total_loss : 8.9916  avg_loss_step : 8.9844  learning_rate : 0.00050100003  loss_scaler : 16777216 
DLL 2022-11-26 19:25:40.736690 - Iteration: 170  throughput_train : 4145.165 sequences/s mlm_loss : 8.3699  nsp_loss : 0.6309  total_loss : 9.0007  avg_loss_step : 8.9860  learning_rate : 0.000504  loss_scaler : 16777216 
DLL 2022-11-26 19:25:57.016751 - Iteration: 171  throughput_train : 4154.810 sequences/s mlm_loss : 8.4437  nsp_loss : 0.6720  total_loss : 9.1157  avg_loss_step : 8.9735  learning_rate : 0.000507  loss_scaler : 16777216 
DLL 2022-11-26 19:26:13.392710 - Iteration: 172  throughput_train : 4130.381 sequences/s mlm_loss : 8.3853  nsp_loss : 0.6408  total_loss : 9.0261  avg_loss_step : 8.9584  learning_rate : 0.00051000004  loss_scaler : 16777216 
DLL 2022-11-26 19:26:29.702650 - Iteration: 173  throughput_train : 4147.305 sequences/s mlm_loss : 8.2959  nsp_loss : 0.5747  total_loss : 8.8706  avg_loss_step : 8.9361  learning_rate : 0.000513  loss_scaler : 16777216 
DLL 2022-11-26 19:26:46.047135 - Iteration: 174  throughput_train : 4138.321 sequences/s mlm_loss : 8.2840  nsp_loss : 0.6814  total_loss : 8.9654  avg_loss_step : 8.9389  learning_rate : 0.00051600003  loss_scaler : 16777216 
DLL 2022-11-26 19:27:02.348591 - Iteration: 175  throughput_train : 4149.593 sequences/s mlm_loss : 8.3056  nsp_loss : 0.5984  total_loss : 8.9040  avg_loss_step : 8.9294  learning_rate : 0.000519  loss_scaler : 16777216 
DLL 2022-11-26 19:27:18.701694 - Iteration: 176  throughput_train : 4136.244 sequences/s mlm_loss : 8.3269  nsp_loss : 0.6469  total_loss : 8.9739  avg_loss_step : 8.9096  learning_rate : 0.000522  loss_scaler : 16777216 
DLL 2022-11-26 19:27:34.983440 - Iteration: 177  throughput_train : 4154.571 sequences/s mlm_loss : 8.1970  nsp_loss : 0.6162  total_loss : 8.8132  avg_loss_step : 8.8892  learning_rate : 0.00052500004  loss_scaler : 16777216 
DLL 2022-11-26 19:27:51.302660 - Iteration: 178  throughput_train : 4144.868 sequences/s mlm_loss : 8.1555  nsp_loss : 0.5941  total_loss : 8.7495  avg_loss_step : 8.8704  learning_rate : 0.000528  loss_scaler : 16777216 
DLL 2022-11-26 19:28:07.576454 - Iteration: 179  throughput_train : 4156.375 sequences/s mlm_loss : 8.1825  nsp_loss : 0.6247  total_loss : 8.8072  avg_loss_step : 8.8693  learning_rate : 0.000531  loss_scaler : 16777216 
DLL 2022-11-26 19:28:23.867144 - Iteration: 180  throughput_train : 4152.302 sequences/s mlm_loss : 8.1809  nsp_loss : 0.6689  total_loss : 8.8498  avg_loss_step : 8.8762  learning_rate : 0.000534  loss_scaler : 16777216 
DLL 2022-11-26 19:28:40.211463 - Iteration: 181  throughput_train : 4150.943 sequences/s mlm_loss : 8.0984  nsp_loss : 0.6660  total_loss : 8.7644  avg_loss_step : 8.8481  learning_rate : 0.000537  loss_scaler : 16777216 
INFO:tensorflow:Saving checkpoints for 180 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt.
I1126 19:28:40.212973 139662769284928 basic_session_run_hooks.py:606] Saving checkpoints for 180 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 8.96519.
I1126 19:28:41.093113 140580483716928 estimator.py:371] Loss for final step: 8.96519.
INFO:tensorflow:Loss for final step: 8.992294.
I1126 19:28:41.115050 139659189745472 estimator.py:371] Loss for final step: 8.992294.
INFO:tensorflow:Loss for final step: 8.760617.
I1126 19:28:41.141422 140620976506688 estimator.py:371] Loss for final step: 8.760617.
INFO:tensorflow:Loss for final step: 8.929044.
I1126 19:28:41.195162 139671492257600 estimator.py:371] Loss for final step: 8.929044.
INFO:tensorflow:Loss for final step: 8.795289.
I1126 19:28:41.201047 139713062618944 estimator.py:371] Loss for final step: 8.795289.
INFO:tensorflow:Loss for final step: 8.841921.
I1126 19:28:41.270371 140058966173504 estimator.py:371] Loss for final step: 8.841921.
INFO:tensorflow:Loss for final step: 8.687126.
I1126 19:28:41.291837 139767222495040 estimator.py:371] Loss for final step: 8.687126.
INFO:tensorflow:Loss for final step: 8.764396.
I1126 19:28:45.620105 139662769284928 estimator.py:371] Loss for final step: 8.764396.
INFO:tensorflow:-----------------------------
I1126 19:28:45.622227 139662769284928 run_pretraining.py:647] -----------------------------
INFO:tensorflow:Total Training Time = 3371.83 for Sentences = 12165120
I1126 19:28:45.622312 139662769284928 run_pretraining.py:649] Total Training Time = 3371.83 for Sentences = 12165120
INFO:tensorflow:Total Training Time W/O Overhead = 2919.87 for Sentences = 11286528
I1126 19:28:45.622380 139662769284928 run_pretraining.py:651] Total Training Time W/O Overhead = 2919.87 for Sentences = 11286528
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 3607.86
I1126 19:28:45.622444 139662769284928 run_pretraining.py:652] Throughput Average (sentences/sec) with overhead = 3607.86
INFO:tensorflow:Throughput Average (sentences/sec) = 3865.42
I1126 19:28:45.622508 139662769284928 run_pretraining.py:653] Throughput Average (sentences/sec) = 3865.42
DLL 2022-11-26 19:28:45.622563 -  throughput_train : 3865.420 sequences/s
DLL 2022-11-26 19:28:45.622699 -  total_loss : 8.8481 
INFO:tensorflow:-----------------------------
I1126 19:28:45.622762 139662769284928 run_pretraining.py:657] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1126 19:28:45.622860 139662769284928 run_pretraining.py:660] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1126 19:28:45.622910 139662769284928 run_pretraining.py:661]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1126 19:28:45.661677 139662769284928 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 19:28:45.661865 139662769284928 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1126 19:28:45.661993 139662769284928 run_pretraining.py:262]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1126 19:28:45.662067 139662769284928 run_pretraining.py:262]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1126 19:28:45.662136 139662769284928 run_pretraining.py:262]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1126 19:28:45.662201 139662769284928 run_pretraining.py:262]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1126 19:28:45.662266 139662769284928 run_pretraining.py:262]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1126 19:28:45.662328 139662769284928 run_pretraining.py:262]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1126 19:28:45.662389 139662769284928 run_pretraining.py:262]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:340: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1126 19:28:47.059640 139662769284928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:340: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:344: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1126 19:28:47.098279 139662769284928 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:344: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1126 19:28:47.158573 139662769284928 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2022-11-26T19:28:47Z
I1126 19:28:47.173968 139662769284928 evaluation.py:255] Starting evaluation at 2022-11-26T19:28:47Z
INFO:tensorflow:Graph was finalized.
I1126 19:28:47.456056 139662769284928 monitored_session.py:240] Graph was finalized.
2022-11-26 19:28:47.457200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 19:28:47.458110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2022-11-26 19:28:47.458168: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 19:28:47.458279: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 19:28:47.458305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 19:28:47.458322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 19:28:47.458338: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 19:28:47.458355: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 19:28:47.458374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 19:28:47.458474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 19:28:47.459310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 19:28:47.460075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2022-11-26 19:28:47.460122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 19:28:47.460133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-11-26 19:28:47.460139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-11-26 19:28:47.460253: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 19:28:47.461088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 19:28:47.461870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt-180
I1126 19:28:47.462919 139662769284928 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt-180
2022-11-26 19:28:47.604604: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:47.607206: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 19:28:48.128094: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:48.129738: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1126 19:28:48.297420 139662769284928 session_manager.py:500] Running local_init_op.
2022-11-26 19:28:48.338219: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:48.338599: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1126 19:28:48.594503 139662769284928 session_manager.py:502] Done running local_init_op.
2022-11-26 19:28:48.679823: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:48.681561: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 19:28:48.905604: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:48.905923: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 19:28:48.910103: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 19:28:48.912414: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-11-26 19:28:49.158567: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:49.168514: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 2026
Recognized nodes available for conversion: 1004
Total nodes converted: 276
Total FP16 Cast ops used (excluding Const and Variable casts): 39
Whitelisted nodes converted: 100
Blacklisted nodes blocking conversion: 139
Nodes blocked from conversion by blacklisted nodes: 239

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:Evaluation [10/100]
I1126 19:28:55.224921 139662769284928 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1126 19:28:55.333690 139662769284928 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1126 19:28:55.440310 139662769284928 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1126 19:28:55.545805 139662769284928 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1126 19:28:55.652070 139662769284928 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1126 19:28:55.757798 139662769284928 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1126 19:28:55.863051 139662769284928 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1126 19:28:55.969528 139662769284928 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1126 19:28:56.075178 139662769284928 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1126 19:28:56.181149 139662769284928 evaluation.py:167] Evaluation [100/100]
2022-11-26 19:28:56.243118: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-11-26 19:28:56.243497: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Finished evaluation at 2022-11-26-19:28:56
I1126 19:28:56.580246 139662769284928 evaluation.py:275] Finished evaluation at 2022-11-26-19:28:56
INFO:tensorflow:Saving dict for global step 180: global_step = 180, loss = 8.843297, masked_lm_accuracy = 0.09193665, masked_lm_loss = 8.144436, next_sentence_accuracy = 0.54249996, next_sentence_loss = 0.69950897
I1126 19:28:56.580833 139662769284928 estimator.py:2049] Saving dict for global step 180: global_step = 180, loss = 8.843297, masked_lm_accuracy = 0.09193665, masked_lm_loss = 8.144436, next_sentence_accuracy = 0.54249996, next_sentence_loss = 0.69950897
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 180: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt-180
I1126 19:28:56.899256 139662769284928 estimator.py:2109] Saving 'checkpoint_path' summary for global step 180: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_221126183230/phase_1/model.ckpt-180
INFO:tensorflow:-----------------------------
I1126 19:28:56.900168 139662769284928 run_pretraining.py:689] -----------------------------
INFO:tensorflow:Total Inference Time = 11.28 for Sentences = 800
I1126 19:28:56.900316 139662769284928 run_pretraining.py:691] Total Inference Time = 11.28 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 1.05 for Sentences = 792
I1126 19:28:56.900383 139662769284928 run_pretraining.py:693] Total Inference Time W/O Overhead = 1.05 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1126 19:28:56.900451 139662769284928 run_pretraining.py:694] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1126 19:28:56.900503 139662769284928 run_pretraining.py:695] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1126 19:28:56.900591 139662769284928 run_pretraining.py:696] Sequence Length = 128
INFO:tensorflow:Precision = fp16
I1126 19:28:56.900646 139662769284928 run_pretraining.py:697] Precision = fp16
INFO:tensorflow:Throughput Average (sentences/sec) = 750.88
I1126 19:28:56.900696 139662769284928 run_pretraining.py:698] Throughput Average (sentences/sec) = 750.88
DLL 2022-11-26 19:28:56.900764 -  throughput_val : 750.8827503210911 
INFO:tensorflow:-----------------------------
I1126 19:28:56.900920 139662769284928 run_pretraining.py:700] -----------------------------
INFO:tensorflow:***** Eval results *****
I1126 19:28:56.901047 139662769284928 run_pretraining.py:704] ***** Eval results *****
INFO:tensorflow:  global_step = 180
I1126 19:28:56.901105 139662769284928 run_pretraining.py:706]   global_step = 180
INFO:tensorflow:  loss = 8.843297
I1126 19:28:56.901336 139662769284928 run_pretraining.py:706]   loss = 8.843297
INFO:tensorflow:  masked_lm_accuracy = 0.09193665
I1126 19:28:56.901418 139662769284928 run_pretraining.py:706]   masked_lm_accuracy = 0.09193665
INFO:tensorflow:  masked_lm_loss = 8.144436
I1126 19:28:56.901465 139662769284928 run_pretraining.py:706]   masked_lm_loss = 8.144436
INFO:tensorflow:  next_sentence_accuracy = 0.54249996
I1126 19:28:56.901508 139662769284928 run_pretraining.py:706]   next_sentence_accuracy = 0.54249996
INFO:tensorflow:  next_sentence_loss = 0.69950897
I1126 19:28:56.901551 139662769284928 run_pretraining.py:706]   next_sentence_loss = 0.69950897
