Sun May 29 09:24:26 2022[1,0]<stdout>:DLL 2022-05-29 09:24:26.407978 - Iteration: 1  throughput_train : 1537.697 seq/s mlm_loss : 10.3920  nsp_loss : 0.6799  total_loss : 11.0719  avg_loss_step : 11.1088  learning_rate : 0.0  loss_scaler : 4294967296 
Sun May 29 09:24:41 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:24:41 2022[1,0]<stdout>:DLL 2022-05-29 09:24:41.946833 - Iteration: 1  throughput_train : 16817.724 seq/s mlm_loss : 10.3849  nsp_loss : 0.7301  total_loss : 11.1150  avg_loss_step : 11.1076  learning_rate : 0.0  loss_scaler : 2147483648 
Sun May 29 09:24:57 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:24:57 2022[1,0]<stdout>:DLL 2022-05-29 09:24:57.503702 - Iteration: 1  throughput_train : 16797.968 seq/s mlm_loss : 10.3884  nsp_loss : 0.7073  total_loss : 11.0958  avg_loss_step : 11.1049  learning_rate : 0.0  loss_scaler : 1073741824 
Sun May 29 09:25:13 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:25:13 2022[1,0]<stdout>:DLL 2022-05-29 09:25:13.419579 - Iteration: 1  throughput_train : 16418.729 seq/s mlm_loss : 10.4205  nsp_loss : 0.7051  total_loss : 11.1255  avg_loss_step : 11.1116  learning_rate : 0.0  loss_scaler : 536870912 
Sun May 29 09:25:29 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:25:29 2022[1,0]<stdout>:DLL 2022-05-29 09:25:29.400654 - Iteration: 1  throughput_train : 16351.545 seq/s mlm_loss : 10.3961  nsp_loss : 0.7299  total_loss : 11.1260  avg_loss_step : 11.1041  learning_rate : 0.0  loss_scaler : 268435456 
Sun May 29 09:25:45 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:25:45 2022[1,0]<stdout>:DLL 2022-05-29 09:25:45.380487 - Iteration: 1  throughput_train : 16353.038 seq/s mlm_loss : 10.4058  nsp_loss : 0.6905  total_loss : 11.0963  avg_loss_step : 11.1124  learning_rate : 0.0  loss_scaler : 134217728 
Sun May 29 09:26:01 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:26:01 2022[1,0]<stdout>:DLL 2022-05-29 09:26:01.405037 - Iteration: 1  throughput_train : 16307.322 seq/s mlm_loss : 10.3805  nsp_loss : 0.7062  total_loss : 11.0866  avg_loss_step : 11.1112  learning_rate : 0.0  loss_scaler : 67108864 
Sun May 29 09:27:46 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:27:46 2022[1,0]<stdout>:DLL 2022-05-29 09:27:46.840718 - Iteration: 1  throughput_train : 2476.871 seq/s mlm_loss : 10.4114  nsp_loss : 0.7106  total_loss : 11.1220  avg_loss_step : 11.1148  learning_rate : 0.0  loss_scaler : 33554432 
Sun May 29 09:28:08 2022[1,0]<stdout>:Skipping time record for  0  due to checkpoint-saving/warmup overhead
Sun May 29 09:28:08 2022[1,0]<stdout>:DLL 2022-05-29 09:28:08.507448 - Iteration: 1  throughput_train : 12058.514 seq/s mlm_loss : 10.3860  nsp_loss : 0.7210  total_loss : 11.1071  avg_loss_step : 11.1115  learning_rate : 0.0  loss_scaler : 16777216 
Sun May 29 09:29:02 2022[1,0]<stdout>:Skipping time record for  1  due to checkpoint-saving/warmup overhead
Sun May 29 09:29:02 2022[1,0]<stdout>:DLL 2022-05-29 09:29:02.934138 - Iteration: 2  throughput_train : 4798.740 seq/s mlm_loss : 10.4063  nsp_loss : 0.7044  total_loss : 11.1107  avg_loss_step : 11.1100  learning_rate : 0.0  loss_scaler : 8388608 
Sun May 29 09:29:18 2022[1,0]<stdout>:Skipping time record for  2  due to checkpoint-saving/warmup overhead
Sun May 29 09:29:18 2022[1,0]<stdout>:DLL 2022-05-29 09:29:18.609001 - Iteration: 3  throughput_train : 16671.702 seq/s mlm_loss : 10.3707  nsp_loss : 0.7224  total_loss : 11.0932  avg_loss_step : 11.1055  learning_rate : 1.2e-05  loss_scaler : 8388608 
Sun May 29 09:29:34 2022[1,0]<stdout>:Skipping time record for  3  due to checkpoint-saving/warmup overhead
Sun May 29 09:29:34 2022[1,0]<stdout>:DLL 2022-05-29 09:29:34.573342 - Iteration: 4  throughput_train : 16368.732 seq/s mlm_loss : 10.3981  nsp_loss : 0.7389  total_loss : 11.1370  avg_loss_step : 11.1012  learning_rate : 2.4e-05  loss_scaler : 8388608 
Sun May 29 09:29:50 2022[1,0]<stdout>:Skipping time record for  4  due to checkpoint-saving/warmup overhead
Sun May 29 09:29:50 2022[1,0]<stdout>:DLL 2022-05-29 09:29:50.608880 - Iteration: 5  throughput_train : 16296.066 seq/s mlm_loss : 10.3949  nsp_loss : 0.7047  total_loss : 11.0996  avg_loss_step : 11.0916  learning_rate : 3.6e-05  loss_scaler : 8388608 
Sun May 29 09:30:06 2022[1,0]<stdout>:Skipping time record for  5  due to checkpoint-saving/warmup overhead
Sun May 29 09:30:06 2022[1,0]<stdout>:DLL 2022-05-29 09:30:06.697459 - Iteration: 6  throughput_train : 16242.230 seq/s mlm_loss : 10.3457  nsp_loss : 0.7080  total_loss : 11.0536  avg_loss_step : 11.0739  learning_rate : 4.8e-05  loss_scaler : 8388608 
Sun May 29 09:30:22 2022[1,0]<stdout>:DLL 2022-05-29 09:30:22.823303 - Iteration: 7  throughput_train : 16204.734 seq/s mlm_loss : 10.3762  nsp_loss : 0.7055  total_loss : 11.0816  avg_loss_step : 11.0575  learning_rate : 6.0000002e-05  loss_scaler : 8388608 
Sun May 29 09:30:38 2022[1,0]<stdout>:DLL 2022-05-29 09:30:38.953842 - Iteration: 8  throughput_train : 16200.071 seq/s mlm_loss : 10.3055  nsp_loss : 0.6987  total_loss : 11.0042  avg_loss_step : 11.0336  learning_rate : 7.2e-05  loss_scaler : 8388608 
Sun May 29 09:30:55 2022[1,0]<stdout>:DLL 2022-05-29 09:30:55.115159 - Iteration: 9  throughput_train : 16169.041 seq/s mlm_loss : 10.3185  nsp_loss : 0.6803  total_loss : 10.9988  avg_loss_step : 11.0078  learning_rate : 8.4e-05  loss_scaler : 8388608 
Sun May 29 09:31:11 2022[1,0]<stdout>:DLL 2022-05-29 09:31:11.329963 - Iteration: 10  throughput_train : 16115.627 seq/s mlm_loss : 10.3115  nsp_loss : 0.6599  total_loss : 10.9714  avg_loss_step : 10.9867  learning_rate : 9.6e-05  loss_scaler : 8388608 
Sun May 29 09:31:27 2022[1,0]<stdout>:DLL 2022-05-29 09:31:27.507322 - Iteration: 11  throughput_train : 16152.932 seq/s mlm_loss : 10.2575  nsp_loss : 0.7052  total_loss : 10.9627  avg_loss_step : 10.9508  learning_rate : 0.00010800001  loss_scaler : 8388608 
Sun May 29 09:31:43 2022[1,0]<stdout>:DLL 2022-05-29 09:31:43.715667 - Iteration: 12  throughput_train : 16122.051 seq/s mlm_loss : 10.2536  nsp_loss : 0.6920  total_loss : 10.9456  avg_loss_step : 10.9352  learning_rate : 0.000120000004  loss_scaler : 8388608 
Sun May 29 09:31:59 2022[1,0]<stdout>:DLL 2022-05-29 09:31:59.945184 - Iteration: 13  throughput_train : 16101.023 seq/s mlm_loss : 10.2313  nsp_loss : 0.6183  total_loss : 10.8496  avg_loss_step : 10.8950  learning_rate : 0.000132  loss_scaler : 8388608 
Sun May 29 09:32:16 2022[1,0]<stdout>:DLL 2022-05-29 09:32:16.191674 - Iteration: 14  throughput_train : 16084.320 seq/s mlm_loss : 10.1203  nsp_loss : 0.6387  total_loss : 10.7590  avg_loss_step : 10.8559  learning_rate : 0.000144  loss_scaler : 8388608 
Sun May 29 09:32:32 2022[1,0]<stdout>:DLL 2022-05-29 09:32:32.451014 - Iteration: 15  throughput_train : 16071.816 seq/s mlm_loss : 10.1199  nsp_loss : 0.7293  total_loss : 10.8491  avg_loss_step : 10.8165  learning_rate : 0.00015600001  loss_scaler : 8388608 
Sun May 29 09:32:48 2022[1,0]<stdout>:DLL 2022-05-29 09:32:48.673321 - Iteration: 16  throughput_train : 16108.165 seq/s mlm_loss : 10.0642  nsp_loss : 0.7249  total_loss : 10.7891  avg_loss_step : 10.7764  learning_rate : 0.000168  loss_scaler : 8388608 
Sun May 29 09:33:04 2022[1,0]<stdout>:DLL 2022-05-29 09:33:04.950518 - Iteration: 17  throughput_train : 16053.925 seq/s mlm_loss : 10.0781  nsp_loss : 0.7008  total_loss : 10.7788  avg_loss_step : 10.7498  learning_rate : 0.00018  loss_scaler : 8388608 
Sun May 29 09:33:21 2022[1,0]<stdout>:DLL 2022-05-29 09:33:21.211856 - Iteration: 18  throughput_train : 16069.474 seq/s mlm_loss : 9.9618  nsp_loss : 0.7090  total_loss : 10.6707  avg_loss_step : 10.6698  learning_rate : 0.000192  loss_scaler : 8388608 
Sun May 29 09:33:37 2022[1,0]<stdout>:DLL 2022-05-29 09:33:37.469771 - Iteration: 19  throughput_train : 16072.789 seq/s mlm_loss : 9.9691  nsp_loss : 0.6691  total_loss : 10.6382  avg_loss_step : 10.6194  learning_rate : 0.00020400001  loss_scaler : 8388608 
Sun May 29 09:33:53 2022[1,0]<stdout>:DLL 2022-05-29 09:33:53.741922 - Iteration: 20  throughput_train : 16058.830 seq/s mlm_loss : 9.9515  nsp_loss : 0.6702  total_loss : 10.6216  avg_loss_step : 10.5876  learning_rate : 0.00021600001  loss_scaler : 8388608 
Sun May 29 09:34:09 2022[1,0]<stdout>:DLL 2022-05-29 09:34:09.983326 - Iteration: 21  throughput_train : 16089.536 seq/s mlm_loss : 9.8300  nsp_loss : 0.6888  total_loss : 10.5189  avg_loss_step : 10.5432  learning_rate : 0.000228  loss_scaler : 8388608 
Sun May 29 09:34:26 2022[1,0]<stdout>:DLL 2022-05-29 09:34:26.205801 - Iteration: 22  throughput_train : 16108.247 seq/s mlm_loss : 9.8464  nsp_loss : 0.6847  total_loss : 10.5311  avg_loss_step : 10.5028  learning_rate : 0.00024000001  loss_scaler : 8388608 
Sun May 29 09:34:42 2022[1,0]<stdout>:DLL 2022-05-29 09:34:42.460928 - Iteration: 23  throughput_train : 16075.798 seq/s mlm_loss : 9.8402  nsp_loss : 0.6847  total_loss : 10.5249  avg_loss_step : 10.4600  learning_rate : 0.000252  loss_scaler : 8388608 
Sun May 29 09:34:58 2022[1,0]<stdout>:DLL 2022-05-29 09:34:58.722605 - Iteration: 24  throughput_train : 16069.138 seq/s mlm_loss : 9.7496  nsp_loss : 0.6894  total_loss : 10.4391  avg_loss_step : 10.4284  learning_rate : 0.000264  loss_scaler : 8388608 
Sun May 29 09:35:14 2022[1,0]<stdout>:DLL 2022-05-29 09:35:14.968285 - Iteration: 25  throughput_train : 16084.973 seq/s mlm_loss : 9.6531  nsp_loss : 0.6798  total_loss : 10.3329  avg_loss_step : 10.3870  learning_rate : 0.000276  loss_scaler : 8388608 
Sun May 29 09:35:31 2022[1,0]<stdout>:DLL 2022-05-29 09:35:31.240999 - Iteration: 26  throughput_train : 16058.285 seq/s mlm_loss : 9.6499  nsp_loss : 0.7019  total_loss : 10.3518  avg_loss_step : 10.3442  learning_rate : 0.000288  loss_scaler : 8388608 
Sun May 29 09:35:47 2022[1,0]<stdout>:DLL 2022-05-29 09:35:47.520711 - Iteration: 27  throughput_train : 16051.381 seq/s mlm_loss : 9.5734  nsp_loss : 0.7234  total_loss : 10.2969  avg_loss_step : 10.2957  learning_rate : 0.0003  loss_scaler : 8388608 
Sun May 29 09:36:03 2022[1,0]<stdout>:DLL 2022-05-29 09:36:03.880354 - Iteration: 28  throughput_train : 16015.090 seq/s mlm_loss : 9.5780  nsp_loss : 0.6549  total_loss : 10.2329  avg_loss_step : 10.2756  learning_rate : 0.00031200002  loss_scaler : 8388608 
