+ batch_size=32
+ num_gpus=8
+ precision=fp32
++ expr 67584 / 32 / 8
+ num_accumulation_steps_phase1=264
+ train_steps=100
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 32 64 8 7.5e-4 5e-4 fp32 true 8 2000 200 100 200 264 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726
Logs written to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144.211217121726.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2021-12-17 12:17:27.279547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279716: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279725: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:27.279722: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

--------------------------------------------------------------------------
[[23301,1],6]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.273979 140273021019968 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274007 139761270613824 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274080 140031798708032 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274169 140296910014272 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274234 140234784094016 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274225 140519955982144 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274419 139644968515392 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1217 12:17:29.274641 139972812793664 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c4da21978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.287904 139972812793664 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4c4da21978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4c4da2b0d0>) includes params argument, but params are not passed to Estimator.
W1217 12:17:30.288615 139972812793664 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4c4da2b0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:17:30.289009 139972812793664 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 12:17:30.289072 139972812793664 run_pretraining.py:626]   Batch size = 32
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5a0977a9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.300644 140031798708032 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5a0977a9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5a097850d0>) includes params argument, but params are not passed to Estimator.
W1217 12:17:30.301536 140031798708032 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5a097850d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:17:30.302076 140031798708032 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 12:17:30.302169 140031798708032 run_pretraining.py:626]   Batch size = 32
INFO:tensorflow:***** Configuaration *****
I1217 12:17:30.323122 140234784094016 run_pretraining.py:579] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1217 12:17:30.323338 140234784094016 run_pretraining.py:581]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1217 12:17:30.323402 140234784094016 run_pretraining.py:581]   alsologtostderr: False
INFO:tensorflow:  log_dir: 
I1217 12:17:30.323455 140234784094016 run_pretraining.py:581]   log_dir: 
INFO:tensorflow:  v: 0
I1217 12:17:30.323505 140234784094016 run_pretraining.py:581]   v: 0
INFO:tensorflow:  verbosity: 0
I1217 12:17:30.323574 140234784094016 run_pretraining.py:581]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1217 12:17:30.323620 140234784094016 run_pretraining.py:581]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1217 12:17:30.323665 140234784094016 run_pretraining.py:581]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1217 12:17:30.323716 140234784094016 run_pretraining.py:581]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1217 12:17:30.323761 140234784094016 run_pretraining.py:581]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1217 12:17:30.323806 140234784094016 run_pretraining.py:581]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1217 12:17:30.323853 140234784094016 run_pretraining.py:581]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1217 12:17:30.323897 140234784094016 run_pretraining.py:581]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1217 12:17:30.323944 140234784094016 run_pretraining.py:581]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1217 12:17:30.323990 140234784094016 run_pretraining.py:581]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1217 12:17:30.324036 140234784094016 run_pretraining.py:581]   test_random_seed: 301
INFO:tensorflow:  test_srcdir: 
I1217 12:17:30.324087 140234784094016 run_pretraining.py:581]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1217 12:17:30.324132 140234784094016 run_pretraining.py:581]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed: 
I1217 12:17:30.324177 140234784094016 run_pretraining.py:581]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I1217 12:17:30.324220 140234784094016 run_pretraining.py:581]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1217 12:17:30.324265 140234784094016 run_pretraining.py:581]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1217 12:17:30.324311 140234784094016 run_pretraining.py:581]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1217 12:17:30.324358 140234784094016 run_pretraining.py:581]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1
I1217 12:17:30.324404 140234784094016 run_pretraining.py:581]   output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1217 12:17:30.324448 140234784094016 run_pretraining.py:581]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1217 12:17:30.324493 140234784094016 run_pretraining.py:581]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1217 12:17:30.324548 140234784094016 run_pretraining.py:581]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1217 12:17:30.324593 140234784094016 run_pretraining.py:581]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1217 12:17:30.324638 140234784094016 run_pretraining.py:581]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1217 12:17:30.324683 140234784094016 run_pretraining.py:581]   do_train: True
INFO:tensorflow:  do_eval: False
I1217 12:17:30.324733 140234784094016 run_pretraining.py:581]   do_eval: False
INFO:tensorflow:  train_batch_size: 32
I1217 12:17:30.324778 140234784094016 run_pretraining.py:581]   train_batch_size: 32
INFO:tensorflow:  eval_batch_size: 8
I1217 12:17:30.324823 140234784094016 run_pretraining.py:581]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1217 12:17:30.324870 140234784094016 run_pretraining.py:581]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 90
I1217 12:17:30.324915 140234784094016 run_pretraining.py:581]   num_train_steps: 90
INFO:tensorflow:  num_warmup_steps: 2000
I1217 12:17:30.324960 140234784094016 run_pretraining.py:581]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1217 12:17:30.325005 140234784094016 run_pretraining.py:581]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1217 12:17:30.325050 140234784094016 run_pretraining.py:581]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1217 12:17:30.325093 140234784094016 run_pretraining.py:581]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1217 12:17:30.325142 140234784094016 run_pretraining.py:581]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 264
I1217 12:17:30.325186 140234784094016 run_pretraining.py:581]   num_accumulation_steps: 264
INFO:tensorflow:  allreduce_post_accumulation: True
I1217 12:17:30.325231 140234784094016 run_pretraining.py:581]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1217 12:17:30.325276 140234784094016 run_pretraining.py:581]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1217 12:17:30.325320 140234784094016 run_pretraining.py:581]   horovod: True
INFO:tensorflow:  report_loss: True
I1217 12:17:30.325363 140234784094016 run_pretraining.py:581]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1217 12:17:30.325408 140234784094016 run_pretraining.py:581]   manual_fp16: False
INFO:tensorflow:  amp: False
I1217 12:17:30.325452 140234784094016 run_pretraining.py:581]   amp: False
INFO:tensorflow:  use_xla: True
I1217 12:17:30.325495 140234784094016 run_pretraining.py:581]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1217 12:17:30.325559 140234784094016 run_pretraining.py:581]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1217 12:17:30.325606 140234784094016 run_pretraining.py:581]   ?: False
INFO:tensorflow:  help: False
I1217 12:17:30.325650 140234784094016 run_pretraining.py:581]   help: False
INFO:tensorflow:  helpshort: False
I1217 12:17:30.326131 140234784094016 run_pretraining.py:581]   helpshort: False
INFO:tensorflow:  helpfull: False
I1217 12:17:30.326212 140234784094016 run_pretraining.py:581]   helpfull: False
INFO:tensorflow:  helpxml: False
I1217 12:17:30.326261 140234784094016 run_pretraining.py:581]   helpxml: False
INFO:tensorflow:**************************
I1217 12:17:30.326304 140234784094016 run_pretraining.py:582] **************************
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efff8974978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.326174 139644968515392 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efff8974978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbb1e889e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9233701a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.326478 140519955982144 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcbb1e889e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.326565 140273021019968 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9233701a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b0cbc8978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7efff897e0d0>) includes params argument, but params are not passed to Estimator.
I1217 12:17:30.326631 139761270613824 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b0cbc8978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W1217 12:17:30.326935 139644968515392 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7efff897e0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f894c56d908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.326785 140234784094016 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f894c56d908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Running training *****
I1217 12:17:30.327295 139644968515392 run_pretraining.py:625] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcbb1e930d0>) includes params argument, but params are not passed to Estimator.
W1217 12:17:30.327179 140519955982144 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcbb1e930d0>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f923370b0d0>) includes params argument, but params are not passed to Estimator.
W1217 12:17:30.327239 140273021019968 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f923370b0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  Batch size = 32
INFO:tensorflow:***** Running training *****
I1217 12:17:30.327357 139644968515392 run_pretraining.py:626]   Batch size = 32
I1217 12:17:30.327569 140519955982144 run_pretraining.py:625] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1b0cbd20d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
W1217 12:17:30.327351 139761270613824 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1b0cbd20d0>) includes params argument, but params are not passed to Estimator.
I1217 12:17:30.327615 140273021019968 run_pretraining.py:625] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f894c5781e0>) includes params argument, but params are not passed to Estimator.
W1217 12:17:30.327394 140234784094016 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f894c5781e0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:17:30.327741 139761270613824 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:***** Running training *****
I1217 12:17:30.327788 140234784094016 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 12:17:30.327633 140519955982144 run_pretraining.py:626]   Batch size = 32
INFO:tensorflow:  Batch size = 32
I1217 12:17:30.327676 140273021019968 run_pretraining.py:626]   Batch size = 32
INFO:tensorflow:  Batch size = 32
I1217 12:17:30.327810 139761270613824 run_pretraining.py:626]   Batch size = 32
INFO:tensorflow:  Batch size = 32
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f97c3553978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1217 12:17:30.327850 140234784094016 run_pretraining.py:626]   Batch size = 32
I1217 12:17:30.327225 140296910014272 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f97c3553978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f97c355d0d0>) includes params argument, but params are not passed to Estimator.
W1217 12:17:30.328366 140296910014272 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f97c355d0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1217 12:17:30.329023 140296910014272 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 32
I1217 12:17:30.329143 140296910014272 run_pretraining.py:626]   Batch size = 32
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.384244 139972812793664 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.422486 140519955982144 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.422852 139644968515392 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.423535 140273021019968 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.424340 140234784094016 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.425579 139761270613824 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.426750 140031798708032 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1217 12:17:30.444198 140296910014272 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1217 12:17:30.486500 139972812793664 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:17:30.486696 139972812793664 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 12:17:30.486802 139972812793664 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.486874 139972812793664 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.486939 139972812793664 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.487001 139972812793664 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.487061 139972812793664 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.487119 139972812793664 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 12:17:30.487177 139972812793664 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.487357 139972812793664 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:17:30.488355 139972812793664 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Calling model_fn.
I1217 12:17:30.525498 139644968515392 estimator.py:1148] Calling model_fn.
I1217 12:17:30.525494 140519955982144 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:17:30.525675 139644968515392 run_pretraining.py:258] *** Features ***
INFO:tensorflow:*** Features ***
I1217 12:17:30.525676 140519955982144 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 12:17:30.525772 139644968515392 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
I1217 12:17:30.525776 140519955982144 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.525843 139644968515392 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
I1217 12:17:30.525842 140519955982144 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.525907 139644968515392 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.525907 140519955982144 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.525967 139644968515392 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.525966 140519955982144 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.526025 139644968515392 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.526026 140519955982144 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.526083 139644968515392 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.526082 140519955982144 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 12:17:30.526139 140519955982144 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
I1217 12:17:30.526137 139644968515392 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.526313 140519955982144 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.526318 139644968515392 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1217 12:17:30.527088 140234784094016 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:17:30.527258 140234784094016 run_pretraining.py:258] *** Features ***
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = input_ids, shape = (32, 128)
W1217 12:17:30.527291 139644968515392 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1217 12:17:30.527349 140234784094016 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
W1217 12:17:30.527289 140519955982144 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.527414 140234784094016 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.527479 140234784094016 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.527552 140234784094016 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.527612 140234784094016 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.527669 140234784094016 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 12:17:30.527738 140234784094016 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.527916 140234784094016 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:17:30.528903 140234784094016 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 12:17:30.529344 140031798708032 estimator.py:1148] Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:17:30.529517 140031798708032 run_pretraining.py:258] *** Features ***
I1217 12:17:30.529467 139761270613824 estimator.py:1148] Calling model_fn.
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 12:17:30.529623 140031798708032 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
INFO:tensorflow:*** Features ***
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.529655 139761270613824 run_pretraining.py:258] *** Features ***
I1217 12:17:30.529689 140031798708032 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.529764 139761270613824 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
I1217 12:17:30.529758 140031798708032 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.529823 140031798708032 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.529834 139761270613824 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.529882 140031798708032 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.529897 139761270613824 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.529940 140031798708032 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.529958 139761270613824 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.529996 140031798708032 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
I1217 12:17:30.530015 139761270613824 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.530071 139761270613824 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 12:17:30.530133 139761270613824 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.530178 140031798708032 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.530317 139761270613824 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:17:30.531171 140031798708032 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:17:30.531368 139761270613824 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 12:17:30.547008 140296910014272 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:17:30.547185 140296910014272 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 12:17:30.547278 140296910014272 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.547352 140296910014272 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.547418 140296910014272 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.547481 140296910014272 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.547557 140296910014272 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.547618 140296910014272 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 12:17:30.547676 140296910014272 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.547861 140296910014272 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:17:30.548847 140296910014272 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1217 12:17:30.549867 140273021019968 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 12:17:30.550032 140273021019968 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (32, 128)
I1217 12:17:30.550123 140273021019968 run_pretraining.py:260]   name = input_ids, shape = (32, 128)
INFO:tensorflow:  name = input_mask, shape = (32, 128)
I1217 12:17:30.550194 140273021019968 run_pretraining.py:260]   name = input_mask, shape = (32, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (32, 20)
I1217 12:17:30.550258 140273021019968 run_pretraining.py:260]   name = masked_lm_ids, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (32, 20)
I1217 12:17:30.550319 140273021019968 run_pretraining.py:260]   name = masked_lm_positions, shape = (32, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (32, 20)
I1217 12:17:30.550379 140273021019968 run_pretraining.py:260]   name = masked_lm_weights, shape = (32, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (32, 1)
I1217 12:17:30.550436 140273021019968 run_pretraining.py:260]   name = next_sentence_labels, shape = (32, 1)
INFO:tensorflow:  name = segment_ids, shape = (32, 128)
I1217 12:17:30.550493 140273021019968 run_pretraining.py:260]   name = segment_ids, shape = (32, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1217 12:17:30.550680 140273021019968 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1217 12:17:30.551638 140273021019968 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.912183 139972812793664 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.955359 139644968515392 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.959070 140519955982144 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.967895 140234784094016 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.974168 140273021019968 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.975244 140031798708032 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:31.995713 140296910014272 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1217 12:17:32.079448 139761270613824 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.704347 139972812793664 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.760844 139644968515392 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.774728 140519955982144 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.783918 140273021019968 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.793986 140234784094016 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.813233 140031798708032 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:34.823471 140296910014272 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1217 12:17:35.126667 139761270613824 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.072434 139972812793664 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.122268 139644968515392 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.207401 140234784094016 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1217 12:17:42.208491 140234784094016 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.286154 140273021019968 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.312104 140296910014272 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.329236 140031798708032 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:42.367090 140519955982144 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1217 12:17:43.281447 139761270613824 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1217 12:17:46.568762 139972812793664 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:46.579499: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:46.584768: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562ef20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:46.584791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:46.587756: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:17:46.590714 139644968515392 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:46.602195: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:46.606510: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x553cd10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:46.606551: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:46.609322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:17:46.681573 140234784094016 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:46.693737: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:46.699530: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6761070 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:46.699556: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:46.703207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:17:46.910106 140296910014272 monitored_session.py:240] Graph was finalized.
INFO:tensorflow:Graph was finalized.
I1217 12:17:46.912390 140031798708032 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:46.923239: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:46.923691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:46.928851: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f32a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:46.928884: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:46.928969: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11506610 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:46.929004: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:46.931952: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-17 12:17:46.932197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1217 12:17:47.003856 140273021019968 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:47.022131: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
INFO:tensorflow:Graph was finalized.
I1217 12:17:47.025620 140519955982144 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:47.027124: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12688430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.027186: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:47.031781: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-17 12:17:47.038038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:47.043159: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6847740 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.043192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:47.046465: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-17 12:17:47.600142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.636576: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54bf990 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.636615: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.640697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.648652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:05:00.0
2021-12-17 12:17:47.648715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.704479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.705630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.716536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5632c50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.716567: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.717119: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x66e3f30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.717144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.718424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.718897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.731703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
2021-12-17 12:17:47.731759: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.732066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2021-12-17 12:17:47.732108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.781777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.787040: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5459f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.787090: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.788476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.796198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
2021-12-17 12:17:47.796261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.801720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.805540: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.805814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.806195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.806654: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e7f4c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.806682: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.807661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.808101: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.814936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0a:00.0
2021-12-17 12:17:47.814996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.817806: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.824494: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.824482: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.824598: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.824636: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.825147: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.841547: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.841549: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.841550: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.841584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.841647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.862894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.864731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.865070: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.865489: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x129c0520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.865532: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.865827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.866205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.866234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.866687: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.869091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:09:00.0
2021-12-17 12:17:47.869136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.869141: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.871653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x57f13c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:47.871680: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:47.871957: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.871963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.872001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.872277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.872342: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.872710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.872780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.872993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.873008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.873013: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.873037: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.873066: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.873136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.873160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.873181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.873210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.873224: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.873742: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.874080: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.876417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
2021-12-17 12:17:47.876461: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.876721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.877286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.877485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.877623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.880740: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:47.882674: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:47.883068: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:47.885543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.885610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.885699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.885763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.885850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.886980: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:47.887813: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:47.888023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:47.888152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.889854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.900213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2021-12-17 12:17:47.900264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.900348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2021-12-17 12:17:47.900396: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.900416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-12-17 12:17:47.900462: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.900602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2021-12-17 12:17:47.900650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.900693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2021-12-17 12:17:47.900734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.902837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:47.910914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2021-12-17 12:17:47.910981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:47.918237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2021-12-17 12:17:47.918278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1217 12:17:48.148512 139761270613824 monitored_session.py:240] Graph was finalized.
2021-12-17 12:17:48.161837: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-17 12:17:48.167424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x677d250 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:48.167471: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-17 12:17:48.171194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-17 12:17:48.401166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.404741: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x135962b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-17 12:17:48.404781: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-17 12:17:48.405503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.407792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:06:00.0
2021-12-17 12:17:48.407854: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:48.411182: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:17:48.412619: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-17 12:17:48.412970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-17 12:17:48.415818: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-17 12:17:48.416414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-17 12:17:48.416639: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:17:48.416803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.419471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.421988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2021-12-17 12:17:48.422038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-17 12:17:48.466677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.466724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2021-12-17 12:17:48.466735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2021-12-17 12:17:48.467117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.468274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.468321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2021-12-17 12:17:48.468331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2021-12-17 12:17:48.469645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.470787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.473580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.475864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
2021-12-17 12:17:48.476226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.476261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2021-12-17 12:17:48.476270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2021-12-17 12:17:48.477246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.477617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
2021-12-17 12:17:48.479852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.482471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2021-12-17 12:17:48.483383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.483417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2021-12-17 12:17:48.483427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2021-12-17 12:17:48.484246: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.486679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.489332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
2021-12-17 12:17:48.589816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.589882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2021-12-17 12:17:48.589893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2021-12-17 12:17:48.590288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.592543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.594639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2021-12-17 12:17:48.639841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.639885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2021-12-17 12:17:48.639894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2021-12-17 12:17:48.640208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.640701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.640749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2021-12-17 12:17:48.640758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2021-12-17 12:17:48.642170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.642398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.646743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.646810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2021-12-17 12:17:48.648770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
2021-12-17 12:17:48.838780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-17 12:17:48.838843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2021-12-17 12:17:48.838855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2021-12-17 12:17:48.839167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.841325: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-17 12:17:48.843326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
2021-12-17 12:17:54.728777: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:54.769572: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:54.800247: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:54.878107: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:54.999480: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:55.066808: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:55.135122: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-17 12:17:55.694330: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1217 12:17:59.492134 139972812793664 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:17:59.584126 140296910014272 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:17:59.688670 140519955982144 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:17:59.737927 140031798708032 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:17:59.835144 140273021019968 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:17:59.866355 139761270613824 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:18:00.046187 139644968515392 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.054301 139972812793664 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.143263 140296910014272 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.238741 140519955982144 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.331457 140031798708032 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.409532 140273021019968 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.425931 139761270613824 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1217 12:18:00.547312 140234784094016 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:00.704207 139644968515392 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 12:18:01.121464 140234784094016 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1/model.ckpt.
I1217 12:18:12.332400 140234784094016 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1217 12:18:23.955743 140234784094016 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2021-12-17 12:18:38.360457: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:38.930660: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:39.358090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:39.897555: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:41.130192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:41.512780: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:41.589676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:41.650195: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:41.710199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:42.060634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:42.114853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:42.129601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:42.202328: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:42.659216: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-17 12:18:43.283123: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-17 12:18:43.503179: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:43.513288: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:43.513385: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:43.517955: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:43.519180: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:43.578449: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:43.590676: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:44.137504: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-17 12:18:44.191427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
INFO:tensorflow:loss = 11.145636, step = 0
I1217 12:19:02.312496 140031798708032 basic_session_run_hooks.py:262] loss = 11.145636, step = 0
INFO:tensorflow:loss = 11.193846, step = 0
I1217 12:19:02.865633 140519955982144 basic_session_run_hooks.py:262] loss = 11.193846, step = 0
INFO:tensorflow:loss = 11.125649, step = 0
I1217 12:19:03.130389 140296910014272 basic_session_run_hooks.py:262] loss = 11.125649, step = 0
INFO:tensorflow:loss = 11.155201, step = 0
I1217 12:19:03.619628 139761270613824 basic_session_run_hooks.py:262] loss = 11.155201, step = 0
INFO:tensorflow:loss = 11.130019, step = 0
I1217 12:19:04.391200 139644968515392 basic_session_run_hooks.py:262] loss = 11.130019, step = 0
INFO:tensorflow:loss = 11.128104, step = 0
I1217 12:19:05.038098 140273021019968 basic_session_run_hooks.py:262] loss = 11.128104, step = 0
INFO:tensorflow:loss = 11.148576, step = 0
I1217 12:19:05.160720 139972812793664 basic_session_run_hooks.py:262] loss = 11.148576, step = 0
INFO:tensorflow:loss = 11.116394, step = 0
I1217 12:19:06.873439 140234784094016 basic_session_run_hooks.py:262] loss = 11.116394, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:38.367077 140296910014272 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:38.368226 140519955982144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:38.375810 140031798708032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:38.377272 140273021019968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:38.964149 139972812793664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:38.999054 139644968515392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:39.435756 139761270613824 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.044582 140234784094016 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.059496 140296910014272 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.059558 140031798708032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.059632 139761270613824 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.059663 140273021019968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.059586 139972812793664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.059734 140519955982144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.060397 139644968515392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.286405 140234784094016 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.302663 140031798708032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.302683 140519955982144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.302710 139761270613824 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.302710 139972812793664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.302843 140296910014272 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.302807 139644968515392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.303435 140273021019968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.506587 140234784094016 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.535431 140273021019968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.535584 140031798708032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.535581 139761270613824 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.535624 140519955982144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.535736 140296910014272 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.535856 139644968515392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.539425 139972812793664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.727148 140234784094016 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763634 140296910014272 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763724 139972812793664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763712 140519955982144 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763751 140031798708032 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763754 140273021019968 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763944 139761270613824 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.763985 139644968515392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1217 12:19:43.945885 140234784094016 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2021-12-17 12:21:08.379412 - Iteration: 2  throughput_train : 413.230 seq/s mlm_loss : 10.4390  nsp_loss : 0.7055  total_loss : 11.1445  avg_loss_step : 11.1592  learning_rate : 0.0 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2021-12-17 12:22:10.418990 - Iteration: 3  throughput_train : 1089.978 seq/s mlm_loss : 10.4501  nsp_loss : 0.7355  total_loss : 11.1856  avg_loss_step : 11.1657  learning_rate : 3e-06 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2021-12-17 12:23:11.251628 - Iteration: 4  throughput_train : 1111.627 seq/s mlm_loss : 10.4563  nsp_loss : 0.6975  total_loss : 11.1538  avg_loss_step : 11.1587  learning_rate : 6e-06 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2021-12-17 12:24:12.017572 - Iteration: 5  throughput_train : 1113.102 seq/s mlm_loss : 10.4146  nsp_loss : 0.7548  total_loss : 11.1693  avg_loss_step : 11.1593  learning_rate : 9e-06 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2021-12-17 12:25:13.005545 - Iteration: 6  throughput_train : 1108.828 seq/s mlm_loss : 10.4438  nsp_loss : 0.7063  total_loss : 11.1501  avg_loss_step : 11.1551  learning_rate : 1.2e-05 
DLL 2021-12-17 12:26:13.605186 - Iteration: 7  throughput_train : 1115.874 seq/s mlm_loss : 10.4332  nsp_loss : 0.7078  total_loss : 11.1410  avg_loss_step : 11.1488  learning_rate : 1.50000005e-05 
DLL 2021-12-17 12:27:14.197700 - Iteration: 8  throughput_train : 1116.066 seq/s mlm_loss : 10.4454  nsp_loss : 0.6931  total_loss : 11.1385  avg_loss_step : 11.1464  learning_rate : 1.8e-05 
DLL 2021-12-17 12:28:15.108151 - Iteration: 9  throughput_train : 1110.185 seq/s mlm_loss : 10.4298  nsp_loss : 0.7290  total_loss : 11.1588  avg_loss_step : 11.1389  learning_rate : 2.1e-05 
DLL 2021-12-17 12:29:16.032034 - Iteration: 10  throughput_train : 1109.937 seq/s mlm_loss : 10.4253  nsp_loss : 0.6981  total_loss : 11.1234  avg_loss_step : 11.1293  learning_rate : 2.4e-05 
DLL 2021-12-17 12:30:16.537311 - Iteration: 11  throughput_train : 1117.637 seq/s mlm_loss : 10.4053  nsp_loss : 0.6945  total_loss : 11.0998  avg_loss_step : 11.1152  learning_rate : 2.7000002e-05 
DLL 2021-12-17 12:31:17.478073 - Iteration: 12  throughput_train : 1109.686 seq/s mlm_loss : 10.4225  nsp_loss : 0.6881  total_loss : 11.1107  avg_loss_step : 11.1076  learning_rate : 3.0000001e-05 
DLL 2021-12-17 12:32:18.417997 - Iteration: 13  throughput_train : 1109.660 seq/s mlm_loss : 10.4139  nsp_loss : 0.7044  total_loss : 11.1183  avg_loss_step : 11.0978  learning_rate : 3.3e-05 
DLL 2021-12-17 12:33:19.431619 - Iteration: 14  throughput_train : 1108.387 seq/s mlm_loss : 10.3864  nsp_loss : 0.6829  total_loss : 11.0693  avg_loss_step : 11.0805  learning_rate : 3.6e-05 
DLL 2021-12-17 12:34:20.186880 - Iteration: 15  throughput_train : 1113.157 seq/s mlm_loss : 10.4274  nsp_loss : 0.6744  total_loss : 11.1018  avg_loss_step : 11.0718  learning_rate : 3.9000002e-05 
DLL 2021-12-17 12:35:20.896363 - Iteration: 16  throughput_train : 1113.875 seq/s mlm_loss : 10.4041  nsp_loss : 0.7117  total_loss : 11.1158  avg_loss_step : 11.0652  learning_rate : 4.2e-05 
DLL 2021-12-17 12:36:21.723709 - Iteration: 17  throughput_train : 1111.721 seq/s mlm_loss : 10.3698  nsp_loss : 0.6937  total_loss : 11.0635  avg_loss_step : 11.0520  learning_rate : 4.5e-05 
DLL 2021-12-17 12:37:22.684781 - Iteration: 18  throughput_train : 1109.307 seq/s mlm_loss : 10.3928  nsp_loss : 0.6616  total_loss : 11.0544  avg_loss_step : 11.0316  learning_rate : 4.8e-05 
DLL 2021-12-17 12:38:23.450714 - Iteration: 19  throughput_train : 1112.822 seq/s mlm_loss : 10.3236  nsp_loss : 0.6922  total_loss : 11.0158  avg_loss_step : 11.0216  learning_rate : 5.1000003e-05 
DLL 2021-12-17 12:39:23.993815 - Iteration: 20  throughput_train : 1116.958 seq/s mlm_loss : 10.3397  nsp_loss : 0.7253  total_loss : 11.0650  avg_loss_step : 11.0034  learning_rate : 5.4000004e-05 
DLL 2021-12-17 12:40:24.861509 - Iteration: 21  throughput_train : 1111.040 seq/s mlm_loss : 10.3300  nsp_loss : 0.6515  total_loss : 10.9815  avg_loss_step : 10.9860  learning_rate : 5.7e-05 
DLL 2021-12-17 12:41:25.457013 - Iteration: 22  throughput_train : 1115.976 seq/s mlm_loss : 10.3233  nsp_loss : 0.6921  total_loss : 11.0154  avg_loss_step : 10.9781  learning_rate : 6.0000002e-05 
DLL 2021-12-17 12:42:25.973460 - Iteration: 23  throughput_train : 1117.461 seq/s mlm_loss : 10.2570  nsp_loss : 0.6939  total_loss : 10.9509  avg_loss_step : 10.9529  learning_rate : 6.3e-05 
DLL 2021-12-17 12:43:26.880056 - Iteration: 24  throughput_train : 1110.285 seq/s mlm_loss : 10.2727  nsp_loss : 0.6747  total_loss : 10.9474  avg_loss_step : 10.9355  learning_rate : 6.6e-05 
DLL 2021-12-17 12:44:27.688626 - Iteration: 25  throughput_train : 1112.162 seq/s mlm_loss : 10.2215  nsp_loss : 0.6432  total_loss : 10.8647  avg_loss_step : 10.9191  learning_rate : 6.9e-05 
DLL 2021-12-17 12:45:28.602356 - Iteration: 26  throughput_train : 1110.292 seq/s mlm_loss : 10.2069  nsp_loss : 0.6777  total_loss : 10.8846  avg_loss_step : 10.8938  learning_rate : 7.2e-05 
DLL 2021-12-17 12:46:29.597639 - Iteration: 27  throughput_train : 1108.921 seq/s mlm_loss : 10.1750  nsp_loss : 0.7161  total_loss : 10.8911  avg_loss_step : 10.8747  learning_rate : 7.5e-05 
DLL 2021-12-17 12:47:30.409628 - Iteration: 28  throughput_train : 1112.038 seq/s mlm_loss : 10.2275  nsp_loss : 0.6444  total_loss : 10.8719  avg_loss_step : 10.8497  learning_rate : 7.8000005e-05 
DLL 2021-12-17 12:48:31.359245 - Iteration: 29  throughput_train : 1109.479 seq/s mlm_loss : 10.2061  nsp_loss : 0.6293  total_loss : 10.8354  avg_loss_step : 10.8229  learning_rate : 8.1000006e-05 
DLL 2021-12-17 12:49:32.358564 - Iteration: 30  throughput_train : 1108.608 seq/s mlm_loss : 10.1241  nsp_loss : 0.6498  total_loss : 10.7740  avg_loss_step : 10.8011  learning_rate : 8.4e-05 
DLL 2021-12-17 12:50:33.287202 - Iteration: 31  throughput_train : 1109.885 seq/s mlm_loss : 10.0646  nsp_loss : 0.6892  total_loss : 10.7538  avg_loss_step : 10.7831  learning_rate : 8.7e-05 
DLL 2021-12-17 12:51:34.107570 - Iteration: 32  throughput_train : 1111.837 seq/s mlm_loss : 10.0697  nsp_loss : 0.7536  total_loss : 10.8232  avg_loss_step : 10.7611  learning_rate : 9e-05 
DLL 2021-12-17 12:52:34.724219 - Iteration: 33  throughput_train : 1115.574 seq/s mlm_loss : 10.0089  nsp_loss : 0.7228  total_loss : 10.7317  avg_loss_step : 10.7271  learning_rate : 9.3e-05 
DLL 2021-12-17 12:53:35.694537 - Iteration: 34  throughput_train : 1109.104 seq/s mlm_loss : 10.0668  nsp_loss : 0.6928  total_loss : 10.7596  avg_loss_step : 10.7140  learning_rate : 9.6e-05 
DLL 2021-12-17 12:54:36.619313 - Iteration: 35  throughput_train : 1110.023 seq/s mlm_loss : 10.0179  nsp_loss : 0.7285  total_loss : 10.7463  avg_loss_step : 10.6829  learning_rate : 9.9000004e-05 
DLL 2021-12-17 12:55:37.344668 - Iteration: 36  throughput_train : 1113.600 seq/s mlm_loss : 10.0114  nsp_loss : 0.7023  total_loss : 10.7137  avg_loss_step : 10.6549  learning_rate : 0.000102000005 
DLL 2021-12-17 12:56:38.017284 - Iteration: 37  throughput_train : 1114.568 seq/s mlm_loss : 10.0175  nsp_loss : 0.6907  total_loss : 10.7082  avg_loss_step : 10.6254  learning_rate : 0.00010500001 
DLL 2021-12-17 12:57:38.719352 - Iteration: 38  throughput_train : 1114.066 seq/s mlm_loss : 9.9055  nsp_loss : 0.7067  total_loss : 10.6122  avg_loss_step : 10.6120  learning_rate : 0.00010800001 
INFO:tensorflow:loss = 10.675266, step = 37 (2384.326 sec)
INFO:tensorflow:loss = 10.5639515, step = 37 (2383.555 sec)
I1217 12:58:47.945943 139761270613824 basic_session_run_hooks.py:260] loss = 10.675266, step = 37 (2384.326 sec)
INFO:tensorflow:loss = 10.5224085, step = 37 (2385.633 sec)
INFO:tensorflow:loss = 10.58802, step = 37 (2382.785 sec)
INFO:tensorflow:loss = 10.601577, step = 37 (2382.908 sec)
INFO:tensorflow:loss = 10.494598, step = 37 (2385.081 sec)
I1217 12:58:47.946051 139644968515392 basic_session_run_hooks.py:260] loss = 10.5639515, step = 37 (2383.555 sec)
INFO:tensorflow:loss = 10.564172, step = 37 (2384.816 sec)
I1217 12:58:47.945940 140031798708032 basic_session_run_hooks.py:260] loss = 10.5224085, step = 37 (2385.633 sec)
I1217 12:58:47.946189 140273021019968 basic_session_run_hooks.py:260] loss = 10.601577, step = 37 (2382.908 sec)
I1217 12:58:47.946013 139972812793664 basic_session_run_hooks.py:260] loss = 10.58802, step = 37 (2382.785 sec)
I1217 12:58:47.946228 140519955982144 basic_session_run_hooks.py:260] loss = 10.494598, step = 37 (2385.081 sec)
I1217 12:58:47.946355 140296910014272 basic_session_run_hooks.py:260] loss = 10.564172, step = 37 (2384.816 sec)
INFO:tensorflow:loss = 10.545156, step = 37 (2397.686 sec)
I1217 12:59:04.559878 140234784094016 basic_session_run_hooks.py:260] loss = 10.545156, step = 37 (2397.686 sec)
DLL 2021-12-17 12:59:11.558724 - Iteration: 39  throughput_train : 728.278 seq/s mlm_loss : 9.8643  nsp_loss : 0.7099  total_loss : 10.5742  avg_loss_step : 10.5868  learning_rate : 0.000111 
DLL 2021-12-17 13:00:12.261358 - Iteration: 40  throughput_train : 1113.993 seq/s mlm_loss : 9.9122  nsp_loss : 0.6567  total_loss : 10.5689  avg_loss_step : 10.5537  learning_rate : 0.000114 
DLL 2021-12-17 13:01:13.129737 - Iteration: 41  throughput_train : 1110.960 seq/s mlm_loss : 9.8007  nsp_loss : 0.6880  total_loss : 10.4887  avg_loss_step : 10.5279  learning_rate : 0.000117 
DLL 2021-12-17 13:02:13.782182 - Iteration: 42  throughput_train : 1115.019 seq/s mlm_loss : 9.8573  nsp_loss : 0.6444  total_loss : 10.5017  avg_loss_step : 10.5049  learning_rate : 0.000120000004 
DLL 2021-12-17 13:03:14.617808 - Iteration: 43  throughput_train : 1111.572 seq/s mlm_loss : 9.8675  nsp_loss : 0.7170  total_loss : 10.5845  avg_loss_step : 10.4892  learning_rate : 0.000123 
DLL 2021-12-17 13:04:15.715128 - Iteration: 44  throughput_train : 1106.792 seq/s mlm_loss : 9.7185  nsp_loss : 0.6211  total_loss : 10.3396  avg_loss_step : 10.4696  learning_rate : 0.000126 
DLL 2021-12-17 13:05:16.492706 - Iteration: 45  throughput_train : 1112.616 seq/s mlm_loss : 9.8051  nsp_loss : 0.6612  total_loss : 10.4663  avg_loss_step : 10.4425  learning_rate : 0.00012900001 
DLL 2021-12-17 13:06:17.165418 - Iteration: 46  throughput_train : 1114.573 seq/s mlm_loss : 9.7006  nsp_loss : 0.6284  total_loss : 10.3290  avg_loss_step : 10.4104  learning_rate : 0.000132 
DLL 2021-12-17 13:07:18.060404 - Iteration: 47  throughput_train : 1110.484 seq/s mlm_loss : 9.6283  nsp_loss : 0.6986  total_loss : 10.3269  avg_loss_step : 10.4057  learning_rate : 0.00013500001 
DLL 2021-12-17 13:08:18.975844 - Iteration: 48  throughput_train : 1110.116 seq/s mlm_loss : 9.8478  nsp_loss : 0.7252  total_loss : 10.5730  avg_loss_step : 10.3773  learning_rate : 0.000138 
DLL 2021-12-17 13:09:19.777889 - Iteration: 49  throughput_train : 1112.236 seq/s mlm_loss : 9.6273  nsp_loss : 0.7144  total_loss : 10.3417  avg_loss_step : 10.3464  learning_rate : 0.00014100001 
DLL 2021-12-17 13:10:20.410142 - Iteration: 50  throughput_train : 1115.288 seq/s mlm_loss : 9.5366  nsp_loss : 0.6783  total_loss : 10.2149  avg_loss_step : 10.3367  learning_rate : 0.000144 
DLL 2021-12-17 13:11:21.046078 - Iteration: 51  throughput_train : 1115.224 seq/s mlm_loss : 9.5245  nsp_loss : 0.6707  total_loss : 10.1952  avg_loss_step : 10.3151  learning_rate : 0.000147 
DLL 2021-12-17 13:12:21.999790 - Iteration: 52  throughput_train : 1109.421 seq/s mlm_loss : 9.6273  nsp_loss : 0.6715  total_loss : 10.2989  avg_loss_step : 10.2903  learning_rate : 0.00015 
DLL 2021-12-17 13:13:22.474558 - Iteration: 53  throughput_train : 1118.226 seq/s mlm_loss : 9.5103  nsp_loss : 0.6739  total_loss : 10.1843  avg_loss_step : 10.2736  learning_rate : 0.000153 
DLL 2021-12-17 13:14:23.509597 - Iteration: 54  throughput_train : 1107.988 seq/s mlm_loss : 9.5547  nsp_loss : 0.6941  total_loss : 10.2489  avg_loss_step : 10.2608  learning_rate : 0.00015600001 
DLL 2021-12-17 13:15:24.316973 - Iteration: 55  throughput_train : 1112.087 seq/s mlm_loss : 9.5745  nsp_loss : 0.6700  total_loss : 10.2444  avg_loss_step : 10.2519  learning_rate : 0.000159 
DLL 2021-12-17 13:16:25.120469 - Iteration: 56  throughput_train : 1112.156 seq/s mlm_loss : 9.4557  nsp_loss : 0.6685  total_loss : 10.1242  avg_loss_step : 10.2324  learning_rate : 0.00016200001 
DLL 2021-12-17 13:17:25.815809 - Iteration: 57  throughput_train : 1114.144 seq/s mlm_loss : 9.4618  nsp_loss : 0.6467  total_loss : 10.1085  avg_loss_step : 10.1999  learning_rate : 0.000165 
DLL 2021-12-17 13:18:26.894877 - Iteration: 58  throughput_train : 1107.144 seq/s mlm_loss : 9.4499  nsp_loss : 0.6677  total_loss : 10.1175  avg_loss_step : 10.1868  learning_rate : 0.000168 
DLL 2021-12-17 13:19:27.736198 - Iteration: 59  throughput_train : 1111.477 seq/s mlm_loss : 9.4173  nsp_loss : 0.7111  total_loss : 10.1285  avg_loss_step : 10.1466  learning_rate : 0.000171 
DLL 2021-12-17 13:20:28.775583 - Iteration: 60  throughput_train : 1107.861 seq/s mlm_loss : 9.4085  nsp_loss : 0.7065  total_loss : 10.1150  avg_loss_step : 10.1428  learning_rate : 0.000174 
DLL 2021-12-17 13:21:29.780714 - Iteration: 61  throughput_train : 1108.494 seq/s mlm_loss : 9.3641  nsp_loss : 0.6761  total_loss : 10.0401  avg_loss_step : 10.1277  learning_rate : 0.00017700001 
DLL 2021-12-17 13:22:30.827045 - Iteration: 62  throughput_train : 1107.736 seq/s mlm_loss : 9.4019  nsp_loss : 0.6594  total_loss : 10.0613  avg_loss_step : 10.1138  learning_rate : 0.00018 
DLL 2021-12-17 13:23:31.914125 - Iteration: 63  throughput_train : 1106.992 seq/s mlm_loss : 9.2475  nsp_loss : 0.7271  total_loss : 9.9746  avg_loss_step : 10.1049  learning_rate : 0.00018300001 
DLL 2021-12-17 13:24:32.820844 - Iteration: 64  throughput_train : 1110.262 seq/s mlm_loss : 9.5416  nsp_loss : 0.6506  total_loss : 10.1922  avg_loss_step : 10.0755  learning_rate : 0.000186 
DLL 2021-12-17 13:25:33.605579 - Iteration: 65  throughput_train : 1112.494 seq/s mlm_loss : 9.3759  nsp_loss : 0.6847  total_loss : 10.0606  avg_loss_step : 10.0627  learning_rate : 0.00018900001 
DLL 2021-12-17 13:26:34.347087 - Iteration: 66  throughput_train : 1113.285 seq/s mlm_loss : 9.3695  nsp_loss : 0.7283  total_loss : 10.0978  avg_loss_step : 10.0474  learning_rate : 0.000192 
DLL 2021-12-17 13:27:34.795909 - Iteration: 67  throughput_train : 1118.691 seq/s mlm_loss : 9.3002  nsp_loss : 0.7318  total_loss : 10.0320  avg_loss_step : 10.0282  learning_rate : 0.000195 
DLL 2021-12-17 13:28:35.735367 - Iteration: 68  throughput_train : 1109.679 seq/s mlm_loss : 9.3721  nsp_loss : 0.6961  total_loss : 10.0682  avg_loss_step : 10.0303  learning_rate : 0.00019800001 
DLL 2021-12-17 13:29:36.406508 - Iteration: 69  throughput_train : 1114.675 seq/s mlm_loss : 9.3123  nsp_loss : 0.6689  total_loss : 9.9812  avg_loss_step : 10.0001  learning_rate : 0.000201 
DLL 2021-12-17 13:30:37.322137 - Iteration: 70  throughput_train : 1110.185 seq/s mlm_loss : 9.3671  nsp_loss : 0.6419  total_loss : 10.0090  avg_loss_step : 9.9901  learning_rate : 0.00020400001 
DLL 2021-12-17 13:31:38.220013 - Iteration: 71  throughput_train : 1110.427 seq/s mlm_loss : 9.2213  nsp_loss : 0.6993  total_loss : 9.9206  avg_loss_step : 9.9656  learning_rate : 0.000207 
DLL 2021-12-17 13:32:38.972397 - Iteration: 72  throughput_train : 1113.085 seq/s mlm_loss : 9.0787  nsp_loss : 0.7095  total_loss : 9.7882  avg_loss_step : 9.9612  learning_rate : 0.00021000001 
DLL 2021-12-17 13:33:39.599905 - Iteration: 73  throughput_train : 1115.439 seq/s mlm_loss : 9.2296  nsp_loss : 0.7050  total_loss : 9.9346  avg_loss_step : 9.9297  learning_rate : 0.000213 
DLL 2021-12-17 13:34:40.349777 - Iteration: 74  throughput_train : 1113.173 seq/s mlm_loss : 9.3646  nsp_loss : 0.6724  total_loss : 10.0370  avg_loss_step : 9.9467  learning_rate : 0.00021600001 
DLL 2021-12-17 13:35:41.104725 - Iteration: 75  throughput_train : 1113.058 seq/s mlm_loss : 9.2310  nsp_loss : 0.6568  total_loss : 9.8878  avg_loss_step : 9.9152  learning_rate : 0.00021900001 
DLL 2021-12-17 13:36:41.772738 - Iteration: 76  throughput_train : 1114.636 seq/s mlm_loss : 9.2211  nsp_loss : 0.6763  total_loss : 9.8974  avg_loss_step : 9.9068  learning_rate : 0.000222 
INFO:tensorflow:loss = 9.986257, step = 75 (2320.193 sec)
INFO:tensorflow:loss = 10.106777, step = 75 (2320.193 sec)
INFO:tensorflow:loss = 9.989413, step = 75 (2320.193 sec)
I1217 13:37:28.139393 140031798708032 basic_session_run_hooks.py:260] loss = 9.986257, step = 75 (2320.193 sec)
I1217 13:37:28.139482 140273021019968 basic_session_run_hooks.py:260] loss = 9.989413, step = 75 (2320.193 sec)
I1217 13:37:28.139464 140519955982144 basic_session_run_hooks.py:260] loss = 10.106777, step = 75 (2320.193 sec)
INFO:tensorflow:loss = 9.736845, step = 75 (2320.194 sec)
I1217 13:37:28.140046 139761270613824 basic_session_run_hooks.py:260] loss = 9.736845, step = 75 (2320.194 sec)
INFO:tensorflow:loss = 9.891427, step = 75 (2320.195 sec)
I1217 13:37:28.141203 140296910014272 basic_session_run_hooks.py:260] loss = 9.891427, step = 75 (2320.195 sec)
INFO:tensorflow:loss = 9.901575, step = 75 (2303.580 sec)
INFO:tensorflow:loss = 9.900213, step = 75 (2320.194 sec)
I1217 13:37:28.140189 140234784094016 basic_session_run_hooks.py:260] loss = 9.901575, step = 75 (2303.580 sec)
I1217 13:37:28.140176 139972812793664 basic_session_run_hooks.py:260] loss = 9.900213, step = 75 (2320.194 sec)
INFO:tensorflow:loss = 9.932756, step = 75 (2320.205 sec)
I1217 13:37:28.151574 139644968515392 basic_session_run_hooks.py:260] loss = 9.932756, step = 75 (2320.205 sec)
DLL 2021-12-17 13:37:42.651037 - Iteration: 77  throughput_train : 1110.853 seq/s mlm_loss : 9.2239  nsp_loss : 0.6863  total_loss : 9.9103  avg_loss_step : 9.8981  learning_rate : 0.00022500001 
DLL 2021-12-17 13:38:43.273280 - Iteration: 78  throughput_train : 1115.507 seq/s mlm_loss : 9.2973  nsp_loss : 0.6688  total_loss : 9.9661  avg_loss_step : 9.8939  learning_rate : 0.000228 
DLL 2021-12-17 13:39:44.199554 - Iteration: 79  throughput_train : 1109.960 seq/s mlm_loss : 9.1166  nsp_loss : 0.6940  total_loss : 9.8106  avg_loss_step : 9.8848  learning_rate : 0.00023100001 
DLL 2021-12-17 13:40:44.901151 - Iteration: 80  throughput_train : 1114.037 seq/s mlm_loss : 9.3851  nsp_loss : 0.6877  total_loss : 10.0728  avg_loss_step : 9.8769  learning_rate : 0.000234 
DLL 2021-12-17 13:41:45.583778 - Iteration: 81  throughput_train : 1114.414 seq/s mlm_loss : 9.0939  nsp_loss : 0.7049  total_loss : 9.7989  avg_loss_step : 9.8636  learning_rate : 0.00023700001 
DLL 2021-12-17 13:42:46.499377 - Iteration: 82  throughput_train : 1110.122 seq/s mlm_loss : 9.1652  nsp_loss : 0.6854  total_loss : 9.8505  avg_loss_step : 9.8421  learning_rate : 0.00024000001 
DLL 2021-12-17 13:43:46.827740 - Iteration: 83  throughput_train : 1120.981 seq/s mlm_loss : 9.1681  nsp_loss : 0.6702  total_loss : 9.8383  avg_loss_step : 9.8443  learning_rate : 0.000243 
DLL 2021-12-17 13:44:47.578737 - Iteration: 84  throughput_train : 1113.146 seq/s mlm_loss : 9.2060  nsp_loss : 0.7431  total_loss : 9.9491  avg_loss_step : 9.8274  learning_rate : 0.000246 
DLL 2021-12-17 13:45:48.430065 - Iteration: 85  throughput_train : 1111.316 seq/s mlm_loss : 9.1683  nsp_loss : 0.6946  total_loss : 9.8629  avg_loss_step : 9.7974  learning_rate : 0.000249 
DLL 2021-12-17 13:46:49.062258 - Iteration: 86  throughput_train : 1115.360 seq/s mlm_loss : 9.1570  nsp_loss : 0.6801  total_loss : 9.8371  avg_loss_step : 9.8185  learning_rate : 0.000252 
DLL 2021-12-17 13:47:49.995482 - Iteration: 87  throughput_train : 1109.822 seq/s mlm_loss : 9.1759  nsp_loss : 0.6560  total_loss : 9.8319  avg_loss_step : 9.7928  learning_rate : 0.00025500002 
DLL 2021-12-17 13:48:50.773348 - Iteration: 88  throughput_train : 1112.629 seq/s mlm_loss : 9.2999  nsp_loss : 0.6581  total_loss : 9.9580  avg_loss_step : 9.7764  learning_rate : 0.00025800001 
DLL 2021-12-17 13:49:51.587847 - Iteration: 89  throughput_train : 1112.035 seq/s mlm_loss : 9.0581  nsp_loss : 0.6868  total_loss : 9.7448  avg_loss_step : 9.7709  learning_rate : 0.000261 
DLL 2021-12-17 13:50:52.168128 - Iteration: 90  throughput_train : 1116.278 seq/s mlm_loss : 8.9612  nsp_loss : 0.6435  total_loss : 9.6047  avg_loss_step : 9.7867  learning_rate : 0.000264 
DLL 2021-12-17 13:51:52.838831 - Iteration: 91  throughput_train : 1117.350 seq/s mlm_loss : 9.1425  nsp_loss : 0.7024  total_loss : 9.8449  avg_loss_step : 9.7761  learning_rate : 0.000267 
INFO:tensorflow:Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1/model.ckpt.
I1217 13:51:52.840070 140234784094016 basic_session_run_hooks.py:606] Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211217121726/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 9.700874.
I1217 13:51:53.599854 140296910014272 estimator.py:371] Loss for final step: 9.700874.
INFO:tensorflow:Loss for final step: 9.597081.
I1217 13:51:53.603811 139972812793664 estimator.py:371] Loss for final step: 9.597081.
INFO:tensorflow:Loss for final step: 9.689812.
I1217 13:51:53.660362 139761270613824 estimator.py:371] Loss for final step: 9.689812.
INFO:tensorflow:Loss for final step: 9.894553.
I1217 13:51:53.718115 139644968515392 estimator.py:371] Loss for final step: 9.894553.
INFO:tensorflow:Loss for final step: 9.662056.
I1217 13:51:53.764567 140031798708032 estimator.py:371] Loss for final step: 9.662056.
INFO:tensorflow:Loss for final step: 9.733712.
I1217 13:51:53.799113 140519955982144 estimator.py:371] Loss for final step: 9.733712.
INFO:tensorflow:Loss for final step: 9.7454605.
I1217 13:51:53.815781 140273021019968 estimator.py:371] Loss for final step: 9.7454605.
INFO:tensorflow:Loss for final step: 9.844866.
I1217 13:51:57.941174 140234784094016 estimator.py:371] Loss for final step: 9.844866.
INFO:tensorflow:-----------------------------
I1217 13:51:57.943046 140234784094016 run_pretraining.py:644] -----------------------------
INFO:tensorflow:Total Training Time = 5667.61 for Sentences = 6082560
I1217 13:51:57.943133 140234784094016 run_pretraining.py:646] Total Training Time = 5667.61 for Sentences = 6082560
INFO:tensorflow:Total Training Time W/O Overhead = 5196.59 for Sentences = 5744640
I1217 13:51:57.943201 140234784094016 run_pretraining.py:648] Total Training Time W/O Overhead = 5196.59 for Sentences = 5744640
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 1073.21
I1217 13:51:57.943246 140234784094016 run_pretraining.py:649] Throughput Average (sentences/sec) with overhead = 1073.21
INFO:tensorflow:Throughput Average (sentences/sec) = 1105.46
I1217 13:51:57.943302 140234784094016 run_pretraining.py:650] Throughput Average (sentences/sec) = 1105.46
DLL 2021-12-17 13:51:57.943353 -  throughput_train : 1105.463 seq/s
INFO:tensorflow:-----------------------------
I1217 13:51:57.943514 140234784094016 run_pretraining.py:652] -----------------------------
