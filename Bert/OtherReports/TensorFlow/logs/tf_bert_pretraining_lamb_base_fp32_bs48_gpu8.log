+ batch_size=48
+ num_gpus=8
+ precision=fp32
++ expr 67584 / 48 / 8
+ num_accumulation_steps_phase1=176
+ train_steps=100
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 48 64 8 7.5e-4 5e-4 fp32 true 8 2000 200 100 200 176 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541
Logs written to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144.211218005541.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2021-12-18 00:55:41.584440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584434: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584440: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:55:41.584425: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

--------------------------------------------------------------------------
[[18807,1],5]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.176450 140246266607424 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.176458 140570896533312 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.176536 140140594693952 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.176592 140375910307648 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.176844 140114195191616 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.176840 139814680368960 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.177003 140681884444480 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 00:55:43.177291 139803626526528 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8bf8c00978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 00:55:44.036568 140246266607424 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8bf8c00978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8bf8c0b0d0>) includes params argument, but params are not passed to Estimator.
W1218 00:55:44.037415 140246266607424 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8bf8c0b0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 00:55:44.037988 140246266607424 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.038065 140246266607424 run_pretraining.py:626]   Batch size = 48
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f735e36a9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 00:55:44.052913 140140594693952 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f735e36a9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f735e3740d0>) includes params argument, but params are not passed to Estimator.
W1218 00:55:44.053645 140140594693952 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f735e3740d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 00:55:44.054096 140140594693952 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.054193 140140594693952 run_pretraining.py:626]   Batch size = 48
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faa281e1978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 00:55:44.073584 140375910307648 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7faa281e1978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7faa281eb0d0>) includes params argument, but params are not passed to Estimator.
W1218 00:55:44.074289 140375910307648 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7faa281eb0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 00:55:44.074686 140375910307648 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.074748 140375910307648 run_pretraining.py:626]   Batch size = 48
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd78e33b978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 00:55:44.078111 140570896533312 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd78e33b978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Configuaration *****
I1218 00:55:44.078610 139814680368960 run_pretraining.py:579] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1218 00:55:44.079237 139814680368960 run_pretraining.py:581]   logtostderr: False
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f24e95c69b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  alsologtostderr: False
I1218 00:55:44.079314 139814680368960 run_pretraining.py:581]   alsologtostderr: False
I1218 00:55:44.078824 139803626526528 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f24e95c69b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  log_dir: 
I1218 00:55:44.079364 139814680368960 run_pretraining.py:581]   log_dir: 
INFO:tensorflow:  v: 0
I1218 00:55:44.079411 139814680368960 run_pretraining.py:581]   v: 0
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6d38ae2a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  verbosity: 0
I1218 00:55:44.079458 139814680368960 run_pretraining.py:581]   verbosity: 0
I1218 00:55:44.078973 140114195191616 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6d38ae2a20>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  stderrthreshold: fatal
I1218 00:55:44.079500 139814680368960 run_pretraining.py:581]   stderrthreshold: fatal
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd78e3450d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  showprefixforinfo: True
W1218 00:55:44.079231 140570896533312 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fd78e3450d0>) includes params argument, but params are not passed to Estimator.
I1218 00:55:44.079555 139814680368960 run_pretraining.py:581]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1218 00:55:44.079609 139814680368960 run_pretraining.py:581]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
INFO:tensorflow:***** Running training *****
I1218 00:55:44.079654 139814680368960 run_pretraining.py:581]   pdb_post_mortem: False
I1218 00:55:44.079664 140570896533312 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  run_with_profiling: False
I1218 00:55:44.079699 139814680368960 run_pretraining.py:581]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1218 00:55:44.079742 139814680368960 run_pretraining.py:581]   profile_file: None
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f24e95d00d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  use_cprofile_for_profiling: True
I1218 00:55:44.079787 139814680368960 run_pretraining.py:581]   use_cprofile_for_profiling: True
W1218 00:55:44.079487 139803626526528 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f24e95d00d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  only_check_args: False
I1218 00:55:44.079828 139814680368960 run_pretraining.py:581]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
INFO:tensorflow:***** Running training *****
I1218 00:55:44.079873 139814680368960 run_pretraining.py:581]   op_conversion_fallback_to_while_loop: False
I1218 00:55:44.079882 139803626526528 run_pretraining.py:625] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6d38aec0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  test_random_seed: 301
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.079918 139814680368960 run_pretraining.py:581]   test_random_seed: 301
W1218 00:55:44.079645 140114195191616 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6d38aec0d0>) includes params argument, but params are not passed to Estimator.
I1218 00:55:44.079722 140570896533312 run_pretraining.py:626]   Batch size = 48
INFO:tensorflow:  test_srcdir: 
I1218 00:55:44.079959 139814680368960 run_pretraining.py:581]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1218 00:55:44.080000 139814680368960 run_pretraining.py:581]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:***** Running training *****
INFO:tensorflow:  test_randomize_ordering_seed: 
I1218 00:55:44.080023 140114195191616 run_pretraining.py:625] ***** Running training *****
I1218 00:55:44.080044 139814680368960 run_pretraining.py:581]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I1218 00:55:44.080085 139814680368960 run_pretraining.py:581]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1218 00:55:44.080130 139814680368960 run_pretraining.py:581]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  Batch size = 48
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1218 00:55:44.079937 139803626526528 run_pretraining.py:626]   Batch size = 48
I1218 00:55:44.080175 139814680368960 run_pretraining.py:581]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1218 00:55:44.080222 139814680368960 run_pretraining.py:581]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.080267 139814680368960 run_pretraining.py:581]   output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1
I1218 00:55:44.080079 140114195191616 run_pretraining.py:626]   Batch size = 48
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1218 00:55:44.080312 139814680368960 run_pretraining.py:581]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1218 00:55:44.080354 139814680368960 run_pretraining.py:581]   init_checkpoint: None
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1659ce978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  optimizer_type: lamb
I1218 00:55:44.080398 139814680368960 run_pretraining.py:581]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1218 00:55:44.079733 140681884444480 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff1659ce978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 00:55:44.080442 139814680368960 run_pretraining.py:581]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1218 00:55:44.080487 139814680368960 run_pretraining.py:581]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1218 00:55:44.080539 139814680368960 run_pretraining.py:581]   do_train: True
INFO:tensorflow:  do_eval: False
I1218 00:55:44.080590 139814680368960 run_pretraining.py:581]   do_eval: False
INFO:tensorflow:  train_batch_size: 48
I1218 00:55:44.080635 139814680368960 run_pretraining.py:581]   train_batch_size: 48
INFO:tensorflow:  eval_batch_size: 8
I1218 00:55:44.080679 139814680368960 run_pretraining.py:581]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1218 00:55:44.080730 139814680368960 run_pretraining.py:581]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 90
I1218 00:55:44.080775 139814680368960 run_pretraining.py:581]   num_train_steps: 90
INFO:tensorflow:  num_warmup_steps: 2000
I1218 00:55:44.080819 139814680368960 run_pretraining.py:581]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1218 00:55:44.080863 139814680368960 run_pretraining.py:581]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1218 00:55:44.080908 139814680368960 run_pretraining.py:581]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1218 00:55:44.080951 139814680368960 run_pretraining.py:581]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1218 00:55:44.080995 139814680368960 run_pretraining.py:581]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 176
I1218 00:55:44.081039 139814680368960 run_pretraining.py:581]   num_accumulation_steps: 176
INFO:tensorflow:  allreduce_post_accumulation: True
I1218 00:55:44.081082 139814680368960 run_pretraining.py:581]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1218 00:55:44.081126 139814680368960 run_pretraining.py:581]   verbose_logging: False
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff1659d80d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  horovod: True
I1218 00:55:44.081171 139814680368960 run_pretraining.py:581]   horovod: True
INFO:tensorflow:  report_loss: True
W1218 00:55:44.080666 140681884444480 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7ff1659d80d0>) includes params argument, but params are not passed to Estimator.
I1218 00:55:44.081213 139814680368960 run_pretraining.py:581]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1218 00:55:44.081258 139814680368960 run_pretraining.py:581]   manual_fp16: False
INFO:tensorflow:  amp: False
I1218 00:55:44.081302 139814680368960 run_pretraining.py:581]   amp: False
INFO:tensorflow:  use_xla: True
I1218 00:55:44.081346 139814680368960 run_pretraining.py:581]   use_xla: True
INFO:tensorflow:***** Running training *****
INFO:tensorflow:  init_loss_scale: 4294967296
I1218 00:55:44.081391 139814680368960 run_pretraining.py:581]   init_loss_scale: 4294967296
I1218 00:55:44.081347 140681884444480 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  ?: False
I1218 00:55:44.081433 139814680368960 run_pretraining.py:581]   ?: False
INFO:tensorflow:  help: False
I1218 00:55:44.081477 139814680368960 run_pretraining.py:581]   help: False
INFO:tensorflow:  helpshort: False
I1218 00:55:44.081530 139814680368960 run_pretraining.py:581]   helpshort: False
INFO:tensorflow:  helpfull: False
I1218 00:55:44.081582 139814680368960 run_pretraining.py:581]   helpfull: False
INFO:tensorflow:  helpxml: False
I1218 00:55:44.081628 139814680368960 run_pretraining.py:581]   helpxml: False
INFO:tensorflow:**************************
I1218 00:55:44.081668 139814680368960 run_pretraining.py:582] **************************
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.081459 140681884444480 run_pretraining.py:626]   Batch size = 48
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f277c354978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 00:55:44.082108 139814680368960 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f277c354978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f277c35e1e0>) includes params argument, but params are not passed to Estimator.
W1218 00:55:44.082727 139814680368960 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f277c35e1e0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 00:55:44.083108 139814680368960 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1218 00:55:44.083170 139814680368960 run_pretraining.py:626]   Batch size = 48
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.152757 140140594693952 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.158665 140246266607424 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.168475 140375910307648 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.173820 140570896533312 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.174732 140114195191616 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.174779 139803626526528 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.177727 139814680368960 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 00:55:44.188217 140681884444480 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.256811 140140594693952 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.257013 140140594693952 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.257142 140140594693952 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.257241 140140594693952 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.257355 140140594693952 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.257467 140140594693952 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.257600 140140594693952 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.257712 140140594693952 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.257818 140140594693952 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.258068 140140594693952 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.259183 140140594693952 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.261192 140246266607424 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.261367 140246266607424 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.261460 140246266607424 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.261547 140246266607424 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.261624 140246266607424 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.261687 140246266607424 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.261747 140246266607424 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.261805 140246266607424 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.261861 140246266607424 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.262039 140246266607424 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.263048 140246266607424 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.270320 140375910307648 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.270493 140375910307648 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.270605 140375910307648 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.270678 140375910307648 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.270741 140375910307648 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.270803 140375910307648 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.270862 140375910307648 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.270920 140375910307648 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.270977 140375910307648 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.271161 140375910307648 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.272147 140375910307648 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.274281 140570896533312 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.274438 140570896533312 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.274541 140570896533312 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.274621 140570896533312 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.274685 140570896533312 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.274747 140570896533312 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.274807 140570896533312 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.274865 140570896533312 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.274922 140570896533312 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.275094 140570896533312 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.276073 140570896533312 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.276517 139803626526528 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.276689 139803626526528 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.276780 139803626526528 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.276851 139803626526528 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.276915 139803626526528 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.276976 139803626526528 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.277034 139803626526528 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.277092 139803626526528 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.277148 139803626526528 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.277318 139803626526528 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.277339 140114195191616 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.277494 140114195191616 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.277605 140114195191616 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.277674 140114195191616 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.277739 140114195191616 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.277799 140114195191616 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.277858 140114195191616 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.277916 140114195191616 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.277973 140114195191616 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.278142 140114195191616 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.278310 139803626526528 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.279122 140114195191616 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.280061 139814680368960 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.280212 139814680368960 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.280304 139814680368960 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.280374 139814680368960 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.280436 139814680368960 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.280497 139814680368960 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.280568 139814680368960 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.280633 139814680368960 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.280689 139814680368960 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.280863 139814680368960 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.281852 139814680368960 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 00:55:44.290120 140681884444480 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 00:55:44.290284 140681884444480 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1218 00:55:44.290380 140681884444480 run_pretraining.py:260]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1218 00:55:44.290451 140681884444480 run_pretraining.py:260]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1218 00:55:44.290517 140681884444480 run_pretraining.py:260]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1218 00:55:44.290609 140681884444480 run_pretraining.py:260]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1218 00:55:44.290670 140681884444480 run_pretraining.py:260]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1218 00:55:44.290729 140681884444480 run_pretraining.py:260]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1218 00:55:44.290786 140681884444480 run_pretraining.py:260]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 00:55:44.290960 140681884444480 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 00:55:44.291940 140681884444480 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.685499 140114195191616 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.685837 140375910307648 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.695776 140570896533312 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.697782 140246266607424 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.707827 139814680368960 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.712453 139803626526528 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.717953 140681884444480 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 00:55:45.821989 140140594693952 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.446423 140114195191616 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.471628 140375910307648 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.496367 140570896533312 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.518659 140246266607424 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.522052 139814680368960 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.531248 140681884444480 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.604355 139803626526528 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 00:55:48.938477 140140594693952 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1218 00:55:55.692360 140114195191616 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:55.746452 140375910307648 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:55.851403 140570896533312 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:55.870415 139814680368960 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1218 00:55:55.871516 139814680368960 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:55.921144 140681884444480 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:56.125866 140246266607424 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:56.200725 139803626526528 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 00:55:57.106651 140140594693952 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1218 00:56:00.155322 140114195191616 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:00.166941: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:00.172428: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x116e3450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:00.172456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:00.175711: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 00:56:00.349076 140570896533312 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:00.360788: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:00.366251: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58b3ec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:00.366277: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:00.369735: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 00:56:00.420391 139814680368960 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:00.432060: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
INFO:tensorflow:Graph was finalized.
I1218 00:56:00.435897 140681884444480 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:00.436902: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x62cb050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:00.436927: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:00.440076: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 00:56:00.448455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:00.453976: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x123eb6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:00.454009: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:tensorflow:Graph was finalized.
I1218 00:56:00.455594 140375910307648 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:00.457171: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 00:56:00.467376: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:00.472000: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x548c660 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:00.472027: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:00.474807: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 00:56:00.905412 139803626526528 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:00.916921: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:00.922090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x65bd360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:00.922115: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:00.925127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 00:56:01.027662 140246266607424 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:01.040623: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:01.045444: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58be210 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.045484: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:01.048908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 00:56:01.155056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.157213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.162038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58b7bf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.162064: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.164207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.165087: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x115f35a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.165112: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.166112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.168930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
2021-12-18 00:56:01.168976: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.171618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:05:00.0
2021-12-18 00:56:01.171665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.172491: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.173981: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.174343: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.174556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.175855: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.176211: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.177387: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.178056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.178270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.178396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.178924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.179559: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.179757: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.179873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.182572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.185932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.188894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2021-12-18 00:56:01.188945: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.193920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2021-12-18 00:56:01.193967: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.197812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.198087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.209784: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1663e4b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.209815: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.210229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1536a9f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.210257: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.211121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.211563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.211933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.224117: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12469030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.224143: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.224335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0a:00.0
2021-12-18 00:56:01.224386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.224745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
2021-12-18 00:56:01.224797: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.226858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.227909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.228051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.229284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.229404: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.229634: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.229755: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.232538: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.232816: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.233193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.233392: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.233505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.233814: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.234024: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.234155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.234902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2021-12-18 00:56:01.234947: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.237644: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.238869: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.239198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.241641: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.242193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.242404: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.242513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.244629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.244767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.254948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.257261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2021-12-18 00:56:01.257306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.257411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2021-12-18 00:56:01.257466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.267531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-12-18 00:56:01.267575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.598532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.601215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x12669fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.601252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.601899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.604388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:09:00.0
2021-12-18 00:56:01.604439: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.607863: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.609304: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.609684: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.612447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.613099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.613314: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.613481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.615582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.618713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2021-12-18 00:56:01.618769: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.635952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.642186: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15799940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.642233: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.643268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.645649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:06:00.0
2021-12-18 00:56:01.645731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:01.650378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:01.652430: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:01.652960: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:01.657078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:01.657959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:01.658231: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:01.658434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.660990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.663305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2021-12-18 00:56:01.663373: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
INFO:tensorflow:Graph was finalized.
I1218 00:56:01.737636 140140594693952 monitored_session.py:240] Graph was finalized.
2021-12-18 00:56:01.750533: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 00:56:01.755465: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x127b5c70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.755511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 00:56:01.759178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 00:56:01.774171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:01.774219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2021-12-18 00:56:01.774229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2021-12-18 00:56:01.774658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.778062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.782532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2021-12-18 00:56:01.817089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:01.817135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2021-12-18 00:56:01.817147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2021-12-18 00:56:01.819168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.823503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.827551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2021-12-18 00:56:01.894388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:01.894440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2021-12-18 00:56:01.894451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2021-12-18 00:56:01.894947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.898866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.902966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2021-12-18 00:56:01.905229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:01.905264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2021-12-18 00:56:01.905273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2021-12-18 00:56:01.905611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.909684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.913393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
2021-12-18 00:56:01.924623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:01.924680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2021-12-18 00:56:01.924694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2021-12-18 00:56:01.925071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.928758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.932788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
2021-12-18 00:56:01.996484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:01.999104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11f88400 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 00:56:01.999132: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 00:56:01.999708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.001677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
2021-12-18 00:56:02.001719: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:02.004929: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:02.006320: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 00:56:02.006683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 00:56:02.009379: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 00:56:02.010023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 00:56:02.010240: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:02.010367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.013238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.015458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2021-12-18 00:56:02.015500: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 00:56:02.135416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:02.135468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2021-12-18 00:56:02.135478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2021-12-18 00:56:02.135871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.138359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.140694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
2021-12-18 00:56:02.156990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:02.157039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2021-12-18 00:56:02.157050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2021-12-18 00:56:02.157354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.159466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.161466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
2021-12-18 00:56:02.413359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 00:56:02.413410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2021-12-18 00:56:02.413421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2021-12-18 00:56:02.413734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.415822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 00:56:02.417795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
2021-12-18 00:56:07.834136: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:07.876117: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:07.923136: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:08.197374: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:08.540261: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:08.546545: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:08.555815: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 00:56:08.562128: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1218 00:56:12.673863 140375910307648 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:12.702666 140681884444480 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:12.848144 140246266607424 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:13.000727 140570896533312 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:13.054943 140114195191616 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:13.200441 140140594693952 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:13.231746 140375910307648 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:13.259638 140681884444480 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:13.411160 140246266607424 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:13.548409 140570896533312 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:13.629788 140114195191616 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:13.648991 139803626526528 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 00:56:13.712864 139814680368960 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:13.758188 140140594693952 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:14.203481 139803626526528 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 00:56:14.259988 139814680368960 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1/model.ckpt.
I1218 00:56:26.240898 139814680368960 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1218 00:56:37.488183 139814680368960 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2021-12-18 00:56:52.988867: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:53.223679: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:53.623845: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:53.821159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:55.574508: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:56.131402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:56.386624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:56.437955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:56.941827: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:57.004907: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:57.131543: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:57.131548: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:57.132398: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 00:56:57.368065: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:57.396031: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:57.416582: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:57.759919: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:57.910992: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:57.945694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:57.948305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 00:56:57.962953: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:57.993876: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:58.049305: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 00:56:58.060799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
INFO:tensorflow:loss = 11.128082, step = 0
I1218 00:57:17.245029 140246266607424 basic_session_run_hooks.py:262] loss = 11.128082, step = 0
INFO:tensorflow:loss = 11.145598, step = 0
I1218 00:57:20.549679 140570896533312 basic_session_run_hooks.py:262] loss = 11.145598, step = 0
INFO:tensorflow:loss = 11.086854, step = 0
I1218 00:57:20.584956 140140594693952 basic_session_run_hooks.py:262] loss = 11.086854, step = 0
INFO:tensorflow:loss = 11.111229, step = 0
I1218 00:57:20.644625 139814680368960 basic_session_run_hooks.py:262] loss = 11.111229, step = 0
INFO:tensorflow:loss = 11.138833, step = 0
I1218 00:57:21.656915 140375910307648 basic_session_run_hooks.py:262] loss = 11.138833, step = 0
INFO:tensorflow:loss = 11.094684, step = 0
I1218 00:57:21.858881 140681884444480 basic_session_run_hooks.py:262] loss = 11.094684, step = 0
INFO:tensorflow:loss = 11.078894, step = 0
I1218 00:57:23.117763 140114195191616 basic_session_run_hooks.py:262] loss = 11.078894, step = 0
INFO:tensorflow:loss = 11.096476, step = 0
I1218 00:57:25.216007 139803626526528 basic_session_run_hooks.py:262] loss = 11.096476, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:57:58.430353 140570896533312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:57:58.430551 140140594693952 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:57:58.432898 139814680368960 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:57:58.436681 140246266607424 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:57:58.843366 140375910307648 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:00.493438 140681884444480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:01.577659 139803626526528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.943053 140114195191616 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.960933 140681884444480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.960998 140246266607424 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.961040 140375910307648 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.961242 140570896533312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.961469 140140594693952 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.961494 139803626526528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:03.961915 139814680368960 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.277888 140114195191616 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.289370 139803626526528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.289465 140140594693952 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.289484 140246266607424 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.289555 140681884444480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.289655 140375910307648 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.289862 140570896533312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.291187 139814680368960 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.583328 140114195191616 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.603158 139803626526528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.603187 140140594693952 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.603214 140246266607424 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.603265 139814680368960 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.603350 140681884444480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.603677 140375910307648 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.607926 140570896533312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.891416 140114195191616 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.917056 140140594693952 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.917059 140246266607424 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.917158 140375910307648 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.917156 139803626526528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.917244 139814680368960 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.924437 140570896533312 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:04.931239 140681884444480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 00:58:05.202450 140114195191616 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 00:59:27.336812 - Iteration: 2  throughput_train : 399.966 seq/s mlm_loss : 10.4678  nsp_loss : 0.7035  total_loss : 11.1713  avg_loss_step : 11.1254  learning_rate : 0.0 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 01:00:23.566228 - Iteration: 3  throughput_train : 1202.480 seq/s mlm_loss : 10.4249  nsp_loss : 0.6752  total_loss : 11.1001  avg_loss_step : 11.1251  learning_rate : 3e-06 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 01:01:19.987650 - Iteration: 4  throughput_train : 1198.473 seq/s mlm_loss : 10.4680  nsp_loss : 0.6905  total_loss : 11.1585  avg_loss_step : 11.1258  learning_rate : 6e-06 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 01:02:16.372170 - Iteration: 5  throughput_train : 1199.193 seq/s mlm_loss : 10.4313  nsp_loss : 0.6732  total_loss : 11.1045  avg_loss_step : 11.1239  learning_rate : 9e-06 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 01:03:12.792010 - Iteration: 6  throughput_train : 1198.506 seq/s mlm_loss : 10.4675  nsp_loss : 0.6763  total_loss : 11.1437  avg_loss_step : 11.1241  learning_rate : 1.2e-05 
DLL 2021-12-18 01:04:09.151101 - Iteration: 7  throughput_train : 1199.788 seq/s mlm_loss : 10.4147  nsp_loss : 0.7090  total_loss : 11.1237  avg_loss_step : 11.1191  learning_rate : 1.50000005e-05 
DLL 2021-12-18 01:05:05.500653 - Iteration: 8  throughput_train : 1199.896 seq/s mlm_loss : 10.3961  nsp_loss : 0.6901  total_loss : 11.0862  avg_loss_step : 11.1103  learning_rate : 1.8e-05 
DLL 2021-12-18 01:06:01.910594 - Iteration: 9  throughput_train : 1198.579 seq/s mlm_loss : 10.4333  nsp_loss : 0.6966  total_loss : 11.1300  avg_loss_step : 11.1083  learning_rate : 2.1e-05 
DLL 2021-12-18 01:06:58.338760 - Iteration: 10  throughput_train : 1198.200 seq/s mlm_loss : 10.4189  nsp_loss : 0.7084  total_loss : 11.1273  avg_loss_step : 11.0997  learning_rate : 2.4e-05 
DLL 2021-12-18 01:07:54.746009 - Iteration: 11  throughput_train : 1198.630 seq/s mlm_loss : 10.4255  nsp_loss : 0.6728  total_loss : 11.0983  avg_loss_step : 11.0958  learning_rate : 2.7000002e-05 
DLL 2021-12-18 01:08:51.180122 - Iteration: 12  throughput_train : 1198.070 seq/s mlm_loss : 10.4012  nsp_loss : 0.6887  total_loss : 11.0899  avg_loss_step : 11.0860  learning_rate : 3.0000001e-05 
DLL 2021-12-18 01:09:47.588997 - Iteration: 13  throughput_train : 1198.635 seq/s mlm_loss : 10.3868  nsp_loss : 0.6586  total_loss : 11.0454  avg_loss_step : 11.0753  learning_rate : 3.3e-05 
DLL 2021-12-18 01:10:44.025717 - Iteration: 14  throughput_train : 1198.005 seq/s mlm_loss : 10.3741  nsp_loss : 0.6853  total_loss : 11.0594  avg_loss_step : 11.0624  learning_rate : 3.6e-05 
DLL 2021-12-18 01:11:40.521973 - Iteration: 15  throughput_train : 1196.778 seq/s mlm_loss : 10.3439  nsp_loss : 0.7026  total_loss : 11.0464  avg_loss_step : 11.0609  learning_rate : 3.9000002e-05 
DLL 2021-12-18 01:12:36.985484 - Iteration: 16  throughput_train : 1197.432 seq/s mlm_loss : 10.3491  nsp_loss : 0.6913  total_loss : 11.0404  avg_loss_step : 11.0489  learning_rate : 4.2e-05 
DLL 2021-12-18 01:13:33.462845 - Iteration: 17  throughput_train : 1197.166 seq/s mlm_loss : 10.3663  nsp_loss : 0.7058  total_loss : 11.0721  avg_loss_step : 11.0390  learning_rate : 4.5e-05 
DLL 2021-12-18 01:14:29.931834 - Iteration: 18  throughput_train : 1197.321 seq/s mlm_loss : 10.3398  nsp_loss : 0.6667  total_loss : 11.0065  avg_loss_step : 11.0198  learning_rate : 4.8e-05 
DLL 2021-12-18 01:15:26.355220 - Iteration: 19  throughput_train : 1198.287 seq/s mlm_loss : 10.3173  nsp_loss : 0.7211  total_loss : 11.0383  avg_loss_step : 11.0082  learning_rate : 5.1000003e-05 
DLL 2021-12-18 01:16:22.748802 - Iteration: 20  throughput_train : 1198.928 seq/s mlm_loss : 10.2767  nsp_loss : 0.6538  total_loss : 10.9305  avg_loss_step : 10.9935  learning_rate : 5.4000004e-05 
DLL 2021-12-18 01:17:19.166646 - Iteration: 21  throughput_train : 1198.458 seq/s mlm_loss : 10.3158  nsp_loss : 0.7327  total_loss : 11.0485  avg_loss_step : 10.9740  learning_rate : 5.7e-05 
DLL 2021-12-18 01:18:15.553263 - Iteration: 22  throughput_train : 1199.067 seq/s mlm_loss : 10.2638  nsp_loss : 0.7293  total_loss : 10.9931  avg_loss_step : 10.9581  learning_rate : 6.0000002e-05 
DLL 2021-12-18 01:19:11.954575 - Iteration: 23  throughput_train : 1198.758 seq/s mlm_loss : 10.2553  nsp_loss : 0.6864  total_loss : 10.9418  avg_loss_step : 10.9419  learning_rate : 6.3e-05 
DLL 2021-12-18 01:20:08.396315 - Iteration: 24  throughput_train : 1197.901 seq/s mlm_loss : 10.2699  nsp_loss : 0.6863  total_loss : 10.9562  avg_loss_step : 10.9321  learning_rate : 6.6e-05 
DLL 2021-12-18 01:21:04.856452 - Iteration: 25  throughput_train : 1197.528 seq/s mlm_loss : 10.1943  nsp_loss : 0.7003  total_loss : 10.8946  avg_loss_step : 10.9154  learning_rate : 6.9e-05 
DLL 2021-12-18 01:22:01.295877 - Iteration: 26  throughput_train : 1197.963 seq/s mlm_loss : 10.2144  nsp_loss : 0.6865  total_loss : 10.9008  avg_loss_step : 10.8969  learning_rate : 7.2e-05 
DLL 2021-12-18 01:22:57.783793 - Iteration: 27  throughput_train : 1196.934 seq/s mlm_loss : 10.2159  nsp_loss : 0.6974  total_loss : 10.9134  avg_loss_step : 10.8795  learning_rate : 7.5e-05 
DLL 2021-12-18 01:23:54.263178 - Iteration: 28  throughput_train : 1197.108 seq/s mlm_loss : 10.2373  nsp_loss : 0.6849  total_loss : 10.9222  avg_loss_step : 10.8508  learning_rate : 7.8000005e-05 
DLL 2021-12-18 01:24:50.673688 - Iteration: 29  throughput_train : 1198.560 seq/s mlm_loss : 10.1825  nsp_loss : 0.7089  total_loss : 10.8914  avg_loss_step : 10.8313  learning_rate : 8.1000006e-05 
DLL 2021-12-18 01:25:47.078600 - Iteration: 30  throughput_train : 1198.695 seq/s mlm_loss : 10.1495  nsp_loss : 0.7056  total_loss : 10.8551  avg_loss_step : 10.8098  learning_rate : 8.4e-05 
DLL 2021-12-18 01:26:43.537626 - Iteration: 31  throughput_train : 1197.531 seq/s mlm_loss : 10.1239  nsp_loss : 0.6975  total_loss : 10.8214  avg_loss_step : 10.7912  learning_rate : 8.7e-05 
DLL 2021-12-18 01:27:39.988537 - Iteration: 32  throughput_train : 1197.729 seq/s mlm_loss : 10.0310  nsp_loss : 0.7021  total_loss : 10.7331  avg_loss_step : 10.7698  learning_rate : 9e-05 
DLL 2021-12-18 01:28:36.443579 - Iteration: 33  throughput_train : 1197.622 seq/s mlm_loss : 10.0436  nsp_loss : 0.6788  total_loss : 10.7224  avg_loss_step : 10.7415  learning_rate : 9.3e-05 
DLL 2021-12-18 01:29:32.845837 - Iteration: 34  throughput_train : 1198.747 seq/s mlm_loss : 10.0008  nsp_loss : 0.6917  total_loss : 10.6925  avg_loss_step : 10.7255  learning_rate : 9.6e-05 
DLL 2021-12-18 01:30:29.294331 - Iteration: 35  throughput_train : 1197.825 seq/s mlm_loss : 10.0326  nsp_loss : 0.6961  total_loss : 10.7287  avg_loss_step : 10.7021  learning_rate : 9.9000004e-05 
DLL 2021-12-18 01:31:25.763802 - Iteration: 36  throughput_train : 1197.316 seq/s mlm_loss : 10.0125  nsp_loss : 0.6639  total_loss : 10.6764  avg_loss_step : 10.6747  learning_rate : 0.000102000005 
DLL 2021-12-18 01:32:22.215900 - Iteration: 37  throughput_train : 1197.732 seq/s mlm_loss : 9.9953  nsp_loss : 0.7092  total_loss : 10.7045  avg_loss_step : 10.6497  learning_rate : 0.00010500001 
DLL 2021-12-18 01:33:18.595288 - Iteration: 38  throughput_train : 1199.304 seq/s mlm_loss : 9.8799  nsp_loss : 0.6998  total_loss : 10.5797  avg_loss_step : 10.6385  learning_rate : 0.00010800001 
DLL 2021-12-18 01:34:15.030111 - Iteration: 39  throughput_train : 1198.071 seq/s mlm_loss : 9.9239  nsp_loss : 0.6923  total_loss : 10.6162  avg_loss_step : 10.6143  learning_rate : 0.000111 
DLL 2021-12-18 01:35:11.452504 - Iteration: 40  throughput_train : 1198.312 seq/s mlm_loss : 9.9559  nsp_loss : 0.6409  total_loss : 10.5968  avg_loss_step : 10.5831  learning_rate : 0.000114 
DLL 2021-12-18 01:36:07.884287 - Iteration: 41  throughput_train : 1198.114 seq/s mlm_loss : 9.9455  nsp_loss : 0.6753  total_loss : 10.6208  avg_loss_step : 10.5641  learning_rate : 0.000117 
DLL 2021-12-18 01:37:04.332691 - Iteration: 42  throughput_train : 1197.746 seq/s mlm_loss : 9.8456  nsp_loss : 0.6866  total_loss : 10.5321  avg_loss_step : 10.5423  learning_rate : 0.000120000004 
DLL 2021-12-18 01:38:00.818867 - Iteration: 43  throughput_train : 1196.978 seq/s mlm_loss : 9.8558  nsp_loss : 0.6976  total_loss : 10.5535  avg_loss_step : 10.5229  learning_rate : 0.000123 
DLL 2021-12-18 01:38:57.231823 - Iteration: 44  throughput_train : 1198.539 seq/s mlm_loss : 9.7833  nsp_loss : 0.6605  total_loss : 10.4437  avg_loss_step : 10.4986  learning_rate : 0.000126 
DLL 2021-12-18 01:39:53.658828 - Iteration: 45  throughput_train : 1198.207 seq/s mlm_loss : 9.7030  nsp_loss : 0.7041  total_loss : 10.4072  avg_loss_step : 10.4732  learning_rate : 0.00012900001 
DLL 2021-12-18 01:40:50.095464 - Iteration: 46  throughput_train : 1197.998 seq/s mlm_loss : 9.7782  nsp_loss : 0.6429  total_loss : 10.4211  avg_loss_step : 10.4425  learning_rate : 0.000132 
DLL 2021-12-18 01:41:46.535874 - Iteration: 47  throughput_train : 1197.953 seq/s mlm_loss : 9.7562  nsp_loss : 0.6669  total_loss : 10.4231  avg_loss_step : 10.4403  learning_rate : 0.00013500001 
DLL 2021-12-18 01:42:42.950578 - Iteration: 48  throughput_train : 1198.512 seq/s mlm_loss : 9.7123  nsp_loss : 0.6609  total_loss : 10.3732  avg_loss_step : 10.4155  learning_rate : 0.000138 
DLL 2021-12-18 01:43:39.387624 - Iteration: 49  throughput_train : 1198.004 seq/s mlm_loss : 9.7879  nsp_loss : 0.6871  total_loss : 10.4751  avg_loss_step : 10.3864  learning_rate : 0.00014100001 
DLL 2021-12-18 01:44:35.812859 - Iteration: 50  throughput_train : 1198.246 seq/s mlm_loss : 9.6260  nsp_loss : 0.6829  total_loss : 10.3089  avg_loss_step : 10.3752  learning_rate : 0.000144 
DLL 2021-12-18 01:45:32.208323 - Iteration: 51  throughput_train : 1198.890 seq/s mlm_loss : 9.7297  nsp_loss : 0.7304  total_loss : 10.4601  avg_loss_step : 10.3560  learning_rate : 0.000147 
DLL 2021-12-18 01:46:28.630050 - Iteration: 52  throughput_train : 1198.317 seq/s mlm_loss : 9.5886  nsp_loss : 0.6695  total_loss : 10.2581  avg_loss_step : 10.3289  learning_rate : 0.00015 
DLL 2021-12-18 01:47:25.025388 - Iteration: 53  throughput_train : 1198.907 seq/s mlm_loss : 9.5737  nsp_loss : 0.6914  total_loss : 10.2651  avg_loss_step : 10.3109  learning_rate : 0.000153 
DLL 2021-12-18 01:48:21.421540 - Iteration: 54  throughput_train : 1198.870 seq/s mlm_loss : 9.5713  nsp_loss : 0.6793  total_loss : 10.2506  avg_loss_step : 10.2930  learning_rate : 0.00015600001 
DLL 2021-12-18 01:49:17.814567 - Iteration: 55  throughput_train : 1198.934 seq/s mlm_loss : 9.6790  nsp_loss : 0.6449  total_loss : 10.3239  avg_loss_step : 10.2822  learning_rate : 0.000159 
DLL 2021-12-18 01:50:14.234999 - Iteration: 56  throughput_train : 1198.366 seq/s mlm_loss : 9.5513  nsp_loss : 0.6533  total_loss : 10.2046  avg_loss_step : 10.2650  learning_rate : 0.00016200001 
DLL 2021-12-18 01:51:10.600502 - Iteration: 57  throughput_train : 1199.526 seq/s mlm_loss : 9.5361  nsp_loss : 0.6917  total_loss : 10.2279  avg_loss_step : 10.2360  learning_rate : 0.000165 
INFO:tensorflow:loss = 10.264994, step = 56 (3310.112 sec)
INFO:tensorflow:loss = 10.314644, step = 56 (3305.482 sec)
I1218 01:52:30.697251 140140594693952 basic_session_run_hooks.py:260] loss = 10.264994, step = 56 (3310.112 sec)
I1218 01:52:30.697430 139803626526528 basic_session_run_hooks.py:260] loss = 10.314644, step = 56 (3305.482 sec)
INFO:tensorflow:loss = 10.227093, step = 56 (3308.839 sec)
INFO:tensorflow:loss = 10.064116, step = 56 (3307.580 sec)
I1218 01:52:30.697685 140681884444480 basic_session_run_hooks.py:260] loss = 10.227093, step = 56 (3308.839 sec)
INFO:tensorflow:loss = 10.201052, step = 56 (3310.148 sec)
I1218 01:52:30.697824 140114195191616 basic_session_run_hooks.py:260] loss = 10.064116, step = 56 (3307.580 sec)
INFO:tensorflow:loss = 10.351018, step = 56 (3313.453 sec)
I1218 01:52:30.697890 140570896533312 basic_session_run_hooks.py:260] loss = 10.201052, step = 56 (3310.148 sec)
I1218 01:52:30.698004 140246266607424 basic_session_run_hooks.py:260] loss = 10.351018, step = 56 (3313.453 sec)
INFO:tensorflow:loss = 10.167567, step = 56 (3309.041 sec)
I1218 01:52:30.698301 140375910307648 basic_session_run_hooks.py:260] loss = 10.167567, step = 56 (3309.041 sec)
INFO:tensorflow:loss = 10.176317, step = 56 (3310.066 sec)
I1218 01:52:30.710338 139814680368960 basic_session_run_hooks.py:260] loss = 10.176317, step = 56 (3310.066 sec)
DLL 2021-12-18 01:52:40.647976 - Iteration: 58  throughput_train : 750.746 seq/s mlm_loss : 9.4248  nsp_loss : 0.6979  total_loss : 10.1227  avg_loss_step : 10.2205  learning_rate : 0.000168 
DLL 2021-12-18 01:53:36.959213 - Iteration: 59  throughput_train : 1200.732 seq/s mlm_loss : 9.4818  nsp_loss : 0.6660  total_loss : 10.1478  avg_loss_step : 10.1879  learning_rate : 0.000171 
DLL 2021-12-18 01:54:33.378351 - Iteration: 60  throughput_train : 1198.437 seq/s mlm_loss : 9.4920  nsp_loss : 0.6575  total_loss : 10.1495  avg_loss_step : 10.1775  learning_rate : 0.000174 
DLL 2021-12-18 01:55:29.794499 - Iteration: 61  throughput_train : 1198.502 seq/s mlm_loss : 9.4742  nsp_loss : 0.6745  total_loss : 10.1487  avg_loss_step : 10.1722  learning_rate : 0.00017700001 
DLL 2021-12-18 01:56:26.206676 - Iteration: 62  throughput_train : 1198.572 seq/s mlm_loss : 9.4438  nsp_loss : 0.6913  total_loss : 10.1351  avg_loss_step : 10.1526  learning_rate : 0.00018 
DLL 2021-12-18 01:57:22.625008 - Iteration: 63  throughput_train : 1198.414 seq/s mlm_loss : 9.3894  nsp_loss : 0.6817  total_loss : 10.0711  avg_loss_step : 10.1375  learning_rate : 0.00018300001 
DLL 2021-12-18 01:58:19.034676 - Iteration: 64  throughput_train : 1198.600 seq/s mlm_loss : 9.4371  nsp_loss : 0.6831  total_loss : 10.1203  avg_loss_step : 10.1141  learning_rate : 0.000186 
DLL 2021-12-18 01:59:15.381323 - Iteration: 65  throughput_train : 1199.922 seq/s mlm_loss : 9.4478  nsp_loss : 0.6300  total_loss : 10.0778  avg_loss_step : 10.1027  learning_rate : 0.00018900001 
DLL 2021-12-18 02:00:11.809753 - Iteration: 66  throughput_train : 1198.213 seq/s mlm_loss : 9.4127  nsp_loss : 0.6778  total_loss : 10.0905  avg_loss_step : 10.0914  learning_rate : 0.000192 
DLL 2021-12-18 02:01:08.187918 - Iteration: 67  throughput_train : 1199.284 seq/s mlm_loss : 9.4145  nsp_loss : 0.7231  total_loss : 10.1377  avg_loss_step : 10.0775  learning_rate : 0.000195 
DLL 2021-12-18 02:02:04.564628 - Iteration: 68  throughput_train : 1199.289 seq/s mlm_loss : 9.2861  nsp_loss : 0.7138  total_loss : 9.9999  avg_loss_step : 10.0666  learning_rate : 0.00019800001 
DLL 2021-12-18 02:03:00.985188 - Iteration: 69  throughput_train : 1198.340 seq/s mlm_loss : 9.4918  nsp_loss : 0.7024  total_loss : 10.1941  avg_loss_step : 10.0443  learning_rate : 0.000201 
DLL 2021-12-18 02:03:57.360030 - Iteration: 70  throughput_train : 1199.317 seq/s mlm_loss : 9.3401  nsp_loss : 0.7249  total_loss : 10.0650  avg_loss_step : 10.0345  learning_rate : 0.00020400001 
DLL 2021-12-18 02:04:53.783904 - Iteration: 71  throughput_train : 1198.286 seq/s mlm_loss : 9.4061  nsp_loss : 0.7219  total_loss : 10.1280  avg_loss_step : 10.0162  learning_rate : 0.000207 
DLL 2021-12-18 02:05:50.183048 - Iteration: 72  throughput_train : 1198.852 seq/s mlm_loss : 9.2467  nsp_loss : 0.6619  total_loss : 9.9085  avg_loss_step : 10.0129  learning_rate : 0.00021000001 
DLL 2021-12-18 02:06:46.587418 - Iteration: 73  throughput_train : 1198.694 seq/s mlm_loss : 9.2291  nsp_loss : 0.6947  total_loss : 9.9238  avg_loss_step : 9.9825  learning_rate : 0.000213 
DLL 2021-12-18 02:07:42.972073 - Iteration: 74  throughput_train : 1199.111 seq/s mlm_loss : 9.3151  nsp_loss : 0.6816  total_loss : 9.9967  avg_loss_step : 9.9788  learning_rate : 0.00021600001 
DLL 2021-12-18 02:08:39.333487 - Iteration: 75  throughput_train : 1199.679 seq/s mlm_loss : 9.3884  nsp_loss : 0.6665  total_loss : 10.0549  avg_loss_step : 9.9586  learning_rate : 0.00021900001 
DLL 2021-12-18 02:09:35.711642 - Iteration: 76  throughput_train : 1199.252 seq/s mlm_loss : 9.3096  nsp_loss : 0.6662  total_loss : 9.9758  avg_loss_step : 9.9517  learning_rate : 0.000222 
DLL 2021-12-18 02:10:32.075549 - Iteration: 77  throughput_train : 1199.549 seq/s mlm_loss : 9.3643  nsp_loss : 0.7035  total_loss : 10.0678  avg_loss_step : 9.9413  learning_rate : 0.00022500001 
DLL 2021-12-18 02:11:28.436479 - Iteration: 78  throughput_train : 1199.640 seq/s mlm_loss : 9.2668  nsp_loss : 0.6634  total_loss : 9.9302  avg_loss_step : 9.9336  learning_rate : 0.000228 
DLL 2021-12-18 02:12:24.793908 - Iteration: 79  throughput_train : 1199.735 seq/s mlm_loss : 9.3101  nsp_loss : 0.6998  total_loss : 10.0099  avg_loss_step : 9.9344  learning_rate : 0.00023100001 
DLL 2021-12-18 02:13:21.184265 - Iteration: 80  throughput_train : 1198.984 seq/s mlm_loss : 9.2224  nsp_loss : 0.6562  total_loss : 9.8786  avg_loss_step : 9.9126  learning_rate : 0.000234 
DLL 2021-12-18 02:14:17.567924 - Iteration: 81  throughput_train : 1199.129 seq/s mlm_loss : 9.2114  nsp_loss : 0.6720  total_loss : 9.8834  avg_loss_step : 9.9072  learning_rate : 0.00023700001 
DLL 2021-12-18 02:15:13.937460 - Iteration: 82  throughput_train : 1199.452 seq/s mlm_loss : 9.1291  nsp_loss : 0.6724  total_loss : 9.8015  avg_loss_step : 9.8861  learning_rate : 0.00024000001 
DLL 2021-12-18 02:16:10.361326 - Iteration: 83  throughput_train : 1198.311 seq/s mlm_loss : 9.1182  nsp_loss : 0.6633  total_loss : 9.7815  avg_loss_step : 9.8813  learning_rate : 0.000243 
DLL 2021-12-18 02:17:06.711403 - Iteration: 84  throughput_train : 1199.857 seq/s mlm_loss : 9.1019  nsp_loss : 0.7029  total_loss : 9.8049  avg_loss_step : 9.8724  learning_rate : 0.000246 
DLL 2021-12-18 02:18:03.106977 - Iteration: 85  throughput_train : 1198.881 seq/s mlm_loss : 9.1132  nsp_loss : 0.6563  total_loss : 9.7695  avg_loss_step : 9.8506  learning_rate : 0.000249 
DLL 2021-12-18 02:18:59.543047 - Iteration: 86  throughput_train : 1198.012 seq/s mlm_loss : 9.1708  nsp_loss : 0.6816  total_loss : 9.8524  avg_loss_step : 9.8553  learning_rate : 0.000252 
DLL 2021-12-18 02:19:55.906985 - Iteration: 87  throughput_train : 1199.558 seq/s mlm_loss : 9.1738  nsp_loss : 0.6726  total_loss : 9.8464  avg_loss_step : 9.8499  learning_rate : 0.00025500002 
DLL 2021-12-18 02:20:52.326717 - Iteration: 88  throughput_train : 1198.363 seq/s mlm_loss : 9.2048  nsp_loss : 0.6734  total_loss : 9.8782  avg_loss_step : 9.8232  learning_rate : 0.00025800001 
DLL 2021-12-18 02:21:48.661063 - Iteration: 89  throughput_train : 1200.183 seq/s mlm_loss : 9.1704  nsp_loss : 0.7098  total_loss : 9.8802  avg_loss_step : 9.8150  learning_rate : 0.000261 
DLL 2021-12-18 02:22:45.045677 - Iteration: 90  throughput_train : 1199.141 seq/s mlm_loss : 9.0793  nsp_loss : 0.6828  total_loss : 9.7621  avg_loss_step : 9.8292  learning_rate : 0.000264 
DLL 2021-12-18 02:23:41.442414 - Iteration: 91  throughput_train : 1200.656 seq/s mlm_loss : 9.1010  nsp_loss : 0.6806  total_loss : 9.7816  avg_loss_step : 9.8171  learning_rate : 0.000267 
INFO:tensorflow:Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1/model.ckpt.
I1218 02:23:41.443876 139814680368960 basic_session_run_hooks.py:606] Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_211218005541/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 9.931844.
I1218 02:23:42.196437 140375910307648 estimator.py:371] Loss for final step: 9.931844.
INFO:tensorflow:Loss for final step: 9.927652.
I1218 02:23:42.214278 140570896533312 estimator.py:371] Loss for final step: 9.927652.
INFO:tensorflow:Loss for final step: 9.750504.
I1218 02:23:42.220271 139803626526528 estimator.py:371] Loss for final step: 9.750504.
INFO:tensorflow:Loss for final step: 9.761064.
I1218 02:23:42.272923 140681884444480 estimator.py:371] Loss for final step: 9.761064.
INFO:tensorflow:Loss for final step: 9.90196.
I1218 02:23:42.280298 140140594693952 estimator.py:371] Loss for final step: 9.90196.
INFO:tensorflow:Loss for final step: 9.917021.
I1218 02:23:42.290204 140114195191616 estimator.py:371] Loss for final step: 9.917021.
INFO:tensorflow:Loss for final step: 9.667119.
I1218 02:23:42.310218 140246266607424 estimator.py:371] Loss for final step: 9.667119.
INFO:tensorflow:Loss for final step: 9.781606.
I1218 02:23:46.575662 139814680368960 estimator.py:371] Loss for final step: 9.781606.
INFO:tensorflow:-----------------------------
I1218 02:23:46.577299 139814680368960 run_pretraining.py:644] -----------------------------
INFO:tensorflow:Total Training Time = 5282.49 for Sentences = 6082560
I1218 02:23:46.577385 139814680368960 run_pretraining.py:646] Total Training Time = 5282.49 for Sentences = 6082560
INFO:tensorflow:Total Training Time W/O Overhead = 4826.55 for Sentences = 5744640
I1218 02:23:46.577456 139814680368960 run_pretraining.py:648] Total Training Time W/O Overhead = 4826.55 for Sentences = 5744640
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 1151.46
I1218 02:23:46.577506 139814680368960 run_pretraining.py:649] Throughput Average (sentences/sec) with overhead = 1151.46
INFO:tensorflow:Throughput Average (sentences/sec) = 1190.22
I1218 02:23:46.577579 139814680368960 run_pretraining.py:650] Throughput Average (sentences/sec) = 1190.22
DLL 2021-12-18 02:23:46.577635 -  throughput_train : 1190.217 seq/s
INFO:tensorflow:-----------------------------
I1218 02:23:46.577756 139814680368960 run_pretraining.py:652] -----------------------------
