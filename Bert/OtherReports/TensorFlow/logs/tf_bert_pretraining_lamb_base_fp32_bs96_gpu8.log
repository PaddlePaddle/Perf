+ batch_size=96
+ num_gpus=8
+ precision=fp32
++ expr 67584 / 96 / 8
+ num_accumulation_steps_phase1=88
+ train_steps=200
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 96 64 8 7.5e-4 5e-4 fp32 true 8 2000 200 200 200 88 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528
Logs written to /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144.221126091528.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2022-11-26 09:15:28.646054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646058: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646054: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646051: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646086: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:28.646087: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

--------------------------------------------------------------------------
[[9381,1],4]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.245624 139823941363520 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246100 140210787432256 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246211 139856856876864 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246377 139916827465536 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246499 140307689948992 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246530 140161565357888 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246532 139624373462848 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1126 09:15:30.246571 140581824722752 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efb2d07c780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 09:15:31.093843 139624373462848 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efb2d07c780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7efb2d086158>) includes params argument, but params are not passed to Estimator.
W1126 09:15:31.094521 139624373462848 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7efb2d086158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 09:15:31.094919 139624373462848 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 09:15:31.094982 139624373462848 run_pretraining.py:629]   Batch size = 96
INFO:tensorflow:***** Configuaration *****
I1126 09:15:31.097082 140307689948992 run_pretraining.py:581] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1126 09:15:31.097345 140307689948992 run_pretraining.py:583]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1126 09:15:31.097481 140307689948992 run_pretraining.py:583]   alsologtostderr: False
INFO:tensorflow:  log_dir: 
I1126 09:15:31.097563 140307689948992 run_pretraining.py:583]   log_dir: 
INFO:tensorflow:  v: 0
I1126 09:15:31.097638 140307689948992 run_pretraining.py:583]   v: 0
INFO:tensorflow:  verbosity: 0
I1126 09:15:31.097710 140307689948992 run_pretraining.py:583]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1126 09:15:31.097778 140307689948992 run_pretraining.py:583]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1126 09:15:31.097836 140307689948992 run_pretraining.py:583]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1126 09:15:31.097883 140307689948992 run_pretraining.py:583]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1126 09:15:31.097929 140307689948992 run_pretraining.py:583]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1126 09:15:31.097974 140307689948992 run_pretraining.py:583]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1126 09:15:31.098023 140307689948992 run_pretraining.py:583]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1126 09:15:31.098068 140307689948992 run_pretraining.py:583]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1126 09:15:31.098113 140307689948992 run_pretraining.py:583]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1126 09:15:31.098158 140307689948992 run_pretraining.py:583]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1126 09:15:31.098203 140307689948992 run_pretraining.py:583]   test_random_seed: 301
INFO:tensorflow:  test_srcdir: 
I1126 09:15:31.098248 140307689948992 run_pretraining.py:583]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1126 09:15:31.098292 140307689948992 run_pretraining.py:583]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed: 
I1126 09:15:31.098336 140307689948992 run_pretraining.py:583]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I1126 09:15:31.098380 140307689948992 run_pretraining.py:583]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1126 09:15:31.098437 140307689948992 run_pretraining.py:583]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1126 09:15:31.098489 140307689948992 run_pretraining.py:583]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1126 09:15:31.098535 140307689948992 run_pretraining.py:583]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1
I1126 09:15:31.098579 140307689948992 run_pretraining.py:583]   output_dir: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f314e1f3780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1126 09:15:31.098624 140307689948992 run_pretraining.py:583]   dllog_path: /results/bert_dllog.json
I1126 09:15:31.098109 139856856876864 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f314e1f3780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  init_checkpoint: None
I1126 09:15:31.098669 140307689948992 run_pretraining.py:583]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1126 09:15:31.098710 140307689948992 run_pretraining.py:583]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1126 09:15:31.098753 140307689948992 run_pretraining.py:583]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1126 09:15:31.098797 140307689948992 run_pretraining.py:583]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1126 09:15:31.098841 140307689948992 run_pretraining.py:583]   do_train: True
INFO:tensorflow:  do_eval: True
I1126 09:15:31.098885 140307689948992 run_pretraining.py:583]   do_eval: True
INFO:tensorflow:  train_batch_size: 96
I1126 09:15:31.098929 140307689948992 run_pretraining.py:583]   train_batch_size: 96
INFO:tensorflow:  eval_batch_size: 8
I1126 09:15:31.098973 140307689948992 run_pretraining.py:583]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f314e1fd158>) includes params argument, but params are not passed to Estimator.
I1126 09:15:31.099022 140307689948992 run_pretraining.py:583]   learning_rate: 0.00075
W1126 09:15:31.098781 139856856876864 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f314e1fd158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  num_train_steps: 180
I1126 09:15:31.099067 140307689948992 run_pretraining.py:583]   num_train_steps: 180
INFO:tensorflow:  num_warmup_steps: 2000
I1126 09:15:31.099113 140307689948992 run_pretraining.py:583]   num_warmup_steps: 2000
INFO:tensorflow:***** Running training *****
INFO:tensorflow:  save_checkpoints_steps: 200
I1126 09:15:31.099157 140307689948992 run_pretraining.py:583]   save_checkpoints_steps: 200
I1126 09:15:31.099152 139856856876864 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  display_loss_steps: 1
I1126 09:15:31.099201 140307689948992 run_pretraining.py:583]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1126 09:15:31.099244 140307689948992 run_pretraining.py:583]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1126 09:15:31.099289 140307689948992 run_pretraining.py:583]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 88
I1126 09:15:31.099332 140307689948992 run_pretraining.py:583]   num_accumulation_steps: 88
INFO:tensorflow:  allreduce_post_accumulation: True
I1126 09:15:31.099376 140307689948992 run_pretraining.py:583]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1126 09:15:31.099428 140307689948992 run_pretraining.py:583]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1126 09:15:31.099477 140307689948992 run_pretraining.py:583]   horovod: True
INFO:tensorflow:  report_loss: True
I1126 09:15:31.099522 140307689948992 run_pretraining.py:583]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1126 09:15:31.099567 140307689948992 run_pretraining.py:583]   manual_fp16: False
INFO:tensorflow:  Batch size = 96
INFO:tensorflow:  amp: False
I1126 09:15:31.099209 139856856876864 run_pretraining.py:629]   Batch size = 96
I1126 09:15:31.099611 140307689948992 run_pretraining.py:583]   amp: False
INFO:tensorflow:  use_xla: True
I1126 09:15:31.099654 140307689948992 run_pretraining.py:583]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1126 09:15:31.099698 140307689948992 run_pretraining.py:583]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1126 09:15:31.099743 140307689948992 run_pretraining.py:583]   ?: False
INFO:tensorflow:  help: False
I1126 09:15:31.099786 140307689948992 run_pretraining.py:583]   help: False
INFO:tensorflow:  helpshort: False
I1126 09:15:31.099830 140307689948992 run_pretraining.py:583]   helpshort: False
INFO:tensorflow:  helpfull: False
I1126 09:15:31.099874 140307689948992 run_pretraining.py:583]   helpfull: False
INFO:tensorflow:  helpxml: False
I1126 09:15:31.099919 140307689948992 run_pretraining.py:583]   helpxml: False
INFO:tensorflow:**************************
I1126 09:15:31.099959 140307689948992 run_pretraining.py:584] **************************
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9a45dde780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 09:15:31.100414 140307689948992 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9a45dde780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9a45de8268>) includes params argument, but params are not passed to Estimator.
W1126 09:15:31.101012 140307689948992 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9a45de8268>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 09:15:31.101369 140307689948992 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fda1996a710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 09:15:31.101056 140581824722752 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fda1996a710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  Batch size = 96
I1126 09:15:31.101441 140307689948992 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fda19974158>) includes params argument, but params are not passed to Estimator.
W1126 09:15:31.101708 140581824722752 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fda19974158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 09:15:31.102074 140581824722752 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 09:15:31.102137 140581824722752 run_pretraining.py:629]   Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29a4345780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 09:15:31.138164 139823941363520 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29a4345780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f29a434f158>) includes params argument, but params are not passed to Estimator.
W1126 09:15:31.139206 139823941363520 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f29a434f158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 09:15:31.139865 139823941363520 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 09:15:31.139968 139823941363520 run_pretraining.py:629]   Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f83b60ad748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 09:15:31.150326 140210787432256 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f83b60ad748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3f44a9b780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f83b60b7158>) includes params argument, but params are not passed to Estimator.
I1126 09:15:31.150757 139916827465536 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3f44a9b780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W1126 09:15:31.151061 140210787432256 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f83b60b7158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 09:15:31.151447 140210787432256 run_pretraining.py:628] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f3f44aa5158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  Batch size = 96
W1126 09:15:31.151481 139916827465536 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f3f44aa5158>) includes params argument, but params are not passed to Estimator.
I1126 09:15:31.151523 140210787432256 run_pretraining.py:629]   Batch size = 96
INFO:tensorflow:***** Running training *****
I1126 09:15:31.151879 139916827465536 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 09:15:31.151943 139916827465536 run_pretraining.py:629]   Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78402996d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1126 09:15:31.153249 140161565357888 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f78402996d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f78402a3158>) includes params argument, but params are not passed to Estimator.
W1126 09:15:31.153993 140161565357888 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f78402a3158>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1126 09:15:31.154378 140161565357888 run_pretraining.py:628] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1126 09:15:31.154461 140161565357888 run_pretraining.py:629]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.190492 139624373462848 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.195850 139856856876864 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.196558 140581824722752 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.199683 140307689948992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.239873 139823941363520 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.247548 140210787432256 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.247741 139916827465536 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1126 09:15:31.252617 140161565357888 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.292460 139624373462848 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.292614 139624373462848 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.292708 139624373462848 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.292779 139624373462848 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.292844 139624373462848 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.292906 139624373462848 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.292965 139624373462848 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.293023 139624373462848 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.293080 139624373462848 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.293250 139624373462848 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.294230 139624373462848 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.298177 140581824722752 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.298327 140581824722752 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.298432 140581824722752 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.298511 140581824722752 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.298577 140581824722752 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.298640 140581824722752 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.298699 140581824722752 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.298757 140581824722752 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.298814 140581824722752 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.298985 140581824722752 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.299956 140581824722752 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.301381 139856856876864 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.301556 139856856876864 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.301648 139856856876864 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.301718 139856856876864 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.301781 139856856876864 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.301841 139856856876864 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.301900 139856856876864 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.301957 139856856876864 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.302012 139856856876864 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.302183 139856856876864 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.303158 139856856876864 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.303951 140307689948992 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.304105 140307689948992 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.304194 140307689948992 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.304266 140307689948992 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.304332 140307689948992 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.304404 140307689948992 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.304473 140307689948992 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.304535 140307689948992 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.304593 140307689948992 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.304762 140307689948992 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.305804 140307689948992 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.343136 139823941363520 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.343317 139823941363520 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.343424 139823941363520 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.343507 139823941363520 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.343572 139823941363520 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.343634 139823941363520 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.343693 139823941363520 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.343751 139823941363520 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.343807 139823941363520 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.343988 139823941363520 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.345012 139823941363520 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.349976 139916827465536 estimator.py:1148] Calling model_fn.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.350065 140210787432256 estimator.py:1148] Calling model_fn.
I1126 09:15:31.350158 139916827465536 run_pretraining.py:260] *** Features ***
INFO:tensorflow:*** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.350222 140210787432256 run_pretraining.py:260] *** Features ***
I1126 09:15:31.350251 139916827465536 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.350318 140210787432256 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
I1126 09:15:31.350317 139916827465536 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.350386 140210787432256 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
I1126 09:15:31.350381 139916827465536 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.350454 139916827465536 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.350461 140210787432256 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.350522 139916827465536 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.350530 140210787432256 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.350580 139916827465536 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.350587 140210787432256 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.350636 139916827465536 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
I1126 09:15:31.350642 140210787432256 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.350695 140210787432256 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.350817 139916827465536 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.350875 140210787432256 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.351818 139916827465536 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.351878 140210787432256 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1126 09:15:31.357241 140161565357888 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 09:15:31.357437 140161565357888 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1126 09:15:31.357546 140161565357888 run_pretraining.py:262]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1126 09:15:31.357622 140161565357888 run_pretraining.py:262]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1126 09:15:31.357689 140161565357888 run_pretraining.py:262]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1126 09:15:31.357755 140161565357888 run_pretraining.py:262]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1126 09:15:31.357818 140161565357888 run_pretraining.py:262]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1126 09:15:31.357879 140161565357888 run_pretraining.py:262]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1126 09:15:31.357940 140161565357888 run_pretraining.py:262]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1126 09:15:31.358131 140161565357888 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1126 09:15:31.359216 140161565357888 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.711596 140307689948992 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.715662 140581824722752 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.716059 139624373462848 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.716995 139856856876864 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.788443 139916827465536 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.795728 140210787432256 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.828071 139823941363520 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1126 09:15:32.918563 140161565357888 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:298: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.482618 140307689948992 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.485936 140581824722752 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.495271 139856856876864 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.511634 139624373462848 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.600609 139916827465536 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.623533 140210787432256 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.731564 139823941363520 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1126 09:15:35.971480 140161565357888 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1126 09:15:42.769182 140307689948992 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1126 09:15:42.770302 140307689948992 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:42.779231 140581824722752 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:42.812376 139856856876864 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:42.867362 139624373462848 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:42.926520 139916827465536 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:42.994432 140210787432256 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:43.307271 139823941363520 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1126 09:15:43.971442 140161565357888 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.242612 140307689948992 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.253579: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.258667: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10c0ca70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.258691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:47.261526: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.278651 139856856876864 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.290246: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.295345: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x10e43310 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.295377: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.295311 140581824722752 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.300188: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-11-26 09:15:47.306877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.311195: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565b500 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.311219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:47.314311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.358917 139624373462848 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.371349: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.375391: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56dc820 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.375432: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:47.379064: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.591204 140210787432256 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.603119: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.608210: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5745ce0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.608244: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:47.611139: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.709535 139916827465536 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.722002: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.726857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x11956a60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.726894: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:47.729819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1126 09:15:47.934516 139823941363520 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:47.949115: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:47.956084: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ba5420 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:47.956120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:47.959875: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-11-26 09:15:48.352189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.359762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x156b4690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.359790: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.361103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.366553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:05:00.0
2022-11-26 09:15:48.366601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.369876: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.371233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.371556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.374167: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.374835: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.375034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.375136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.384134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.389518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.390470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2022-11-26 09:15:48.390512: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.396890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.397804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a7be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.397835: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.399341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.406295: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x567b8a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.406349: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.408476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.408696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.408962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:09:00.0
2022-11-26 09:15:48.409025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.413359: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.414874: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.415219: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.417039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
2022-11-26 09:15:48.417090: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.418112: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14bd98e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.418142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.418646: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.419198: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.419414: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.419555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.421022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.422583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.423100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.424819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.425206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.428854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.430536: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.431574: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.431794: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.431882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2022-11-26 09:15:48.431931: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.431938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.434733: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.435027: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x117dca30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.435053: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.435973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.436308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.438793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.439129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.439346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.439546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.439682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.440419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2022-11-26 09:15:48.440481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.441302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.452070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0a:00.0
2022-11-26 09:15:48.452115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.452617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.453733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2022-11-26 09:15:48.453782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.455036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.456348: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.456710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.459300: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.459880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.460079: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.460194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.462780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2022-11-26 09:15:48.462832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.470995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.481819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2022-11-26 09:15:48.481864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.671576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.674540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x65d7fa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.674573: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.675149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.678966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
2022-11-26 09:15:48.679043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.683663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.685707: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.686115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.689999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.691246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.691511: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.691692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.693801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.696785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2022-11-26 09:15:48.696833: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.717597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.721430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4af1a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.721480: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.722488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.724992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
2022-11-26 09:15:48.725043: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.731157: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.733610: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.734071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.739880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.741126: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.741376: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.741579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Graph was finalized.
I1126 09:15:48.742577 140161565357888 monitored_session.py:240] Graph was finalized.
2022-11-26 09:15:48.744525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.746504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2022-11-26 09:15:48.746549: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.755041: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-11-26 09:15:48.760192: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x570b320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.760222: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-11-26 09:15:48.763566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-11-26 09:15:48.964116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:48.964168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2022-11-26 09:15:48.964179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2022-11-26 09:15:48.964525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.967492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.969500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2022-11-26 09:15:48.973971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.976501: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x570f050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-11-26 09:15:48.976549: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-11-26 09:15:48.977262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.980513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:06:00.0
2022-11-26 09:15:48.980575: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:48.983761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:15:48.985145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 09:15:48.985498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 09:15:48.988153: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 09:15:48.988820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 09:15:48.989037: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:15:48.989201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.992179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:48.994458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2022-11-26 09:15:48.994501: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 09:15:49.009387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.009447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-11-26 09:15:49.009458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-11-26 09:15:49.010213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.014684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.019348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
2022-11-26 09:15:49.043182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.043235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2022-11-26 09:15:49.043245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2022-11-26 09:15:49.043566: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.045687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.048203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
2022-11-26 09:15:49.048349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.048403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2022-11-26 09:15:49.048415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2022-11-26 09:15:49.048760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.051281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.053612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
2022-11-26 09:15:49.199116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.199164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2022-11-26 09:15:49.199175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2022-11-26 09:15:49.199578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.201956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.204188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2022-11-26 09:15:49.256204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.256261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2022-11-26 09:15:49.256272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2022-11-26 09:15:49.256628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.259339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.261359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2022-11-26 09:15:49.276095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.276139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2022-11-26 09:15:49.276150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2022-11-26 09:15:49.276547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.278729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.281045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
2022-11-26 09:15:49.390482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 09:15:49.390536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2022-11-26 09:15:49.390547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2022-11-26 09:15:49.390909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.393049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 09:15:49.395047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
2022-11-26 09:15:54.889883: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:54.948862: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:54.963379: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:55.030960: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:55.186963: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:55.193896: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:55.630317: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-11-26 09:15:55.918096: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1126 09:15:59.833608 140210787432256 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:15:59.943688 139856856876864 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:15:59.980630 139916827465536 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:16:00.000374 140307689948992 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:16:00.137170 140581824722752 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:00.389407 140210787432256 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:00.495971 139856856876864 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:00.532632 139916827465536 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:16:00.547480 139823941363520 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:00.553705 140307689948992 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:16:00.563952 139624373462848 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:00.723113 140581824722752 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1126 09:16:01.039608 140161565357888 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:01.140466 139624373462848 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:01.167599 139823941363520 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 09:16:01.604956 140161565357888 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt.
I1126 09:16:11.573330 140307689948992 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1126 09:16:23.173869 140307689948992 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2022-11-26 09:16:40.642114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:41.274789: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:41.806094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:42.399436: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:48.241449: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:48.846655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:49.191831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:49.741378: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:52.963152: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:53.290727: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:53.517512: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:53.645553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:53.899094: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:54.292247: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 09:16:54.297197: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 09:16:54.508973: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:54.526545: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:54.545938: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:54.555228: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:54.556471: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:54.776857: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:55.068920: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:55.115814: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-11-26 09:16:55.149726: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
INFO:tensorflow:loss = 11.119066, step = 0
I1126 09:17:11.886599 139916827465536 basic_session_run_hooks.py:262] loss = 11.119066, step = 0
INFO:tensorflow:loss = 11.133734, step = 0
I1126 09:17:14.134878 139823941363520 basic_session_run_hooks.py:262] loss = 11.133734, step = 0
INFO:tensorflow:loss = 11.134825, step = 0
I1126 09:17:27.205946 139856856876864 basic_session_run_hooks.py:262] loss = 11.134825, step = 0
INFO:tensorflow:loss = 11.166045, step = 0
I1126 09:17:27.275499 140581824722752 basic_session_run_hooks.py:262] loss = 11.166045, step = 0
INFO:tensorflow:loss = 11.160081, step = 0
I1126 09:17:27.526845 140210787432256 basic_session_run_hooks.py:262] loss = 11.160081, step = 0
INFO:tensorflow:loss = 11.105632, step = 0
I1126 09:17:27.679593 139624373462848 basic_session_run_hooks.py:262] loss = 11.105632, step = 0
INFO:tensorflow:loss = 11.174982, step = 0
I1126 09:17:28.390326 140161565357888 basic_session_run_hooks.py:262] loss = 11.174982, step = 0
INFO:tensorflow:loss = 11.146148, step = 0
I1126 09:17:29.276329 140307689948992 basic_session_run_hooks.py:262] loss = 11.146148, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.415317 140581824722752 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.415496 140210787432256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.415789 139823941363520 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.416964 139916827465536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.418122 140161565357888 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.424561 139624373462848 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:23.858310 139856856876864 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.051269 140307689948992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.642777 140161565357888 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.642820 139823941363520 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.642818 139916827465536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.642841 140581824722752 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.642840 139856856876864 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.642950 139624373462848 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.643161 140307689948992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:24.643126 140210787432256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.235085 139624373462848 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.235081 139856856876864 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.235128 140581824722752 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.235195 139916827465536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.235255 140161565357888 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.235560 140307689948992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.236206 139823941363520 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.238033 140210787432256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.827046 140581824722752 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.827028 139624373462848 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.827123 140307689948992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.827140 139856856876864 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.827215 139823941363520 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.827209 139916827465536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.830464 140210787432256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:25.831647 140161565357888 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424694 140307689948992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424718 139856856876864 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424684 140581824722752 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424749 139823941363520 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424759 139624373462848 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424754 140210787432256 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.424788 139916827465536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1126 09:18:26.433628 140161565357888 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 09:19:43.832021 - Iteration: 2  throughput_train : 338.156 sequences/s mlm_loss : 10.4405  nsp_loss : 0.6998  total_loss : 11.1403  avg_loss_step : 11.1424  learning_rate : 0.0 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 09:20:37.830079 - Iteration: 3  throughput_train : 1251.898 sequences/s mlm_loss : 10.4296  nsp_loss : 0.7126  total_loss : 11.1422  avg_loss_step : 11.1426  learning_rate : 3e-06 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 09:21:31.715996 - Iteration: 4  throughput_train : 1254.505 sequences/s mlm_loss : 10.4227  nsp_loss : 0.7251  total_loss : 11.1477  avg_loss_step : 11.1441  learning_rate : 6e-06 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 09:22:25.790300 - Iteration: 5  throughput_train : 1250.131 sequences/s mlm_loss : 10.4356  nsp_loss : 0.7298  total_loss : 11.1655  avg_loss_step : 11.1392  learning_rate : 9e-06 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2022-11-26 09:23:19.864810 - Iteration: 6  throughput_train : 1250.125 sequences/s mlm_loss : 10.4480  nsp_loss : 0.6985  total_loss : 11.1465  avg_loss_step : 11.1395  learning_rate : 1.2e-05 
DLL 2022-11-26 09:24:13.966825 - Iteration: 7  throughput_train : 1249.483 sequences/s mlm_loss : 10.4179  nsp_loss : 0.7162  total_loss : 11.1341  avg_loss_step : 11.1309  learning_rate : 1.50000005e-05 
DLL 2022-11-26 09:25:08.147614 - Iteration: 8  throughput_train : 1247.669 sequences/s mlm_loss : 10.4090  nsp_loss : 0.7003  total_loss : 11.1093  avg_loss_step : 11.1265  learning_rate : 1.8e-05 
DLL 2022-11-26 09:26:02.211387 - Iteration: 9  throughput_train : 1250.373 sequences/s mlm_loss : 10.4064  nsp_loss : 0.7004  total_loss : 11.1068  avg_loss_step : 11.1182  learning_rate : 2.1e-05 
DLL 2022-11-26 09:26:56.336274 - Iteration: 10  throughput_train : 1248.957 sequences/s mlm_loss : 10.4158  nsp_loss : 0.7023  total_loss : 11.1181  avg_loss_step : 11.1092  learning_rate : 2.4e-05 
DLL 2022-11-26 09:27:50.439884 - Iteration: 11  throughput_train : 1249.449 sequences/s mlm_loss : 10.4201  nsp_loss : 0.6888  total_loss : 11.1089  avg_loss_step : 11.0993  learning_rate : 2.7000002e-05 
DLL 2022-11-26 09:28:44.506207 - Iteration: 12  throughput_train : 1250.327 sequences/s mlm_loss : 10.3958  nsp_loss : 0.6925  total_loss : 11.0884  avg_loss_step : 11.0887  learning_rate : 3.0000001e-05 
DLL 2022-11-26 09:29:38.569135 - Iteration: 13  throughput_train : 1250.394 sequences/s mlm_loss : 10.3898  nsp_loss : 0.6892  total_loss : 11.0790  avg_loss_step : 11.0796  learning_rate : 3.3e-05 
DLL 2022-11-26 09:30:32.610076 - Iteration: 14  throughput_train : 1250.897 sequences/s mlm_loss : 10.3852  nsp_loss : 0.7049  total_loss : 11.0900  avg_loss_step : 11.0723  learning_rate : 3.6e-05 
DLL 2022-11-26 09:31:26.706267 - Iteration: 15  throughput_train : 1249.622 sequences/s mlm_loss : 10.3624  nsp_loss : 0.6693  total_loss : 11.0317  avg_loss_step : 11.0554  learning_rate : 3.9000002e-05 
DLL 2022-11-26 09:32:20.808776 - Iteration: 16  throughput_train : 1249.473 sequences/s mlm_loss : 10.3539  nsp_loss : 0.6912  total_loss : 11.0451  avg_loss_step : 11.0394  learning_rate : 4.2e-05 
DLL 2022-11-26 09:33:14.875641 - Iteration: 17  throughput_train : 1250.304 sequences/s mlm_loss : 10.3393  nsp_loss : 0.6865  total_loss : 11.0258  avg_loss_step : 11.0326  learning_rate : 4.5e-05 
DLL 2022-11-26 09:34:08.928633 - Iteration: 18  throughput_train : 1250.620 sequences/s mlm_loss : 10.3092  nsp_loss : 0.6962  total_loss : 11.0054  avg_loss_step : 11.0124  learning_rate : 4.8e-05 
DLL 2022-11-26 09:35:02.964669 - Iteration: 19  throughput_train : 1251.010 sequences/s mlm_loss : 10.2900  nsp_loss : 0.6766  total_loss : 10.9666  avg_loss_step : 10.9957  learning_rate : 5.1000003e-05 
DLL 2022-11-26 09:35:57.023891 - Iteration: 20  throughput_train : 1250.472 sequences/s mlm_loss : 10.2898  nsp_loss : 0.6705  total_loss : 10.9604  avg_loss_step : 10.9804  learning_rate : 5.4000004e-05 
DLL 2022-11-26 09:36:51.061265 - Iteration: 21  throughput_train : 1250.984 sequences/s mlm_loss : 10.2660  nsp_loss : 0.7157  total_loss : 10.9817  avg_loss_step : 10.9639  learning_rate : 5.7e-05 
DLL 2022-11-26 09:37:45.117277 - Iteration: 22  throughput_train : 1250.547 sequences/s mlm_loss : 10.2512  nsp_loss : 0.6911  total_loss : 10.9422  avg_loss_step : 10.9498  learning_rate : 6.0000002e-05 
DLL 2022-11-26 09:38:39.106938 - Iteration: 23  throughput_train : 1252.076 sequences/s mlm_loss : 10.2552  nsp_loss : 0.7378  total_loss : 10.9930  avg_loss_step : 10.9271  learning_rate : 6.3e-05 
DLL 2022-11-26 09:39:33.186175 - Iteration: 24  throughput_train : 1249.996 sequences/s mlm_loss : 10.2432  nsp_loss : 0.6862  total_loss : 10.9294  avg_loss_step : 10.9001  learning_rate : 6.6e-05 
DLL 2022-11-26 09:40:27.275484 - Iteration: 25  throughput_train : 1249.769 sequences/s mlm_loss : 10.1808  nsp_loss : 0.7033  total_loss : 10.8841  avg_loss_step : 10.8901  learning_rate : 6.9e-05 
DLL 2022-11-26 09:41:21.397917 - Iteration: 26  throughput_train : 1249.007 sequences/s mlm_loss : 10.1747  nsp_loss : 0.6750  total_loss : 10.8497  avg_loss_step : 10.8591  learning_rate : 7.2e-05 
DLL 2022-11-26 09:42:15.445406 - Iteration: 27  throughput_train : 1250.744 sequences/s mlm_loss : 10.1641  nsp_loss : 0.6822  total_loss : 10.8463  avg_loss_step : 10.8439  learning_rate : 7.5e-05 
DLL 2022-11-26 09:43:09.500732 - Iteration: 28  throughput_train : 1250.550 sequences/s mlm_loss : 10.1120  nsp_loss : 0.6917  total_loss : 10.8037  avg_loss_step : 10.8218  learning_rate : 7.8000005e-05 
DLL 2022-11-26 09:44:03.645783 - Iteration: 29  throughput_train : 1248.485 sequences/s mlm_loss : 10.1068  nsp_loss : 0.7110  total_loss : 10.8178  avg_loss_step : 10.7955  learning_rate : 8.1000006e-05 
DLL 2022-11-26 09:44:57.674318 - Iteration: 30  throughput_train : 1251.179 sequences/s mlm_loss : 10.0996  nsp_loss : 0.6411  total_loss : 10.7407  avg_loss_step : 10.7735  learning_rate : 8.4e-05 
DLL 2022-11-26 09:45:51.712626 - Iteration: 31  throughput_train : 1250.947 sequences/s mlm_loss : 10.0537  nsp_loss : 0.6560  total_loss : 10.7098  avg_loss_step : 10.7480  learning_rate : 8.7e-05 
DLL 2022-11-26 09:46:45.816098 - Iteration: 32  throughput_train : 1249.439 sequences/s mlm_loss : 10.0165  nsp_loss : 0.6734  total_loss : 10.6899  avg_loss_step : 10.7186  learning_rate : 9e-05 
DLL 2022-11-26 09:47:39.870758 - Iteration: 33  throughput_train : 1250.572 sequences/s mlm_loss : 10.0332  nsp_loss : 0.6799  total_loss : 10.7132  avg_loss_step : 10.6990  learning_rate : 9.3e-05 
DLL 2022-11-26 09:48:33.960129 - Iteration: 34  throughput_train : 1249.761 sequences/s mlm_loss : 10.0199  nsp_loss : 0.6951  total_loss : 10.7150  avg_loss_step : 10.6799  learning_rate : 9.6e-05 
DLL 2022-11-26 09:49:28.074992 - Iteration: 35  throughput_train : 1249.180 sequences/s mlm_loss : 9.9900  nsp_loss : 0.6971  total_loss : 10.6870  avg_loss_step : 10.6543  learning_rate : 9.9000004e-05 
DLL 2022-11-26 09:50:22.153256 - Iteration: 36  throughput_train : 1250.025 sequences/s mlm_loss : 9.9333  nsp_loss : 0.6747  total_loss : 10.6080  avg_loss_step : 10.6277  learning_rate : 0.000102000005 
DLL 2022-11-26 09:51:16.280875 - Iteration: 37  throughput_train : 1248.880 sequences/s mlm_loss : 9.9094  nsp_loss : 0.7065  total_loss : 10.6159  avg_loss_step : 10.5953  learning_rate : 0.00010500001 
DLL 2022-11-26 09:52:10.302099 - Iteration: 38  throughput_train : 1251.338 sequences/s mlm_loss : 9.9158  nsp_loss : 0.6815  total_loss : 10.5973  avg_loss_step : 10.5782  learning_rate : 0.00010800001 
DLL 2022-11-26 09:53:04.327432 - Iteration: 39  throughput_train : 1251.244 sequences/s mlm_loss : 9.8582  nsp_loss : 0.6926  total_loss : 10.5508  avg_loss_step : 10.5486  learning_rate : 0.000111 
DLL 2022-11-26 09:53:58.354869 - Iteration: 40  throughput_train : 1251.197 sequences/s mlm_loss : 9.8662  nsp_loss : 0.6769  total_loss : 10.5431  avg_loss_step : 10.5257  learning_rate : 0.000114 
DLL 2022-11-26 09:54:52.392900 - Iteration: 41  throughput_train : 1250.946 sequences/s mlm_loss : 9.8215  nsp_loss : 0.6830  total_loss : 10.5045  avg_loss_step : 10.4926  learning_rate : 0.000117 
DLL 2022-11-26 09:55:46.452646 - Iteration: 42  throughput_train : 1250.445 sequences/s mlm_loss : 9.7869  nsp_loss : 0.6419  total_loss : 10.4288  avg_loss_step : 10.4754  learning_rate : 0.000120000004 
DLL 2022-11-26 09:56:40.495067 - Iteration: 43  throughput_train : 1250.856 sequences/s mlm_loss : 9.7907  nsp_loss : 0.6856  total_loss : 10.4762  avg_loss_step : 10.4551  learning_rate : 0.000123 
DLL 2022-11-26 09:57:34.543350 - Iteration: 44  throughput_train : 1250.707 sequences/s mlm_loss : 9.7980  nsp_loss : 0.6851  total_loss : 10.4831  avg_loss_step : 10.4283  learning_rate : 0.000126 
DLL 2022-11-26 09:58:28.607792 - Iteration: 45  throughput_train : 1250.339 sequences/s mlm_loss : 9.7316  nsp_loss : 0.6914  total_loss : 10.4231  avg_loss_step : 10.4052  learning_rate : 0.00012900001 
DLL 2022-11-26 09:59:22.750893 - Iteration: 46  throughput_train : 1248.530 sequences/s mlm_loss : 9.7070  nsp_loss : 0.6913  total_loss : 10.3983  avg_loss_step : 10.3928  learning_rate : 0.000132 
DLL 2022-11-26 10:00:16.768171 - Iteration: 47  throughput_train : 1251.438 sequences/s mlm_loss : 9.6732  nsp_loss : 0.6425  total_loss : 10.3156  avg_loss_step : 10.3676  learning_rate : 0.00013500001 
DLL 2022-11-26 10:01:10.832880 - Iteration: 48  throughput_train : 1250.340 sequences/s mlm_loss : 9.6798  nsp_loss : 0.6556  total_loss : 10.3354  avg_loss_step : 10.3513  learning_rate : 0.000138 
DLL 2022-11-26 10:02:04.895261 - Iteration: 49  throughput_train : 1250.385 sequences/s mlm_loss : 9.5796  nsp_loss : 0.6904  total_loss : 10.2700  avg_loss_step : 10.3223  learning_rate : 0.00014100001 
DLL 2022-11-26 10:02:59.091233 - Iteration: 50  throughput_train : 1247.307 sequences/s mlm_loss : 9.6698  nsp_loss : 0.6904  total_loss : 10.3602  avg_loss_step : 10.2883  learning_rate : 0.000144 
DLL 2022-11-26 10:03:53.296723 - Iteration: 51  throughput_train : 1247.084 sequences/s mlm_loss : 9.6245  nsp_loss : 0.6916  total_loss : 10.3161  avg_loss_step : 10.2879  learning_rate : 0.000147 
DLL 2022-11-26 10:04:47.354148 - Iteration: 52  throughput_train : 1250.516 sequences/s mlm_loss : 9.5376  nsp_loss : 0.6877  total_loss : 10.2254  avg_loss_step : 10.2575  learning_rate : 0.00015 
DLL 2022-11-26 10:05:41.449172 - Iteration: 53  throughput_train : 1249.631 sequences/s mlm_loss : 9.5588  nsp_loss : 0.6513  total_loss : 10.2100  avg_loss_step : 10.2357  learning_rate : 0.000153 
DLL 2022-11-26 10:06:35.524794 - Iteration: 54  throughput_train : 1250.077 sequences/s mlm_loss : 9.6004  nsp_loss : 0.6756  total_loss : 10.2760  avg_loss_step : 10.2296  learning_rate : 0.00015600001 
DLL 2022-11-26 10:07:29.565113 - Iteration: 55  throughput_train : 1250.898 sequences/s mlm_loss : 9.5150  nsp_loss : 0.6796  total_loss : 10.1946  avg_loss_step : 10.2031  learning_rate : 0.000159 
DLL 2022-11-26 10:08:23.584624 - Iteration: 56  throughput_train : 1251.383 sequences/s mlm_loss : 9.4622  nsp_loss : 0.7079  total_loss : 10.1701  avg_loss_step : 10.1845  learning_rate : 0.00016200001 
DLL 2022-11-26 10:09:17.609619 - Iteration: 57  throughput_train : 1251.258 sequences/s mlm_loss : 9.5166  nsp_loss : 0.6950  total_loss : 10.2116  avg_loss_step : 10.1703  learning_rate : 0.000165 
DLL 2022-11-26 10:10:11.627256 - Iteration: 58  throughput_train : 1251.422 sequences/s mlm_loss : 9.4852  nsp_loss : 0.6856  total_loss : 10.1707  avg_loss_step : 10.1538  learning_rate : 0.000168 
DLL 2022-11-26 10:11:05.651899 - Iteration: 59  throughput_train : 1251.269 sequences/s mlm_loss : 9.4626  nsp_loss : 0.6731  total_loss : 10.1357  avg_loss_step : 10.1363  learning_rate : 0.000171 
DLL 2022-11-26 10:11:59.698490 - Iteration: 60  throughput_train : 1250.750 sequences/s mlm_loss : 9.3666  nsp_loss : 0.6925  total_loss : 10.0591  avg_loss_step : 10.1107  learning_rate : 0.000174 
DLL 2022-11-26 10:12:53.677541 - Iteration: 61  throughput_train : 1252.315 sequences/s mlm_loss : 9.4071  nsp_loss : 0.6643  total_loss : 10.0714  avg_loss_step : 10.1133  learning_rate : 0.00017700001 
DLL 2022-11-26 10:13:47.711725 - Iteration: 62  throughput_train : 1251.033 sequences/s mlm_loss : 9.3529  nsp_loss : 0.6564  total_loss : 10.0092  avg_loss_step : 10.0929  learning_rate : 0.00018 
DLL 2022-11-26 10:14:41.746164 - Iteration: 63  throughput_train : 1251.034 sequences/s mlm_loss : 9.3452  nsp_loss : 0.6750  total_loss : 10.0202  avg_loss_step : 10.0804  learning_rate : 0.00018300001 
DLL 2022-11-26 10:15:35.872822 - Iteration: 64  throughput_train : 1248.898 sequences/s mlm_loss : 9.4248  nsp_loss : 0.6716  total_loss : 10.0964  avg_loss_step : 10.0515  learning_rate : 0.000186 
DLL 2022-11-26 10:16:29.933816 - Iteration: 65  throughput_train : 1250.424 sequences/s mlm_loss : 9.3893  nsp_loss : 0.6796  total_loss : 10.0689  avg_loss_step : 10.0361  learning_rate : 0.00018900001 
DLL 2022-11-26 10:17:23.961118 - Iteration: 66  throughput_train : 1251.204 sequences/s mlm_loss : 9.3492  nsp_loss : 0.6998  total_loss : 10.0490  avg_loss_step : 10.0323  learning_rate : 0.000192 
DLL 2022-11-26 10:18:18.076736 - Iteration: 67  throughput_train : 1249.153 sequences/s mlm_loss : 9.3854  nsp_loss : 0.6828  total_loss : 10.0682  avg_loss_step : 10.0220  learning_rate : 0.000195 
DLL 2022-11-26 10:19:12.145287 - Iteration: 68  throughput_train : 1250.240 sequences/s mlm_loss : 9.2686  nsp_loss : 0.6781  total_loss : 9.9467  avg_loss_step : 10.0016  learning_rate : 0.00019800001 
DLL 2022-11-26 10:20:06.212666 - Iteration: 69  throughput_train : 1250.268 sequences/s mlm_loss : 9.1783  nsp_loss : 0.6727  total_loss : 9.8511  avg_loss_step : 9.9837  learning_rate : 0.000201 
DLL 2022-11-26 10:21:00.375746 - Iteration: 70  throughput_train : 1248.060 sequences/s mlm_loss : 9.3953  nsp_loss : 0.6975  total_loss : 10.0928  avg_loss_step : 9.9857  learning_rate : 0.00020400001 
DLL 2022-11-26 10:21:54.452130 - Iteration: 71  throughput_train : 1250.094 sequences/s mlm_loss : 9.2741  nsp_loss : 0.6811  total_loss : 9.9552  avg_loss_step : 9.9517  learning_rate : 0.000207 
DLL 2022-11-26 10:22:48.476976 - Iteration: 72  throughput_train : 1251.253 sequences/s mlm_loss : 9.2555  nsp_loss : 0.6607  total_loss : 9.9163  avg_loss_step : 9.9299  learning_rate : 0.00021000001 
DLL 2022-11-26 10:23:42.518840 - Iteration: 73  throughput_train : 1250.867 sequences/s mlm_loss : 9.2024  nsp_loss : 0.6970  total_loss : 9.8994  avg_loss_step : 9.9290  learning_rate : 0.000213 
DLL 2022-11-26 10:24:36.525570 - Iteration: 74  throughput_train : 1251.679 sequences/s mlm_loss : 9.1844  nsp_loss : 0.7069  total_loss : 9.8913  avg_loss_step : 9.9196  learning_rate : 0.00021600001 
DLL 2022-11-26 10:25:30.541526 - Iteration: 75  throughput_train : 1251.455 sequences/s mlm_loss : 9.1989  nsp_loss : 0.6942  total_loss : 9.8931  avg_loss_step : 9.9116  learning_rate : 0.00021900001 
DLL 2022-11-26 10:26:24.627392 - Iteration: 76  throughput_train : 1249.847 sequences/s mlm_loss : 9.2596  nsp_loss : 0.6531  total_loss : 9.9126  avg_loss_step : 9.8868  learning_rate : 0.000222 
DLL 2022-11-26 10:27:18.771358 - Iteration: 77  throughput_train : 1248.503 sequences/s mlm_loss : 9.3423  nsp_loss : 0.6756  total_loss : 10.0179  avg_loss_step : 9.8727  learning_rate : 0.00022500001 
DLL 2022-11-26 10:28:12.793767 - Iteration: 78  throughput_train : 1251.315 sequences/s mlm_loss : 9.2393  nsp_loss : 0.7039  total_loss : 9.9433  avg_loss_step : 9.8647  learning_rate : 0.000228 
DLL 2022-11-26 10:29:06.920010 - Iteration: 79  throughput_train : 1248.911 sequences/s mlm_loss : 9.1890  nsp_loss : 0.6673  total_loss : 9.8562  avg_loss_step : 9.8542  learning_rate : 0.00023100001 
DLL 2022-11-26 10:30:00.952836 - Iteration: 80  throughput_train : 1251.073 sequences/s mlm_loss : 9.1351  nsp_loss : 0.6800  total_loss : 9.8151  avg_loss_step : 9.8532  learning_rate : 0.000234 
DLL 2022-11-26 10:30:54.960077 - Iteration: 81  throughput_train : 1251.664 sequences/s mlm_loss : 9.1369  nsp_loss : 0.6859  total_loss : 9.8228  avg_loss_step : 9.8347  learning_rate : 0.00023700001 
DLL 2022-11-26 10:31:49.108467 - Iteration: 82  throughput_train : 1248.402 sequences/s mlm_loss : 9.1111  nsp_loss : 0.6342  total_loss : 9.7452  avg_loss_step : 9.8303  learning_rate : 0.00024000001 
DLL 2022-11-26 10:32:43.189922 - Iteration: 83  throughput_train : 1249.952 sequences/s mlm_loss : 9.1163  nsp_loss : 0.7194  total_loss : 9.8357  avg_loss_step : 9.8331  learning_rate : 0.000243 
DLL 2022-11-26 10:33:37.300559 - Iteration: 84  throughput_train : 1249.266 sequences/s mlm_loss : 9.1472  nsp_loss : 0.6744  total_loss : 9.8216  avg_loss_step : 9.8067  learning_rate : 0.000246 
DLL 2022-11-26 10:34:31.271480 - Iteration: 85  throughput_train : 1252.501 sequences/s mlm_loss : 9.0896  nsp_loss : 0.6736  total_loss : 9.7632  avg_loss_step : 9.7869  learning_rate : 0.000249 
DLL 2022-11-26 10:35:25.539184 - Iteration: 86  throughput_train : 1245.648 sequences/s mlm_loss : 9.1270  nsp_loss : 0.6942  total_loss : 9.8212  avg_loss_step : 9.7939  learning_rate : 0.000252 
DLL 2022-11-26 10:36:19.589428 - Iteration: 87  throughput_train : 1250.664 sequences/s mlm_loss : 9.0793  nsp_loss : 0.6542  total_loss : 9.7334  avg_loss_step : 9.7821  learning_rate : 0.00025500002 
DLL 2022-11-26 10:37:13.649030 - Iteration: 88  throughput_train : 1250.443 sequences/s mlm_loss : 9.1866  nsp_loss : 0.6781  total_loss : 9.8647  avg_loss_step : 9.7776  learning_rate : 0.00025800001 
DLL 2022-11-26 10:38:07.700494 - Iteration: 89  throughput_train : 1250.636 sequences/s mlm_loss : 9.1479  nsp_loss : 0.6641  total_loss : 9.8120  avg_loss_step : 9.7536  learning_rate : 0.000261 
DLL 2022-11-26 10:39:01.755915 - Iteration: 90  throughput_train : 1250.549 sequences/s mlm_loss : 9.0895  nsp_loss : 0.6913  total_loss : 9.7808  avg_loss_step : 9.7492  learning_rate : 0.000264 
DLL 2022-11-26 10:39:55.775316 - Iteration: 91  throughput_train : 1251.386 sequences/s mlm_loss : 9.0686  nsp_loss : 0.6783  total_loss : 9.7469  avg_loss_step : 9.7477  learning_rate : 0.000267 
DLL 2022-11-26 10:40:49.780657 - Iteration: 92  throughput_train : 1251.710 sequences/s mlm_loss : 8.9867  nsp_loss : 0.6778  total_loss : 9.6644  avg_loss_step : 9.7290  learning_rate : 0.00027000002 
DLL 2022-11-26 10:41:44.367348 - Iteration: 93  throughput_train : 1238.377 sequences/s mlm_loss : 9.0915  nsp_loss : 0.6871  total_loss : 9.7786  avg_loss_step : 9.7159  learning_rate : 0.000273 
DLL 2022-11-26 10:42:38.395344 - Iteration: 94  throughput_train : 1251.184 sequences/s mlm_loss : 9.0397  nsp_loss : 0.6867  total_loss : 9.7264  avg_loss_step : 9.7082  learning_rate : 0.000276 
DLL 2022-11-26 10:43:32.386115 - Iteration: 95  throughput_train : 1252.051 sequences/s mlm_loss : 9.0343  nsp_loss : 0.6820  total_loss : 9.7163  avg_loss_step : 9.7007  learning_rate : 0.000279 
DLL 2022-11-26 10:44:26.417695 - Iteration: 96  throughput_train : 1251.097 sequences/s mlm_loss : 9.0168  nsp_loss : 0.6762  total_loss : 9.6930  avg_loss_step : 9.6890  learning_rate : 0.00028200002 
DLL 2022-11-26 10:45:20.430462 - Iteration: 97  throughput_train : 1251.539 sequences/s mlm_loss : 9.0132  nsp_loss : 0.6962  total_loss : 9.7094  avg_loss_step : 9.6828  learning_rate : 0.00028500002 
DLL 2022-11-26 10:46:14.397581 - Iteration: 98  throughput_train : 1252.593 sequences/s mlm_loss : 9.0635  nsp_loss : 0.6861  total_loss : 9.7496  avg_loss_step : 9.6850  learning_rate : 0.000288 
DLL 2022-11-26 10:47:08.374511 - Iteration: 99  throughput_train : 1252.370 sequences/s mlm_loss : 8.9144  nsp_loss : 0.6658  total_loss : 9.5801  avg_loss_step : 9.6790  learning_rate : 0.000291 
DLL 2022-11-26 10:48:02.430180 - Iteration: 100  throughput_train : 1250.544 sequences/s mlm_loss : 9.0256  nsp_loss : 0.6817  total_loss : 9.7073  avg_loss_step : 9.6728  learning_rate : 0.000294 
DLL 2022-11-26 10:48:56.401338 - Iteration: 101  throughput_train : 1252.498 sequences/s mlm_loss : 8.9476  nsp_loss : 0.6665  total_loss : 9.6141  avg_loss_step : 9.6591  learning_rate : 0.00029700002 
DLL 2022-11-26 10:49:50.386522 - Iteration: 102  throughput_train : 1252.173 sequences/s mlm_loss : 8.9689  nsp_loss : 0.6806  total_loss : 9.6496  avg_loss_step : 9.6385  learning_rate : 0.0003 
DLL 2022-11-26 10:50:44.480678 - Iteration: 103  throughput_train : 1249.650 sequences/s mlm_loss : 8.9671  nsp_loss : 0.7013  total_loss : 9.6684  avg_loss_step : 9.6383  learning_rate : 0.000303 
DLL 2022-11-26 10:51:38.503009 - Iteration: 104  throughput_train : 1251.318 sequences/s mlm_loss : 8.9256  nsp_loss : 0.6730  total_loss : 9.5986  avg_loss_step : 9.6340  learning_rate : 0.000306 
DLL 2022-11-26 10:52:32.472372 - Iteration: 105  throughput_train : 1252.542 sequences/s mlm_loss : 8.9359  nsp_loss : 0.6548  total_loss : 9.5907  avg_loss_step : 9.6126  learning_rate : 0.00030900002 
DLL 2022-11-26 10:53:26.443889 - Iteration: 106  throughput_train : 1252.494 sequences/s mlm_loss : 8.9855  nsp_loss : 0.6916  total_loss : 9.6772  avg_loss_step : 9.6169  learning_rate : 0.00031200002 
DLL 2022-11-26 10:54:20.403466 - Iteration: 107  throughput_train : 1252.769 sequences/s mlm_loss : 8.9242  nsp_loss : 0.6839  total_loss : 9.6081  avg_loss_step : 9.6097  learning_rate : 0.000315 
DLL 2022-11-26 10:55:14.385564 - Iteration: 108  throughput_train : 1252.245 sequences/s mlm_loss : 8.8224  nsp_loss : 0.6854  total_loss : 9.5078  avg_loss_step : 9.5926  learning_rate : 0.000318 
DLL 2022-11-26 10:56:08.363410 - Iteration: 109  throughput_train : 1252.341 sequences/s mlm_loss : 8.9140  nsp_loss : 0.6494  total_loss : 9.5634  avg_loss_step : 9.5842  learning_rate : 0.000321 
DLL 2022-11-26 10:57:02.397569 - Iteration: 110  throughput_train : 1251.040 sequences/s mlm_loss : 8.8844  nsp_loss : 0.6789  total_loss : 9.5633  avg_loss_step : 9.5805  learning_rate : 0.00032400002 
DLL 2022-11-26 10:57:56.369136 - Iteration: 111  throughput_train : 1252.487 sequences/s mlm_loss : 8.8825  nsp_loss : 0.6801  total_loss : 9.5626  avg_loss_step : 9.5808  learning_rate : 0.00032700002 
DLL 2022-11-26 10:58:50.422976 - Iteration: 112  throughput_train : 1250.580 sequences/s mlm_loss : 8.8260  nsp_loss : 0.6853  total_loss : 9.5113  avg_loss_step : 9.5484  learning_rate : 0.00033 
DLL 2022-11-26 10:59:44.427143 - Iteration: 113  throughput_train : 1251.737 sequences/s mlm_loss : 8.9990  nsp_loss : 0.6559  total_loss : 9.6549  avg_loss_step : 9.5631  learning_rate : 0.000333 
DLL 2022-11-26 11:00:38.437267 - Iteration: 114  throughput_train : 1251.601 sequences/s mlm_loss : 8.8771  nsp_loss : 0.6742  total_loss : 9.5513  avg_loss_step : 9.5454  learning_rate : 0.000336 
INFO:tensorflow:loss = 9.666968, step = 113 (6273.890 sec)
INFO:tensorflow:loss = 9.555172, step = 113 (6274.600 sec)
INFO:tensorflow:loss = 9.576338, step = 113 (6275.005 sec)
I1126 11:02:02.279882 140161565357888 basic_session_run_hooks.py:260] loss = 9.666968, step = 113 (6273.890 sec)
I1126 11:02:02.279957 139624373462848 basic_session_run_hooks.py:260] loss = 9.555172, step = 113 (6274.600 sec)
I1126 11:02:02.280045 140581824722752 basic_session_run_hooks.py:260] loss = 9.576338, step = 113 (6275.005 sec)
INFO:tensorflow:loss = 9.602398, step = 113 (6274.754 sec)
I1126 11:02:02.280527 140210787432256 basic_session_run_hooks.py:260] loss = 9.602398, step = 113 (6274.754 sec)
INFO:tensorflow:loss = 9.554328, step = 113 (6275.075 sec)
I1126 11:02:02.281189 139856856876864 basic_session_run_hooks.py:260] loss = 9.554328, step = 113 (6275.075 sec)
INFO:tensorflow:loss = 9.58566, step = 113 (6290.395 sec)
INFO:tensorflow:loss = 9.543957, step = 113 (6288.146 sec)
I1126 11:02:02.281180 139916827465536 basic_session_run_hooks.py:260] loss = 9.58566, step = 113 (6290.395 sec)
I1126 11:02:02.281250 139823941363520 basic_session_run_hooks.py:260] loss = 9.543957, step = 113 (6288.146 sec)
INFO:tensorflow:loss = 9.464182, step = 113 (6273.019 sec)
I1126 11:02:02.295087 140307689948992 basic_session_run_hooks.py:260] loss = 9.464182, step = 113 (6273.019 sec)
DLL 2022-11-26 11:02:21.251646 - Iteration: 115  throughput_train : 657.425 sequences/s mlm_loss : 8.9309  nsp_loss : 0.6614  total_loss : 9.5922  avg_loss_step : 9.5451  learning_rate : 0.00033900002 
DLL 2022-11-26 11:03:15.202909 - Iteration: 116  throughput_train : 1252.963 sequences/s mlm_loss : 8.7428  nsp_loss : 0.6848  total_loss : 9.4276  avg_loss_step : 9.5253  learning_rate : 0.000342 
DLL 2022-11-26 11:04:09.247892 - Iteration: 117  throughput_train : 1250.784 sequences/s mlm_loss : 8.9157  nsp_loss : 0.6713  total_loss : 9.5870  avg_loss_step : 9.5068  learning_rate : 0.000345 
DLL 2022-11-26 11:05:03.284324 - Iteration: 118  throughput_train : 1250.993 sequences/s mlm_loss : 8.9062  nsp_loss : 0.6883  total_loss : 9.5945  avg_loss_step : 9.5050  learning_rate : 0.000348 
DLL 2022-11-26 11:05:57.282890 - Iteration: 119  throughput_train : 1251.860 sequences/s mlm_loss : 8.8718  nsp_loss : 0.6583  total_loss : 9.5301  avg_loss_step : 9.4966  learning_rate : 0.00035100002 
DLL 2022-11-26 11:06:51.287131 - Iteration: 120  throughput_train : 1251.734 sequences/s mlm_loss : 8.7296  nsp_loss : 0.6655  total_loss : 9.3951  avg_loss_step : 9.4874  learning_rate : 0.00035400002 
DLL 2022-11-26 11:07:45.304815 - Iteration: 121  throughput_train : 1251.421 sequences/s mlm_loss : 8.7781  nsp_loss : 0.6803  total_loss : 9.4584  avg_loss_step : 9.4672  learning_rate : 0.000357 
DLL 2022-11-26 11:08:39.293707 - Iteration: 122  throughput_train : 1252.092 sequences/s mlm_loss : 8.7093  nsp_loss : 0.6740  total_loss : 9.3833  avg_loss_step : 9.4736  learning_rate : 0.00036 
DLL 2022-11-26 11:09:33.290152 - Iteration: 123  throughput_train : 1251.906 sequences/s mlm_loss : 8.7097  nsp_loss : 0.6477  total_loss : 9.3574  avg_loss_step : 9.4501  learning_rate : 0.000363 
DLL 2022-11-26 11:10:27.301459 - Iteration: 124  throughput_train : 1251.568 sequences/s mlm_loss : 8.7718  nsp_loss : 0.6599  total_loss : 9.4317  avg_loss_step : 9.4161  learning_rate : 0.00036600002 
DLL 2022-11-26 11:11:21.365657 - Iteration: 125  throughput_train : 1250.344 sequences/s mlm_loss : 8.7784  nsp_loss : 0.6183  total_loss : 9.3967  avg_loss_step : 9.4281  learning_rate : 0.00036900002 
DLL 2022-11-26 11:12:15.418714 - Iteration: 126  throughput_train : 1250.599 sequences/s mlm_loss : 8.8131  nsp_loss : 0.6532  total_loss : 9.4663  avg_loss_step : 9.4116  learning_rate : 0.000372 
DLL 2022-11-26 11:13:09.481474 - Iteration: 127  throughput_train : 1250.381 sequences/s mlm_loss : 8.7110  nsp_loss : 0.6688  total_loss : 9.3799  avg_loss_step : 9.3950  learning_rate : 0.000375 
DLL 2022-11-26 11:14:03.604337 - Iteration: 128  throughput_train : 1248.984 sequences/s mlm_loss : 8.7878  nsp_loss : 0.6881  total_loss : 9.4759  avg_loss_step : 9.3912  learning_rate : 0.00037800003 
DLL 2022-11-26 11:14:57.655587 - Iteration: 129  throughput_train : 1250.653 sequences/s mlm_loss : 8.6671  nsp_loss : 0.6983  total_loss : 9.3654  avg_loss_step : 9.3874  learning_rate : 0.00038100002 
DLL 2022-11-26 11:15:51.697703 - Iteration: 130  throughput_train : 1250.857 sequences/s mlm_loss : 8.6740  nsp_loss : 0.6824  total_loss : 9.3565  avg_loss_step : 9.4095  learning_rate : 0.000384 
DLL 2022-11-26 11:16:45.759517 - Iteration: 131  throughput_train : 1250.398 sequences/s mlm_loss : 8.7792  nsp_loss : 0.6203  total_loss : 9.3996  avg_loss_step : 9.3657  learning_rate : 0.000387 
DLL 2022-11-26 11:17:39.876214 - Iteration: 132  throughput_train : 1249.129 sequences/s mlm_loss : 8.7870  nsp_loss : 0.6873  total_loss : 9.4743  avg_loss_step : 9.3483  learning_rate : 0.00039 
DLL 2022-11-26 11:18:33.889162 - Iteration: 133  throughput_train : 1251.527 sequences/s mlm_loss : 8.7324  nsp_loss : 0.6588  total_loss : 9.3912  avg_loss_step : 9.3320  learning_rate : 0.00039300002 
DLL 2022-11-26 11:19:27.882226 - Iteration: 134  throughput_train : 1251.991 sequences/s mlm_loss : 8.5727  nsp_loss : 0.6654  total_loss : 9.2381  avg_loss_step : 9.3313  learning_rate : 0.00039600002 
DLL 2022-11-26 11:20:21.880900 - Iteration: 135  throughput_train : 1251.859 sequences/s mlm_loss : 8.7206  nsp_loss : 0.6909  total_loss : 9.4115  avg_loss_step : 9.3332  learning_rate : 0.000399 
DLL 2022-11-26 11:21:15.922829 - Iteration: 136  throughput_train : 1250.856 sequences/s mlm_loss : 8.7268  nsp_loss : 0.6041  total_loss : 9.3309  avg_loss_step : 9.3155  learning_rate : 0.000402 
DLL 2022-11-26 11:22:09.962196 - Iteration: 137  throughput_train : 1250.919 sequences/s mlm_loss : 8.5881  nsp_loss : 0.6913  total_loss : 9.2794  avg_loss_step : 9.2754  learning_rate : 0.00040500003 
DLL 2022-11-26 11:23:04.016354 - Iteration: 138  throughput_train : 1250.583 sequences/s mlm_loss : 8.5768  nsp_loss : 0.6660  total_loss : 9.2429  avg_loss_step : 9.2900  learning_rate : 0.00040800002 
DLL 2022-11-26 11:23:58.191343 - Iteration: 139  throughput_train : 1247.790 sequences/s mlm_loss : 8.6407  nsp_loss : 0.7256  total_loss : 9.3663  avg_loss_step : 9.2841  learning_rate : 0.00041100002 
DLL 2022-11-26 11:24:52.257375 - Iteration: 140  throughput_train : 1250.302 sequences/s mlm_loss : 8.7062  nsp_loss : 0.6363  total_loss : 9.3426  avg_loss_step : 9.2529  learning_rate : 0.000414 
DLL 2022-11-26 11:25:46.318279 - Iteration: 141  throughput_train : 1250.429 sequences/s mlm_loss : 8.6593  nsp_loss : 0.6432  total_loss : 9.3025  avg_loss_step : 9.2527  learning_rate : 0.000417 
DLL 2022-11-26 11:26:40.372614 - Iteration: 142  throughput_train : 1250.575 sequences/s mlm_loss : 8.4732  nsp_loss : 0.6365  total_loss : 9.1097  avg_loss_step : 9.2276  learning_rate : 0.00042000003 
DLL 2022-11-26 11:27:34.531711 - Iteration: 143  throughput_train : 1248.152 sequences/s mlm_loss : 8.5418  nsp_loss : 0.6318  total_loss : 9.1737  avg_loss_step : 9.2349  learning_rate : 0.00042300002 
DLL 2022-11-26 11:28:28.619462 - Iteration: 144  throughput_train : 1249.803 sequences/s mlm_loss : 8.4816  nsp_loss : 0.6777  total_loss : 9.1592  avg_loss_step : 9.2170  learning_rate : 0.000426 
DLL 2022-11-26 11:29:22.710907 - Iteration: 145  throughput_train : 1249.706 sequences/s mlm_loss : 8.6456  nsp_loss : 0.6949  total_loss : 9.3405  avg_loss_step : 9.2097  learning_rate : 0.000429 
DLL 2022-11-26 11:30:16.752700 - Iteration: 146  throughput_train : 1250.867 sequences/s mlm_loss : 8.5839  nsp_loss : 0.5944  total_loss : 9.1784  avg_loss_step : 9.1743  learning_rate : 0.00043200003 
DLL 2022-11-26 11:31:10.848244 - Iteration: 147  throughput_train : 1249.618 sequences/s mlm_loss : 8.4975  nsp_loss : 0.6788  total_loss : 9.1763  avg_loss_step : 9.1963  learning_rate : 0.00043500002 
DLL 2022-11-26 11:32:04.861577 - Iteration: 148  throughput_train : 1251.522 sequences/s mlm_loss : 8.3990  nsp_loss : 0.6576  total_loss : 9.0566  avg_loss_step : 9.1607  learning_rate : 0.00043800002 
DLL 2022-11-26 11:32:58.961222 - Iteration: 149  throughput_train : 1249.526 sequences/s mlm_loss : 8.4861  nsp_loss : 0.6646  total_loss : 9.1506  avg_loss_step : 9.1557  learning_rate : 0.000441 
DLL 2022-11-26 11:33:53.014322 - Iteration: 150  throughput_train : 1250.602 sequences/s mlm_loss : 8.4225  nsp_loss : 0.6166  total_loss : 9.0392  avg_loss_step : 9.1578  learning_rate : 0.000444 
DLL 2022-11-26 11:34:47.042125 - Iteration: 151  throughput_train : 1251.181 sequences/s mlm_loss : 8.4772  nsp_loss : 0.6603  total_loss : 9.1375  avg_loss_step : 9.1532  learning_rate : 0.00044700003 
DLL 2022-11-26 11:35:41.118962 - Iteration: 152  throughput_train : 1250.052 sequences/s mlm_loss : 8.4851  nsp_loss : 0.6162  total_loss : 9.1013  avg_loss_step : 9.1379  learning_rate : 0.00045000002 
DLL 2022-11-26 11:36:35.108904 - Iteration: 153  throughput_train : 1252.058 sequences/s mlm_loss : 8.5037  nsp_loss : 0.6692  total_loss : 9.1729  avg_loss_step : 9.1272  learning_rate : 0.00045300002 
DLL 2022-11-26 11:37:29.102762 - Iteration: 154  throughput_train : 1251.970 sequences/s mlm_loss : 8.5738  nsp_loss : 0.6480  total_loss : 9.2218  avg_loss_step : 9.1058  learning_rate : 0.000456 
DLL 2022-11-26 11:38:23.177182 - Iteration: 155  throughput_train : 1250.111 sequences/s mlm_loss : 8.4204  nsp_loss : 0.6764  total_loss : 9.0968  avg_loss_step : 9.0855  learning_rate : 0.000459 
DLL 2022-11-26 11:39:17.269603 - Iteration: 156  throughput_train : 1249.690 sequences/s mlm_loss : 8.5212  nsp_loss : 0.6207  total_loss : 9.1419  avg_loss_step : 9.0865  learning_rate : 0.00046200003 
DLL 2022-11-26 11:40:11.347857 - Iteration: 157  throughput_train : 1250.021 sequences/s mlm_loss : 8.3435  nsp_loss : 0.6675  total_loss : 9.0110  avg_loss_step : 9.0678  learning_rate : 0.00046500002 
DLL 2022-11-26 11:41:05.398004 - Iteration: 158  throughput_train : 1250.664 sequences/s mlm_loss : 8.4733  nsp_loss : 0.6400  total_loss : 9.1134  avg_loss_step : 9.0606  learning_rate : 0.000468 
DLL 2022-11-26 11:41:59.491517 - Iteration: 159  throughput_train : 1249.672 sequences/s mlm_loss : 8.4285  nsp_loss : 0.6781  total_loss : 9.1066  avg_loss_step : 9.0356  learning_rate : 0.000471 
DLL 2022-11-26 11:42:53.527505 - Iteration: 160  throughput_train : 1250.999 sequences/s mlm_loss : 8.3831  nsp_loss : 0.6564  total_loss : 9.0394  avg_loss_step : 9.0410  learning_rate : 0.00047400003 
DLL 2022-11-26 11:43:47.550787 - Iteration: 161  throughput_train : 1251.289 sequences/s mlm_loss : 8.4483  nsp_loss : 0.5932  total_loss : 9.0415  avg_loss_step : 9.0207  learning_rate : 0.00047700002 
DLL 2022-11-26 11:44:41.632448 - Iteration: 162  throughput_train : 1249.943 sequences/s mlm_loss : 8.3773  nsp_loss : 0.6701  total_loss : 9.0474  avg_loss_step : 9.0158  learning_rate : 0.00048000002 
DLL 2022-11-26 11:45:35.709844 - Iteration: 163  throughput_train : 1250.047 sequences/s mlm_loss : 8.2427  nsp_loss : 0.6903  total_loss : 8.9330  avg_loss_step : 9.0160  learning_rate : 0.000483 
DLL 2022-11-26 11:46:29.750797 - Iteration: 164  throughput_train : 1250.874 sequences/s mlm_loss : 8.4286  nsp_loss : 0.7199  total_loss : 9.1486  avg_loss_step : 9.0020  learning_rate : 0.000486 
DLL 2022-11-26 11:47:23.791264 - Iteration: 165  throughput_train : 1250.889 sequences/s mlm_loss : 8.3077  nsp_loss : 0.6743  total_loss : 8.9820  avg_loss_step : 8.9801  learning_rate : 0.000489 
DLL 2022-11-26 11:48:17.768744 - Iteration: 166  throughput_train : 1252.351 sequences/s mlm_loss : 8.3746  nsp_loss : 0.6681  total_loss : 9.0427  avg_loss_step : 8.9920  learning_rate : 0.000492 
DLL 2022-11-26 11:49:11.863527 - Iteration: 167  throughput_train : 1249.634 sequences/s mlm_loss : 8.2985  nsp_loss : 0.7093  total_loss : 9.0078  avg_loss_step : 8.9835  learning_rate : 0.00049500004 
DLL 2022-11-26 11:50:05.948275 - Iteration: 168  throughput_train : 1249.862 sequences/s mlm_loss : 8.3789  nsp_loss : 0.6910  total_loss : 9.0699  avg_loss_step : 8.9516  learning_rate : 0.000498 
DLL 2022-11-26 11:50:59.981143 - Iteration: 169  throughput_train : 1251.067 sequences/s mlm_loss : 8.2148  nsp_loss : 0.6763  total_loss : 8.8911  avg_loss_step : 8.9369  learning_rate : 0.00050100003 
DLL 2022-11-26 11:51:54.019215 - Iteration: 170  throughput_train : 1250.945 sequences/s mlm_loss : 8.2715  nsp_loss : 0.6383  total_loss : 8.9098  avg_loss_step : 8.9275  learning_rate : 0.000504 
DLL 2022-11-26 11:52:48.059034 - Iteration: 171  throughput_train : 1250.914 sequences/s mlm_loss : 8.3006  nsp_loss : 0.6768  total_loss : 8.9774  avg_loss_step : 8.9099  learning_rate : 0.000507 
DLL 2022-11-26 11:53:42.102535 - Iteration: 172  throughput_train : 1250.818 sequences/s mlm_loss : 8.2939  nsp_loss : 0.6161  total_loss : 8.9099  avg_loss_step : 8.9060  learning_rate : 0.00051000004 
DLL 2022-11-26 11:54:36.134546 - Iteration: 173  throughput_train : 1251.090 sequences/s mlm_loss : 8.1281  nsp_loss : 0.7059  total_loss : 8.8340  avg_loss_step : 8.8919  learning_rate : 0.000513 
DLL 2022-11-26 11:55:30.235218 - Iteration: 174  throughput_train : 1249.497 sequences/s mlm_loss : 8.3393  nsp_loss : 0.6156  total_loss : 8.9549  avg_loss_step : 8.8841  learning_rate : 0.00051600003 
DLL 2022-11-26 11:56:24.300559 - Iteration: 175  throughput_train : 1250.316 sequences/s mlm_loss : 8.2646  nsp_loss : 0.6547  total_loss : 8.9193  avg_loss_step : 8.8893  learning_rate : 0.000519 
DLL 2022-11-26 11:57:18.519152 - Iteration: 176  throughput_train : 1246.783 sequences/s mlm_loss : 8.0724  nsp_loss : 0.6328  total_loss : 8.7051  avg_loss_step : 8.8707  learning_rate : 0.000522 
DLL 2022-11-26 11:58:12.564221 - Iteration: 177  throughput_train : 1250.781 sequences/s mlm_loss : 8.2263  nsp_loss : 0.6432  total_loss : 8.8695  avg_loss_step : 8.8306  learning_rate : 0.00052500004 
DLL 2022-11-26 11:59:06.730808 - Iteration: 178  throughput_train : 1247.980 sequences/s mlm_loss : 8.2381  nsp_loss : 0.7118  total_loss : 8.9498  avg_loss_step : 8.8308  learning_rate : 0.000528 
DLL 2022-11-26 12:00:00.824680 - Iteration: 179  throughput_train : 1249.661 sequences/s mlm_loss : 8.3459  nsp_loss : 0.7137  total_loss : 9.0596  avg_loss_step : 8.8115  learning_rate : 0.000531 
DLL 2022-11-26 12:00:54.867266 - Iteration: 180  throughput_train : 1250.837 sequences/s mlm_loss : 8.2077  nsp_loss : 0.6884  total_loss : 8.8961  avg_loss_step : 8.8047  learning_rate : 0.000534 
DLL 2022-11-26 12:01:48.926610 - Iteration: 181  throughput_train : 1251.422 sequences/s mlm_loss : 8.1389  nsp_loss : 0.6803  total_loss : 8.8192  avg_loss_step : 8.7982  learning_rate : 0.000537 
INFO:tensorflow:Saving checkpoints for 180 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt.
I1126 12:01:48.927939 140307689948992 basic_session_run_hooks.py:606] Saving checkpoints for 180 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 8.659339.
I1126 12:01:49.694157 140210787432256 estimator.py:371] Loss for final step: 8.659339.
INFO:tensorflow:Loss for final step: 8.752252.
I1126 12:01:49.738502 140581824722752 estimator.py:371] Loss for final step: 8.752252.
INFO:tensorflow:Loss for final step: 8.7780285.
I1126 12:01:49.765966 139624373462848 estimator.py:371] Loss for final step: 8.7780285.
INFO:tensorflow:Loss for final step: 8.85923.
I1126 12:01:49.787000 140161565357888 estimator.py:371] Loss for final step: 8.85923.
INFO:tensorflow:Loss for final step: 8.805693.
I1126 12:01:49.792316 139856856876864 estimator.py:371] Loss for final step: 8.805693.
INFO:tensorflow:Loss for final step: 8.717302.
I1126 12:01:49.871077 139823941363520 estimator.py:371] Loss for final step: 8.717302.
INFO:tensorflow:Loss for final step: 8.899865.
I1126 12:01:49.892596 139916827465536 estimator.py:371] Loss for final step: 8.899865.
INFO:tensorflow:Loss for final step: 8.819179.
I1126 12:01:54.065948 140307689948992 estimator.py:371] Loss for final step: 8.819179.
INFO:tensorflow:-----------------------------
I1126 12:01:54.067481 140307689948992 run_pretraining.py:647] -----------------------------
INFO:tensorflow:Total Training Time = 9982.97 for Sentences = 12165120
I1126 12:01:54.067568 140307689948992 run_pretraining.py:649] Total Training Time = 9982.97 for Sentences = 12165120
INFO:tensorflow:Total Training Time W/O Overhead = 9506.92 for Sentences = 11827200
I1126 12:01:54.067637 140307689948992 run_pretraining.py:651] Total Training Time W/O Overhead = 9506.92 for Sentences = 11827200
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 1218.59
I1126 12:01:54.067689 140307689948992 run_pretraining.py:652] Throughput Average (sentences/sec) with overhead = 1218.59
INFO:tensorflow:Throughput Average (sentences/sec) = 1244.06
I1126 12:01:54.067753 140307689948992 run_pretraining.py:653] Throughput Average (sentences/sec) = 1244.06
DLL 2022-11-26 12:01:54.067805 -  throughput_train : 1244.062 sequences/s
DLL 2022-11-26 12:01:54.067923 -  total_loss : 8.7982 
INFO:tensorflow:-----------------------------
I1126 12:01:54.067983 140307689948992 run_pretraining.py:657] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1126 12:01:54.068066 140307689948992 run_pretraining.py:660] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1126 12:01:54.068115 140307689948992 run_pretraining.py:661]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1126 12:01:54.103300 140307689948992 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1126 12:01:54.103474 140307689948992 run_pretraining.py:260] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1126 12:01:54.103614 140307689948992 run_pretraining.py:262]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1126 12:01:54.103690 140307689948992 run_pretraining.py:262]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1126 12:01:54.103755 140307689948992 run_pretraining.py:262]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1126 12:01:54.103819 140307689948992 run_pretraining.py:262]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1126 12:01:54.103882 140307689948992 run_pretraining.py:262]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1126 12:01:54.103942 140307689948992 run_pretraining.py:262]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1126 12:01:54.104002 140307689948992 run_pretraining.py:262]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:340: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1126 12:01:55.362094 140307689948992 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:340: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:344: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1126 12:01:55.397542 140307689948992 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:344: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1126 12:01:55.450504 140307689948992 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2022-11-26T12:01:55Z
I1126 12:01:55.462718 140307689948992 evaluation.py:255] Starting evaluation at 2022-11-26T12:01:55Z
INFO:tensorflow:Graph was finalized.
I1126 12:01:56.050459 140307689948992 monitored_session.py:240] Graph was finalized.
2022-11-26 12:01:56.051303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 12:01:56.052216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2022-11-26 12:01:56.052263: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-11-26 12:01:56.052357: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-11-26 12:01:56.052409: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-11-26 12:01:56.052437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-11-26 12:01:56.052456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-11-26 12:01:56.052472: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-11-26 12:01:56.052495: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-11-26 12:01:56.052581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 12:01:56.053410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 12:01:56.054164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2022-11-26 12:01:56.054227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-11-26 12:01:56.054241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-11-26 12:01:56.054247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-11-26 12:01:56.054367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 12:01:56.055222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-11-26 12:01:56.056003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt-180
I1126 12:01:56.056995 140307689948992 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt-180
INFO:tensorflow:Running local_init_op.
I1126 12:01:56.933356 140307689948992 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1126 12:01:56.992780 140307689948992 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
I1126 12:02:02.810929 140307689948992 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1126 12:02:03.030392 140307689948992 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1126 12:02:03.250220 140307689948992 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1126 12:02:03.470042 140307689948992 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1126 12:02:03.690036 140307689948992 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1126 12:02:03.909817 140307689948992 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1126 12:02:04.129175 140307689948992 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1126 12:02:04.348459 140307689948992 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1126 12:02:04.568038 140307689948992 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1126 12:02:04.787573 140307689948992 evaluation.py:167] Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2022-11-26-12:02:05
I1126 12:02:05.156664 140307689948992 evaluation.py:275] Finished evaluation at 2022-11-26-12:02:05
INFO:tensorflow:Saving dict for global step 180: global_step = 180, loss = 8.850041, masked_lm_accuracy = 0.08905687, masked_lm_loss = 8.105519, next_sentence_accuracy = 0.54375, next_sentence_loss = 0.7455262
I1126 12:02:05.157210 140307689948992 estimator.py:2049] Saving dict for global step 180: global_step = 180, loss = 8.850041, masked_lm_accuracy = 0.08905687, masked_lm_loss = 8.105519, next_sentence_accuracy = 0.54375, next_sentence_loss = 0.7455262
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 180: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt-180
I1126 12:02:05.482749 140307689948992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 180: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs2262144_221126091528/phase_1/model.ckpt-180
INFO:tensorflow:-----------------------------
I1126 12:02:05.483824 140307689948992 run_pretraining.py:689] -----------------------------
INFO:tensorflow:Total Inference Time = 11.41 for Sentences = 800
I1126 12:02:05.483960 140307689948992 run_pretraining.py:691] Total Inference Time = 11.41 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 2.18 for Sentences = 792
I1126 12:02:05.484029 140307689948992 run_pretraining.py:693] Total Inference Time W/O Overhead = 2.18 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1126 12:02:05.484084 140307689948992 run_pretraining.py:694] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1126 12:02:05.484136 140307689948992 run_pretraining.py:695] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1126 12:02:05.484220 140307689948992 run_pretraining.py:696] Sequence Length = 128
INFO:tensorflow:Precision = fp32
I1126 12:02:05.484276 140307689948992 run_pretraining.py:697] Precision = fp32
INFO:tensorflow:Throughput Average (sentences/sec) = 363.38
I1126 12:02:05.484328 140307689948992 run_pretraining.py:698] Throughput Average (sentences/sec) = 363.38
DLL 2022-11-26 12:02:05.484422 -  throughput_val : 363.38067445799004 
INFO:tensorflow:-----------------------------
I1126 12:02:05.484629 140307689948992 run_pretraining.py:700] -----------------------------
INFO:tensorflow:***** Eval results *****
I1126 12:02:05.484756 140307689948992 run_pretraining.py:704] ***** Eval results *****
INFO:tensorflow:  global_step = 180
I1126 12:02:05.484812 140307689948992 run_pretraining.py:706]   global_step = 180
INFO:tensorflow:  loss = 8.850041
I1126 12:02:05.484980 140307689948992 run_pretraining.py:706]   loss = 8.850041
INFO:tensorflow:  masked_lm_accuracy = 0.08905687
I1126 12:02:05.485039 140307689948992 run_pretraining.py:706]   masked_lm_accuracy = 0.08905687
INFO:tensorflow:  masked_lm_loss = 8.105519
I1126 12:02:05.485083 140307689948992 run_pretraining.py:706]   masked_lm_loss = 8.105519
INFO:tensorflow:  next_sentence_accuracy = 0.54375
I1126 12:02:05.485126 140307689948992 run_pretraining.py:706]   next_sentence_accuracy = 0.54375
INFO:tensorflow:  next_sentence_loss = 0.7455262
I1126 12:02:05.485169 140307689948992 run_pretraining.py:706]   next_sentence_loss = 0.7455262
