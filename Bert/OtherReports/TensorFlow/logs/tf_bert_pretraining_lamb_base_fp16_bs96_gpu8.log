+ batch_size=96
+ num_gpus=8
+ precision=fp16
++ expr 67584 / 96 / 8
+ num_accumulation_steps_phase1=88
+ train_steps=200
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 96 64 8 7.5e-4 5e-4 fp16 true 8 2000 200 200 200 88 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201
Logs written to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144.220604201201.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2022-06-04 20:12:01.635308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635268: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635315: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635327: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635317: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635325: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635318: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:01.635322: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

--------------------------------------------------------------------------
[[17670,1],3]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.229693 139731936220992 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.229710 140204806985536 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.229745 140071876900672 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.229871 140104855435072 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.230028 140364662961984 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.230044 139839092963136 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.230114 139713267980096 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W0604 20:12:03.230203 139743670941504 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:***** Configuaration *****
I0604 20:12:04.073518 139713267980096 run_pretraining.py:579] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I0604 20:12:04.073876 139713267980096 run_pretraining.py:581]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I0604 20:12:04.073979 139713267980096 run_pretraining.py:581]   alsologtostderr: False
INFO:tensorflow:  log_dir: 
I0604 20:12:04.074036 139713267980096 run_pretraining.py:581]   log_dir: 
INFO:tensorflow:  v: 0
I0604 20:12:04.074090 139713267980096 run_pretraining.py:581]   v: 0
INFO:tensorflow:  verbosity: 0
I0604 20:12:04.074141 139713267980096 run_pretraining.py:581]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I0604 20:12:04.074188 139713267980096 run_pretraining.py:581]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I0604 20:12:04.074236 139713267980096 run_pretraining.py:581]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I0604 20:12:04.074284 139713267980096 run_pretraining.py:581]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I0604 20:12:04.074331 139713267980096 run_pretraining.py:581]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I0604 20:12:04.074378 139713267980096 run_pretraining.py:581]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I0604 20:12:04.074430 139713267980096 run_pretraining.py:581]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I0604 20:12:04.074477 139713267980096 run_pretraining.py:581]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I0604 20:12:04.074525 139713267980096 run_pretraining.py:581]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I0604 20:12:04.074573 139713267980096 run_pretraining.py:581]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I0604 20:12:04.074623 139713267980096 run_pretraining.py:581]   test_random_seed: 301
INFO:tensorflow:  test_srcdir: 
I0604 20:12:04.074671 139713267980096 run_pretraining.py:581]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I0604 20:12:04.074718 139713267980096 run_pretraining.py:581]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed: 
I0604 20:12:04.074766 139713267980096 run_pretraining.py:581]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I0604 20:12:04.074825 139713267980096 run_pretraining.py:581]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I0604 20:12:04.074872 139713267980096 run_pretraining.py:581]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I0604 20:12:04.074931 139713267980096 run_pretraining.py:581]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I0604 20:12:04.074982 139713267980096 run_pretraining.py:581]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1
I0604 20:12:04.075032 139713267980096 run_pretraining.py:581]   output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I0604 20:12:04.075080 139713267980096 run_pretraining.py:581]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I0604 20:12:04.075128 139713267980096 run_pretraining.py:581]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I0604 20:12:04.075176 139713267980096 run_pretraining.py:581]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I0604 20:12:04.075222 139713267980096 run_pretraining.py:581]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I0604 20:12:04.075268 139713267980096 run_pretraining.py:581]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I0604 20:12:04.075315 139713267980096 run_pretraining.py:581]   do_train: True
INFO:tensorflow:  do_eval: False
I0604 20:12:04.075362 139713267980096 run_pretraining.py:581]   do_eval: False
INFO:tensorflow:  train_batch_size: 96
I0604 20:12:04.075409 139713267980096 run_pretraining.py:581]   train_batch_size: 96
INFO:tensorflow:  eval_batch_size: 8
I0604 20:12:04.075455 139713267980096 run_pretraining.py:581]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I0604 20:12:04.075523 139713267980096 run_pretraining.py:581]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 180
I0604 20:12:04.075572 139713267980096 run_pretraining.py:581]   num_train_steps: 180
INFO:tensorflow:  num_warmup_steps: 2000
I0604 20:12:04.075620 139713267980096 run_pretraining.py:581]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I0604 20:12:04.075667 139713267980096 run_pretraining.py:581]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I0604 20:12:04.075713 139713267980096 run_pretraining.py:581]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I0604 20:12:04.075761 139713267980096 run_pretraining.py:581]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I0604 20:12:04.075818 139713267980096 run_pretraining.py:581]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 88
I0604 20:12:04.075865 139713267980096 run_pretraining.py:581]   num_accumulation_steps: 88
INFO:tensorflow:  allreduce_post_accumulation: True
I0604 20:12:04.076073 139713267980096 run_pretraining.py:581]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I0604 20:12:04.076186 139713267980096 run_pretraining.py:581]   verbose_logging: False
INFO:tensorflow:  horovod: True
I0604 20:12:04.076253 139713267980096 run_pretraining.py:581]   horovod: True
INFO:tensorflow:  report_loss: True
I0604 20:12:04.076303 139713267980096 run_pretraining.py:581]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I0604 20:12:04.076351 139713267980096 run_pretraining.py:581]   manual_fp16: False
INFO:tensorflow:  amp: True
I0604 20:12:04.076399 139713267980096 run_pretraining.py:581]   amp: True
INFO:tensorflow:  use_xla: True
I0604 20:12:04.076446 139713267980096 run_pretraining.py:581]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I0604 20:12:04.076493 139713267980096 run_pretraining.py:581]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I0604 20:12:04.076543 139713267980096 run_pretraining.py:581]   ?: False
INFO:tensorflow:  help: False
I0604 20:12:04.076590 139713267980096 run_pretraining.py:581]   help: False
INFO:tensorflow:  helpshort: False
I0604 20:12:04.076639 139713267980096 run_pretraining.py:581]   helpshort: False
INFO:tensorflow:  helpfull: False
I0604 20:12:04.076688 139713267980096 run_pretraining.py:581]   helpfull: False
INFO:tensorflow:  helpxml: False
I0604 20:12:04.076736 139713267980096 run_pretraining.py:581]   helpxml: False
INFO:tensorflow:**************************
I0604 20:12:04.076785 139713267980096 run_pretraining.py:582] **************************
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.077000 139713267980096 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0fdf8e5710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.077654 139713267980096 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0fdf8e5710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0fdf8f01e0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.078467 139713267980096 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f0fdf8f01e0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.078933 139713267980096 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.079004 139713267980096 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.097168 140204806985536 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.098277 139743670941504 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f82519046a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.098180 140204806985536 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f82519046a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f82519100d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.099169 140204806985536 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f82519100d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f16f3b6c710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:***** Running training *****
I0604 20:12:04.099064 139743670941504 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f16f3b6c710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.099642 140204806985536 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.099734 140204806985536 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f16f3b780d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.099818 139743670941504 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f16f3b780d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.100419 139743670941504 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.100546 139743670941504 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.115567 139839092963136 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2d2b4f9710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.116222 139839092963136 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2d2b4f9710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2d2b5050d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.116858 139839092963136 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2d2b5050d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.117228 139839092963136 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.117292 139839092963136 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.127463 140071876900672 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f635e5436a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.128102 140071876900672 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f635e5436a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f635e54e0d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.128836 140364662961984 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.128691 140071876900672 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f635e54e0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.129075 140071876900672 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.129135 140071876900672 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.129486 139731936220992 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa789b90780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.129467 140364662961984 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa789b90780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fa789b9b0d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.130134 140364662961984 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fa789b9b0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.130475 140364662961984 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.130536 140364662961984 run_pretraining.py:626]   Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f14384517f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.130344 139731936220992 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f14384517f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f143845d0d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.131139 139731936220992 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f143845d0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.131500 139731936220992 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.131562 139731936220992 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W0604 20:12:04.132322 140104855435072 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6b0bfd0780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I0604 20:12:04.133229 140104855435072 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6b0bfd0780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6b0bfdb0d0>) includes params argument, but params are not passed to Estimator.
W0604 20:12:04.134121 140104855435072 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6b0bfdb0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I0604 20:12:04.134751 140104855435072 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I0604 20:12:04.134873 140104855435072 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.214225 139839092963136 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.218651 139713267980096 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.224747 140071876900672 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.227393 140364662961984 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.230274 140204806985536 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.233292 139743670941504 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.235318 139731936220992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W0604 20:12:04.246355 140104855435072 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I0604 20:12:04.317716 139839092963136 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0604 20:12:04.317921 139839092963136 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.318020 139839092963136 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.318090 139839092963136 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.318154 139839092963136 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.318215 139839092963136 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.318275 139839092963136 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.318332 139839092963136 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.318388 139839092963136 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0604 20:12:04.318565 139839092963136 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.319588 139839092963136 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I0604 20:12:04.326243 139713267980096 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0604 20:12:04.326459 139713267980096 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.326564 139713267980096 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.326638 139713267980096 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.326706 139713267980096 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.326771 139713267980096 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.326846 139713267980096 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.326920 139713267980096 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.326984 139713267980096 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
INFO:tensorflow:Calling model_fn.
I0604 20:12:04.327083 140071876900672 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:*** Features ***
W0604 20:12:04.327207 139713267980096 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I0604 20:12:04.327234 140071876900672 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.327323 140071876900672 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.327393 140071876900672 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.327457 140071876900672 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.327517 140071876900672 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.327576 140071876900672 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.327635 140071876900672 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.327691 140071876900672 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0604 20:12:04.327868 140071876900672 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.328373 139713267980096 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.328860 140071876900672 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I0604 20:12:04.330873 140364662961984 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0604 20:12:04.331062 140364662961984 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.331158 140364662961984 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.331232 140364662961984 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.331296 140364662961984 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.331357 140364662961984 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.331418 140364662961984 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.331477 140364662961984 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.331533 140364662961984 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0604 20:12:04.331716 140364662961984 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.332730 140364662961984 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I0604 20:12:04.335589 140204806985536 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0604 20:12:04.335774 140204806985536 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.335879 140204806985536 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.335983 140204806985536 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.336050 140204806985536 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.336112 140204806985536 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.336172 140204806985536 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.336229 140204806985536 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.336287 140204806985536 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0604 20:12:04.336477 140204806985536 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.337515 140204806985536 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I0604 20:12:04.338152 139743670941504 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0604 20:12:04.338367 139743670941504 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.338462 139743670941504 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.338530 139743670941504 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.338592 139743670941504 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.338652 139743670941504 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:Calling model_fn.
I0604 20:12:04.338711 139743670941504 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.338768 139743670941504 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.338668 139731936220992 estimator.py:1148] Calling model_fn.
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
INFO:tensorflow:*** Features ***
I0604 20:12:04.338836 139743670941504 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
I0604 20:12:04.338849 139731936220992 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.338957 139731936220992 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I0604 20:12:04.339030 139731936220992 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
W0604 20:12:04.339045 139743670941504 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.339094 139731936220992 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.339153 139731936220992 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.339212 139731936220992 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.339270 139731936220992 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.339327 139731936220992 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0604 20:12:04.339511 139731936220992 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.340127 139743670941504 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.340559 139731936220992 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I0604 20:12:04.348196 140104855435072 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I0604 20:12:04.348346 140104855435072 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I0604 20:12:04.348434 140104855435072 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I0604 20:12:04.348502 140104855435072 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I0604 20:12:04.348566 140104855435072 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I0604 20:12:04.348625 140104855435072 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I0604 20:12:04.348685 140104855435072 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I0604 20:12:04.348742 140104855435072 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I0604 20:12:04.348809 140104855435072 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0604 20:12:04.348996 140104855435072 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W0604 20:12:04.349982 140104855435072 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.904608 139839092963136 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.914109 140364662961984 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.918204 140104855435072 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.922785 140071876900672 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.960718 139731936220992 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.969101 139743670941504 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:05.996930 140204806985536 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W0604 20:12:06.074190 139713267980096 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:08.846615 140104855435072 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:08.875342 139839092963136 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:08.878206 140364662961984 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:08.883632 140071876900672 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:08.923414 139731936220992 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:09.001913 139743670941504 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:09.045655 140204806985536 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.066942 140104855435072 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.098102 139839092963136 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.103786 140364662961984 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.106194 140071876900672 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.142731 139731936220992 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.226109 139743670941504 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.273464 140204806985536 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W0604 20:12:09.339096 139713267980096 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W0604 20:12:09.583070 139713267980096 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I0604 20:12:17.912436 140104855435072 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:18.049248 139731936220992 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:18.059049 140364662961984 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:18.070358 139839092963136 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:18.102925 140071876900672 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:18.219316 139743670941504 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:18.413501 140204806985536 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I0604 20:12:19.329690 139713267980096 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I0604 20:12:19.332773 139713267980096 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.294421 140104855435072 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:23.303608: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.305782: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e94300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.305806: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:23.308939: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.519459 139731936220992 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:23.532034: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.534357: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1456d900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.534380: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:23.538601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.547974 140364662961984 monitored_session.py:240] Graph was finalized.
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.554034 140071876900672 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:23.557593: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.559930: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5712e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.559953: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.560853 139839092963136 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:23.562842: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.562930: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-06-04 20:12:23.564925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f39b90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.564947: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:23.567706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-06-04 20:12:23.569883: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.572032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6998a60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.572054: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:23.574732: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.747598 139743670941504 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:23.761699: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.763808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x145a45c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.763830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:23.768082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I0604 20:12:23.953562 140204806985536 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:23.966916: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:23.969247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14a68ff0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:23.969271: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:23.973264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-06-04 20:12:24.352785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e231f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.352818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.362049: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4e98030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.362075: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.366597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:63:00.0
2022-06-04 20:12:24.366644: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.369770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.371143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.371521: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.371600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:61:00.0
2022-06-04 20:12:24.371648: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.374196: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.374513: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.374766: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.375008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.375775: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.376148: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.378637: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.379203: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.379419: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.389051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2022-06-04 20:12:24.389095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.393878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2022-06-04 20:12:24.393934: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.416755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f23500 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.416782: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.428293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:62:00.0
2022-06-04 20:12:24.428336: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.431256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.432601: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.432956: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.435783: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.436442: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.436648: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.441432: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1103ae10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.441460: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.454053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:42:00.0
2022-06-04 20:12:24.454099: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.455252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2022-06-04 20:12:24.455298: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.457182: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.458531: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.458859: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.461417: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.462005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.462218: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.467224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5717fe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.467252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.479076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:44:00.0
2022-06-04 20:12:24.479120: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.479565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2022-06-04 20:12:24.479609: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.482096: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.483503: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.483857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.486761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.487432: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.487652: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.503184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2022-06-04 20:12:24.503228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.673121: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaaea830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.673155: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.677099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:43:00.0
2022-06-04 20:12:24.677152: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.680312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.681685: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.682063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.684686: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.685270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.685481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.690443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2022-06-04 20:12:24.690487: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.716947: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x142677b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:24.716982: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:24.720484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:64:00.0
2022-06-04 20:12:24.720549: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.723837: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:24.725370: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:24.725782: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:24.728847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:24.729553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:24.729770: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:24.734620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2022-06-04 20:12:24.734665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:24.902559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:24.902605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2022-06-04 20:12:24.902615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2022-06-04 20:12:24.904776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:24.904814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2022-06-04 20:12:24.904823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2022-06-04 20:12:24.909760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:61:00.0, compute capability: 7.0)
2022-06-04 20:12:24.912275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:63:00.0, compute capability: 7.0)
2022-06-04 20:12:24.971869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:24.971941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2022-06-04 20:12:24.971953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2022-06-04 20:12:24.977139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:62:00.0, compute capability: 7.0)
2022-06-04 20:12:24.983824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:24.983866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2022-06-04 20:12:24.983876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2022-06-04 20:12:24.988362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:42:00.0, compute capability: 7.0)
2022-06-04 20:12:25.007062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:25.007110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2022-06-04 20:12:25.007120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2022-06-04 20:12:25.011702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:44:00.0, compute capability: 7.0)
2022-06-04 20:12:25.093683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:25.093729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2022-06-04 20:12:25.093740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2022-06-04 20:12:25.098405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:43:00.0, compute capability: 7.0)
2022-06-04 20:12:25.155346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:25.155394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2022-06-04 20:12:25.155404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2022-06-04 20:12:25.159787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:64:00.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I0604 20:12:25.262665 139713267980096 monitored_session.py:240] Graph was finalized.
2022-06-04 20:12:25.279138: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2022-06-04 20:12:25.281461: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x98cd3f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:25.281488: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-06-04 20:12:25.286122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2022-06-04 20:12:25.474069: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x63b7e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-06-04 20:12:25.474104: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-06-04 20:12:25.476624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:41:00.0
2022-06-04 20:12:25.476676: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:25.480056: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:12:25.481403: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2022-06-04 20:12:25.481754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2022-06-04 20:12:25.484412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2022-06-04 20:12:25.485030: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2022-06-04 20:12:25.485256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:12:25.489304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2022-06-04 20:12:25.489352: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2022-06-04 20:12:25.894816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-06-04 20:12:25.894870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2022-06-04 20:12:25.894881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2022-06-04 20:12:25.899266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30168 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:41:00.0, compute capability: 7.0)
2022-06-04 20:12:28.371984: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.384912: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:28.429288: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.435808: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.445272: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:28.451391: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:28.464290: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.481208: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:28.483350: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.499485: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:28.608754: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.621544: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:28.627554: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:28.643838: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:29.650884: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:29.669879: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:31.011048: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:31.020808: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:31.067197: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:31.185305: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:31.194063: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:31.226876: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:31.393296: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:32.402392: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2022-06-04 20:12:34.911875: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:34.918804: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:34.982450: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:34.989238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:35.089522: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:35.096406: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:35.221429: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:35.228321: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:35.281366: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:35.284301: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:35.288434: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:35.291254: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:35.313792: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:35.320916: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I0604 20:12:35.603439 140104855435072 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I0604 20:12:35.661838 139731936220992 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I0604 20:12:35.787052 140071876900672 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I0604 20:12:35.912580 140204806985536 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I0604 20:12:35.986274 139743670941504 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I0604 20:12:36.006679 140364662961984 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I0604 20:12:36.042744 139839092963136 session_manager.py:500] Running local_init_op.
2022-06-04 20:12:36.107302: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.107531: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:36.166060: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.166292: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.238459 140104855435072 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.295846 139731936220992 session_manager.py:502] Done running local_init_op.
2022-06-04 20:12:36.302943: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.303181: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:36.397690: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.405090: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:36.429447: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.429674: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.436192 140071876900672 session_manager.py:502] Done running local_init_op.
2022-06-04 20:12:36.498330: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.498569: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:36.528191: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.528420: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.561650 140204806985536 session_manager.py:502] Done running local_init_op.
2022-06-04 20:12:36.566977: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.567216: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.630683 139743670941504 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.659929 140364662961984 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I0604 20:12:36.702384 139839092963136 session_manager.py:502] Done running local_init_op.
2022-06-04 20:12:36.891726: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.898840: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:36.944513: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:36.951486: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:37.099376: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:37.106353: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I0604 20:12:37.154480 139713267980096 session_manager.py:500] Running local_init_op.
2022-06-04 20:12:37.224635: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:37.231561: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:37.299562: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:37.306558: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:37.333924: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:37.340890: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:37.379221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:37.386343: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:37.674978: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:37.675230: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I0604 20:12:37.801764 139713267980096 session_manager.py:502] Done running local_init_op.
2022-06-04 20:12:38.065155: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.065501: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.070098: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.071993: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.074583: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.116554: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.116914: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.121487: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.123360: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.125922: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.302135: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.302469: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.307073: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.308969: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.311566: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.436481: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.436831: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.441479: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.443323: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.445886: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.483295: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.490618: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.494201: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.494530: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.499255: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.501180: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.503788: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.555409: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.555762: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.560528: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.562465: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.565078: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.660695: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:38.661073: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.665535: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.667367: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.669918: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:38.988987: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.004378: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.096456: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.111318: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.251094: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.266913: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.426242: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.441432: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.443809: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.459529: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.577384: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.593706: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.643152: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.658288: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:39.751214: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:39.751528: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1/model.ckpt.
I0604 20:12:49.732650 139713267980096 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1/model.ckpt.
2022-06-04 20:12:50.584512: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:50.593452: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:56.893195: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:56.893556: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:56.898779: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:56.900956: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:56.903859: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:12:57.909168: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:12:57.923960: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W0604 20:13:00.769615 139713267980096 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2022-06-04 20:13:01.350297: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:01.350572: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:13:17.734129: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:17.881513: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:17.884238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:17.921331: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:18.072346: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:18.075065: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:18.437123: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:18.570319: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:18.575787: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:18.616947: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:18.633427: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:18.750820: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:18.757431: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:18.817230: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:19.328667: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:13:19.499210: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:13:28.741103: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:28.971408: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:29.053194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:29.186230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:29.380632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:29.596475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:29.681040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:29.721022: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:29.775663: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:29.807649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:29.809083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:30.347925: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:30.402415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:30.432714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:13:31.406880: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2022-06-04 20:13:32.031937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2022-06-04 20:14:02.984326: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:03.022312: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:03.190448: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:03.196880: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:03.684321: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:03.759291: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:03.898566: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-04 20:14:06.671234: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.158314, step = 0
I0604 20:14:08.687314 139713267980096 basic_session_run_hooks.py:262] loss = 11.158314, step = 0
2022-06-04 20:14:09.378174: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.378479: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:14:09.380135: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.380423: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:14:09.381917: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.382216: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:14:09.382296: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.382578: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:14:09.385195: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.385466: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:14:09.385881: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.386197: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2022-06-04 20:14:09.389755: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:09.390064: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:loss = 11.162051, step = 0
I0604 20:14:09.537550 140104855435072 basic_session_run_hooks.py:262] loss = 11.162051, step = 0
INFO:tensorflow:loss = 11.084377, step = 0
I0604 20:14:09.539404 139731936220992 basic_session_run_hooks.py:262] loss = 11.084377, step = 0
INFO:tensorflow:loss = 11.15417, step = 0
I0604 20:14:09.541101 139839092963136 basic_session_run_hooks.py:262] loss = 11.15417, step = 0
INFO:tensorflow:loss = 11.163949, step = 0
I0604 20:14:09.544248 140071876900672 basic_session_run_hooks.py:262] loss = 11.163949, step = 0
INFO:tensorflow:loss = 11.199877, step = 0
I0604 20:14:09.546108 140364662961984 basic_session_run_hooks.py:262] loss = 11.199877, step = 0
INFO:tensorflow:loss = 11.135074, step = 0
I0604 20:14:09.547643 140204806985536 basic_session_run_hooks.py:262] loss = 11.135074, step = 0
INFO:tensorflow:loss = 11.174571, step = 0
I0604 20:14:09.556391 139743670941504 basic_session_run_hooks.py:262] loss = 11.174571, step = 0
2022-06-04 20:14:26.805737: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:26.857848: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:26.860347: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:26.877699: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:26.987076: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.039818: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.041500: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.068502: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.396962: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:27.413770: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:27.556362: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:27.559760: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:14:27.573889: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.591192: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.737051: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2022-06-04 20:14:27.739870: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.031354 140104855435072 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.228666 140364662961984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.249841 139839092963136 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.401428 139743670941504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.406510 139731936220992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.570634 140204806985536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.719513 140071876900672 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.758303 139713267980096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936412 140071876900672 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936619 140104855435072 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936620 139731936220992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936636 140204806985536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936703 139839092963136 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936726 140364662961984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.936793 139743670941504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:11.942038 139713267980096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.113483 140071876900672 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.113507 140204806985536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.113546 139731936220992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.114177 140364662961984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.114399 140104855435072 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.114616 139743670941504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.116235 139839092963136 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.120407 139713267980096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.290385 140104855435072 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.290451 140204806985536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.290464 139731936220992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.290480 140071876900672 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.290532 140364662961984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.290739 139839092963136 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.291166 139743670941504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.297934 139713267980096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467483 140104855435072 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467490 140204806985536 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467503 140071876900672 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467502 139839092963136 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467514 139731936220992 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467541 139743670941504 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.467598 140364662961984 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W0604 20:15:12.472999 139713267980096 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:15:34.971423 - Iteration: 1  throughput_train : 440.473 seq/s mlm_loss : 10.4549  nsp_loss : 0.6831  total_loss : 11.1380  avg_loss_step : 11.1406  learning_rate : 0.0  loss_scaler : 4294967296 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:15:50.602099 - Iteration: 1  throughput_train : 4327.281 seq/s mlm_loss : 10.4451  nsp_loss : 0.6548  total_loss : 11.0998  avg_loss_step : 11.1413  learning_rate : 0.0  loss_scaler : 2147483648 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:16:06.204054 - Iteration: 1  throughput_train : 4335.158 seq/s mlm_loss : 10.4550  nsp_loss : 0.6567  total_loss : 11.1116  avg_loss_step : 11.1423  learning_rate : 0.0  loss_scaler : 1073741824 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:16:22.057993 - Iteration: 1  throughput_train : 4266.200 seq/s mlm_loss : 10.4680  nsp_loss : 0.6648  total_loss : 11.1329  avg_loss_step : 11.1415  learning_rate : 0.0  loss_scaler : 536870912 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:16:37.896766 - Iteration: 1  throughput_train : 4270.421 seq/s mlm_loss : 10.4552  nsp_loss : 0.6753  total_loss : 11.1305  avg_loss_step : 11.1396  learning_rate : 0.0  loss_scaler : 268435456 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:16:53.714125 - Iteration: 1  throughput_train : 4276.249 seq/s mlm_loss : 10.4254  nsp_loss : 0.6807  total_loss : 11.1061  avg_loss_step : 11.1348  learning_rate : 0.0  loss_scaler : 134217728 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:17:09.548486 - Iteration: 1  throughput_train : 4271.516 seq/s mlm_loss : 10.4424  nsp_loss : 0.6601  total_loss : 11.1025  avg_loss_step : 11.1299  learning_rate : 0.0  loss_scaler : 67108864 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:17:38.303395 - Iteration: 1  throughput_train : 2351.404 seq/s mlm_loss : 10.4699  nsp_loss : 0.6982  total_loss : 11.1682  avg_loss_step : 11.1350  learning_rate : 0.0  loss_scaler : 33554432 
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:18:21.379825 - Iteration: 2  throughput_train : 1569.392 seq/s mlm_loss : 10.4355  nsp_loss : 0.7017  total_loss : 11.1372  avg_loss_step : 11.1351  learning_rate : 0.0  loss_scaler : 16777216 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:18:37.942083 - Iteration: 3  throughput_train : 4083.721 seq/s mlm_loss : 10.4417  nsp_loss : 0.6588  total_loss : 11.1005  avg_loss_step : 11.1426  learning_rate : 3e-06  loss_scaler : 16777216 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:18:54.046124 - Iteration: 4  throughput_train : 4199.945 seq/s mlm_loss : 10.4682  nsp_loss : 0.6831  total_loss : 11.1512  avg_loss_step : 11.1348  learning_rate : 6e-06  loss_scaler : 16777216 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:19:10.177115 - Iteration: 5  throughput_train : 4192.893 seq/s mlm_loss : 10.4691  nsp_loss : 0.6816  total_loss : 11.1507  avg_loss_step : 11.1365  learning_rate : 9e-06  loss_scaler : 16777216 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2022-06-04 20:19:26.290204 - Iteration: 6  throughput_train : 4197.644 seq/s mlm_loss : 10.4430  nsp_loss : 0.6883  total_loss : 11.1313  avg_loss_step : 11.1394  learning_rate : 1.2e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:19:42.396112 - Iteration: 7  throughput_train : 4199.386 seq/s mlm_loss : 10.4527  nsp_loss : 0.6702  total_loss : 11.1229  avg_loss_step : 11.1310  learning_rate : 1.50000005e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:19:58.538117 - Iteration: 8  throughput_train : 4190.087 seq/s mlm_loss : 10.4482  nsp_loss : 0.7014  total_loss : 11.1496  avg_loss_step : 11.1241  learning_rate : 1.8e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:20:14.671351 - Iteration: 9  throughput_train : 4192.385 seq/s mlm_loss : 10.4247  nsp_loss : 0.6854  total_loss : 11.1101  avg_loss_step : 11.1233  learning_rate : 2.1e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:20:30.780725 - Iteration: 10  throughput_train : 4198.538 seq/s mlm_loss : 10.4317  nsp_loss : 0.6562  total_loss : 11.0879  avg_loss_step : 11.1094  learning_rate : 2.4e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:20:46.919884 - Iteration: 11  throughput_train : 4190.802 seq/s mlm_loss : 10.4348  nsp_loss : 0.6632  total_loss : 11.0980  avg_loss_step : 11.1051  learning_rate : 2.7000002e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:21:02.999657 - Iteration: 12  throughput_train : 4206.259 seq/s mlm_loss : 10.4043  nsp_loss : 0.6765  total_loss : 11.0808  avg_loss_step : 11.0911  learning_rate : 3.0000001e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:21:19.114829 - Iteration: 13  throughput_train : 4196.922 seq/s mlm_loss : 10.4097  nsp_loss : 0.6982  total_loss : 11.1079  avg_loss_step : 11.0856  learning_rate : 3.3e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:21:35.192685 - Iteration: 14  throughput_train : 4206.801 seq/s mlm_loss : 10.4008  nsp_loss : 0.6856  total_loss : 11.0864  avg_loss_step : 11.0762  learning_rate : 3.6e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:21:51.269557 - Iteration: 15  throughput_train : 4207.012 seq/s mlm_loss : 10.3992  nsp_loss : 0.6945  total_loss : 11.0937  avg_loss_step : 11.0662  learning_rate : 3.9000002e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:22:07.371748 - Iteration: 16  throughput_train : 4200.644 seq/s mlm_loss : 10.3838  nsp_loss : 0.7096  total_loss : 11.0934  avg_loss_step : 11.0559  learning_rate : 4.2e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:22:23.465385 - Iteration: 17  throughput_train : 4202.638 seq/s mlm_loss : 10.3303  nsp_loss : 0.6787  total_loss : 11.0090  avg_loss_step : 11.0420  learning_rate : 4.5e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:22:39.569279 - Iteration: 18  throughput_train : 4200.124 seq/s mlm_loss : 10.3372  nsp_loss : 0.6800  total_loss : 11.0172  avg_loss_step : 11.0300  learning_rate : 4.8e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:22:55.638193 - Iteration: 19  throughput_train : 4209.045 seq/s mlm_loss : 10.3455  nsp_loss : 0.7058  total_loss : 11.0513  avg_loss_step : 11.0175  learning_rate : 5.1000003e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:23:11.735043 - Iteration: 20  throughput_train : 4201.907 seq/s mlm_loss : 10.3632  nsp_loss : 0.6845  total_loss : 11.0477  avg_loss_step : 11.0014  learning_rate : 5.4000004e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:23:27.811348 - Iteration: 21  throughput_train : 4207.212 seq/s mlm_loss : 10.2906  nsp_loss : 0.7200  total_loss : 11.0106  avg_loss_step : 10.9766  learning_rate : 5.7e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:23:43.961192 - Iteration: 22  throughput_train : 4187.918 seq/s mlm_loss : 10.2784  nsp_loss : 0.6828  total_loss : 10.9612  avg_loss_step : 10.9607  learning_rate : 6.0000002e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:24:00.076428 - Iteration: 23  throughput_train : 4197.010 seq/s mlm_loss : 10.2518  nsp_loss : 0.7043  total_loss : 10.9561  avg_loss_step : 10.9516  learning_rate : 6.3e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:24:16.138809 - Iteration: 24  throughput_train : 4210.768 seq/s mlm_loss : 10.2446  nsp_loss : 0.7223  total_loss : 10.9669  avg_loss_step : 10.9330  learning_rate : 6.6e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:24:32.246343 - Iteration: 25  throughput_train : 4199.227 seq/s mlm_loss : 10.2378  nsp_loss : 0.6885  total_loss : 10.9262  avg_loss_step : 10.8999  learning_rate : 6.9e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:24:48.359470 - Iteration: 26  throughput_train : 4197.426 seq/s mlm_loss : 10.2470  nsp_loss : 0.6946  total_loss : 10.9416  avg_loss_step : 10.8939  learning_rate : 7.2e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:25:04.453612 - Iteration: 27  throughput_train : 4202.424 seq/s mlm_loss : 10.1984  nsp_loss : 0.6900  total_loss : 10.8885  avg_loss_step : 10.8682  learning_rate : 7.5e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:25:20.538574 - Iteration: 28  throughput_train : 4204.949 seq/s mlm_loss : 10.1748  nsp_loss : 0.6755  total_loss : 10.8503  avg_loss_step : 10.8375  learning_rate : 7.8000005e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:25:36.642287 - Iteration: 29  throughput_train : 4199.946 seq/s mlm_loss : 10.1139  nsp_loss : 0.6637  total_loss : 10.7776  avg_loss_step : 10.8164  learning_rate : 8.1000006e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:25:52.731701 - Iteration: 30  throughput_train : 4203.724 seq/s mlm_loss : 10.0843  nsp_loss : 0.6967  total_loss : 10.7810  avg_loss_step : 10.8030  learning_rate : 8.4e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:26:08.822277 - Iteration: 31  throughput_train : 4203.362 seq/s mlm_loss : 10.0917  nsp_loss : 0.7055  total_loss : 10.7972  avg_loss_step : 10.7797  learning_rate : 8.7e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:26:24.894476 - Iteration: 32  throughput_train : 4208.228 seq/s mlm_loss : 10.0820  nsp_loss : 0.6353  total_loss : 10.7172  avg_loss_step : 10.7501  learning_rate : 9e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:26:41.000352 - Iteration: 33  throughput_train : 4199.474 seq/s mlm_loss : 10.0326  nsp_loss : 0.6995  total_loss : 10.7322  avg_loss_step : 10.7298  learning_rate : 9.3e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:26:57.092116 - Iteration: 34  throughput_train : 4203.108 seq/s mlm_loss : 9.9792  nsp_loss : 0.6793  total_loss : 10.6585  avg_loss_step : 10.7060  learning_rate : 9.6e-05  loss_scaler : 16777216 
DLL 2022-06-04 20:27:13.227816 - Iteration: 35  throughput_train : 4191.622 seq/s mlm_loss : 10.0128  nsp_loss : 0.6578  total_loss : 10.6706  avg_loss_step : 10.7067  learning_rate : 9.9000004e-05  loss_scaler : 8388608 
DLL 2022-06-04 20:27:29.339093 - Iteration: 36  throughput_train : 4197.975 seq/s mlm_loss : 10.0124  nsp_loss : 0.6656  total_loss : 10.6780  avg_loss_step : 10.6849  learning_rate : 0.000102000005  loss_scaler : 8388608 
DLL 2022-06-04 20:27:45.435983 - Iteration: 37  throughput_train : 4201.754 seq/s mlm_loss : 9.9344  nsp_loss : 0.6916  total_loss : 10.6260  avg_loss_step : 10.6503  learning_rate : 0.00010500001  loss_scaler : 8388608 
DLL 2022-06-04 20:28:01.530669 - Iteration: 38  throughput_train : 4202.282 seq/s mlm_loss : 9.9910  nsp_loss : 0.6373  total_loss : 10.6283  avg_loss_step : 10.6251  learning_rate : 0.00010800001  loss_scaler : 8388608 
DLL 2022-06-04 20:28:17.612822 - Iteration: 39  throughput_train : 4205.557 seq/s mlm_loss : 9.9492  nsp_loss : 0.6692  total_loss : 10.6184  avg_loss_step : 10.6145  learning_rate : 0.000111  loss_scaler : 8388608 
DLL 2022-06-04 20:28:33.723860 - Iteration: 40  throughput_train : 4198.056 seq/s mlm_loss : 9.8936  nsp_loss : 0.7055  total_loss : 10.5991  avg_loss_step : 10.5763  learning_rate : 0.000114  loss_scaler : 8388608 
DLL 2022-06-04 20:28:49.846182 - Iteration: 41  throughput_train : 4195.106 seq/s mlm_loss : 9.9042  nsp_loss : 0.6850  total_loss : 10.5892  avg_loss_step : 10.5479  learning_rate : 0.000117  loss_scaler : 8388608 
DLL 2022-06-04 20:29:05.958003 - Iteration: 42  throughput_train : 4197.810 seq/s mlm_loss : 9.8553  nsp_loss : 0.6889  total_loss : 10.5441  avg_loss_step : 10.5343  learning_rate : 0.000120000004  loss_scaler : 8388608 
DLL 2022-06-04 20:29:22.083384 - Iteration: 43  throughput_train : 4194.367 seq/s mlm_loss : 9.7953  nsp_loss : 0.6527  total_loss : 10.4480  avg_loss_step : 10.5050  learning_rate : 0.000123  loss_scaler : 8388608 
DLL 2022-06-04 20:29:38.184702 - Iteration: 44  throughput_train : 4200.596 seq/s mlm_loss : 9.8167  nsp_loss : 0.6509  total_loss : 10.4675  avg_loss_step : 10.4809  learning_rate : 0.000126  loss_scaler : 8388608 
DLL 2022-06-04 20:29:54.304759 - Iteration: 45  throughput_train : 4195.753 seq/s mlm_loss : 9.7631  nsp_loss : 0.7106  total_loss : 10.4737  avg_loss_step : 10.4528  learning_rate : 0.00012900001  loss_scaler : 8388608 
DLL 2022-06-04 20:30:10.421239 - Iteration: 46  throughput_train : 4196.704 seq/s mlm_loss : 9.7831  nsp_loss : 0.6717  total_loss : 10.4547  avg_loss_step : 10.4324  learning_rate : 0.000132  loss_scaler : 8388608 
DLL 2022-06-04 20:30:26.533411 - Iteration: 47  throughput_train : 4197.664 seq/s mlm_loss : 9.7387  nsp_loss : 0.6771  total_loss : 10.4158  avg_loss_step : 10.4195  learning_rate : 0.00013500001  loss_scaler : 8388608 
DLL 2022-06-04 20:30:42.671143 - Iteration: 48  throughput_train : 4191.141 seq/s mlm_loss : 9.6931  nsp_loss : 0.6928  total_loss : 10.3859  avg_loss_step : 10.3998  learning_rate : 0.000138  loss_scaler : 8388608 
DLL 2022-06-04 20:30:58.783329 - Iteration: 49  throughput_train : 4197.831 seq/s mlm_loss : 9.7235  nsp_loss : 0.6867  total_loss : 10.4102  avg_loss_step : 10.3618  learning_rate : 0.00014100001  loss_scaler : 8388608 
DLL 2022-06-04 20:31:14.905427 - Iteration: 50  throughput_train : 4195.180 seq/s mlm_loss : 9.7006  nsp_loss : 0.6578  total_loss : 10.3584  avg_loss_step : 10.3380  learning_rate : 0.000144  loss_scaler : 8388608 
DLL 2022-06-04 20:31:31.057094 - Iteration: 51  throughput_train : 4187.531 seq/s mlm_loss : 9.6446  nsp_loss : 0.6458  total_loss : 10.2905  avg_loss_step : 10.3030  learning_rate : 0.000147  loss_scaler : 8388608 
DLL 2022-06-04 20:31:47.174262 - Iteration: 52  throughput_train : 4196.463 seq/s mlm_loss : 9.6385  nsp_loss : 0.7098  total_loss : 10.3483  avg_loss_step : 10.2912  learning_rate : 0.00015  loss_scaler : 8388608 
DLL 2022-06-04 20:32:03.247943 - Iteration: 53  throughput_train : 4207.779 seq/s mlm_loss : 9.5770  nsp_loss : 0.6552  total_loss : 10.2322  avg_loss_step : 10.2795  learning_rate : 0.000153  loss_scaler : 8388608 
DLL 2022-06-04 20:32:19.333838 - Iteration: 54  throughput_train : 4204.574 seq/s mlm_loss : 9.5205  nsp_loss : 0.6702  total_loss : 10.1908  avg_loss_step : 10.2570  learning_rate : 0.00015600001  loss_scaler : 8388608 
DLL 2022-06-04 20:32:35.436210 - Iteration: 55  throughput_train : 4200.283 seq/s mlm_loss : 9.5647  nsp_loss : 0.6920  total_loss : 10.2567  avg_loss_step : 10.2465  learning_rate : 0.000159  loss_scaler : 8388608 
DLL 2022-06-04 20:32:51.525523 - Iteration: 56  throughput_train : 4203.701 seq/s mlm_loss : 9.4802  nsp_loss : 0.6823  total_loss : 10.1624  avg_loss_step : 10.2103  learning_rate : 0.00016200001  loss_scaler : 8388608 
DLL 2022-06-04 20:33:07.608736 - Iteration: 57  throughput_train : 4205.228 seq/s mlm_loss : 9.5264  nsp_loss : 0.6685  total_loss : 10.1949  avg_loss_step : 10.1990  learning_rate : 0.000165  loss_scaler : 8388608 
DLL 2022-06-04 20:33:23.697291 - Iteration: 58  throughput_train : 4203.830 seq/s mlm_loss : 9.5254  nsp_loss : 0.6760  total_loss : 10.2014  avg_loss_step : 10.1823  learning_rate : 0.000168  loss_scaler : 8388608 
DLL 2022-06-04 20:33:39.831483 - Iteration: 59  throughput_train : 4192.008 seq/s mlm_loss : 9.5485  nsp_loss : 0.6909  total_loss : 10.2394  avg_loss_step : 10.1630  learning_rate : 0.000171  loss_scaler : 8388608 
DLL 2022-06-04 20:33:55.955258 - Iteration: 60  throughput_train : 4194.656 seq/s mlm_loss : 9.4344  nsp_loss : 0.6866  total_loss : 10.1209  avg_loss_step : 10.1565  learning_rate : 0.000174  loss_scaler : 8388608 
DLL 2022-06-04 20:34:12.082987 - Iteration: 61  throughput_train : 4193.650 seq/s mlm_loss : 9.4689  nsp_loss : 0.6680  total_loss : 10.1368  avg_loss_step : 10.1273  learning_rate : 0.00017700001  loss_scaler : 8388608 
DLL 2022-06-04 20:34:28.231572 - Iteration: 62  throughput_train : 4188.403 seq/s mlm_loss : 9.3611  nsp_loss : 0.6951  total_loss : 10.0562  avg_loss_step : 10.1168  learning_rate : 0.00018  loss_scaler : 8388608 
DLL 2022-06-04 20:34:44.378641 - Iteration: 63  throughput_train : 4188.765 seq/s mlm_loss : 9.4197  nsp_loss : 0.6989  total_loss : 10.1187  avg_loss_step : 10.0884  learning_rate : 0.00018300001  loss_scaler : 8388608 
DLL 2022-06-04 20:35:00.502689 - Iteration: 64  throughput_train : 4194.579 seq/s mlm_loss : 9.4119  nsp_loss : 0.6849  total_loss : 10.0967  avg_loss_step : 10.0874  learning_rate : 0.000186  loss_scaler : 8388608 
DLL 2022-06-04 20:35:16.650812 - Iteration: 65  throughput_train : 4188.401 seq/s mlm_loss : 9.4817  nsp_loss : 0.7001  total_loss : 10.1818  avg_loss_step : 10.0508  learning_rate : 0.00018900001  loss_scaler : 8388608 
DLL 2022-06-04 20:35:32.781024 - Iteration: 66  throughput_train : 4193.101 seq/s mlm_loss : 9.3925  nsp_loss : 0.6711  total_loss : 10.0636  avg_loss_step : 10.0643  learning_rate : 0.000192  loss_scaler : 8388608 
DLL 2022-06-04 20:35:48.929889 - Iteration: 67  throughput_train : 4189.064 seq/s mlm_loss : 9.4121  nsp_loss : 0.6869  total_loss : 10.0991  avg_loss_step : 10.0267  learning_rate : 0.000195  loss_scaler : 8388608 
DLL 2022-06-04 20:36:05.078003 - Iteration: 68  throughput_train : 4188.484 seq/s mlm_loss : 9.2179  nsp_loss : 0.6880  total_loss : 9.9058  avg_loss_step : 10.0218  learning_rate : 0.00019800001  loss_scaler : 8388608 
DLL 2022-06-04 20:36:21.214393 - Iteration: 69  throughput_train : 4191.499 seq/s mlm_loss : 9.4341  nsp_loss : 0.6952  total_loss : 10.1293  avg_loss_step : 10.0062  learning_rate : 0.000201  loss_scaler : 8388608 
DLL 2022-06-04 20:36:37.325823 - Iteration: 70  throughput_train : 4197.944 seq/s mlm_loss : 9.3640  nsp_loss : 0.6914  total_loss : 10.0555  avg_loss_step : 10.0016  learning_rate : 0.00020400001  loss_scaler : 8388608 
DLL 2022-06-04 20:36:53.428391 - Iteration: 71  throughput_train : 4200.215 seq/s mlm_loss : 9.3713  nsp_loss : 0.6741  total_loss : 10.0454  avg_loss_step : 9.9919  learning_rate : 0.000207  loss_scaler : 8388608 
DLL 2022-06-04 20:37:09.551821 - Iteration: 72  throughput_train : 4194.774 seq/s mlm_loss : 9.2471  nsp_loss : 0.7158  total_loss : 9.9629  avg_loss_step : 9.9756  learning_rate : 0.00021000001  loss_scaler : 8388608 
DLL 2022-06-04 20:37:25.618140 - Iteration: 73  throughput_train : 4209.663 seq/s mlm_loss : 9.1685  nsp_loss : 0.6799  total_loss : 9.8484  avg_loss_step : 9.9640  learning_rate : 0.000213  loss_scaler : 8388608 
DLL 2022-06-04 20:37:41.720149 - Iteration: 74  throughput_train : 4200.484 seq/s mlm_loss : 9.2300  nsp_loss : 0.6983  total_loss : 9.9283  avg_loss_step : 9.9332  learning_rate : 0.00021600001  loss_scaler : 8388608 
DLL 2022-06-04 20:37:57.806841 - Iteration: 75  throughput_train : 4204.476 seq/s mlm_loss : 9.2344  nsp_loss : 0.6855  total_loss : 9.9199  avg_loss_step : 9.9398  learning_rate : 0.00021900001  loss_scaler : 8388608 
DLL 2022-06-04 20:38:13.897849 - Iteration: 76  throughput_train : 4203.312 seq/s mlm_loss : 9.1752  nsp_loss : 0.7032  total_loss : 9.8784  avg_loss_step : 9.9195  learning_rate : 0.000222  loss_scaler : 8388608 
DLL 2022-06-04 20:38:29.973330 - Iteration: 77  throughput_train : 4207.291 seq/s mlm_loss : 9.1434  nsp_loss : 0.6831  total_loss : 9.8265  avg_loss_step : 9.8861  learning_rate : 0.00022500001  loss_scaler : 8388608 
DLL 2022-06-04 20:38:46.087169 - Iteration: 78  throughput_train : 4197.321 seq/s mlm_loss : 9.2407  nsp_loss : 0.7129  total_loss : 9.9536  avg_loss_step : 9.9101  learning_rate : 0.000228  loss_scaler : 8388608 
DLL 2022-06-04 20:39:02.135504 - Iteration: 79  throughput_train : 4214.490 seq/s mlm_loss : 9.1911  nsp_loss : 0.6785  total_loss : 9.8696  avg_loss_step : 9.8804  learning_rate : 0.00023100001  loss_scaler : 8388608 
DLL 2022-06-04 20:39:18.226704 - Iteration: 80  throughput_train : 4203.159 seq/s mlm_loss : 9.2103  nsp_loss : 0.6589  total_loss : 9.8692  avg_loss_step : 9.8556  learning_rate : 0.000234  loss_scaler : 8388608 
DLL 2022-06-04 20:39:34.328749 - Iteration: 81  throughput_train : 4200.429 seq/s mlm_loss : 9.2426  nsp_loss : 0.6834  total_loss : 9.9260  avg_loss_step : 9.8484  learning_rate : 0.00023700001  loss_scaler : 8388608 
DLL 2022-06-04 20:39:50.422869 - Iteration: 82  throughput_train : 4202.465 seq/s mlm_loss : 9.1090  nsp_loss : 0.7050  total_loss : 9.8140  avg_loss_step : 9.8664  learning_rate : 0.00024000001  loss_scaler : 8388608 
DLL 2022-06-04 20:40:06.506415 - Iteration: 83  throughput_train : 4205.220 seq/s mlm_loss : 9.2681  nsp_loss : 0.6840  total_loss : 9.9520  avg_loss_step : 9.8579  learning_rate : 0.000243  loss_scaler : 8388608 
DLL 2022-06-04 20:40:22.597307 - Iteration: 84  throughput_train : 4203.245 seq/s mlm_loss : 9.1849  nsp_loss : 0.6978  total_loss : 9.8827  avg_loss_step : 9.8242  learning_rate : 0.000246  loss_scaler : 8388608 
DLL 2022-06-04 20:40:38.688435 - Iteration: 85  throughput_train : 4203.245 seq/s mlm_loss : 9.1484  nsp_loss : 0.6768  total_loss : 9.8252  avg_loss_step : 9.8080  learning_rate : 0.000249  loss_scaler : 8388608 
DLL 2022-06-04 20:40:54.757163 - Iteration: 86  throughput_train : 4209.059 seq/s mlm_loss : 9.1266  nsp_loss : 0.6523  total_loss : 9.7789  avg_loss_step : 9.8037  learning_rate : 0.000252  loss_scaler : 8388608 
DLL 2022-06-04 20:41:10.851831 - Iteration: 87  throughput_train : 4202.389 seq/s mlm_loss : 9.1182  nsp_loss : 0.6814  total_loss : 9.7996  avg_loss_step : 9.8015  learning_rate : 0.00025500002  loss_scaler : 8388608 
DLL 2022-06-04 20:41:26.918836 - Iteration: 88  throughput_train : 4209.654 seq/s mlm_loss : 9.1950  nsp_loss : 0.6472  total_loss : 9.8423  avg_loss_step : 9.8053  learning_rate : 0.00025800001  loss_scaler : 8388608 
DLL 2022-06-04 20:41:43.029562 - Iteration: 89  throughput_train : 4198.235 seq/s mlm_loss : 9.0071  nsp_loss : 0.6820  total_loss : 9.6891  avg_loss_step : 9.7820  learning_rate : 0.000261  loss_scaler : 8388608 
DLL 2022-06-04 20:41:59.104262 - Iteration: 90  throughput_train : 4207.523 seq/s mlm_loss : 9.1008  nsp_loss : 0.6575  total_loss : 9.7584  avg_loss_step : 9.7553  learning_rate : 0.000264  loss_scaler : 8388608 
DLL 2022-06-04 20:42:15.192117 - Iteration: 91  throughput_train : 4204.042 seq/s mlm_loss : 9.1167  nsp_loss : 0.7011  total_loss : 9.8178  avg_loss_step : 9.7806  learning_rate : 0.000267  loss_scaler : 8388608 
DLL 2022-06-04 20:42:31.313092 - Iteration: 92  throughput_train : 4195.482 seq/s mlm_loss : 9.0698  nsp_loss : 0.6671  total_loss : 9.7369  avg_loss_step : 9.7624  learning_rate : 0.00027000002  loss_scaler : 8388608 
DLL 2022-06-04 20:42:47.398180 - Iteration: 93  throughput_train : 4204.802 seq/s mlm_loss : 9.1444  nsp_loss : 0.6915  total_loss : 9.8359  avg_loss_step : 9.7344  learning_rate : 0.000273  loss_scaler : 8388608 
DLL 2022-06-04 20:43:03.453173 - Iteration: 94  throughput_train : 4212.762 seq/s mlm_loss : 9.0286  nsp_loss : 0.6945  total_loss : 9.7230  avg_loss_step : 9.7366  learning_rate : 0.000276  loss_scaler : 8388608 
DLL 2022-06-04 20:43:19.556315 - Iteration: 95  throughput_train : 4200.084 seq/s mlm_loss : 9.0218  nsp_loss : 0.6845  total_loss : 9.7062  avg_loss_step : 9.7343  learning_rate : 0.000279  loss_scaler : 8388608 
DLL 2022-06-04 20:43:35.650756 - Iteration: 96  throughput_train : 4202.414 seq/s mlm_loss : 9.0415  nsp_loss : 0.6644  total_loss : 9.7059  avg_loss_step : 9.7135  learning_rate : 0.00028200002  loss_scaler : 8388608 
DLL 2022-06-04 20:43:51.789513 - Iteration: 97  throughput_train : 4190.995 seq/s mlm_loss : 8.9656  nsp_loss : 0.6905  total_loss : 9.6561  avg_loss_step : 9.7080  learning_rate : 0.00028500002  loss_scaler : 8388608 
DLL 2022-06-04 20:44:07.863187 - Iteration: 98  throughput_train : 4207.841 seq/s mlm_loss : 9.0278  nsp_loss : 0.7054  total_loss : 9.7332  avg_loss_step : 9.6998  learning_rate : 0.000288  loss_scaler : 8388608 
DLL 2022-06-04 20:44:23.932974 - Iteration: 99  throughput_train : 4208.859 seq/s mlm_loss : 9.0177  nsp_loss : 0.6960  total_loss : 9.7137  avg_loss_step : 9.7088  learning_rate : 0.000291  loss_scaler : 8388608 
DLL 2022-06-04 20:44:40.051419 - Iteration: 100  throughput_train : 4196.455 seq/s mlm_loss : 8.8965  nsp_loss : 0.6777  total_loss : 9.5742  avg_loss_step : 9.7022  learning_rate : 0.000294  loss_scaler : 8388608 
DLL 2022-06-04 20:44:56.120139 - Iteration: 101  throughput_train : 4209.074 seq/s mlm_loss : 8.9934  nsp_loss : 0.6798  total_loss : 9.6733  avg_loss_step : 9.6718  learning_rate : 0.00029700002  loss_scaler : 8388608 
DLL 2022-06-04 20:45:12.206274 - Iteration: 102  throughput_train : 4204.611 seq/s mlm_loss : 8.8914  nsp_loss : 0.6700  total_loss : 9.5613  avg_loss_step : 9.6626  learning_rate : 0.0003  loss_scaler : 8388608 
DLL 2022-06-04 20:45:28.292418 - Iteration: 103  throughput_train : 4204.572 seq/s mlm_loss : 8.9414  nsp_loss : 0.6902  total_loss : 9.6316  avg_loss_step : 9.6254  learning_rate : 0.000303  loss_scaler : 8388608 
DLL 2022-06-04 20:45:44.382836 - Iteration: 104  throughput_train : 4203.448 seq/s mlm_loss : 8.9752  nsp_loss : 0.7026  total_loss : 9.6778  avg_loss_step : 9.6377  learning_rate : 0.000306  loss_scaler : 8388608 
DLL 2022-06-04 20:46:00.464705 - Iteration: 105  throughput_train : 4205.641 seq/s mlm_loss : 8.8136  nsp_loss : 0.6546  total_loss : 9.4682  avg_loss_step : 9.6369  learning_rate : 0.00030900002  loss_scaler : 8388608 
DLL 2022-06-04 20:46:16.523777 - Iteration: 106  throughput_train : 4211.641 seq/s mlm_loss : 8.9881  nsp_loss : 0.6732  total_loss : 9.6614  avg_loss_step : 9.6273  learning_rate : 0.00031200002  loss_scaler : 8388608 
2022-06-04 20:46:42.904926: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2022-06-04 20:46:43.041880: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:loss = 9.536226, step = 105 (1994.400 sec)
INFO:tensorflow:loss = 9.618778, step = 105 (1994.407 sec)
INFO:tensorflow:loss = 9.50812, step = 105 (1994.390 sec)
INFO:tensorflow:loss = 9.531254, step = 105 (1994.399 sec)
INFO:tensorflow:loss = 9.624498, step = 105 (1994.405 sec)
INFO:tensorflow:loss = 9.666329, step = 105 (1994.409 sec)
I0604 20:47:23.946159 140364662961984 basic_session_run_hooks.py:260] loss = 9.536226, step = 105 (1994.400 sec)
I0604 20:47:23.946097 139731936220992 basic_session_run_hooks.py:260] loss = 9.618778, step = 105 (1994.407 sec)
I0604 20:47:23.946110 139743670941504 basic_session_run_hooks.py:260] loss = 9.50812, step = 105 (1994.390 sec)
I0604 20:47:23.946176 140204806985536 basic_session_run_hooks.py:260] loss = 9.531254, step = 105 (1994.399 sec)
I0604 20:47:23.946294 140104855435072 basic_session_run_hooks.py:260] loss = 9.666329, step = 105 (1994.409 sec)
I0604 20:47:23.946255 139839092963136 basic_session_run_hooks.py:260] loss = 9.624498, step = 105 (1994.405 sec)
INFO:tensorflow:loss = 9.576521, step = 105 (1994.403 sec)
I0604 20:47:23.946823 140071876900672 basic_session_run_hooks.py:260] loss = 9.576521, step = 105 (1994.403 sec)
INFO:tensorflow:loss = 9.725315, step = 105 (1999.536 sec)
I0604 20:47:28.223718 139713267980096 basic_session_run_hooks.py:260] loss = 9.725315, step = 105 (1999.536 sec)
DLL 2022-06-04 20:47:33.908750 - Iteration: 107  throughput_train : 873.501 seq/s mlm_loss : 8.8781  nsp_loss : 0.6863  total_loss : 9.5645  avg_loss_step : 9.6247  learning_rate : 0.000315  loss_scaler : 8388608 
DLL 2022-06-04 20:47:49.952870 - Iteration: 108  throughput_train : 4215.635 seq/s mlm_loss : 9.0073  nsp_loss : 0.6800  total_loss : 9.6873  avg_loss_step : 9.6013  learning_rate : 0.000318  loss_scaler : 8388608 
DLL 2022-06-04 20:48:06.004533 - Iteration: 109  throughput_train : 4213.575 seq/s mlm_loss : 8.8609  nsp_loss : 0.7103  total_loss : 9.5712  avg_loss_step : 9.5925  learning_rate : 0.000321  loss_scaler : 8388608 
DLL 2022-06-04 20:48:22.080472 - Iteration: 110  throughput_train : 4207.186 seq/s mlm_loss : 8.9529  nsp_loss : 0.6887  total_loss : 9.6416  avg_loss_step : 9.5906  learning_rate : 0.00032400002  loss_scaler : 8388608 
DLL 2022-06-04 20:48:38.192497 - Iteration: 111  throughput_train : 4197.808 seq/s mlm_loss : 9.0416  nsp_loss : 0.6797  total_loss : 9.7212  avg_loss_step : 9.5730  learning_rate : 0.00032700002  loss_scaler : 8388608 
DLL 2022-06-04 20:48:54.284273 - Iteration: 112  throughput_train : 4203.099 seq/s mlm_loss : 8.8618  nsp_loss : 0.6698  total_loss : 9.5316  avg_loss_step : 9.5828  learning_rate : 0.00033  loss_scaler : 8388608 
DLL 2022-06-04 20:49:10.397857 - Iteration: 113  throughput_train : 4197.527 seq/s mlm_loss : 8.9205  nsp_loss : 0.6963  total_loss : 9.6168  avg_loss_step : 9.5516  learning_rate : 0.000333  loss_scaler : 8388608 
DLL 2022-06-04 20:49:26.546817 - Iteration: 114  throughput_train : 4188.201 seq/s mlm_loss : 8.8203  nsp_loss : 0.6703  total_loss : 9.4905  avg_loss_step : 9.5500  learning_rate : 0.000336  loss_scaler : 8388608 
DLL 2022-06-04 20:49:42.648023 - Iteration: 115  throughput_train : 4200.603 seq/s mlm_loss : 8.9099  nsp_loss : 0.7126  total_loss : 9.6225  avg_loss_step : 9.5258  learning_rate : 0.00033900002  loss_scaler : 8388608 
DLL 2022-06-04 20:49:58.790058 - Iteration: 116  throughput_train : 4190.076 seq/s mlm_loss : 8.7973  nsp_loss : 0.6504  total_loss : 9.4477  avg_loss_step : 9.5310  learning_rate : 0.000342  loss_scaler : 8388608 
DLL 2022-06-04 20:50:14.937042 - Iteration: 117  throughput_train : 4188.845 seq/s mlm_loss : 8.8193  nsp_loss : 0.7014  total_loss : 9.5207  avg_loss_step : 9.4943  learning_rate : 0.000345  loss_scaler : 8388608 
DLL 2022-06-04 20:50:31.092079 - Iteration: 118  throughput_train : 4186.640 seq/s mlm_loss : 8.9072  nsp_loss : 0.6897  total_loss : 9.5969  avg_loss_step : 9.5151  learning_rate : 0.000348  loss_scaler : 8388608 
DLL 2022-06-04 20:50:47.194168 - Iteration: 119  throughput_train : 4200.678 seq/s mlm_loss : 8.7754  nsp_loss : 0.6443  total_loss : 9.4197  avg_loss_step : 9.4845  learning_rate : 0.00035100002  loss_scaler : 8388608 
DLL 2022-06-04 20:51:03.296554 - Iteration: 120  throughput_train : 4200.371 seq/s mlm_loss : 8.7497  nsp_loss : 0.6834  total_loss : 9.4331  avg_loss_step : 9.4837  learning_rate : 0.00035400002  loss_scaler : 8388608 
DLL 2022-06-04 20:51:19.386610 - Iteration: 121  throughput_train : 4203.549 seq/s mlm_loss : 8.9400  nsp_loss : 0.6201  total_loss : 9.5601  avg_loss_step : 9.4659  learning_rate : 0.000357  loss_scaler : 8388608 
DLL 2022-06-04 20:51:35.521651 - Iteration: 122  throughput_train : 4191.901 seq/s mlm_loss : 8.8619  nsp_loss : 0.6644  total_loss : 9.5264  avg_loss_step : 9.4667  learning_rate : 0.00036  loss_scaler : 8388608 
DLL 2022-06-04 20:51:51.625720 - Iteration: 123  throughput_train : 4199.822 seq/s mlm_loss : 8.7995  nsp_loss : 0.6655  total_loss : 9.4650  avg_loss_step : 9.4559  learning_rate : 0.000363  loss_scaler : 8388608 
DLL 2022-06-04 20:52:07.738325 - Iteration: 124  throughput_train : 4197.572 seq/s mlm_loss : 8.8233  nsp_loss : 0.6638  total_loss : 9.4871  avg_loss_step : 9.4563  learning_rate : 0.00036600002  loss_scaler : 8388608 
DLL 2022-06-04 20:52:23.821331 - Iteration: 125  throughput_train : 4205.393 seq/s mlm_loss : 8.8100  nsp_loss : 0.7243  total_loss : 9.5343  avg_loss_step : 9.4658  learning_rate : 0.00036900002  loss_scaler : 8388608 
DLL 2022-06-04 20:52:39.949400 - Iteration: 126  throughput_train : 4193.723 seq/s mlm_loss : 8.6939  nsp_loss : 0.6450  total_loss : 9.3389  avg_loss_step : 9.4422  learning_rate : 0.000372  loss_scaler : 8388608 
DLL 2022-06-04 20:52:56.042730 - Iteration: 127  throughput_train : 4202.615 seq/s mlm_loss : 8.6823  nsp_loss : 0.6858  total_loss : 9.3681  avg_loss_step : 9.4320  learning_rate : 0.000375  loss_scaler : 8388608 
DLL 2022-06-04 20:53:12.142887 - Iteration: 128  throughput_train : 4200.914 seq/s mlm_loss : 8.7432  nsp_loss : 0.6440  total_loss : 9.3872  avg_loss_step : 9.4016  learning_rate : 0.00037800003  loss_scaler : 8388608 
DLL 2022-06-04 20:53:28.226947 - Iteration: 129  throughput_train : 4205.102 seq/s mlm_loss : 8.6766  nsp_loss : 0.6401  total_loss : 9.3168  avg_loss_step : 9.3909  learning_rate : 0.00038100002  loss_scaler : 8388608 
DLL 2022-06-04 20:53:44.360211 - Iteration: 130  throughput_train : 4192.328 seq/s mlm_loss : 8.8800  nsp_loss : 0.6697  total_loss : 9.5497  avg_loss_step : 9.4059  learning_rate : 0.000384  loss_scaler : 8388608 
DLL 2022-06-04 20:54:00.462587 - Iteration: 131  throughput_train : 4200.449 seq/s mlm_loss : 8.7039  nsp_loss : 0.5923  total_loss : 9.2963  avg_loss_step : 9.3698  learning_rate : 0.000387  loss_scaler : 8388608 
DLL 2022-06-04 20:54:16.550643 - Iteration: 132  throughput_train : 4204.151 seq/s mlm_loss : 8.7722  nsp_loss : 0.6607  total_loss : 9.4329  avg_loss_step : 9.3443  learning_rate : 0.00039  loss_scaler : 8388608 
DLL 2022-06-04 20:54:32.660354 - Iteration: 133  throughput_train : 4198.452 seq/s mlm_loss : 8.7214  nsp_loss : 0.6157  total_loss : 9.3372  avg_loss_step : 9.3349  learning_rate : 0.00039300002  loss_scaler : 8388608 
DLL 2022-06-04 20:54:48.751935 - Iteration: 134  throughput_train : 4203.162 seq/s mlm_loss : 8.6749  nsp_loss : 0.6708  total_loss : 9.3458  avg_loss_step : 9.3578  learning_rate : 0.00039600002  loss_scaler : 8388608 
DLL 2022-06-04 20:55:04.837201 - Iteration: 135  throughput_train : 4204.748 seq/s mlm_loss : 8.6600  nsp_loss : 0.6244  total_loss : 9.2844  avg_loss_step : 9.3456  learning_rate : 0.000399  loss_scaler : 8388608 
DLL 2022-06-04 20:55:20.948759 - Iteration: 136  throughput_train : 4197.941 seq/s mlm_loss : 8.6105  nsp_loss : 0.6308  total_loss : 9.2412  avg_loss_step : 9.3071  learning_rate : 0.000402  loss_scaler : 8388608 
DLL 2022-06-04 20:55:37.047538 - Iteration: 137  throughput_train : 4201.314 seq/s mlm_loss : 8.6763  nsp_loss : 0.6424  total_loss : 9.3188  avg_loss_step : 9.2978  learning_rate : 0.00040500003  loss_scaler : 8388608 
DLL 2022-06-04 20:55:53.126962 - Iteration: 138  throughput_train : 4206.317 seq/s mlm_loss : 8.5996  nsp_loss : 0.6553  total_loss : 9.2549  avg_loss_step : 9.2939  learning_rate : 0.00040800002  loss_scaler : 8388608 
DLL 2022-06-04 20:56:09.204886 - Iteration: 139  throughput_train : 4206.748 seq/s mlm_loss : 8.5923  nsp_loss : 0.6913  total_loss : 9.2836  avg_loss_step : 9.2923  learning_rate : 0.00041100002  loss_scaler : 8388608 
DLL 2022-06-04 20:56:25.298337 - Iteration: 140  throughput_train : 4202.595 seq/s mlm_loss : 8.6955  nsp_loss : 0.6786  total_loss : 9.3741  avg_loss_step : 9.2941  learning_rate : 0.000414  loss_scaler : 8388608 
DLL 2022-06-04 20:56:41.438702 - Iteration: 141  throughput_train : 4190.416 seq/s mlm_loss : 8.6343  nsp_loss : 0.6493  total_loss : 9.2836  avg_loss_step : 9.2637  learning_rate : 0.000417  loss_scaler : 8388608 
DLL 2022-06-04 20:56:57.537251 - Iteration: 142  throughput_train : 4201.246 seq/s mlm_loss : 8.5344  nsp_loss : 0.6829  total_loss : 9.2174  avg_loss_step : 9.2331  learning_rate : 0.00042000003  loss_scaler : 8388608 
DLL 2022-06-04 20:57:13.625691 - Iteration: 143  throughput_train : 4204.033 seq/s mlm_loss : 8.6078  nsp_loss : 0.6702  total_loss : 9.2780  avg_loss_step : 9.2596  learning_rate : 0.00042300002  loss_scaler : 8388608 
DLL 2022-06-04 20:57:29.732559 - Iteration: 144  throughput_train : 4199.276 seq/s mlm_loss : 8.5731  nsp_loss : 0.6621  total_loss : 9.2352  avg_loss_step : 9.2473  learning_rate : 0.000426  loss_scaler : 8388608 
DLL 2022-06-04 20:57:45.841554 - Iteration: 145  throughput_train : 4198.646 seq/s mlm_loss : 8.6239  nsp_loss : 0.6394  total_loss : 9.2633  avg_loss_step : 9.2057  learning_rate : 0.000429  loss_scaler : 8388608 
DLL 2022-06-04 20:58:01.943053 - Iteration: 146  throughput_train : 4200.499 seq/s mlm_loss : 8.5463  nsp_loss : 0.6121  total_loss : 9.1584  avg_loss_step : 9.2059  learning_rate : 0.00043200003  loss_scaler : 8388608 
DLL 2022-06-04 20:58:18.034632 - Iteration: 147  throughput_train : 4203.040 seq/s mlm_loss : 8.5257  nsp_loss : 0.6857  total_loss : 9.2114  avg_loss_step : 9.2064  learning_rate : 0.00043500002  loss_scaler : 8388608 
DLL 2022-06-04 20:58:34.136087 - Iteration: 148  throughput_train : 4200.508 seq/s mlm_loss : 8.4404  nsp_loss : 0.5989  total_loss : 9.0392  avg_loss_step : 9.1905  learning_rate : 0.00043800002  loss_scaler : 8388608 
DLL 2022-06-04 20:58:50.257730 - Iteration: 149  throughput_train : 4195.307 seq/s mlm_loss : 8.6316  nsp_loss : 0.6497  total_loss : 9.2813  avg_loss_step : 9.1746  learning_rate : 0.000441  loss_scaler : 8388608 
DLL 2022-06-04 20:59:06.377473 - Iteration: 150  throughput_train : 4195.775 seq/s mlm_loss : 8.5538  nsp_loss : 0.6782  total_loss : 9.2320  avg_loss_step : 9.1467  learning_rate : 0.000444  loss_scaler : 8388608 
DLL 2022-06-04 20:59:22.503167 - Iteration: 151  throughput_train : 4194.312 seq/s mlm_loss : 8.4824  nsp_loss : 0.6589  total_loss : 9.1413  avg_loss_step : 9.1527  learning_rate : 0.00044700003  loss_scaler : 8388608 
DLL 2022-06-04 20:59:38.593830 - Iteration: 152  throughput_train : 4203.432 seq/s mlm_loss : 8.4788  nsp_loss : 0.6666  total_loss : 9.1454  avg_loss_step : 9.1618  learning_rate : 0.00045000002  loss_scaler : 8388608 
DLL 2022-06-04 20:59:54.694850 - Iteration: 153  throughput_train : 4200.728 seq/s mlm_loss : 8.3717  nsp_loss : 0.6977  total_loss : 9.0694  avg_loss_step : 9.1285  learning_rate : 0.00045300002  loss_scaler : 8388608 
DLL 2022-06-04 21:00:10.785709 - Iteration: 154  throughput_train : 4203.345 seq/s mlm_loss : 8.4954  nsp_loss : 0.6509  total_loss : 9.1462  avg_loss_step : 9.1145  learning_rate : 0.000456  loss_scaler : 8388608 
DLL 2022-06-04 21:00:26.888811 - Iteration: 155  throughput_train : 4200.095 seq/s mlm_loss : 8.5230  nsp_loss : 0.6423  total_loss : 9.1653  avg_loss_step : 9.0803  learning_rate : 0.000459  loss_scaler : 8388608 
DLL 2022-06-04 21:00:42.997061 - Iteration: 156  throughput_train : 4198.818 seq/s mlm_loss : 8.4320  nsp_loss : 0.6297  total_loss : 9.0617  avg_loss_step : 9.0640  learning_rate : 0.00046200003  loss_scaler : 8388608 
DLL 2022-06-04 21:00:59.083111 - Iteration: 157  throughput_train : 4204.634 seq/s mlm_loss : 8.4683  nsp_loss : 0.6637  total_loss : 9.1320  avg_loss_step : 9.0797  learning_rate : 0.00046500002  loss_scaler : 8388608 
DLL 2022-06-04 21:01:15.184377 - Iteration: 158  throughput_train : 4200.565 seq/s mlm_loss : 8.3799  nsp_loss : 0.6567  total_loss : 9.0367  avg_loss_step : 9.0646  learning_rate : 0.000468  loss_scaler : 8388608 
DLL 2022-06-04 21:01:31.303829 - Iteration: 159  throughput_train : 4195.868 seq/s mlm_loss : 8.4282  nsp_loss : 0.6287  total_loss : 9.0569  avg_loss_step : 9.0585  learning_rate : 0.000471  loss_scaler : 8388608 
DLL 2022-06-04 21:01:47.397050 - Iteration: 160  throughput_train : 4202.719 seq/s mlm_loss : 8.3975  nsp_loss : 0.6971  total_loss : 9.0946  avg_loss_step : 9.0289  learning_rate : 0.00047400003  loss_scaler : 8388608 
DLL 2022-06-04 21:02:03.464651 - Iteration: 161  throughput_train : 4209.418 seq/s mlm_loss : 8.2965  nsp_loss : 0.6894  total_loss : 8.9860  avg_loss_step : 9.0178  learning_rate : 0.00047700002  loss_scaler : 8388608 
DLL 2022-06-04 21:02:19.538361 - Iteration: 162  throughput_train : 4207.844 seq/s mlm_loss : 8.4016  nsp_loss : 0.6247  total_loss : 9.0262  avg_loss_step : 9.0302  learning_rate : 0.00048000002  loss_scaler : 8388608 
DLL 2022-06-04 21:02:35.634935 - Iteration: 163  throughput_train : 4201.904 seq/s mlm_loss : 8.4687  nsp_loss : 0.6920  total_loss : 9.1607  avg_loss_step : 9.0060  learning_rate : 0.000483  loss_scaler : 8388608 
DLL 2022-06-04 21:02:51.739069 - Iteration: 164  throughput_train : 4199.880 seq/s mlm_loss : 8.3662  nsp_loss : 0.6813  total_loss : 9.0476  avg_loss_step : 8.9926  learning_rate : 0.000486  loss_scaler : 8388608 
DLL 2022-06-04 21:03:07.837006 - Iteration: 165  throughput_train : 4201.460 seq/s mlm_loss : 8.2600  nsp_loss : 0.6662  total_loss : 8.9262  avg_loss_step : 8.9904  learning_rate : 0.000489  loss_scaler : 8388608 
DLL 2022-06-04 21:03:23.928037 - Iteration: 166  throughput_train : 4203.293 seq/s mlm_loss : 8.2884  nsp_loss : 0.6142  total_loss : 8.9026  avg_loss_step : 8.9572  learning_rate : 0.000492  loss_scaler : 8388608 
DLL 2022-06-04 21:03:40.058158 - Iteration: 167  throughput_train : 4193.154 seq/s mlm_loss : 8.3281  nsp_loss : 0.6471  total_loss : 8.9752  avg_loss_step : 8.9679  learning_rate : 0.00049500004  loss_scaler : 8388608 
DLL 2022-06-04 21:03:56.175667 - Iteration: 168  throughput_train : 4196.401 seq/s mlm_loss : 8.3037  nsp_loss : 0.6010  total_loss : 8.9047  avg_loss_step : 8.9739  learning_rate : 0.000498  loss_scaler : 8388608 
DLL 2022-06-04 21:04:12.306352 - Iteration: 169  throughput_train : 4193.094 seq/s mlm_loss : 8.1848  nsp_loss : 0.6497  total_loss : 8.8345  avg_loss_step : 8.9460  learning_rate : 0.00050100003  loss_scaler : 8388608 
DLL 2022-06-04 21:04:28.433608 - Iteration: 170  throughput_train : 4193.995 seq/s mlm_loss : 8.3225  nsp_loss : 0.6856  total_loss : 9.0081  avg_loss_step : 8.9035  learning_rate : 0.000504  loss_scaler : 8388608 
DLL 2022-06-04 21:04:44.565873 - Iteration: 171  throughput_train : 4192.598 seq/s mlm_loss : 8.3046  nsp_loss : 0.6688  total_loss : 8.9734  avg_loss_step : 8.9236  learning_rate : 0.000507  loss_scaler : 8388608 
DLL 2022-06-04 21:05:00.684141 - Iteration: 172  throughput_train : 4196.249 seq/s mlm_loss : 8.2180  nsp_loss : 0.6146  total_loss : 8.8326  avg_loss_step : 8.8983  learning_rate : 0.00051000004  loss_scaler : 8388608 
DLL 2022-06-04 21:05:16.822952 - Iteration: 173  throughput_train : 4190.976 seq/s mlm_loss : 8.2429  nsp_loss : 0.6537  total_loss : 8.8966  avg_loss_step : 8.8916  learning_rate : 0.000513  loss_scaler : 8388608 
DLL 2022-06-04 21:05:32.937425 - Iteration: 174  throughput_train : 4197.224 seq/s mlm_loss : 8.3180  nsp_loss : 0.6574  total_loss : 8.9753  avg_loss_step : 8.8929  learning_rate : 0.00051600003  loss_scaler : 8388608 
DLL 2022-06-04 21:05:49.044841 - Iteration: 175  throughput_train : 4199.021 seq/s mlm_loss : 8.1310  nsp_loss : 0.6539  total_loss : 8.7850  avg_loss_step : 8.8778  learning_rate : 0.000519  loss_scaler : 8388608 
DLL 2022-06-04 21:06:05.177194 - Iteration: 176  throughput_train : 4192.663 seq/s mlm_loss : 8.2118  nsp_loss : 0.6177  total_loss : 8.8295  avg_loss_step : 8.8676  learning_rate : 0.000522  loss_scaler : 8388608 
DLL 2022-06-04 21:06:21.286536 - Iteration: 177  throughput_train : 4198.525 seq/s mlm_loss : 8.1496  nsp_loss : 0.6521  total_loss : 8.8017  avg_loss_step : 8.8606  learning_rate : 0.00052500004  loss_scaler : 8388608 
DLL 2022-06-04 21:06:37.392776 - Iteration: 178  throughput_train : 4199.386 seq/s mlm_loss : 8.2151  nsp_loss : 0.6639  total_loss : 8.8790  avg_loss_step : 8.8287  learning_rate : 0.000528  loss_scaler : 8388608 
DLL 2022-06-04 21:06:53.480050 - Iteration: 179  throughput_train : 4204.261 seq/s mlm_loss : 8.1694  nsp_loss : 0.6709  total_loss : 8.8403  avg_loss_step : 8.8395  learning_rate : 0.000531  loss_scaler : 8388608 
DLL 2022-06-04 21:07:09.551090 - Iteration: 180  throughput_train : 4208.579 seq/s mlm_loss : 8.2195  nsp_loss : 0.6003  total_loss : 8.8198  avg_loss_step : 8.8330  learning_rate : 0.000534  loss_scaler : 8388608 
DLL 2022-06-04 21:07:25.651388 - Iteration: 181  throughput_train : 4211.072 seq/s mlm_loss : 8.0029  nsp_loss : 0.7007  total_loss : 8.7036  avg_loss_step : 8.8081  learning_rate : 0.000537  loss_scaler : 8388608 
INFO:tensorflow:Saving checkpoints for 180 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1/model.ckpt.
I0604 21:07:25.652620 139713267980096 basic_session_run_hooks.py:606] Saving checkpoints for 180 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_220604201201/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 8.803027.
I0604 21:07:26.474034 140104855435072 estimator.py:371] Loss for final step: 8.803027.
INFO:tensorflow:Loss for final step: 8.83636.
I0604 21:07:26.491623 140071876900672 estimator.py:371] Loss for final step: 8.83636.
INFO:tensorflow:Loss for final step: 8.884253.
I0604 21:07:26.512133 140204806985536 estimator.py:371] Loss for final step: 8.884253.
INFO:tensorflow:Loss for final step: 8.620899.
I0604 21:07:26.545606 139743670941504 estimator.py:371] Loss for final step: 8.620899.
INFO:tensorflow:Loss for final step: 8.796216.
I0604 21:07:26.553390 139731936220992 estimator.py:371] Loss for final step: 8.796216.
INFO:tensorflow:Loss for final step: 8.669014.
I0604 21:07:26.555960 139839092963136 estimator.py:371] Loss for final step: 8.669014.
INFO:tensorflow:Loss for final step: 8.893976.
I0604 21:07:26.603076 140364662961984 estimator.py:371] Loss for final step: 8.893976.
INFO:tensorflow:Loss for final step: 8.703626.
I0604 21:07:30.550446 139713267980096 estimator.py:371] Loss for final step: 8.703626.
INFO:tensorflow:-----------------------------
I0604 21:07:30.551909 139713267980096 run_pretraining.py:644] -----------------------------
INFO:tensorflow:Total Training Time = 3326.47 for Sentences = 12165120
I0604 21:07:30.551994 139713267980096 run_pretraining.py:646] Total Training Time = 3326.47 for Sentences = 12165120
INFO:tensorflow:Total Training Time W/O Overhead = 2877.17 for Sentences = 11286528
I0604 21:07:30.552060 139713267980096 run_pretraining.py:648] Total Training Time W/O Overhead = 2877.17 for Sentences = 11286528
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 3657.06
I0604 21:07:30.552113 139713267980096 run_pretraining.py:649] Throughput Average (sentences/sec) with overhead = 3657.06
INFO:tensorflow:Throughput Average (sentences/sec) = 3922.78
I0604 21:07:30.552184 139713267980096 run_pretraining.py:650] Throughput Average (sentences/sec) = 3922.78
DLL 2022-06-04 21:07:30.552244 -  throughput_train : 3922.783 seq/s
INFO:tensorflow:-----------------------------
I0604 21:07:30.552393 139713267980096 run_pretraining.py:652] -----------------------------
