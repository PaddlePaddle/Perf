+ batch_size=96
+ num_gpus=8
+ precision=fp16
++ expr 67584 / 96 / 8
+ num_accumulation_steps_phase1=88
+ train_steps=100
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 96 64 8 7.5e-4 5e-4 fp16 true 8 2000 200 100 200 88 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528
Logs written to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144.211218100528.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2021-12-18 10:05:29.246224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246261: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:29.246259: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

--------------------------------------------------------------------------
[[30027,1],1]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.829887 140059395057472 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830009 139822226716480 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830171 140287407834944 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830660 140100619806528 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830655 139876255659840 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830685 139753399105344 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830729 140215365633856 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 10:05:30.830890 140118637983552 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:***** Configuaration *****
I1218 10:05:31.675556 140287407834944 run_pretraining.py:579] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1218 10:05:31.675797 140287407834944 run_pretraining.py:581]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1218 10:05:31.675885 140287407834944 run_pretraining.py:581]   alsologtostderr: False
INFO:tensorflow:  log_dir: 
I1218 10:05:31.675971 140287407834944 run_pretraining.py:581]   log_dir: 
INFO:tensorflow:  v: 0
I1218 10:05:31.676044 140287407834944 run_pretraining.py:581]   v: 0
INFO:tensorflow:  verbosity: 0
I1218 10:05:31.676115 140287407834944 run_pretraining.py:581]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1218 10:05:31.676184 140287407834944 run_pretraining.py:581]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1218 10:05:31.676251 140287407834944 run_pretraining.py:581]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1218 10:05:31.676318 140287407834944 run_pretraining.py:581]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1218 10:05:31.676390 140287407834944 run_pretraining.py:581]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1218 10:05:31.676459 140287407834944 run_pretraining.py:581]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1218 10:05:31.676540 140287407834944 run_pretraining.py:581]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
I1218 10:05:31.676610 140287407834944 run_pretraining.py:581]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1218 10:05:31.676679 140287407834944 run_pretraining.py:581]   only_check_args: False
INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1218 10:05:31.676746 140287407834944 run_pretraining.py:581]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1218 10:05:31.676815 140287407834944 run_pretraining.py:581]   test_random_seed: 301
INFO:tensorflow:  test_srcdir: 
I1218 10:05:31.676881 140287407834944 run_pretraining.py:581]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1218 10:05:31.676942 140287407834944 run_pretraining.py:581]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed: 
I1218 10:05:31.676989 140287407834944 run_pretraining.py:581]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I1218 10:05:31.677034 140287407834944 run_pretraining.py:581]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1218 10:05:31.677080 140287407834944 run_pretraining.py:581]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
I1218 10:05:31.677126 140287407834944 run_pretraining.py:581]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
I1218 10:05:31.677174 140287407834944 run_pretraining.py:581]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1
I1218 10:05:31.677221 140287407834944 run_pretraining.py:581]   output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1218 10:05:31.677267 140287407834944 run_pretraining.py:581]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1218 10:05:31.677311 140287407834944 run_pretraining.py:581]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1218 10:05:31.677356 140287407834944 run_pretraining.py:581]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1218 10:05:31.677401 140287407834944 run_pretraining.py:581]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1218 10:05:31.677446 140287407834944 run_pretraining.py:581]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1218 10:05:31.677492 140287407834944 run_pretraining.py:581]   do_train: True
INFO:tensorflow:  do_eval: False
I1218 10:05:31.677555 140287407834944 run_pretraining.py:581]   do_eval: False
INFO:tensorflow:  train_batch_size: 96
I1218 10:05:31.677620 140287407834944 run_pretraining.py:581]   train_batch_size: 96
INFO:tensorflow:  eval_batch_size: 8
I1218 10:05:31.677675 140287407834944 run_pretraining.py:581]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1218 10:05:31.677728 140287407834944 run_pretraining.py:581]   learning_rate: 0.00075
INFO:tensorflow:  num_train_steps: 90
I1218 10:05:31.677774 140287407834944 run_pretraining.py:581]   num_train_steps: 90
INFO:tensorflow:  num_warmup_steps: 2000
I1218 10:05:31.677819 140287407834944 run_pretraining.py:581]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1218 10:05:31.677863 140287407834944 run_pretraining.py:581]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1218 10:05:31.677908 140287407834944 run_pretraining.py:581]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1218 10:05:31.677960 140287407834944 run_pretraining.py:581]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1218 10:05:31.678004 140287407834944 run_pretraining.py:581]   max_eval_steps: 100
INFO:tensorflow:  num_accumulation_steps: 88
I1218 10:05:31.678049 140287407834944 run_pretraining.py:581]   num_accumulation_steps: 88
INFO:tensorflow:  allreduce_post_accumulation: True
I1218 10:05:31.678094 140287407834944 run_pretraining.py:581]   allreduce_post_accumulation: True
INFO:tensorflow:  verbose_logging: False
I1218 10:05:31.678139 140287407834944 run_pretraining.py:581]   verbose_logging: False
INFO:tensorflow:  horovod: True
I1218 10:05:31.678183 140287407834944 run_pretraining.py:581]   horovod: True
INFO:tensorflow:  report_loss: True
I1218 10:05:31.678227 140287407834944 run_pretraining.py:581]   report_loss: True
INFO:tensorflow:  manual_fp16: False
I1218 10:05:31.678272 140287407834944 run_pretraining.py:581]   manual_fp16: False
INFO:tensorflow:  amp: True
I1218 10:05:31.678316 140287407834944 run_pretraining.py:581]   amp: True
INFO:tensorflow:  use_xla: True
I1218 10:05:31.678360 140287407834944 run_pretraining.py:581]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1218 10:05:31.678406 140287407834944 run_pretraining.py:581]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1218 10:05:31.678452 140287407834944 run_pretraining.py:581]   ?: False
INFO:tensorflow:  help: False
I1218 10:05:31.678500 140287407834944 run_pretraining.py:581]   help: False
INFO:tensorflow:  helpshort: False
I1218 10:05:31.678571 140287407834944 run_pretraining.py:581]   helpshort: False
INFO:tensorflow:  helpfull: False
I1218 10:05:31.678622 140287407834944 run_pretraining.py:581]   helpfull: False
INFO:tensorflow:  helpxml: False
I1218 10:05:31.678670 140287407834944 run_pretraining.py:581]   helpxml: False
INFO:tensorflow:**************************
I1218 10:05:31.678713 140287407834944 run_pretraining.py:582] **************************
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.678854 140287407834944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f958cf56978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.679320 140287407834944 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f958cf56978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f958cf601e0>) includes params argument, but params are not passed to Estimator.
W1218 10:05:31.680109 140287407834944 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f958cf601e0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 10:05:31.680665 140287407834944 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1218 10:05:31.680750 140287407834944 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.685432 140100619806528 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6a0f8669e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.686163 140100619806528 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6a0f8669e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6a0f8700d0>) includes params argument, but params are not passed to Estimator.
W1218 10:05:31.686933 140100619806528 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6a0f8700d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 10:05:31.687433 140100619806528 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1218 10:05:31.687546 140100619806528 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.708273 140215365633856 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.708323 140059395057472 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f84c6eca9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.708852 140215365633856 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f84c6eca9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6076567978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.708926 140059395057472 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6076567978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f84c6ed40d0>) includes params argument, but params are not passed to Estimator.
W1218 10:05:31.709446 140215365633856 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f84c6ed40d0>) includes params argument, but params are not passed to Estimator.
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f60765710d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
W1218 10:05:31.709564 140059395057472 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f60765710d0>) includes params argument, but params are not passed to Estimator.
I1218 10:05:31.709805 140215365633856 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:***** Running training *****
I1218 10:05:31.709909 140059395057472 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1218 10:05:31.709865 140215365633856 run_pretraining.py:626]   Batch size = 96
INFO:tensorflow:  Batch size = 96
I1218 10:05:31.709983 140059395057472 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.712619 139753399105344 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f19378ee978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.713216 139753399105344 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f19378ee978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f19378f80d0>) includes params argument, but params are not passed to Estimator.
W1218 10:05:31.713835 139753399105344 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f19378f80d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 10:05:31.714173 139753399105344 run_pretraining.py:625] ***** Running training *****
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.714199 139822226716480 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:  Batch size = 96
I1218 10:05:31.714234 139753399105344 run_pretraining.py:626]   Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f293e00c9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.715030 139822226716480 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f293e00c9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.715394 140118637983552 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 10:05:31.716081 139876255659840 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f293e0160d0>) includes params argument, but params are not passed to Estimator.
W1218 10:05:31.715980 139822226716480 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f293e0160d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 10:05:31.716613 139822226716480 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6e417dc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 10:05:31.716371 140118637983552 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6e417dc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  Batch size = 96
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f35d26139e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6e417e70d0>) includes params argument, but params are not passed to Estimator.
I1218 10:05:31.716738 139822226716480 run_pretraining.py:626]   Batch size = 96
I1218 10:05:31.716743 139876255659840 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f35d26139e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
W1218 10:05:31.716983 140118637983552 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6e417e70d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 10:05:31.717309 140118637983552 run_pretraining.py:625] ***** Running training *****
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f35d261d0d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  Batch size = 96
W1218 10:05:31.717340 139876255659840 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f35d261d0d0>) includes params argument, but params are not passed to Estimator.
I1218 10:05:31.717370 140118637983552 run_pretraining.py:626]   Batch size = 96
INFO:tensorflow:***** Running training *****
I1218 10:05:31.717693 139876255659840 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 96
I1218 10:05:31.717755 139876255659840 run_pretraining.py:626]   Batch size = 96
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.794419 140287407834944 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.804040 140100619806528 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.804391 140215365633856 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.808110 140059395057472 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.809840 139753399105344 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.811529 140118637983552 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.813374 139876255659840 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 10:05:31.825335 139822226716480 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1218 10:05:31.906104 140215365633856 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 10:05:31.906288 140215365633856 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.906379 140215365633856 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.906450 140215365633856 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.906514 140215365633856 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.906595 140215365633856 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.906655 140215365633856 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.906712 140215365633856 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.906768 140215365633856 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.906955 140215365633856 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1218 10:05:31.907389 140100619806528 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 10:05:31.907574 140100619806528 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.907672 140100619806528 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.907746 140100619806528 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.907811 140100619806528 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.907874 140100619806528 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.907933 140100619806528 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.907999 140100619806528 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
W1218 10:05:31.907971 140215365633856 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.908058 140100619806528 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.908230 140100619806528 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1218 10:05:31.908932 140287407834944 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 10:05:31.909096 140287407834944 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.909185 140287407834944 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.909261 140287407834944 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
W1218 10:05:31.909228 140100619806528 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.909330 140287407834944 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.909395 140287407834944 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.909457 140287407834944 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.909515 140287407834944 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.909613 140287407834944 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.909806 140287407834944 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1218 10:05:31.910725 139753399105344 estimator.py:1148] Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:*** Features ***
W1218 10:05:31.910826 140287407834944 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1218 10:05:31.910876 139753399105344 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.910974 139753399105344 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.911046 139753399105344 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.911110 139753399105344 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.911172 139753399105344 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.911231 139753399105344 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.911288 139753399105344 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.911346 139753399105344 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.911517 139753399105344 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 10:05:31.912495 139753399105344 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1218 10:05:31.912488 140118637983552 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 10:05:31.912647 140118637983552 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.912738 140118637983552 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.912808 140118637983552 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.912871 140118637983552 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.912930 140118637983552 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.912995 140118637983552 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.913052 140118637983552 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.913107 140118637983552 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.913277 140118637983552 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1218 10:05:31.913573 140059395057472 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 10:05:31.913745 140059395057472 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.913840 140059395057472 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.913915 140059395057472 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.913992 140059395057472 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.914056 140059395057472 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.914119 140059395057472 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.914180 140059395057472 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.914240 140059395057472 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 10:05:31.914245 140118637983552 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.914425 140059395057472 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

I1218 10:05:31.915482 139876255659840 estimator.py:1148] Calling model_fn.
W1218 10:05:31.915494 140059395057472 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:*** Features ***
I1218 10:05:31.915651 139876255659840 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.915745 139876255659840 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.915818 139876255659840 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.915884 139876255659840 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.915953 139876255659840 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.916015 139876255659840 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.916073 139876255659840 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.916131 139876255659840 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.916306 139876255659840 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 10:05:31.917295 139876255659840 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 10:05:31.928465 139822226716480 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 10:05:31.928654 139822226716480 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (96, 128)
I1218 10:05:31.928747 139822226716480 run_pretraining.py:260]   name = input_ids, shape = (96, 128)
INFO:tensorflow:  name = input_mask, shape = (96, 128)
I1218 10:05:31.928817 139822226716480 run_pretraining.py:260]   name = input_mask, shape = (96, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (96, 20)
I1218 10:05:31.928879 139822226716480 run_pretraining.py:260]   name = masked_lm_ids, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (96, 20)
I1218 10:05:31.928944 139822226716480 run_pretraining.py:260]   name = masked_lm_positions, shape = (96, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (96, 20)
I1218 10:05:31.929002 139822226716480 run_pretraining.py:260]   name = masked_lm_weights, shape = (96, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (96, 1)
I1218 10:05:31.929058 139822226716480 run_pretraining.py:260]   name = next_sentence_labels, shape = (96, 1)
INFO:tensorflow:  name = segment_ids, shape = (96, 128)
I1218 10:05:31.929115 139822226716480 run_pretraining.py:260]   name = segment_ids, shape = (96, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 10:05:31.929293 139822226716480 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 10:05:31.930276 139822226716480 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.459159 140100619806528 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.461785 140215365633856 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.462854 139753399105344 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.467206 140118637983552 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.470292 139876255659840 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.483777 139822226716480 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.498901 140287407834944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 10:05:33.594744 140059395057472 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.382728 140215365633856 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.382952 139753399105344 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.383653 140100619806528 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.402853 139876255659840 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.411159 139822226716480 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.417297 140118637983552 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.571580 140287407834944 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.601852 139753399105344 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.601918 140100619806528 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.602089 140215365633856 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.622869 139876255659840 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.630755 139822226716480 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.654046 140118637983552 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 10:05:36.759769 140059395057472 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.813624 140287407834944 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 10:05:36.981261 140059395057472 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.493090 139753399105344 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.501655 140100619806528 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.609222 139822226716480 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.751312 139876255659840 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.753556 140118637983552 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.874161 140215365633856 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.904759 140287407834944 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1218 10:05:45.906064 140287407834944 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1218 10:05:45.945648 140059395057472 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1218 10:05:50.939470 140100619806528 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:50.951055: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:50.956505: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x15078380 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:50.956538: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:50.959553: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.092950 139822226716480 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.105479: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.110501: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x8883620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.110545: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.113996: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.158765 139753399105344 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.171256: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.176389: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5289b10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.176424: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.179864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.345861 140059395057472 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.358404: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.362429: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13363b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.362464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.365424: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.376639 140287407834944 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.389122: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.394594: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x141a9070 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.394624: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.397563: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.432250 140215365633856 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.446322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.450871: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x614d160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.450906: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.454034: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.474208 139876255659840 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.487012: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.492406: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x13ff7950 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.492437: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.495458: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 10:05:51.792593 140118637983552 monitored_session.py:240] Graph was finalized.
2021-12-18 10:05:51.805627: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 10:05:51.810358: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x92d0e00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.810391: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 10:05:51.813890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 10:05:51.819925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.825773: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1542e850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.825804: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:51.827375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.836647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.837442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:06:00.0
2021-12-18 10:05:51.837497: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:51.840875: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:51.842715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:51.842962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54a3160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.842988: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:51.843181: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:51.844195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.845783: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:51.846599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:51.846839: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:51.846985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.850775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
2021-12-18 10:05:51.850823: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:51.853214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.853824: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:51.854327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.855077: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:51.855415: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:51.857792: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:51.858340: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:51.858562: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:51.858667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.860744: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x528d840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:51.860778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:51.861232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2021-12-18 10:05:51.861291: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:51.863795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.867021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.872896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:09:00.0
2021-12-18 10:05:51.872946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:51.875742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2021-12-18 10:05:51.875796: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:51.876020: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:51.877941: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:51.878309: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:51.882731: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:51.883903: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:51.884139: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:51.884257: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.893116: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:51.901334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2021-12-18 10:05:51.901371: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.471835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.476392: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x51a1fd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:52.476425: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:52.477419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.481069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2021-12-18 10:05:52.481129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.484452: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:52.485872: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:52.486206: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:52.488773: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:52.489319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:52.489535: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:52.489653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.497134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.499363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.504228: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9c1e9e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:52.504258: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:52.505634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.506746: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.507925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-12-18 10:05:52.507970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.510554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.515211: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xafffab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:52.515236: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:52.515539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
2021-12-18 10:05:52.515594: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.517715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.518632: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:52.519955: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:52.520254: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x74cabc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:52.520284: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:52.520293: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:52.522958: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:52.523516: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:52.523617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.523726: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:52.523849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.525012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0a:00.0
2021-12-18 10:05:52.525067: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.528178: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:52.529585: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:52.529911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:52.531381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
2021-12-18 10:05:52.531431: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.531567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.532800: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:52.533465: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:52.533689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:52.533810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.534683: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:52.536110: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:52.536464: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:52.537847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2021-12-18 10:05:52.537900: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.539365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:52.540042: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:52.540273: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:52.540401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.542681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.549321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:52.549358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2021-12-18 10:05:52.549342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.549370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2021-12-18 10:05:52.551162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.551435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2021-12-18 10:05:52.551492: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.560782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2021-12-18 10:05:52.560831: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.561792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.573493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2021-12-18 10:05:52.586340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.596754: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x68580a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 10:05:52.596791: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 10:05:52.599011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.608454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:05:00.0
2021-12-18 10:05:52.608510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.611908: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:05:52.613301: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 10:05:52.613688: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 10:05:52.616623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 10:05:52.617270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 10:05:52.617481: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:05:52.617655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.625233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.625801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:52.625845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2021-12-18 10:05:52.625856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2021-12-18 10:05:52.626434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.633004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2021-12-18 10:05:52.633059: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 10:05:52.635745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.641820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
2021-12-18 10:05:52.661816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:52.661867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2021-12-18 10:05:52.661876: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2021-12-18 10:05:52.662204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.664737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.666823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
2021-12-18 10:05:52.979808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:52.979860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2021-12-18 10:05:52.979870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2021-12-18 10:05:52.980167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.982731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:52.984718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
2021-12-18 10:05:52.998157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:52.998204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2021-12-18 10:05:52.998214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2021-12-18 10:05:52.998495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.000610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.002610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
2021-12-18 10:05:53.038788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:53.038839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2021-12-18 10:05:53.038851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2021-12-18 10:05:53.039187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.041341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.043333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
2021-12-18 10:05:53.044798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:53.044844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2021-12-18 10:05:53.044853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2021-12-18 10:05:53.045147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.047447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.049722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2021-12-18 10:05:53.061361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 10:05:53.061397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2021-12-18 10:05:53.061405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2021-12-18 10:05:53.061680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.063829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 10:05:53.065817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2021-12-18 10:05:56.114728: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.130751: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.244866: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.261796: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.301094: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.324186: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.497182: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.508455: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.509619: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.522547: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.711084: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.723227: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.729732: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.742535: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:56.917730: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:05:56.931438: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:05:58.675072: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.024047: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.025630: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.138506: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.178854: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.362197: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.520416: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:05:59.806459: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 10:06:02.395201: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:02.402065: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:02.816758: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:02.819636: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:02.823798: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:02.826571: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:03.057275: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:03.064533: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1218 10:06:03.110396 139822226716480 session_manager.py:500] Running local_init_op.
2021-12-18 10:06:03.117951: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:03.124775: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:03.297131: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:03.303845: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:03.335741: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:03.342511: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1218 10:06:03.528038 140100619806528 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 10:06:03.531101 140215365633856 session_manager.py:500] Running local_init_op.
2021-12-18 10:06:03.605404: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:03.612340: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:03.625950: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:03.626178: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 10:06:03.755629 139822226716480 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 10:06:03.801110 139876255659840 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 10:06:03.876347 139753399105344 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 10:06:03.976802 140118637983552 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 10:06:04.009917 140287407834944 session_manager.py:500] Running local_init_op.
2021-12-18 10:06:04.044632: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.044632: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.044863: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:04.044863: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 10:06:04.175855 140215365633856 session_manager.py:502] Done running local_init_op.
I1218 10:06:04.175863 140100619806528 session_manager.py:502] Done running local_init_op.
2021-12-18 10:06:04.290918: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.291156: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1218 10:06:04.297233 140059395057472 session_manager.py:500] Running local_init_op.
2021-12-18 10:06:04.421024: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
INFO:tensorflow:Done running local_init_op.
I1218 10:06:04.421018 139876255659840 session_manager.py:502] Done running local_init_op.
2021-12-18 10:06:04.427632: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:04.479753: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.479982: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:04.515104: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.515325: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:04.524740: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.524984: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 10:06:04.611132 140118637983552 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 10:06:04.643327 140287407834944 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 10:06:04.698607 139753399105344 session_manager.py:502] Done running local_init_op.
2021-12-18 10:06:04.812615: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.812850: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:04.847207: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.854054: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:04.857436: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:04.864456: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 10:06:04.939456 140059395057472 session_manager.py:502] Done running local_init_op.
2021-12-18 10:06:05.060020: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:05.066628: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.280437: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:05.287122: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.386786: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:05.395131: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.455347: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:05.462294: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.601905: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:05.608549: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.619008: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:05.619349: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.623898: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.625744: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:05.628251: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.113427: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.113813: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.118542: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.120437: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.123025: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.129828: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.130144: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.134694: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.136557: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.139124: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.245939: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.246290: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.250919: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.252821: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.255385: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.448560: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.448854: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.540363: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.554373: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.648649: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.648992: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.653459: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.655285: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.657808: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.772392: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.772765: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.777344: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.779168: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.781688: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.786939: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:06.787280: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.791949: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.793859: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:06.796439: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:07.065776: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:07.075295: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:07.080845: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:07.090097: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:07.154849: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:07.169005: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:07.588472: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:07.603291: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:07.723878: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:07.724887: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:07.739534: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:07.740127: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1/model.ckpt.
I1218 10:06:16.073712 140287407834944 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1/model.ckpt.
2021-12-18 10:06:16.882931: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:16.891009: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:23.234256: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:23.234645: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:23.239253: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:23.241128: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:23.243709: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:24.296573: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:24.309478: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1218 10:06:26.995594 140287407834944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2021-12-18 10:06:27.580786: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:27.581052: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:06:43.644292: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:43.828006: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:43.844147: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:43.849967: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:43.850812: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:44.025189: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:44.032872: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:44.033733: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:44.378048: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:44.504077: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:44.579305: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:44.681703: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:44.684517: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:44.749841: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:06:44.868545: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:44.924626: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:06:54.506887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:55.097693: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:55.146089: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:55.267258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:55.593896: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:55.672873: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:55.677798: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:55.737850: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:55.922733: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:56.231173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:56.294456: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:56.313402: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:56.322767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:56.621892: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 10:06:56.987118: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:06:57.344285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 10:07:27.283689: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:28.356926: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:28.804628: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:29.289315: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:30.221456: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:30.563658: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:30.767320: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 10:07:31.008133: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.118572, step = 0
I1218 10:07:33.006020 140287407834944 basic_session_run_hooks.py:262] loss = 11.118572, step = 0
2021-12-18 10:07:33.656008: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.656333: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:07:33.657593: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.657914: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:07:33.676119: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.676432: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:07:33.678228: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.678531: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:07:33.702727: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.703039: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:07:33.716037: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.716342: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 10:07:33.762708: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:33.763042: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:loss = 11.138809, step = 0
I1218 10:07:33.812626 139876255659840 basic_session_run_hooks.py:262] loss = 11.138809, step = 0
INFO:tensorflow:loss = 11.068103, step = 0
I1218 10:07:33.820718 140059395057472 basic_session_run_hooks.py:262] loss = 11.068103, step = 0
INFO:tensorflow:loss = 11.126789, step = 0
I1218 10:07:33.837248 140215365633856 basic_session_run_hooks.py:262] loss = 11.126789, step = 0
INFO:tensorflow:loss = 11.06773, step = 0
I1218 10:07:33.840436 139822226716480 basic_session_run_hooks.py:262] loss = 11.06773, step = 0
INFO:tensorflow:loss = 11.067141, step = 0
I1218 10:07:33.856743 140118637983552 basic_session_run_hooks.py:262] loss = 11.067141, step = 0
INFO:tensorflow:loss = 11.1663685, step = 0
I1218 10:07:33.876828 139753399105344 basic_session_run_hooks.py:262] loss = 11.1663685, step = 0
INFO:tensorflow:loss = 11.144132, step = 0
I1218 10:07:33.940114 140100619806528 basic_session_run_hooks.py:262] loss = 11.144132, step = 0
2021-12-18 10:07:50.815140: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:50.834752: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:50.991592: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:51.009380: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:51.015412: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:51.019238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:51.191952: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:51.197191: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:51.514078: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:51.695784: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:51.959083: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:52.123576: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:52.191332: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:52.278778: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 10:07:52.373276: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 10:07:52.452331: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:35.640768 139876255659840 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:35.641487 139822226716480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:35.643383 140215365633856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:35.646262 139753399105344 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:35.648785 140287407834944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:35.975952 140059395057472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:36.908580 140100619806528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:36.981162 140118637983552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156013 140100619806528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156020 140059395057472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156085 139876255659840 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156096 139753399105344 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156095 140215365633856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156164 139822226716480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.156863 140287407834944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.163724 140118637983552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.333253 140059395057472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.333350 139876255659840 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.333397 139753399105344 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.333794 139822226716480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.334479 140100619806528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.336267 140215365633856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.340291 140287407834944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.341967 140118637983552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.510842 139876255659840 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.510840 139753399105344 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.510942 140059395057472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.510986 140100619806528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.511645 139822226716480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.517384 140215365633856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.518671 140287407834944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.519460 140118637983552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.687979 139876255659840 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.688095 139753399105344 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.688084 140059395057472 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.688235 139822226716480 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.689022 140100619806528 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.696605 140215365633856 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.697921 140287407834944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 10:08:37.698205 140118637983552 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:09:00.548557 - Iteration: 1  throughput_train : 442.317 seq/s mlm_loss : 10.3998  nsp_loss : 0.7258  total_loss : 11.1256  avg_loss_step : 11.1117  learning_rate : 0.0  loss_scaler : 4294967296 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:09:16.730004 - Iteration: 1  throughput_train : 4179.774 seq/s mlm_loss : 10.4347  nsp_loss : 0.6830  total_loss : 11.1177  avg_loss_step : 11.1115  learning_rate : 0.0  loss_scaler : 2147483648 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:09:32.687889 - Iteration: 1  throughput_train : 4238.355 seq/s mlm_loss : 10.4055  nsp_loss : 0.6714  total_loss : 11.0769  avg_loss_step : 11.1065  learning_rate : 0.0  loss_scaler : 1073741824 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:09:48.830272 - Iteration: 1  throughput_train : 4189.826 seq/s mlm_loss : 10.4229  nsp_loss : 0.6954  total_loss : 11.1184  avg_loss_step : 11.1077  learning_rate : 0.0  loss_scaler : 536870912 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:10:04.942310 - Iteration: 1  throughput_train : 4198.740 seq/s mlm_loss : 10.4415  nsp_loss : 0.6942  total_loss : 11.1357  avg_loss_step : 11.1032  learning_rate : 0.0  loss_scaler : 268435456 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:10:21.093811 - Iteration: 1  throughput_train : 4188.177 seq/s mlm_loss : 10.4199  nsp_loss : 0.6691  total_loss : 11.0889  avg_loss_step : 11.1034  learning_rate : 0.0  loss_scaler : 134217728 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:10:37.175350 - Iteration: 1  throughput_train : 4205.817 seq/s mlm_loss : 10.4009  nsp_loss : 0.6577  total_loss : 11.0585  avg_loss_step : 11.1052  learning_rate : 0.0  loss_scaler : 67108864 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:11:02.200185 - Iteration: 1  throughput_train : 2702.053 seq/s mlm_loss : 10.4423  nsp_loss : 0.6703  total_loss : 11.1126  avg_loss_step : 11.1042  learning_rate : 0.0  loss_scaler : 33554432 
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:11:46.488296 - Iteration: 2  throughput_train : 1526.457 seq/s mlm_loss : 10.4234  nsp_loss : 0.6836  total_loss : 11.1070  avg_loss_step : 11.1072  learning_rate : 0.0  loss_scaler : 16777216 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:12:03.117620 - Iteration: 3  throughput_train : 4067.181 seq/s mlm_loss : 10.4142  nsp_loss : 0.6674  total_loss : 11.0816  avg_loss_step : 11.1066  learning_rate : 3e-06  loss_scaler : 16777216 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:12:19.595441 - Iteration: 4  throughput_train : 4104.519 seq/s mlm_loss : 10.3964  nsp_loss : 0.6646  total_loss : 11.0610  avg_loss_step : 11.1083  learning_rate : 6e-06  loss_scaler : 16777216 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:12:35.937720 - Iteration: 5  throughput_train : 4138.724 seq/s mlm_loss : 10.4226  nsp_loss : 0.6728  total_loss : 11.0954  avg_loss_step : 11.1009  learning_rate : 9e-06  loss_scaler : 16777216 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 10:12:52.255778 - Iteration: 6  throughput_train : 4144.824 seq/s mlm_loss : 10.3867  nsp_loss : 0.6681  total_loss : 11.0548  avg_loss_step : 11.0963  learning_rate : 1.2e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:13:08.576174 - Iteration: 7  throughput_train : 4144.339 seq/s mlm_loss : 10.4177  nsp_loss : 0.7351  total_loss : 11.1528  avg_loss_step : 11.0935  learning_rate : 1.50000005e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:13:24.895405 - Iteration: 8  throughput_train : 4144.445 seq/s mlm_loss : 10.4045  nsp_loss : 0.6559  total_loss : 11.0604  avg_loss_step : 11.0935  learning_rate : 1.8e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:13:41.188637 - Iteration: 9  throughput_train : 4151.347 seq/s mlm_loss : 10.4268  nsp_loss : 0.6894  total_loss : 11.1162  avg_loss_step : 11.0842  learning_rate : 2.1e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:13:57.462240 - Iteration: 10  throughput_train : 4156.524 seq/s mlm_loss : 10.3924  nsp_loss : 0.6989  total_loss : 11.0913  avg_loss_step : 11.0826  learning_rate : 2.4e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:14:13.735935 - Iteration: 11  throughput_train : 4156.065 seq/s mlm_loss : 10.3859  nsp_loss : 0.6918  total_loss : 11.0776  avg_loss_step : 11.0713  learning_rate : 2.7000002e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:14:29.953368 - Iteration: 12  throughput_train : 4170.631 seq/s mlm_loss : 10.3935  nsp_loss : 0.6700  total_loss : 11.0635  avg_loss_step : 11.0600  learning_rate : 3.0000001e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:14:46.148030 - Iteration: 13  throughput_train : 4176.155 seq/s mlm_loss : 10.3981  nsp_loss : 0.7377  total_loss : 11.1358  avg_loss_step : 11.0468  learning_rate : 3.3e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:15:02.472054 - Iteration: 14  throughput_train : 4143.422 seq/s mlm_loss : 10.3613  nsp_loss : 0.7001  total_loss : 11.0615  avg_loss_step : 11.0453  learning_rate : 3.6e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:15:18.783460 - Iteration: 15  throughput_train : 4146.775 seq/s mlm_loss : 10.3723  nsp_loss : 0.6765  total_loss : 11.0487  avg_loss_step : 11.0259  learning_rate : 3.9000002e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:15:35.028631 - Iteration: 16  throughput_train : 4163.365 seq/s mlm_loss : 10.3468  nsp_loss : 0.6821  total_loss : 11.0289  avg_loss_step : 11.0172  learning_rate : 4.2e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:15:51.262131 - Iteration: 17  throughput_train : 4166.678 seq/s mlm_loss : 10.3193  nsp_loss : 0.7048  total_loss : 11.0241  avg_loss_step : 11.0096  learning_rate : 4.5e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:16:07.460502 - Iteration: 18  throughput_train : 4177.303 seq/s mlm_loss : 10.3051  nsp_loss : 0.6824  total_loss : 10.9875  avg_loss_step : 10.9923  learning_rate : 4.8e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:16:23.756766 - Iteration: 19  throughput_train : 4150.503 seq/s mlm_loss : 10.2714  nsp_loss : 0.6914  total_loss : 10.9627  avg_loss_step : 10.9783  learning_rate : 5.1000003e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:16:39.970739 - Iteration: 20  throughput_train : 4171.468 seq/s mlm_loss : 10.2899  nsp_loss : 0.6860  total_loss : 10.9760  avg_loss_step : 10.9577  learning_rate : 5.4000004e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:16:56.190284 - Iteration: 21  throughput_train : 4170.302 seq/s mlm_loss : 10.2495  nsp_loss : 0.6706  total_loss : 10.9201  avg_loss_step : 10.9413  learning_rate : 5.7e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:17:12.519860 - Iteration: 22  throughput_train : 4142.005 seq/s mlm_loss : 10.2302  nsp_loss : 0.6655  total_loss : 10.8958  avg_loss_step : 10.9257  learning_rate : 6.0000002e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:17:28.719487 - Iteration: 23  throughput_train : 4175.013 seq/s mlm_loss : 10.2240  nsp_loss : 0.6833  total_loss : 10.9073  avg_loss_step : 10.9101  learning_rate : 6.3e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:17:44.964955 - Iteration: 24  throughput_train : 4163.471 seq/s mlm_loss : 10.1835  nsp_loss : 0.6955  total_loss : 10.8790  avg_loss_step : 10.8904  learning_rate : 6.6e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:18:01.223375 - Iteration: 25  throughput_train : 4160.188 seq/s mlm_loss : 10.1890  nsp_loss : 0.6941  total_loss : 10.8831  avg_loss_step : 10.8703  learning_rate : 6.9e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:18:17.460908 - Iteration: 26  throughput_train : 4165.331 seq/s mlm_loss : 10.1926  nsp_loss : 0.7093  total_loss : 10.9019  avg_loss_step : 10.8465  learning_rate : 7.2e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:18:33.643753 - Iteration: 27  throughput_train : 4179.741 seq/s mlm_loss : 10.1281  nsp_loss : 0.7131  total_loss : 10.8412  avg_loss_step : 10.8255  learning_rate : 7.5e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:18:49.871160 - Iteration: 28  throughput_train : 4167.867 seq/s mlm_loss : 10.1266  nsp_loss : 0.6907  total_loss : 10.8173  avg_loss_step : 10.8025  learning_rate : 7.8000005e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:19:06.072812 - Iteration: 29  throughput_train : 4174.730 seq/s mlm_loss : 10.0876  nsp_loss : 0.6815  total_loss : 10.7691  avg_loss_step : 10.7801  learning_rate : 8.1000006e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:19:22.423752 - Iteration: 30  throughput_train : 4136.286 seq/s mlm_loss : 10.0607  nsp_loss : 0.6581  total_loss : 10.7189  avg_loss_step : 10.7697  learning_rate : 8.4e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:19:38.645268 - Iteration: 31  throughput_train : 4169.400 seq/s mlm_loss : 10.0327  nsp_loss : 0.6928  total_loss : 10.7255  avg_loss_step : 10.7446  learning_rate : 8.7e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:19:54.856013 - Iteration: 32  throughput_train : 4172.114 seq/s mlm_loss : 10.0069  nsp_loss : 0.7053  total_loss : 10.7121  avg_loss_step : 10.7154  learning_rate : 9e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:20:11.159889 - Iteration: 33  throughput_train : 4148.767 seq/s mlm_loss : 10.0055  nsp_loss : 0.6634  total_loss : 10.6690  avg_loss_step : 10.6924  learning_rate : 9.3e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:20:27.408800 - Iteration: 34  throughput_train : 4162.563 seq/s mlm_loss : 9.9832  nsp_loss : 0.6587  total_loss : 10.6419  avg_loss_step : 10.6631  learning_rate : 9.6e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:20:43.659330 - Iteration: 35  throughput_train : 4162.750 seq/s mlm_loss : 9.9703  nsp_loss : 0.6535  total_loss : 10.6238  avg_loss_step : 10.6466  learning_rate : 9.9000004e-05  loss_scaler : 16777216 
DLL 2021-12-18 10:20:59.886056 - Iteration: 36  throughput_train : 4168.112 seq/s mlm_loss : 9.9191  nsp_loss : 0.6494  total_loss : 10.5685  avg_loss_step : 10.6240  learning_rate : 0.000102000005  loss_scaler : 16777216 
DLL 2021-12-18 10:21:16.122782 - Iteration: 37  throughput_train : 4165.644 seq/s mlm_loss : 9.8581  nsp_loss : 0.6437  total_loss : 10.5018  avg_loss_step : 10.5971  learning_rate : 0.00010500001  loss_scaler : 16777216 
DLL 2021-12-18 10:21:32.316393 - Iteration: 38  throughput_train : 4176.890 seq/s mlm_loss : 9.8648  nsp_loss : 0.6794  total_loss : 10.5441  avg_loss_step : 10.5603  learning_rate : 0.00010800001  loss_scaler : 16777216 
DLL 2021-12-18 10:21:48.555505 - Iteration: 39  throughput_train : 4167.000 seq/s mlm_loss : 9.8794  nsp_loss : 0.7086  total_loss : 10.5880  avg_loss_step : 10.5593  learning_rate : 0.000111  loss_scaler : 16777216 
DLL 2021-12-18 10:22:04.771209 - Iteration: 40  throughput_train : 4170.963 seq/s mlm_loss : 9.8734  nsp_loss : 0.6801  total_loss : 10.5534  avg_loss_step : 10.5329  learning_rate : 0.000114  loss_scaler : 16777216 
DLL 2021-12-18 10:22:21.083170 - Iteration: 41  throughput_train : 4146.340 seq/s mlm_loss : 9.8582  nsp_loss : 0.6684  total_loss : 10.5266  avg_loss_step : 10.5003  learning_rate : 0.000117  loss_scaler : 16777216 
DLL 2021-12-18 10:22:37.302596 - Iteration: 42  throughput_train : 4169.933 seq/s mlm_loss : 9.7854  nsp_loss : 0.7164  total_loss : 10.5019  avg_loss_step : 10.4840  learning_rate : 0.000120000004  loss_scaler : 16777216 
DLL 2021-12-18 10:22:53.594921 - Iteration: 43  throughput_train : 4151.229 seq/s mlm_loss : 9.7771  nsp_loss : 0.7071  total_loss : 10.4842  avg_loss_step : 10.4666  learning_rate : 0.000123  loss_scaler : 16777216 
DLL 2021-12-18 10:23:09.837093 - Iteration: 44  throughput_train : 4164.283 seq/s mlm_loss : 9.7536  nsp_loss : 0.6941  total_loss : 10.4477  avg_loss_step : 10.4302  learning_rate : 0.000126  loss_scaler : 16777216 
DLL 2021-12-18 10:23:26.051845 - Iteration: 45  throughput_train : 4171.362 seq/s mlm_loss : 9.7019  nsp_loss : 0.7006  total_loss : 10.4025  avg_loss_step : 10.4121  learning_rate : 0.00012900001  loss_scaler : 16777216 
DLL 2021-12-18 10:23:42.279654 - Iteration: 46  throughput_train : 4168.005 seq/s mlm_loss : 9.6920  nsp_loss : 0.6982  total_loss : 10.3902  avg_loss_step : 10.3860  learning_rate : 0.000132  loss_scaler : 16777216 
DLL 2021-12-18 10:23:58.581114 - Iteration: 47  throughput_train : 4149.049 seq/s mlm_loss : 9.6984  nsp_loss : 0.6941  total_loss : 10.3925  avg_loss_step : 10.3960  learning_rate : 0.00013500001  loss_scaler : 8388608 
DLL 2021-12-18 10:24:14.894673 - Iteration: 48  throughput_train : 4146.306 seq/s mlm_loss : 9.6503  nsp_loss : 0.6789  total_loss : 10.3292  avg_loss_step : 10.3727  learning_rate : 0.000138  loss_scaler : 8388608 
DLL 2021-12-18 10:24:31.134879 - Iteration: 49  throughput_train : 4164.703 seq/s mlm_loss : 9.6089  nsp_loss : 0.6713  total_loss : 10.2802  avg_loss_step : 10.3480  learning_rate : 0.00014100001  loss_scaler : 8388608 
DLL 2021-12-18 10:24:47.329050 - Iteration: 50  throughput_train : 4176.828 seq/s mlm_loss : 9.6461  nsp_loss : 0.6976  total_loss : 10.3436  avg_loss_step : 10.3278  learning_rate : 0.000144  loss_scaler : 8388608 
DLL 2021-12-18 10:25:03.568013 - Iteration: 51  throughput_train : 4165.281 seq/s mlm_loss : 9.5752  nsp_loss : 0.6596  total_loss : 10.2349  avg_loss_step : 10.2945  learning_rate : 0.000147  loss_scaler : 8388608 
DLL 2021-12-18 10:25:19.808286 - Iteration: 52  throughput_train : 4164.971 seq/s mlm_loss : 9.6118  nsp_loss : 0.6768  total_loss : 10.2886  avg_loss_step : 10.2784  learning_rate : 0.00015  loss_scaler : 8388608 
DLL 2021-12-18 10:25:36.012176 - Iteration: 53  throughput_train : 4174.146 seq/s mlm_loss : 9.5876  nsp_loss : 0.6820  total_loss : 10.2696  avg_loss_step : 10.2676  learning_rate : 0.000153  loss_scaler : 8388608 
DLL 2021-12-18 10:25:52.243804 - Iteration: 54  throughput_train : 4167.492 seq/s mlm_loss : 9.5470  nsp_loss : 0.6719  total_loss : 10.2189  avg_loss_step : 10.2445  learning_rate : 0.00015600001  loss_scaler : 8388608 
DLL 2021-12-18 10:26:08.494813 - Iteration: 55  throughput_train : 4161.982 seq/s mlm_loss : 9.5043  nsp_loss : 0.6961  total_loss : 10.2004  avg_loss_step : 10.2242  learning_rate : 0.000159  loss_scaler : 8388608 
DLL 2021-12-18 10:26:24.706217 - Iteration: 56  throughput_train : 4172.456 seq/s mlm_loss : 9.5210  nsp_loss : 0.6722  total_loss : 10.1931  avg_loss_step : 10.1967  learning_rate : 0.00016200001  loss_scaler : 8388608 
DLL 2021-12-18 10:26:40.928459 - Iteration: 57  throughput_train : 4169.419 seq/s mlm_loss : 9.4351  nsp_loss : 0.7024  total_loss : 10.1375  avg_loss_step : 10.1855  learning_rate : 0.000165  loss_scaler : 8388608 
DLL 2021-12-18 10:26:57.138716 - Iteration: 58  throughput_train : 4172.380 seq/s mlm_loss : 9.4901  nsp_loss : 0.6875  total_loss : 10.1776  avg_loss_step : 10.1746  learning_rate : 0.000168  loss_scaler : 8388608 
DLL 2021-12-18 10:27:13.472232 - Iteration: 59  throughput_train : 4141.270 seq/s mlm_loss : 9.5557  nsp_loss : 0.6901  total_loss : 10.2458  avg_loss_step : 10.1491  learning_rate : 0.000171  loss_scaler : 8388608 
DLL 2021-12-18 10:27:29.727777 - Iteration: 60  throughput_train : 4160.952 seq/s mlm_loss : 9.4124  nsp_loss : 0.6801  total_loss : 10.0925  avg_loss_step : 10.1318  learning_rate : 0.000174  loss_scaler : 8388608 
DLL 2021-12-18 10:27:45.929449 - Iteration: 61  throughput_train : 4174.742 seq/s mlm_loss : 9.4922  nsp_loss : 0.6621  total_loss : 10.1542  avg_loss_step : 10.1159  learning_rate : 0.00017700001  loss_scaler : 8388608 
DLL 2021-12-18 10:28:02.105501 - Iteration: 62  throughput_train : 4181.285 seq/s mlm_loss : 9.3334  nsp_loss : 0.6997  total_loss : 10.0331  avg_loss_step : 10.1006  learning_rate : 0.00018  loss_scaler : 8388608 
DLL 2021-12-18 10:28:18.353690 - Iteration: 63  throughput_train : 4162.702 seq/s mlm_loss : 9.3777  nsp_loss : 0.7197  total_loss : 10.0973  avg_loss_step : 10.0841  learning_rate : 0.00018300001  loss_scaler : 8388608 
DLL 2021-12-18 10:28:34.568423 - Iteration: 64  throughput_train : 4171.270 seq/s mlm_loss : 9.4550  nsp_loss : 0.6948  total_loss : 10.1498  avg_loss_step : 10.0767  learning_rate : 0.000186  loss_scaler : 8388608 
DLL 2021-12-18 10:28:50.858663 - Iteration: 65  throughput_train : 4151.734 seq/s mlm_loss : 9.3573  nsp_loss : 0.6736  total_loss : 10.0310  avg_loss_step : 10.0511  learning_rate : 0.00018900001  loss_scaler : 8388608 
DLL 2021-12-18 10:29:07.150919 - Iteration: 66  throughput_train : 4151.679 seq/s mlm_loss : 9.4402  nsp_loss : 0.7110  total_loss : 10.1512  avg_loss_step : 10.0238  learning_rate : 0.000192  loss_scaler : 8388608 
DLL 2021-12-18 10:29:23.469575 - Iteration: 67  throughput_train : 4145.087 seq/s mlm_loss : 9.3268  nsp_loss : 0.6804  total_loss : 10.0073  avg_loss_step : 10.0160  learning_rate : 0.000195  loss_scaler : 8388608 
DLL 2021-12-18 10:29:39.704029 - Iteration: 68  throughput_train : 4167.505 seq/s mlm_loss : 9.3335  nsp_loss : 0.6954  total_loss : 10.0289  avg_loss_step : 9.9941  learning_rate : 0.00019800001  loss_scaler : 8388608 
DLL 2021-12-18 10:29:55.912218 - Iteration: 69  throughput_train : 4173.121 seq/s mlm_loss : 9.1950  nsp_loss : 0.6687  total_loss : 9.8637  avg_loss_step : 9.9856  learning_rate : 0.000201  loss_scaler : 8388608 
DLL 2021-12-18 10:30:12.192473 - Iteration: 70  throughput_train : 4154.537 seq/s mlm_loss : 9.3286  nsp_loss : 0.6913  total_loss : 10.0200  avg_loss_step : 9.9716  learning_rate : 0.00020400001  loss_scaler : 8388608 
DLL 2021-12-18 10:30:28.439421 - Iteration: 71  throughput_train : 4162.940 seq/s mlm_loss : 9.3195  nsp_loss : 0.6823  total_loss : 10.0018  avg_loss_step : 9.9708  learning_rate : 0.000207  loss_scaler : 8388608 
DLL 2021-12-18 10:30:44.681620 - Iteration: 72  throughput_train : 4164.254 seq/s mlm_loss : 9.2975  nsp_loss : 0.6725  total_loss : 9.9700  avg_loss_step : 9.9479  learning_rate : 0.00021000001  loss_scaler : 8388608 
DLL 2021-12-18 10:31:00.939545 - Iteration: 73  throughput_train : 4160.147 seq/s mlm_loss : 9.3196  nsp_loss : 0.6783  total_loss : 9.9979  avg_loss_step : 9.9364  learning_rate : 0.000213  loss_scaler : 8388608 
DLL 2021-12-18 10:31:17.181965 - Iteration: 74  throughput_train : 4164.248 seq/s mlm_loss : 9.1889  nsp_loss : 0.6796  total_loss : 9.8685  avg_loss_step : 9.9132  learning_rate : 0.00021600001  loss_scaler : 8388608 
DLL 2021-12-18 10:31:33.408558 - Iteration: 75  throughput_train : 4168.124 seq/s mlm_loss : 9.2028  nsp_loss : 0.6924  total_loss : 9.8953  avg_loss_step : 9.9107  learning_rate : 0.00021900001  loss_scaler : 8388608 
DLL 2021-12-18 10:31:49.640900 - Iteration: 76  throughput_train : 4166.647 seq/s mlm_loss : 9.2633  nsp_loss : 0.6699  total_loss : 9.9333  avg_loss_step : 9.9070  learning_rate : 0.000222  loss_scaler : 8388608 
DLL 2021-12-18 10:32:05.885414 - Iteration: 77  throughput_train : 4163.837 seq/s mlm_loss : 9.1334  nsp_loss : 0.6829  total_loss : 9.8162  avg_loss_step : 9.8851  learning_rate : 0.00022500001  loss_scaler : 8388608 
DLL 2021-12-18 10:32:22.167662 - Iteration: 78  throughput_train : 4154.283 seq/s mlm_loss : 9.3296  nsp_loss : 0.6874  total_loss : 10.0170  avg_loss_step : 9.8814  learning_rate : 0.000228  loss_scaler : 8388608 
DLL 2021-12-18 10:32:38.365000 - Iteration: 79  throughput_train : 4175.979 seq/s mlm_loss : 9.1621  nsp_loss : 0.6871  total_loss : 9.8492  avg_loss_step : 9.8687  learning_rate : 0.00023100001  loss_scaler : 8388608 
DLL 2021-12-18 10:32:54.567180 - Iteration: 80  throughput_train : 4174.513 seq/s mlm_loss : 9.1355  nsp_loss : 0.6743  total_loss : 9.8098  avg_loss_step : 9.8494  learning_rate : 0.000234  loss_scaler : 8388608 
DLL 2021-12-18 10:33:10.784155 - Iteration: 81  throughput_train : 4170.616 seq/s mlm_loss : 9.1330  nsp_loss : 0.6723  total_loss : 9.8054  avg_loss_step : 9.8366  learning_rate : 0.00023700001  loss_scaler : 8388608 
DLL 2021-12-18 10:33:27.010800 - Iteration: 82  throughput_train : 4168.129 seq/s mlm_loss : 9.1745  nsp_loss : 0.6617  total_loss : 9.8362  avg_loss_step : 9.8394  learning_rate : 0.00024000001  loss_scaler : 8388608 
DLL 2021-12-18 10:33:43.216566 - Iteration: 83  throughput_train : 4173.482 seq/s mlm_loss : 9.1695  nsp_loss : 0.6744  total_loss : 9.8438  avg_loss_step : 9.8254  learning_rate : 0.000243  loss_scaler : 8388608 
DLL 2021-12-18 10:33:59.448299 - Iteration: 84  throughput_train : 4166.728 seq/s mlm_loss : 9.0321  nsp_loss : 0.6660  total_loss : 9.6981  avg_loss_step : 9.8081  learning_rate : 0.000246  loss_scaler : 8388608 
DLL 2021-12-18 10:34:15.657514 - Iteration: 85  throughput_train : 4172.811 seq/s mlm_loss : 9.1816  nsp_loss : 0.6657  total_loss : 9.8473  avg_loss_step : 9.7996  learning_rate : 0.000249  loss_scaler : 8388608 
DLL 2021-12-18 10:34:31.849748 - Iteration: 86  throughput_train : 4177.031 seq/s mlm_loss : 9.0928  nsp_loss : 0.6820  total_loss : 9.7747  avg_loss_step : 9.7985  learning_rate : 0.000252  loss_scaler : 8388608 
DLL 2021-12-18 10:34:48.059720 - Iteration: 87  throughput_train : 4172.731 seq/s mlm_loss : 9.1118  nsp_loss : 0.6918  total_loss : 9.8036  avg_loss_step : 9.7852  learning_rate : 0.00025500002  loss_scaler : 8388608 
DLL 2021-12-18 10:35:04.255922 - Iteration: 88  throughput_train : 4177.049 seq/s mlm_loss : 9.0366  nsp_loss : 0.6759  total_loss : 9.7125  avg_loss_step : 9.7896  learning_rate : 0.00025800001  loss_scaler : 8388608 
DLL 2021-12-18 10:35:20.461770 - Iteration: 89  throughput_train : 4173.550 seq/s mlm_loss : 9.0819  nsp_loss : 0.6727  total_loss : 9.7545  avg_loss_step : 9.7614  learning_rate : 0.000261  loss_scaler : 8388608 
DLL 2021-12-18 10:35:36.661320 - Iteration: 90  throughput_train : 4174.953 seq/s mlm_loss : 9.0332  nsp_loss : 0.6953  total_loss : 9.7284  avg_loss_step : 9.7383  learning_rate : 0.000264  loss_scaler : 8388608 
DLL 2021-12-18 10:35:52.912975 - Iteration: 91  throughput_train : 4175.626 seq/s mlm_loss : 9.1214  nsp_loss : 0.6903  total_loss : 9.8117  avg_loss_step : 9.7612  learning_rate : 0.000267  loss_scaler : 8388608 
INFO:tensorflow:Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1/model.ckpt.
I1218 10:35:52.914362 140287407834944 basic_session_run_hooks.py:606] Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218100528/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 9.742426.
I1218 10:35:53.786280 139822226716480 estimator.py:371] Loss for final step: 9.742426.
INFO:tensorflow:Loss for final step: 9.793242.
I1218 10:35:53.838196 140118637983552 estimator.py:371] Loss for final step: 9.793242.
INFO:tensorflow:Loss for final step: 9.825808.
I1218 10:35:53.865791 139753399105344 estimator.py:371] Loss for final step: 9.825808.
INFO:tensorflow:Loss for final step: 9.713804.
I1218 10:35:53.889003 140100619806528 estimator.py:371] Loss for final step: 9.713804.
INFO:tensorflow:Loss for final step: 9.761125.
I1218 10:35:53.980395 139876255659840 estimator.py:371] Loss for final step: 9.761125.
INFO:tensorflow:Loss for final step: 9.672775.
I1218 10:35:53.987381 140059395057472 estimator.py:371] Loss for final step: 9.672775.
INFO:tensorflow:Loss for final step: 9.712054.
I1218 10:35:53.998513 140215365633856 estimator.py:371] Loss for final step: 9.712054.
INFO:tensorflow:Loss for final step: 9.811697.
I1218 10:35:58.162166 140287407834944 estimator.py:371] Loss for final step: 9.811697.
INFO:tensorflow:-----------------------------
I1218 10:35:58.163818 140287407834944 run_pretraining.py:644] -----------------------------
INFO:tensorflow:Total Training Time = 1826.48 for Sentences = 6082560
I1218 10:35:58.163915 140287407834944 run_pretraining.py:646] Total Training Time = 1826.48 for Sentences = 6082560
INFO:tensorflow:Total Training Time W/O Overhead = 1379.50 for Sentences = 5203968
I1218 10:35:58.163989 140287407834944 run_pretraining.py:648] Total Training Time W/O Overhead = 1379.50 for Sentences = 5203968
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 3330.20
I1218 10:35:58.164050 140287407834944 run_pretraining.py:649] Throughput Average (sentences/sec) with overhead = 3330.20
INFO:tensorflow:Throughput Average (sentences/sec) = 3772.37
I1218 10:35:58.164122 140287407834944 run_pretraining.py:650] Throughput Average (sentences/sec) = 3772.37
DLL 2021-12-18 10:35:58.164179 -  throughput_train : 3772.367 seq/s
INFO:tensorflow:-----------------------------
I1218 10:35:58.164328 140287407834944 run_pretraining.py:652] -----------------------------
