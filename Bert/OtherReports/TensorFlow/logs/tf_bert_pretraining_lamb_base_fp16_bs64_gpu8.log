+ batch_size=64
+ num_gpus=8
+ precision=fp16
++ expr 67584 / 64 / 8
+ num_accumulation_steps_phase1=132
+ train_steps=100
+ bert_model=base
+ bash scripts/run_pretraining_lamb.sh 64 64 8 7.5e-4 5e-4 fp16 true 8 2000 200 100 200 132 512 base
Container nvidia build =  13409399
Saving checkpoints to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617
Logs written to /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144.211218060617.log
Container nvidia build =  13409399
XLA activated
--------------------------------------------------------------------------
WARNING: Open MPI tried to bind a process but failed.  This is a
warning only; your job will continue, though performance may
be degraded.

  Application name:  /usr/bin/python
  Error message:     failed to bind memory
  Location:          rtc_hwloc.c:445

--------------------------------------------------------------------------
2021-12-18 06:06:17.942473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942571: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942621: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942661: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942659: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:17.942655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

--------------------------------------------------------------------------
[[18301,1],6]: A high-performance Open MPI point-to-point messaging module
was unable to find any relevant network interfaces:

Module: OpenFabrics (openib)

Another transport will be used instead, although this may result in
lower performance.

NOTE: You can disable this warning by setting the MCA parameter
btl_base_warn_component_unused to 0.
--------------------------------------------------------------------------
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.542922 140026584057664 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.542981 140471982864192 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.542940 140298288346944 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.543064 140082604967744 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.543204 140517630531392 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.543415 139850373838656 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.543629 140647466776384 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1218 06:06:19.543682 140234342889280 lazy_loader.py:50] 
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 06:06:20.395624 140517630531392 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb274cf978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.396435 140517630531392 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "3"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb274cf978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcb274d90d0>) includes params argument, but params are not passed to Estimator.
W1218 06:06:20.397326 140517630531392 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcb274d90d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 06:06:20.397935 140517630531392 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1218 06:06:20.398037 140517630531392 run_pretraining.py:626]   Batch size = 64
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 06:06:20.401347 140082604967744 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f65ddc1e9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.402141 140082604967744 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "1"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f65ddc1e9e8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f65ddc280d0>) includes params argument, but params are not passed to Estimator.
W1218 06:06:20.403023 140082604967744 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f65ddc280d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 06:06:20.404829 140082604967744 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1218 06:06:20.404900 140082604967744 run_pretraining.py:626]   Batch size = 64
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 06:06:20.427829 140298288346944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98157cc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.428479 140298288346944 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "5"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f98157cc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f98157d70d0>) includes params argument, but params are not passed to Estimator.
W1218 06:06:20.429103 140298288346944 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f98157d70d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 06:06:20.429425 140298288346944 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1218 06:06:20.429486 140298288346944 run_pretraining.py:626]   Batch size = 64
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 06:06:20.442968 140026584057664 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f58d2a669b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.443587 140026584057664 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "4"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f58d2a669b0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f58d2a700d0>) includes params argument, but params are not passed to Estimator.
W1218 06:06:20.444214 140026584057664 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f58d2a700d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 06:06:20.444561 140026584057664 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:***** Configuaration *****
I1218 06:06:20.445079 140471982864192 run_pretraining.py:579] ***** Configuaration *****
INFO:tensorflow:  logtostderr: False
I1218 06:06:20.445473 140471982864192 run_pretraining.py:581]   logtostderr: False
INFO:tensorflow:  alsologtostderr: False
I1218 06:06:20.445558 140471982864192 run_pretraining.py:581]   alsologtostderr: False
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:  log_dir: 
I1218 06:06:20.445612 140471982864192 run_pretraining.py:581]   log_dir: 
W1218 06:06:20.445502 140647466776384 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:  Batch size = 64
INFO:tensorflow:  v: 0
I1218 06:06:20.445328 140026584057664 run_pretraining.py:626]   Batch size = 64
I1218 06:06:20.445662 140471982864192 run_pretraining.py:581]   v: 0
INFO:tensorflow:  verbosity: 0
I1218 06:06:20.445705 140471982864192 run_pretraining.py:581]   verbosity: 0
INFO:tensorflow:  stderrthreshold: fatal
I1218 06:06:20.445749 140471982864192 run_pretraining.py:581]   stderrthreshold: fatal
INFO:tensorflow:  showprefixforinfo: True
I1218 06:06:20.445807 140471982864192 run_pretraining.py:581]   showprefixforinfo: True
INFO:tensorflow:  run_with_pdb: False
I1218 06:06:20.445852 140471982864192 run_pretraining.py:581]   run_with_pdb: False
INFO:tensorflow:  pdb_post_mortem: False
I1218 06:06:20.445896 140471982864192 run_pretraining.py:581]   pdb_post_mortem: False
INFO:tensorflow:  run_with_profiling: False
I1218 06:06:20.445940 140471982864192 run_pretraining.py:581]   run_with_profiling: False
INFO:tensorflow:  profile_file: None
I1218 06:06:20.445986 140471982864192 run_pretraining.py:581]   profile_file: None
INFO:tensorflow:  use_cprofile_for_profiling: True
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

I1218 06:06:20.446031 140471982864192 run_pretraining.py:581]   use_cprofile_for_profiling: True
INFO:tensorflow:  only_check_args: False
I1218 06:06:20.446078 140471982864192 run_pretraining.py:581]   only_check_args: False
W1218 06:06:20.445936 139850373838656 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:  op_conversion_fallback_to_while_loop: False
I1218 06:06:20.446122 140471982864192 run_pretraining.py:581]   op_conversion_fallback_to_while_loop: False
INFO:tensorflow:  test_random_seed: 301
I1218 06:06:20.446174 140471982864192 run_pretraining.py:581]   test_random_seed: 301
INFO:tensorflow:  test_srcdir: 
I1218 06:06:20.446218 140471982864192 run_pretraining.py:581]   test_srcdir: 
INFO:tensorflow:  test_tmpdir: /tmp/absl_testing
I1218 06:06:20.446261 140471982864192 run_pretraining.py:581]   test_tmpdir: /tmp/absl_testing
INFO:tensorflow:  test_randomize_ordering_seed: 
I1218 06:06:20.446304 140471982864192 run_pretraining.py:581]   test_randomize_ordering_seed: 
INFO:tensorflow:  xml_output_file: 
I1218 06:06:20.446347 140471982864192 run_pretraining.py:581]   xml_output_file: 
INFO:tensorflow:  bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
I1218 06:06:20.446387 140471982864192 run_pretraining.py:581]   bert_config_file: data/download/nvidia_pretrained/bert_tf_squad11_base_128/bert_config.json
INFO:tensorflow:  input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

I1218 06:06:20.446432 140471982864192 run_pretraining.py:581]   input_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/training
INFO:tensorflow:  eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
W1218 06:06:20.446372 140234342889280 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe96224f978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.446477 140471982864192 run_pretraining.py:581]   eval_files_dir: data/tfrecord/lower_case_1_seq_len_128_max_pred_20_masked_lm_prob_0.15_random_seed_12345_dupe_factor_5_shard_1472_test_split_10/wikicorpus_en/test
INFO:tensorflow:  output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1
I1218 06:06:20.446066 140647466776384 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "2"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe96224f978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.446532 140471982864192 run_pretraining.py:581]   output_dir: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1
INFO:tensorflow:  dllog_path: /results/bert_dllog.json
I1218 06:06:20.446578 140471982864192 run_pretraining.py:581]   dllog_path: /results/bert_dllog.json
INFO:tensorflow:  init_checkpoint: None
I1218 06:06:20.446621 140471982864192 run_pretraining.py:581]   init_checkpoint: None
INFO:tensorflow:  optimizer_type: lamb
I1218 06:06:20.446665 140471982864192 run_pretraining.py:581]   optimizer_type: lamb
INFO:tensorflow:  max_seq_length: 128
I1218 06:06:20.446708 140471982864192 run_pretraining.py:581]   max_seq_length: 128
INFO:tensorflow:  max_predictions_per_seq: 20
I1218 06:06:20.446751 140471982864192 run_pretraining.py:581]   max_predictions_per_seq: 20
INFO:tensorflow:  do_train: True
I1218 06:06:20.446800 140471982864192 run_pretraining.py:581]   do_train: True
INFO:tensorflow:  do_eval: False
I1218 06:06:20.446844 140471982864192 run_pretraining.py:581]   do_eval: False
INFO:tensorflow:  train_batch_size: 64
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe9622590d0>) includes params argument, but params are not passed to Estimator.
I1218 06:06:20.446887 140471982864192 run_pretraining.py:581]   train_batch_size: 64
W1218 06:06:20.446659 140647466776384 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe9622590d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  eval_batch_size: 8
I1218 06:06:20.446931 140471982864192 run_pretraining.py:581]   eval_batch_size: 8
INFO:tensorflow:  learning_rate: 0.00075
I1218 06:06:20.446976 140471982864192 run_pretraining.py:581]   learning_rate: 0.00075
INFO:tensorflow:***** Running training *****
INFO:tensorflow:  num_train_steps: 90
I1218 06:06:20.447003 140647466776384 run_pretraining.py:625] ***** Running training *****
I1218 06:06:20.447020 140471982864192 run_pretraining.py:581]   num_train_steps: 90
INFO:tensorflow:  num_warmup_steps: 2000
I1218 06:06:20.447059 140471982864192 run_pretraining.py:581]   num_warmup_steps: 2000
INFO:tensorflow:  save_checkpoints_steps: 200
I1218 06:06:20.447102 140471982864192 run_pretraining.py:581]   save_checkpoints_steps: 200
INFO:tensorflow:  display_loss_steps: 1
I1218 06:06:20.447145 140471982864192 run_pretraining.py:581]   display_loss_steps: 1
INFO:tensorflow:  iterations_per_loop: 1000
I1218 06:06:20.447188 140471982864192 run_pretraining.py:581]   iterations_per_loop: 1000
INFO:tensorflow:  max_eval_steps: 100
I1218 06:06:20.447231 140471982864192 run_pretraining.py:581]   max_eval_steps: 100
INFO:tensorflow:  Batch size = 64
INFO:tensorflow:  num_accumulation_steps: 132
I1218 06:06:20.447274 140471982864192 run_pretraining.py:581]   num_accumulation_steps: 132
I1218 06:06:20.447058 140647466776384 run_pretraining.py:626]   Batch size = 64
INFO:tensorflow:  allreduce_post_accumulation: True
I1218 06:06:20.447317 140471982864192 run_pretraining.py:581]   allreduce_post_accumulation: True
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f89320aa978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  verbose_logging: False
I1218 06:06:20.447361 140471982864192 run_pretraining.py:581]   verbose_logging: False
I1218 06:06:20.446946 140234342889280 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "6"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f89320aa978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  horovod: True
I1218 06:06:20.447404 140471982864192 run_pretraining.py:581]   horovod: True
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2fcbb7c978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  report_loss: True
I1218 06:06:20.447448 140471982864192 run_pretraining.py:581]   report_loss: True
I1218 06:06:20.446767 139850373838656 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': None, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "7"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2fcbb7c978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
INFO:tensorflow:  manual_fp16: False
I1218 06:06:20.447491 140471982864192 run_pretraining.py:581]   manual_fp16: False
INFO:tensorflow:  amp: True
I1218 06:06:20.447543 140471982864192 run_pretraining.py:581]   amp: True
INFO:tensorflow:  use_xla: True
I1218 06:06:20.447587 140471982864192 run_pretraining.py:581]   use_xla: True
INFO:tensorflow:  init_loss_scale: 4294967296
I1218 06:06:20.447630 140471982864192 run_pretraining.py:581]   init_loss_scale: 4294967296
INFO:tensorflow:  ?: False
I1218 06:06:20.447675 140471982864192 run_pretraining.py:581]   ?: False
INFO:tensorflow:  help: False
I1218 06:06:20.447718 140471982864192 run_pretraining.py:581]   help: False
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f89320b40d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  helpshort: False
I1218 06:06:20.447768 140471982864192 run_pretraining.py:581]   helpshort: False
W1218 06:06:20.447515 140234342889280 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f89320b40d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  helpfull: False
I1218 06:06:20.447822 140471982864192 run_pretraining.py:581]   helpfull: False
INFO:tensorflow:  helpxml: False
I1218 06:06:20.447865 140471982864192 run_pretraining.py:581]   helpxml: False
INFO:tensorflow:***** Running training *****
INFO:tensorflow:**************************
I1218 06:06:20.447886 140234342889280 run_pretraining.py:625] ***** Running training *****
I1218 06:06:20.447908 140471982864192 run_pretraining.py:582] **************************
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1218 06:06:20.448054 140471982864192 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:589: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2fcbb860d0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:  Batch size = 64
W1218 06:06:20.447678 139850373838656 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f2fcbb860d0>) includes params argument, but params are not passed to Estimator.
I1218 06:06:20.447941 140234342889280 run_pretraining.py:626]   Batch size = 64
INFO:tensorflow:***** Running training *****
I1218 06:06:20.448278 139850373838656 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1218 06:06:20.448398 139850373838656 run_pretraining.py:626]   Batch size = 64
INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0867cc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1218 06:06:20.448512 140471982864192 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': gpu_options {
  visible_device_list: "0"
}
graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc0867cc978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc0867d61e0>) includes params argument, but params are not passed to Estimator.
W1218 06:06:20.449131 140471982864192 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fc0867d61e0>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1218 06:06:20.449499 140471982864192 run_pretraining.py:625] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1218 06:06:20.449578 140471982864192 run_pretraining.py:626]   Batch size = 64
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.503224 140082604967744 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.525665 140298288346944 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.530091 140517630531392 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.540719 140026584057664 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.542333 140647466776384 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.542988 140234342889280 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.546046 140471982864192 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1218 06:06:20.562698 139850373838656 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.606508 140082604967744 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.606694 140082604967744 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.606796 140082604967744 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.606890 140082604967744 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.606959 140082604967744 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.607024 140082604967744 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.607086 140082604967744 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.607147 140082604967744 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.607209 140082604967744 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.607390 140082604967744 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.608447 140082604967744 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.627879 140298288346944 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.628035 140298288346944 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.628125 140298288346944 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.628196 140298288346944 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.628261 140298288346944 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.628323 140298288346944 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.628383 140298288346944 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.628441 140298288346944 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.628498 140298288346944 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.628684 140298288346944 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.629663 140298288346944 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.632823 140517630531392 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.632986 140517630531392 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.633080 140517630531392 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.633152 140517630531392 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.633217 140517630531392 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.633279 140517630531392 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.633338 140517630531392 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.633395 140517630531392 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.633453 140517630531392 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.633638 140517630531392 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.634618 140517630531392 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.642354 140026584057664 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.642503 140026584057664 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.642609 140026584057664 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.642681 140026584057664 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.642745 140026584057664 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.642813 140026584057664 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.642875 140026584057664 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.642933 140026584057664 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.642990 140026584057664 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.643155 140026584057664 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.643824 140234342889280 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.643975 140234342889280 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.644064 140234342889280 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.644133 140234342889280 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.644196 140234342889280 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
W1218 06:06:20.644145 140026584057664 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.644252 140234342889280 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.644309 140234342889280 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.644366 140234342889280 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.644423 140234342889280 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
INFO:tensorflow:Calling model_fn.
I1218 06:06:20.644423 140647466776384 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

I1218 06:06:20.644586 140647466776384 run_pretraining.py:258] *** Features ***
W1218 06:06:20.644602 140234342889280 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.644675 140647466776384 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.644742 140647466776384 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.644809 140647466776384 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.644868 140647466776384 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.644924 140647466776384 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.644980 140647466776384 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.645035 140647466776384 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.645208 140647466776384 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.645585 140234342889280 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.646184 140647466776384 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.648131 140471982864192 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.648286 140471982864192 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.648377 140471982864192 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.648448 140471982864192 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.648512 140471982864192 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.648584 140471982864192 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.648643 140471982864192 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.648699 140471982864192 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.648757 140471982864192 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.648937 140471982864192 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.649930 140471982864192 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

INFO:tensorflow:Calling model_fn.
I1218 06:06:20.664387 139850373838656 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1218 06:06:20.664557 139850373838656 run_pretraining.py:258] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1218 06:06:20.664649 139850373838656 run_pretraining.py:260]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1218 06:06:20.664720 139850373838656 run_pretraining.py:260]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1218 06:06:20.664791 139850373838656 run_pretraining.py:260]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1218 06:06:20.664852 139850373838656 run_pretraining.py:260]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1218 06:06:20.664911 139850373838656 run_pretraining.py:260]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1218 06:06:20.664969 139850373838656 run_pretraining.py:260]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1218 06:06:20.665028 139850373838656 run_pretraining.py:260]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1218 06:06:20.665207 139850373838656 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1218 06:06:20.666210 139850373838656 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.172396 140298288346944 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.173161 140647466776384 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.176242 140517630531392 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
Initializing LAMB Optimizer
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.197997 140234342889280 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.209748 140471982864192 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.245125 139850373838656 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.271044 140082604967744 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1218 06:06:22.358572 140026584057664 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:296: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

decayed_learning_rate_at_crossover_point = 6.000000e-03, adjusted_init_lr = 6.000000e-03
Initializing LAMB Optimizer
WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.053067 140647466776384 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.081315 140517630531392 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.085309 140298288346944 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.148658 140471982864192 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.166450 140082604967744 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.199065 140234342889280 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.222435 139850373838656 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.269628 140647466776384 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.298480 140517630531392 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.302898 140298288346944 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.369988 140471982864192 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.384430 140082604967744 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1218 06:06:25.418679 140234342889280 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.418683 140026584057664 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.446069 139850373838656 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1218 06:06:25.647551 140026584057664 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.011069 140647466776384 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.153152 140517630531392 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.242231 140082604967744 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.323673 140471982864192 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1218 06:06:34.324942 140471982864192 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.344209 140298288346944 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.464473 140234342889280 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.516860 139850373838656 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Done calling model_fn.
I1218 06:06:34.826976 140026584057664 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Graph was finalized.
I1218 06:06:39.371414 140647466776384 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:39.383399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:39.387813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x53a6df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:39.387846: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:39.390843: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 06:06:39.629953 140517630531392 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:39.642557: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:39.646925: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x147314d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:39.646961: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:39.650027: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 06:06:39.674973 140082604967744 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:39.685870: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:39.690492: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4addb30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:39.690526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:39.693794: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 06:06:39.748726 140471982864192 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:39.760611: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:39.765373: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x148e6930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:39.765407: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:39.768399: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 06:06:39.807300 140298288346944 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:39.819315: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:39.825091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14717560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:39.825118: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:39.828095: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
INFO:tensorflow:Graph was finalized.
I1218 06:06:40.017501 139850373838656 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:40.029399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:40.033450: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4acc810 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.033485: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:40.036476: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 06:06:40.163227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.197769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x53aab20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.197807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.199339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.203854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.205656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:05:00.0
2021-12-18 06:06:40.205714: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.208964: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.210283: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56de910 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.210314: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.210324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.210691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.212275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.213339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.213984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.214215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.214340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.218057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:06:00.0
2021-12-18 06:06:40.218109: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.221185: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.221512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.222587: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.222963: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.225560: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.226200: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.226437: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.226579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.227502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 2
2021-12-18 06:06:40.227561: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.235385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.243691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 3
2021-12-18 06:06:40.243767: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.415026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
INFO:tensorflow:Graph was finalized.
I1218 06:06:40.419236 140026584057664 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:40.420588: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17d4cd30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.420626: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.422408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.428938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:04:00.0
2021-12-18 06:06:40.428993: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.431815: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:40.432347: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.433763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.434152: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.436824: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.437374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.437588: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.437745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.437866: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7a146f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.437905: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:40.441046: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 06:06:40.444250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.483264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 1
2021-12-18 06:06:40.483345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.565503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.572030: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x149e2020 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.572058: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.572991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.578589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:03:00.0
2021-12-18 06:06:40.578631: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.581695: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.583016: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.583365: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.586071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.586648: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.586857: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.587004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.591488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.596580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2021-12-18 06:06:40.596624: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.623331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.630446: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d343e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.630481: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.632869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.640283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:08:00.0
2021-12-18 06:06:40.640339: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.643567: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.645035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.645374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.647989: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.648590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.648788: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.648942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.656654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.661144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 5
2021-12-18 06:06:40.661194: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.749336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.753867: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x179b0000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.753922: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.754811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.759573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:0a:00.0
2021-12-18 06:06:40.759625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.762852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.764238: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.764617: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.767254: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.767828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.768055: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.768217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.772629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.777041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 7
2021-12-18 06:06:40.777088: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.819275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:40.819316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      2 
2021-12-18 06:06:40.819327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 2:   N 
2021-12-18 06:06:40.819672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.823360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.827056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:05:00.0, compute capability: 7.0)
2021-12-18 06:06:40.841921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:40.841971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      3 
2021-12-18 06:06:40.841981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 3:   N 
2021-12-18 06:06:40.851083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.855017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.859420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0)
2021-12-18 06:06:40.911903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.914822: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fa0b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:40.914863: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:40.915569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.917588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:07:00.0
2021-12-18 06:06:40.917643: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:40.921164: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:40.922696: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:40.923083: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:40.926223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:40.926948: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:40.927180: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:40.927353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.929452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:40.932230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 4
2021-12-18 06:06:40.932278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:41.007226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:41.007286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      1 
2021-12-18 06:06:41.007297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 1:   N 
2021-12-18 06:06:41.007666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.010068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.012349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)
2021-12-18 06:06:41.085029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:41.085075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2021-12-18 06:06:41.085084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2021-12-18 06:06:41.085364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.087497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.090021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:03:00.0, compute capability: 7.0)
2021-12-18 06:06:41.139440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:41.139495: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      5 
2021-12-18 06:06:41.139506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 5:   N 
2021-12-18 06:06:41.139841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.142225: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.144227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 5, name: Tesla V100-SXM2-32GB, pci bus id: 0000:08:00.0, compute capability: 7.0)
2021-12-18 06:06:41.196879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:41.196939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      7 
2021-12-18 06:06:41.196949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 7:   N 
2021-12-18 06:06:41.197294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.199428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.201413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 7, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0)
INFO:tensorflow:Graph was finalized.
I1218 06:06:41.283142 140234342889280 monitored_session.py:240] Graph was finalized.
2021-12-18 06:06:41.297533: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599995000 Hz
2021-12-18 06:06:41.303165: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x83d8630 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:41.303236: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2021-12-18 06:06:41.306748: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2021-12-18 06:06:41.347237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:41.347278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      4 
2021-12-18 06:06:41.347289: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 4:   N 
2021-12-18 06:06:41.347697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.350416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.353417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 4, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0)
2021-12-18 06:06:41.503554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.506042: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4ffaab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2021-12-18 06:06:41.506096: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2021-12-18 06:06:41.506930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.509115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:09:00.0
2021-12-18 06:06:41.509166: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:41.512701: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:06:41.514270: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2021-12-18 06:06:41.515710: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2021-12-18 06:06:41.519006: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2021-12-18 06:06:41.519717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2021-12-18 06:06:41.519973: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:06:41.520157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.522351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.524402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 6
2021-12-18 06:06:41.524447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2021-12-18 06:06:41.953651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-12-18 06:06:41.953696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      6 
2021-12-18 06:06:41.953706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 6:   N 
2021-12-18 06:06:41.954017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.956294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-12-18 06:06:41.958354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30166 MB memory) -> physical GPU (device: 6, name: Tesla V100-SXM2-32GB, pci bus id: 0000:09:00.0, compute capability: 7.0)
2021-12-18 06:06:44.260483: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:44.276696: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:44.293792: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:44.309962: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:44.603345: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:44.618381: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:44.622424: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:44.638617: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:44.684454: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:44.702504: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:44.944967: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:44.960901: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:44.999892: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:45.014305: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:45.863149: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:45.880929: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:46.868458: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:46.902749: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:47.207415: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:47.297873: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:47.547944: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:47.588716: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:47.775980: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:48.694896: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2021-12-18 06:06:50.732233: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:50.739304: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:50.881087: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:50.887703: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:50.997856: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:51.004741: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:51.103379: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:51.110332: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1218 06:06:51.458059 140517630531392 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 06:06:51.579776 140647466776384 session_manager.py:500] Running local_init_op.
2021-12-18 06:06:51.615009: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:51.621879: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:51.663399: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:51.670241: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1218 06:06:51.681595 140298288346944 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 06:06:51.798655 140082604967744 session_manager.py:500] Running local_init_op.
2021-12-18 06:06:51.808777: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:51.815968: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:51.964771: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:51.965016: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:52.084991: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.085217: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 06:06:52.094660 140517630531392 session_manager.py:502] Done running local_init_op.
2021-12-18 06:06:52.188289: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.188554: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 06:06:52.210270 140647466776384 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 06:06:52.306252 140471982864192 session_manager.py:500] Running local_init_op.
2021-12-18 06:06:52.309312: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.309559: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 06:06:52.316922 140298288346944 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 06:06:52.346796 140026584057664 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 06:06:52.436513 140082604967744 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 06:06:52.545449 139850373838656 session_manager.py:500] Running local_init_op.
2021-12-18 06:06:52.560636: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.567452: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:52.752779: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.759773: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:52.816269: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.816495: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:52.857437: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.857689: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:52.867505: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.874574: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:52.968188: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:52.974937: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 06:06:52.979628 140026584057664 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1218 06:06:52.980410 140471982864192 session_manager.py:502] Done running local_init_op.
2021-12-18 06:06:53.087974: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.088221: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.094991: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.102000: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 06:06:53.217467 139850373838656 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Running local_init_op.
I1218 06:06:53.257510 140234342889280 session_manager.py:500] Running local_init_op.
2021-12-18 06:06:53.608325: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.615041: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.758727: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.758948: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.852802: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.859861: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1218 06:06:53.886831 140234342889280 session_manager.py:502] Done running local_init_op.
2021-12-18 06:06:53.887985: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.895059: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.961770: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:53.962134: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.966787: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.968627: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:53.971131: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.053629: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.053976: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.058593: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.060487: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.063086: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.148859: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.149227: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.153890: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.155787: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.158370: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.298315: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.298676: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.303194: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.305054: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.307621: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.549333: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.556150: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.830152: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.830492: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.835028: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.836887: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.839456: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.902686: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.919464: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:54.972395: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:54.986666: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.101891: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:55.117882: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.197226: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:55.197625: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.202836: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.204992: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.207835: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.264081: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:55.264626: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:55.264927: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.281390: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.740477: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:55.754621: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.772538: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:55.772887: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.777450: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.779245: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:55.781784: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:56.228481: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:56.244114: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:06:56.836535: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:06:56.850234: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1/model.ckpt.
I1218 06:07:06.069183 140471982864192 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1/model.ckpt.
2021-12-18 06:07:06.991913: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:06.999931: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:07:13.700126: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:13.700665: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:07:13.705816: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:07:13.707733: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:07:13.710384: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:07:14.739451: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:14.752486: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1218 06:07:17.471797 140471982864192 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:147: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2021-12-18 06:07:18.076413: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:18.076719: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:07:29.378719: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:29.565780: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:31.031013: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:31.142241: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:31.189148: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:31.218768: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:31.237286: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:31.331311: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:31.369609: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:31.424313: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:31.462204: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:31.617187: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:31.641815: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:31.806536: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:32.288012: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:07:32.440238: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:07:39.878333: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:40.463539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:41.992809: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:42.195987: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:42.645358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:42.681210: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:42.709909: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:42.746613: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:42.840629: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:43.345344: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:43.391949: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:43.403277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:43.538638: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:44.140499: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:07:44.300943: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2021-12-18 06:07:44.913199: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2021-12-18 06:08:10.297827: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:12.817436: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:13.288450: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:14.180562: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:14.437926: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:14.729423: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:14.964533: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2021-12-18 06:08:16.465065: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.096929, step = 0
I1218 06:08:18.452924 140471982864192 basic_session_run_hooks.py:262] loss = 11.096929, step = 0
2021-12-18 06:08:19.133154: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.133499: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:08:19.145249: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.145223: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.145560: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:08:19.145559: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:08:19.145747: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.146031: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:08:19.151869: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.152163: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:08:19.172688: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.172982: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2021-12-18 06:08:19.212785: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:19.213117: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:loss = 11.135113, step = 0
I1218 06:08:19.296959 139850373838656 basic_session_run_hooks.py:262] loss = 11.135113, step = 0
INFO:tensorflow:loss = 11.170155, step = 0
I1218 06:08:19.303121 140234342889280 basic_session_run_hooks.py:262] loss = 11.170155, step = 0
INFO:tensorflow:loss = 11.13018, step = 0
I1218 06:08:19.303614 140647466776384 basic_session_run_hooks.py:262] loss = 11.13018, step = 0
INFO:tensorflow:loss = 11.166478, step = 0
I1218 06:08:19.312387 140026584057664 basic_session_run_hooks.py:262] loss = 11.166478, step = 0
INFO:tensorflow:loss = 11.13744, step = 0
I1218 06:08:19.318685 140517630531392 basic_session_run_hooks.py:262] loss = 11.13744, step = 0
INFO:tensorflow:loss = 11.112404, step = 0
I1218 06:08:19.335918 140298288346944 basic_session_run_hooks.py:262] loss = 11.112404, step = 0
INFO:tensorflow:loss = 11.13326, step = 0
I1218 06:08:19.377557 140082604967744 basic_session_run_hooks.py:262] loss = 11.13326, step = 0
2021-12-18 06:08:33.305145: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:33.309313: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:33.427470: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:33.436179: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:33.451601: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:33.485370: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:33.489278: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:33.499275: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:33.608956: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:33.614322: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:33.636080: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:33.680231: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:34.103253: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:34.289079: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2021-12-18 06:08:34.565658: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:08:34.708016: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25557
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4426

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.217443 140298288346944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.217602 139850373838656 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.217766 140647466776384 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.217949 140082604967744 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.218191 140234342889280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.220654 140026584057664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:16.713244 140517630531392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.611307 140471982864192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.745972 140026584057664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.745985 140517630531392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.745995 140234342889280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.745984 140298288346944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.745975 139850373838656 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.746171 140082604967744 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.746250 140647466776384 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.750772 140471982864192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.877664 139850373838656 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.877680 140517630531392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.879287 140298288346944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.879825 140234342889280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.880087 140026584057664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.881465 140647466776384 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.883003 140471982864192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:17.883020 140082604967744 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.018579 140517630531392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.019217 140082604967744 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.019276 139850373838656 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.019288 140471982864192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.019367 140234342889280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.020433 140647466776384 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.021038 140298288346944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.030346 140026584057664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.161733 140298288346944 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.161772 139850373838656 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.161769 140647466776384 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.161752 140234342889280 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.161794 140082604967744 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.161893 140517630531392 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.162272 140471982864192 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1218 06:09:18.163964 140026584057664 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:09:42.980555 - Iteration: 1  throughput_train : 467.052 seq/s mlm_loss : 10.4451  nsp_loss : 0.6805  total_loss : 11.1256  avg_loss_step : 11.1321  learning_rate : 0.0  loss_scaler : 4294967296 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:10:00.727046 - Iteration: 1  throughput_train : 3813.191 seq/s mlm_loss : 10.4348  nsp_loss : 0.7085  total_loss : 11.1433  avg_loss_step : 11.1330  learning_rate : 0.0  loss_scaler : 2147483648 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:10:18.423406 - Iteration: 1  throughput_train : 3823.910 seq/s mlm_loss : 10.4365  nsp_loss : 0.6950  total_loss : 11.1315  avg_loss_step : 11.1305  learning_rate : 0.0  loss_scaler : 1073741824 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:10:36.120696 - Iteration: 1  throughput_train : 3824.022 seq/s mlm_loss : 10.4239  nsp_loss : 0.6891  total_loss : 11.1129  avg_loss_step : 11.1326  learning_rate : 0.0  loss_scaler : 536870912 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:10:53.892893 - Iteration: 1  throughput_train : 3807.323 seq/s mlm_loss : 10.4408  nsp_loss : 0.6913  total_loss : 11.1321  avg_loss_step : 11.1340  learning_rate : 0.0  loss_scaler : 268435456 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:11:11.685046 - Iteration: 1  throughput_train : 3802.792 seq/s mlm_loss : 10.4719  nsp_loss : 0.6911  total_loss : 11.1629  avg_loss_step : 11.1351  learning_rate : 0.0  loss_scaler : 134217728 
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:11:59.404185 - Iteration: 1  throughput_train : 1416.947 seq/s mlm_loss : 10.4150  nsp_loss : 0.6965  total_loss : 11.1115  avg_loss_step : 11.1324  learning_rate : 0.0  loss_scaler : 67108864 
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:12:21.761082 - Iteration: 2  throughput_train : 3026.022 seq/s mlm_loss : 10.4327  nsp_loss : 0.7196  total_loss : 11.1523  avg_loss_step : 11.1289  learning_rate : 0.0  loss_scaler : 33554432 
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:13:06.867622 - Iteration: 3  throughput_train : 1499.047 seq/s mlm_loss : 10.4395  nsp_loss : 0.6915  total_loss : 11.1310  avg_loss_step : 11.1307  learning_rate : 3e-06  loss_scaler : 16777216 
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:13:26.871990 - Iteration: 4  throughput_train : 3381.961 seq/s mlm_loss : 10.4288  nsp_loss : 0.6937  total_loss : 11.1225  avg_loss_step : 11.1319  learning_rate : 6e-06  loss_scaler : 16777216 
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:13:44.831337 - Iteration: 5  throughput_train : 3767.264 seq/s mlm_loss : 10.4102  nsp_loss : 0.6779  total_loss : 11.0881  avg_loss_step : 11.1315  learning_rate : 9e-06  loss_scaler : 16777216 
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2021-12-18 06:14:02.774871 - Iteration: 6  throughput_train : 3770.783 seq/s mlm_loss : 10.4485  nsp_loss : 0.6849  total_loss : 11.1335  avg_loss_step : 11.1297  learning_rate : 1.2e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:14:20.763738 - Iteration: 7  throughput_train : 3761.124 seq/s mlm_loss : 10.4318  nsp_loss : 0.6881  total_loss : 11.1200  avg_loss_step : 11.1203  learning_rate : 1.50000005e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:14:38.673796 - Iteration: 8  throughput_train : 3777.780 seq/s mlm_loss : 10.4144  nsp_loss : 0.6942  total_loss : 11.1086  avg_loss_step : 11.1206  learning_rate : 1.8e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:14:56.587196 - Iteration: 9  throughput_train : 3777.200 seq/s mlm_loss : 10.4359  nsp_loss : 0.6939  total_loss : 11.1297  avg_loss_step : 11.1055  learning_rate : 2.1e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:15:14.525695 - Iteration: 10  throughput_train : 3771.720 seq/s mlm_loss : 10.3933  nsp_loss : 0.6956  total_loss : 11.0889  avg_loss_step : 11.1018  learning_rate : 2.4e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:15:32.343652 - Iteration: 11  throughput_train : 3797.148 seq/s mlm_loss : 10.4122  nsp_loss : 0.6820  total_loss : 11.0942  avg_loss_step : 11.0972  learning_rate : 2.7000002e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:15:50.199460 - Iteration: 12  throughput_train : 3789.169 seq/s mlm_loss : 10.3819  nsp_loss : 0.6783  total_loss : 11.0602  avg_loss_step : 11.0879  learning_rate : 3.0000001e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:16:08.125993 - Iteration: 13  throughput_train : 3774.145 seq/s mlm_loss : 10.3633  nsp_loss : 0.6803  total_loss : 11.0436  avg_loss_step : 11.0783  learning_rate : 3.3e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:16:26.083034 - Iteration: 14  throughput_train : 3768.217 seq/s mlm_loss : 10.3816  nsp_loss : 0.7044  total_loss : 11.0861  avg_loss_step : 11.0617  learning_rate : 3.6e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:16:43.921537 - Iteration: 15  throughput_train : 3792.676 seq/s mlm_loss : 10.3998  nsp_loss : 0.6933  total_loss : 11.0931  avg_loss_step : 11.0510  learning_rate : 3.9000002e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:17:01.855562 - Iteration: 16  throughput_train : 3772.586 seq/s mlm_loss : 10.3676  nsp_loss : 0.6796  total_loss : 11.0473  avg_loss_step : 11.0423  learning_rate : 4.2e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:17:19.827324 - Iteration: 17  throughput_train : 3764.715 seq/s mlm_loss : 10.3372  nsp_loss : 0.6849  total_loss : 11.0221  avg_loss_step : 11.0268  learning_rate : 4.5e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:17:37.651420 - Iteration: 18  throughput_train : 3796.001 seq/s mlm_loss : 10.3179  nsp_loss : 0.6906  total_loss : 11.0085  avg_loss_step : 11.0153  learning_rate : 4.8e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:17:55.519754 - Iteration: 19  throughput_train : 3786.505 seq/s mlm_loss : 10.3134  nsp_loss : 0.6821  total_loss : 10.9955  avg_loss_step : 11.0017  learning_rate : 5.1000003e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:18:13.417919 - Iteration: 20  throughput_train : 3780.520 seq/s mlm_loss : 10.3145  nsp_loss : 0.6995  total_loss : 11.0140  avg_loss_step : 10.9800  learning_rate : 5.4000004e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:18:31.249108 - Iteration: 21  throughput_train : 3794.396 seq/s mlm_loss : 10.3051  nsp_loss : 0.6893  total_loss : 10.9944  avg_loss_step : 10.9642  learning_rate : 5.7e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:18:49.133109 - Iteration: 22  throughput_train : 3783.044 seq/s mlm_loss : 10.2510  nsp_loss : 0.7209  total_loss : 10.9719  avg_loss_step : 10.9436  learning_rate : 6.0000002e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:19:07.029903 - Iteration: 23  throughput_train : 3780.492 seq/s mlm_loss : 10.2488  nsp_loss : 0.6870  total_loss : 10.9358  avg_loss_step : 10.9305  learning_rate : 6.3e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:19:24.904959 - Iteration: 24  throughput_train : 3785.098 seq/s mlm_loss : 10.1793  nsp_loss : 0.6862  total_loss : 10.8656  avg_loss_step : 10.9089  learning_rate : 6.6e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:19:42.800992 - Iteration: 25  throughput_train : 3780.851 seq/s mlm_loss : 10.1683  nsp_loss : 0.7205  total_loss : 10.8889  avg_loss_step : 10.8916  learning_rate : 6.9e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:20:00.687699 - Iteration: 26  throughput_train : 3783.683 seq/s mlm_loss : 10.1948  nsp_loss : 0.7176  total_loss : 10.9124  avg_loss_step : 10.8609  learning_rate : 7.2e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:20:18.579297 - Iteration: 27  throughput_train : 3782.014 seq/s mlm_loss : 10.1872  nsp_loss : 0.6699  total_loss : 10.8571  avg_loss_step : 10.8453  learning_rate : 7.5e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:20:36.401144 - Iteration: 28  throughput_train : 3796.392 seq/s mlm_loss : 10.1379  nsp_loss : 0.6961  total_loss : 10.8340  avg_loss_step : 10.8211  learning_rate : 7.8000005e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:20:54.209374 - Iteration: 29  throughput_train : 3799.438 seq/s mlm_loss : 10.0985  nsp_loss : 0.6720  total_loss : 10.7705  avg_loss_step : 10.7918  learning_rate : 8.1000006e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:21:12.099542 - Iteration: 30  throughput_train : 3781.937 seq/s mlm_loss : 10.0798  nsp_loss : 0.6824  total_loss : 10.7622  avg_loss_step : 10.7723  learning_rate : 8.4e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:21:29.966155 - Iteration: 31  throughput_train : 3786.981 seq/s mlm_loss : 10.0321  nsp_loss : 0.6794  total_loss : 10.7115  avg_loss_step : 10.7528  learning_rate : 8.7e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:21:47.860090 - Iteration: 32  throughput_train : 3781.156 seq/s mlm_loss : 10.0284  nsp_loss : 0.6968  total_loss : 10.7252  avg_loss_step : 10.7317  learning_rate : 9e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:22:05.693661 - Iteration: 33  throughput_train : 3793.888 seq/s mlm_loss : 10.0518  nsp_loss : 0.6624  total_loss : 10.7142  avg_loss_step : 10.7020  learning_rate : 9.3e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:22:23.571550 - Iteration: 34  throughput_train : 3784.637 seq/s mlm_loss : 10.0102  nsp_loss : 0.6695  total_loss : 10.6796  avg_loss_step : 10.6833  learning_rate : 9.6e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:22:41.430818 - Iteration: 35  throughput_train : 3788.470 seq/s mlm_loss : 9.9344  nsp_loss : 0.6754  total_loss : 10.6098  avg_loss_step : 10.6602  learning_rate : 9.9000004e-05  loss_scaler : 16777216 
DLL 2021-12-18 06:22:59.276494 - Iteration: 36  throughput_train : 3791.361 seq/s mlm_loss : 9.9597  nsp_loss : 0.6465  total_loss : 10.6062  avg_loss_step : 10.6368  learning_rate : 0.000102000005  loss_scaler : 16777216 
DLL 2021-12-18 06:23:17.229503 - Iteration: 37  throughput_train : 3769.154 seq/s mlm_loss : 9.9485  nsp_loss : 0.6659  total_loss : 10.6143  avg_loss_step : 10.6122  learning_rate : 0.00010500001  loss_scaler : 16777216 
DLL 2021-12-18 06:23:35.084393 - Iteration: 38  throughput_train : 3789.820 seq/s mlm_loss : 9.9019  nsp_loss : 0.7002  total_loss : 10.6021  avg_loss_step : 10.5790  learning_rate : 0.00010800001  loss_scaler : 16777216 
DLL 2021-12-18 06:23:52.919306 - Iteration: 39  throughput_train : 3794.308 seq/s mlm_loss : 9.8654  nsp_loss : 0.6696  total_loss : 10.5351  avg_loss_step : 10.5565  learning_rate : 0.000111  loss_scaler : 16777216 
DLL 2021-12-18 06:24:10.825932 - Iteration: 40  throughput_train : 3778.650 seq/s mlm_loss : 9.8824  nsp_loss : 0.6372  total_loss : 10.5196  avg_loss_step : 10.5462  learning_rate : 0.000114  loss_scaler : 16777216 
DLL 2021-12-18 06:24:28.687668 - Iteration: 41  throughput_train : 3788.276 seq/s mlm_loss : 9.8662  nsp_loss : 0.7104  total_loss : 10.5766  avg_loss_step : 10.5131  learning_rate : 0.000117  loss_scaler : 16777216 
DLL 2021-12-18 06:24:46.511088 - Iteration: 42  throughput_train : 3796.290 seq/s mlm_loss : 9.8004  nsp_loss : 0.6582  total_loss : 10.4586  avg_loss_step : 10.4865  learning_rate : 0.000120000004  loss_scaler : 16777216 
DLL 2021-12-18 06:25:04.357761 - Iteration: 43  throughput_train : 3791.323 seq/s mlm_loss : 9.7648  nsp_loss : 0.6427  total_loss : 10.4075  avg_loss_step : 10.4725  learning_rate : 0.000123  loss_scaler : 16777216 
DLL 2021-12-18 06:25:22.283355 - Iteration: 44  throughput_train : 3775.282 seq/s mlm_loss : 9.7172  nsp_loss : 0.6749  total_loss : 10.3921  avg_loss_step : 10.4459  learning_rate : 0.000126  loss_scaler : 16777216 
DLL 2021-12-18 06:25:40.086999 - Iteration: 45  throughput_train : 3800.719 seq/s mlm_loss : 9.7204  nsp_loss : 0.6541  total_loss : 10.3745  avg_loss_step : 10.4153  learning_rate : 0.00012900001  loss_scaler : 16777216 
DLL 2021-12-18 06:25:57.928512 - Iteration: 46  throughput_train : 3792.650 seq/s mlm_loss : 9.6949  nsp_loss : 0.7102  total_loss : 10.4051  avg_loss_step : 10.3982  learning_rate : 0.000132  loss_scaler : 16777216 
DLL 2021-12-18 06:26:15.829173 - Iteration: 47  throughput_train : 3780.233 seq/s mlm_loss : 9.6440  nsp_loss : 0.7118  total_loss : 10.3558  avg_loss_step : 10.3735  learning_rate : 0.00013500001  loss_scaler : 16777216 
DLL 2021-12-18 06:26:33.646403 - Iteration: 48  throughput_train : 3797.612 seq/s mlm_loss : 9.6540  nsp_loss : 0.6946  total_loss : 10.3486  avg_loss_step : 10.3608  learning_rate : 0.000138  loss_scaler : 16777216 
DLL 2021-12-18 06:26:51.455861 - Iteration: 49  throughput_train : 3799.066 seq/s mlm_loss : 9.5902  nsp_loss : 0.7011  total_loss : 10.2913  avg_loss_step : 10.3390  learning_rate : 0.00014100001  loss_scaler : 16777216 
DLL 2021-12-18 06:27:09.346310 - Iteration: 50  throughput_train : 3781.514 seq/s mlm_loss : 9.5974  nsp_loss : 0.6755  total_loss : 10.2729  avg_loss_step : 10.3124  learning_rate : 0.000144  loss_scaler : 16777216 
DLL 2021-12-18 06:27:27.280861 - Iteration: 51  throughput_train : 3772.375 seq/s mlm_loss : 9.5749  nsp_loss : 0.6846  total_loss : 10.2595  avg_loss_step : 10.2930  learning_rate : 0.000147  loss_scaler : 16777216 
DLL 2021-12-18 06:27:45.137503 - Iteration: 52  throughput_train : 3788.727 seq/s mlm_loss : 9.5277  nsp_loss : 0.6501  total_loss : 10.1779  avg_loss_step : 10.2518  learning_rate : 0.00015  loss_scaler : 16777216 
DLL 2021-12-18 06:28:03.013612 - Iteration: 53  throughput_train : 3784.795 seq/s mlm_loss : 9.6593  nsp_loss : 0.7009  total_loss : 10.3602  avg_loss_step : 10.2424  learning_rate : 0.000153  loss_scaler : 16777216 
DLL 2021-12-18 06:28:20.889118 - Iteration: 54  throughput_train : 3784.914 seq/s mlm_loss : 9.4936  nsp_loss : 0.6717  total_loss : 10.1652  avg_loss_step : 10.2308  learning_rate : 0.00015600001  loss_scaler : 16777216 
DLL 2021-12-18 06:28:38.639060 - Iteration: 55  throughput_train : 3811.348 seq/s mlm_loss : 9.4537  nsp_loss : 0.6724  total_loss : 10.1262  avg_loss_step : 10.2060  learning_rate : 0.000159  loss_scaler : 16777216 
DLL 2021-12-18 06:28:56.472128 - Iteration: 56  throughput_train : 3793.805 seq/s mlm_loss : 9.5483  nsp_loss : 0.6874  total_loss : 10.2357  avg_loss_step : 10.1937  learning_rate : 0.00016200001  loss_scaler : 16777216 
DLL 2021-12-18 06:29:14.377593 - Iteration: 57  throughput_train : 3778.291 seq/s mlm_loss : 9.4313  nsp_loss : 0.6920  total_loss : 10.1234  avg_loss_step : 10.1652  learning_rate : 0.000165  loss_scaler : 16777216 
DLL 2021-12-18 06:29:32.239953 - Iteration: 58  throughput_train : 3787.554 seq/s mlm_loss : 9.4705  nsp_loss : 0.6434  total_loss : 10.1139  avg_loss_step : 10.1480  learning_rate : 0.000168  loss_scaler : 16777216 
DLL 2021-12-18 06:29:50.044300 - Iteration: 59  throughput_train : 3799.928 seq/s mlm_loss : 9.3868  nsp_loss : 0.6771  total_loss : 10.0639  avg_loss_step : 10.1406  learning_rate : 0.000171  loss_scaler : 16777216 
DLL 2021-12-18 06:30:07.881628 - Iteration: 60  throughput_train : 3792.895 seq/s mlm_loss : 9.4981  nsp_loss : 0.7098  total_loss : 10.2079  avg_loss_step : 10.1196  learning_rate : 0.000174  loss_scaler : 16777216 
DLL 2021-12-18 06:30:25.725190 - Iteration: 61  throughput_train : 3791.355 seq/s mlm_loss : 9.3997  nsp_loss : 0.6634  total_loss : 10.0631  avg_loss_step : 10.1023  learning_rate : 0.00017700001  loss_scaler : 16777216 
DLL 2021-12-18 06:30:43.628532 - Iteration: 62  throughput_train : 3778.698 seq/s mlm_loss : 9.4545  nsp_loss : 0.6766  total_loss : 10.1310  avg_loss_step : 10.0808  learning_rate : 0.00018  loss_scaler : 16777216 
DLL 2021-12-18 06:31:01.418518 - Iteration: 63  throughput_train : 3803.239 seq/s mlm_loss : 9.3092  nsp_loss : 0.7172  total_loss : 10.0264  avg_loss_step : 10.0688  learning_rate : 0.00018300001  loss_scaler : 16777216 
DLL 2021-12-18 06:31:19.287609 - Iteration: 64  throughput_train : 3786.077 seq/s mlm_loss : 9.4626  nsp_loss : 0.6944  total_loss : 10.1571  avg_loss_step : 10.0438  learning_rate : 0.000186  loss_scaler : 16777216 
DLL 2021-12-18 06:31:37.145276 - Iteration: 65  throughput_train : 3788.362 seq/s mlm_loss : 9.2954  nsp_loss : 0.7333  total_loss : 10.0287  avg_loss_step : 10.0448  learning_rate : 0.00018900001  loss_scaler : 16777216 
DLL 2021-12-18 06:31:55.002881 - Iteration: 66  throughput_train : 3788.366 seq/s mlm_loss : 9.3086  nsp_loss : 0.6798  total_loss : 9.9883  avg_loss_step : 10.0093  learning_rate : 0.000192  loss_scaler : 16777216 
DLL 2021-12-18 06:32:13.001662 - Iteration: 67  throughput_train : 3758.687 seq/s mlm_loss : 9.2966  nsp_loss : 0.7026  total_loss : 9.9992  avg_loss_step : 10.0030  learning_rate : 0.000195  loss_scaler : 16777216 
DLL 2021-12-18 06:32:30.832934 - Iteration: 68  throughput_train : 3793.931 seq/s mlm_loss : 9.3482  nsp_loss : 0.6533  total_loss : 10.0015  avg_loss_step : 9.9868  learning_rate : 0.00019800001  loss_scaler : 16777216 
DLL 2021-12-18 06:32:48.704799 - Iteration: 69  throughput_train : 3786.442 seq/s mlm_loss : 9.2196  nsp_loss : 0.6663  total_loss : 9.8859  avg_loss_step : 9.9699  learning_rate : 0.000201  loss_scaler : 16777216 
2021-12-18 06:33:15.710539: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2021-12-18 06:33:15.862273: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 25559
Recognized nodes available for conversion: 15870
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:loss = 9.920067, step = 68 (1535.287 sec)
I1218 06:33:54.622445 140298288346944 basic_session_run_hooks.py:260] loss = 9.920067, step = 68 (1535.287 sec)
INFO:tensorflow:loss = 9.970766, step = 68 (1535.326 sec)
INFO:tensorflow:loss = 9.857709, step = 68 (1535.304 sec)
INFO:tensorflow:loss = 10.038488, step = 68 (1535.319 sec)
I1218 06:33:54.622817 139850373838656 basic_session_run_hooks.py:260] loss = 9.970766, step = 68 (1535.326 sec)
I1218 06:33:54.623030 140517630531392 basic_session_run_hooks.py:260] loss = 9.857709, step = 68 (1535.304 sec)
I1218 06:33:54.623027 140647466776384 basic_session_run_hooks.py:260] loss = 10.038488, step = 68 (1535.319 sec)
INFO:tensorflow:loss = 9.895681, step = 68 (1535.321 sec)
INFO:tensorflow:loss = 9.915396, step = 68 (1535.246 sec)
INFO:tensorflow:loss = 9.960357, step = 68 (1535.311 sec)
I1218 06:33:54.623411 140082604967744 basic_session_run_hooks.py:260] loss = 9.915396, step = 68 (1535.246 sec)
I1218 06:33:54.623335 140234342889280 basic_session_run_hooks.py:260] loss = 9.895681, step = 68 (1535.321 sec)
I1218 06:33:54.623326 140026584057664 basic_session_run_hooks.py:260] loss = 9.960357, step = 68 (1535.311 sec)
INFO:tensorflow:loss = 9.962108, step = 68 (1540.514 sec)
I1218 06:33:58.967202 140471982864192 basic_session_run_hooks.py:260] loss = 9.962108, step = 68 (1540.514 sec)
DLL 2021-12-18 06:34:03.168988 - Iteration: 70  throughput_train : 907.841 seq/s mlm_loss : 9.3534  nsp_loss : 0.7137  total_loss : 10.0671  avg_loss_step : 9.9620  learning_rate : 0.00020400001  loss_scaler : 16777216 
DLL 2021-12-18 06:34:20.957613 - Iteration: 71  throughput_train : 3803.174 seq/s mlm_loss : 9.3146  nsp_loss : 0.6930  total_loss : 10.0076  avg_loss_step : 9.9509  learning_rate : 0.000207  loss_scaler : 16777216 
DLL 2021-12-18 06:34:38.770053 - Iteration: 72  throughput_train : 3798.077 seq/s mlm_loss : 9.3217  nsp_loss : 0.6982  total_loss : 10.0199  avg_loss_step : 9.9478  learning_rate : 0.00021000001  loss_scaler : 16777216 
DLL 2021-12-18 06:34:56.554451 - Iteration: 73  throughput_train : 3804.142 seq/s mlm_loss : 9.3085  nsp_loss : 0.6841  total_loss : 9.9926  avg_loss_step : 9.9257  learning_rate : 0.000213  loss_scaler : 16777216 
DLL 2021-12-18 06:35:14.390872 - Iteration: 74  throughput_train : 3793.281 seq/s mlm_loss : 9.1578  nsp_loss : 0.6636  total_loss : 9.8214  avg_loss_step : 9.9176  learning_rate : 0.00021600001  loss_scaler : 16777216 
DLL 2021-12-18 06:35:32.196983 - Iteration: 75  throughput_train : 3799.488 seq/s mlm_loss : 9.2651  nsp_loss : 0.6745  total_loss : 9.9395  avg_loss_step : 9.8990  learning_rate : 0.00021900001  loss_scaler : 16777216 
DLL 2021-12-18 06:35:50.017845 - Iteration: 76  throughput_train : 3796.243 seq/s mlm_loss : 9.1671  nsp_loss : 0.6910  total_loss : 9.8581  avg_loss_step : 9.8956  learning_rate : 0.000222  loss_scaler : 16777216 
DLL 2021-12-18 06:36:07.765231 - Iteration: 77  throughput_train : 3811.979 seq/s mlm_loss : 9.0806  nsp_loss : 0.6675  total_loss : 9.7482  avg_loss_step : 9.8822  learning_rate : 0.00022500001  loss_scaler : 16777216 
DLL 2021-12-18 06:36:25.635416 - Iteration: 78  throughput_train : 3785.694 seq/s mlm_loss : 9.1201  nsp_loss : 0.6578  total_loss : 9.7778  avg_loss_step : 9.8613  learning_rate : 0.000228  loss_scaler : 16777216 
DLL 2021-12-18 06:36:43.473636 - Iteration: 79  throughput_train : 3792.494 seq/s mlm_loss : 9.1029  nsp_loss : 0.6722  total_loss : 9.7751  avg_loss_step : 9.8681  learning_rate : 0.00023100001  loss_scaler : 16777216 
DLL 2021-12-18 06:37:01.263675 - Iteration: 80  throughput_train : 3802.763 seq/s mlm_loss : 9.1710  nsp_loss : 0.6866  total_loss : 9.8576  avg_loss_step : 9.8488  learning_rate : 0.000234  loss_scaler : 16777216 
DLL 2021-12-18 06:37:19.166489 - Iteration: 81  throughput_train : 3779.638 seq/s mlm_loss : 9.2725  nsp_loss : 0.6891  total_loss : 9.9616  avg_loss_step : 9.8323  learning_rate : 0.00023700001  loss_scaler : 16777216 
DLL 2021-12-18 06:37:36.993664 - Iteration: 82  throughput_train : 3794.805 seq/s mlm_loss : 9.1009  nsp_loss : 0.6923  total_loss : 9.7931  avg_loss_step : 9.8171  learning_rate : 0.00024000001  loss_scaler : 16777216 
DLL 2021-12-18 06:37:54.799204 - Iteration: 83  throughput_train : 3799.445 seq/s mlm_loss : 9.1827  nsp_loss : 0.6597  total_loss : 9.8424  avg_loss_step : 9.8305  learning_rate : 0.000243  loss_scaler : 16777216 
DLL 2021-12-18 06:38:12.647321 - Iteration: 84  throughput_train : 3790.391 seq/s mlm_loss : 9.0529  nsp_loss : 0.6881  total_loss : 9.7410  avg_loss_step : 9.8160  learning_rate : 0.000246  loss_scaler : 16777216 
DLL 2021-12-18 06:38:30.442640 - Iteration: 85  throughput_train : 3801.681 seq/s mlm_loss : 9.2086  nsp_loss : 0.7308  total_loss : 9.9394  avg_loss_step : 9.7992  learning_rate : 0.000249  loss_scaler : 16777216 
DLL 2021-12-18 06:38:48.299108 - Iteration: 86  throughput_train : 3788.621 seq/s mlm_loss : 9.0526  nsp_loss : 0.6635  total_loss : 9.7161  avg_loss_step : 9.7866  learning_rate : 0.000252  loss_scaler : 16777216 
DLL 2021-12-18 06:39:06.199708 - Iteration: 87  throughput_train : 3779.355 seq/s mlm_loss : 9.0706  nsp_loss : 0.6828  total_loss : 9.7535  avg_loss_step : 9.7856  learning_rate : 0.00025500002  loss_scaler : 16777216 
DLL 2021-12-18 06:39:24.066551 - Iteration: 88  throughput_train : 3786.752 seq/s mlm_loss : 9.0841  nsp_loss : 0.6876  total_loss : 9.7717  avg_loss_step : 9.7827  learning_rate : 0.00025800001  loss_scaler : 16777216 
DLL 2021-12-18 06:39:41.882360 - Iteration: 89  throughput_train : 3797.253 seq/s mlm_loss : 9.1161  nsp_loss : 0.6932  total_loss : 9.8093  avg_loss_step : 9.7828  learning_rate : 0.000261  loss_scaler : 16777216 
DLL 2021-12-18 06:39:59.688544 - Iteration: 90  throughput_train : 3799.355 seq/s mlm_loss : 8.9882  nsp_loss : 0.6719  total_loss : 9.6601  avg_loss_step : 9.7585  learning_rate : 0.000264  loss_scaler : 16777216 
DLL 2021-12-18 06:40:17.599199 - Iteration: 91  throughput_train : 3790.274 seq/s mlm_loss : 9.1526  nsp_loss : 0.6839  total_loss : 9.8364  avg_loss_step : 9.7327  learning_rate : 0.000267  loss_scaler : 16777216 
INFO:tensorflow:Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1/model.ckpt.
I1218 06:40:17.600495 140471982864192 basic_session_run_hooks.py:606] Saving checkpoints for 90 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs2262144_211218060617/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 9.727937.
I1218 06:40:18.513171 140517630531392 estimator.py:371] Loss for final step: 9.727937.
INFO:tensorflow:Loss for final step: 9.734651.
I1218 06:40:18.536370 140082604967744 estimator.py:371] Loss for final step: 9.734651.
INFO:tensorflow:Loss for final step: 9.8170595.
I1218 06:40:18.542449 140298288346944 estimator.py:371] Loss for final step: 9.8170595.
INFO:tensorflow:Loss for final step: 9.841994.
I1218 06:40:18.549986 139850373838656 estimator.py:371] Loss for final step: 9.841994.
INFO:tensorflow:Loss for final step: 9.705056.
I1218 06:40:18.639109 140026584057664 estimator.py:371] Loss for final step: 9.705056.
INFO:tensorflow:Loss for final step: 9.7342415.
I1218 06:40:18.664815 140234342889280 estimator.py:371] Loss for final step: 9.7342415.
INFO:tensorflow:Loss for final step: 9.932827.
I1218 06:40:18.677399 140647466776384 estimator.py:371] Loss for final step: 9.932827.
INFO:tensorflow:Loss for final step: 9.836429.
I1218 06:40:22.974198 140471982864192 estimator.py:371] Loss for final step: 9.836429.
INFO:tensorflow:-----------------------------
I1218 06:40:22.975943 140471982864192 run_pretraining.py:644] -----------------------------
INFO:tensorflow:Total Training Time = 2042.53 for Sentences = 6082560
I1218 06:40:22.976052 140471982864192 run_pretraining.py:646] Total Training Time = 2042.53 for Sentences = 6082560
INFO:tensorflow:Total Training Time W/O Overhead = 1573.10 for Sentences = 5271552
I1218 06:40:22.976125 140471982864192 run_pretraining.py:648] Total Training Time W/O Overhead = 1573.10 for Sentences = 5271552
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 2977.96
I1218 06:40:22.976196 140471982864192 run_pretraining.py:649] Throughput Average (sentences/sec) with overhead = 2977.96
INFO:tensorflow:Throughput Average (sentences/sec) = 3351.06
I1218 06:40:22.976261 140471982864192 run_pretraining.py:650] Throughput Average (sentences/sec) = 3351.06
DLL 2021-12-18 06:40:22.976315 -  throughput_train : 3351.060 seq/s
INFO:tensorflow:-----------------------------
I1218 06:40:22.976458 140471982864192 run_pretraining.py:652] -----------------------------
