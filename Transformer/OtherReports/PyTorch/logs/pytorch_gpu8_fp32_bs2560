| distributed init (rank 3): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 3
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 0
| distributed init (rank 1): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 1
| distributed init (rank 5): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 5
| distributed init (rank 2): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 2
| distributed init (rank 4): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 4
| distributed init (rank 7): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 7
| distributed init (rank 6): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 6
| distributed init done!
| initialized host 5b14333bb733 as rank 0 and device id 0
Namespace(adam_betas=[0.9, 0.997], adam_eps=1e-09, amp=False, arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, beam=4, bpe_codes=None, buffer_size=64, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', data='/data/', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, device_id=0, distributed_backend='nccl', distributed_init_method='env://', distributed_port=-1, distributed_rank=0, distributed_world_size=8, do_sanity_check=False, dropout=0.1, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, file=None, fp16=False, fuse_dropout_add=False, fuse_layer_norm=True, fuse_relu_dropout=False, gen_subset='test', label_smoothing=0.1, left_pad_source=True, left_pad_target=False, lenpen=1, local_rank=0, log_interval=100, lr=[0.000846], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=1, max_len_a=0, max_len_b=200, max_positions=(1024, 1024), max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=2560, max_update=0, min_len=1, min_lr=0.0, momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_save=True, no_token_positional_embeddings=False, num_shards=1, online_eval=False, optimizer='adam', pad_sequence=1, path=None, prefix_size=0, print_alignment=False, quiet=False, raw_text=False, relu_dropout=0.1, remove_bpe=None, replace_unk=None, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='/workspace/checkpoint', save_interval=1, save_predictions=False, seed=1, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, source_lang=None, stat_file='run_log.json', target_bleu=0.0, target_lang=None, test_cased_bleu=False, train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], valid_subset='valid', validate_interval=1, warmup_init_lr=0.0, warmup_updates=4000, weight_decay=0.0)
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
filename test.en-de.de.bin
args.data /data/
args.source_lang en
args.target_lang de
| [en] dictionary: 33712 types
| [de] dictionary: 33712 types
| /data/ train 4575637 examples
| Sentences are being padded to multiples of: 1
| /data/ valid 3000 examples
| Sentences are being padded to multiples of: 1
| /data/ test 3003 examples
| Sentences are being padded to multiples of: 1
| num. model params: 210808832
| NOTICE: your device may support faster training with --amp
| model transformer_wmt_en_de_big_t2t, criterion LabelSmoothedCrossEntropyCriterion
| training on 8 GPUs
| max tokens per GPU = 2560 and max sentences per GPU = None
Transformer | epoch 0 | step 100 |avg loss 13.756 |avg tokens 17622.930 |tokens/s 60073.333 |walltime 42.145 |
Transformer | epoch 0 | step 200 |avg loss 11.755 |avg tokens 17595.390 |tokens/s 59884.034 |walltime 71.527 |
Transformer | epoch 0 | step 300 |avg loss 11.233 |avg tokens 17486.850 |tokens/s 59145.706 |walltime 101.093 |
Transformer | epoch 0 | step 400 |avg loss 10.813 |avg tokens 17498.210 |tokens/s 58840.049 |walltime 130.831 |
Transformer | epoch 0 | step 500 |avg loss 10.289 |avg tokens 17637.670 |tokens/s 59454.879 |walltime 160.497 |
Transformer | epoch 0 | step 600 |avg loss 9.814 |avg tokens 17460.160 |tokens/s 58883.217 |walltime 190.149 |
Transformer | epoch 0 | step 700 |avg loss 9.461 |avg tokens 17342.970 |tokens/s 58285.257 |walltime 219.905 |
Transformer | epoch 0 | step 800 |avg loss 9.104 |avg tokens 17466.050 |tokens/s 58808.216 |walltime 249.605 |
Transformer | epoch 0 | step 900 |avg loss 8.840 |avg tokens 17505.330 |tokens/s 58715.864 |walltime 279.418 |
Transformer | epoch 0 | step 1000 |avg loss 8.590 |avg tokens 17462.590 |tokens/s 58239.438 |walltime 309.402 |
Transformer | epoch 0 | step 1100 |avg loss 8.248 |avg tokens 17572.500 |tokens/s 59009.648 |walltime 339.181 |
Transformer | epoch 0 | step 1200 |avg loss 7.959 |avg tokens 17553.430 |tokens/s 59086.735 |walltime 368.889 |
Transformer | epoch 0 | step 1300 |avg loss 7.664 |avg tokens 17355.130 |tokens/s 58523.592 |walltime 398.544 |
Transformer | epoch 0 | step 1400 |avg loss 7.414 |avg tokens 17295.400 |tokens/s 58153.654 |walltime 428.285 |
Transformer | epoch 0 | step 1500 |avg loss 7.181 |avg tokens 17517.340 |tokens/s 58743.045 |walltime 458.105 |
Transformer | epoch 0 | step 1600 |avg loss 6.873 |avg tokens 17487.490 |tokens/s 58762.743 |walltime 487.865 |
Transformer | epoch 0 | step 1700 |avg loss 6.725 |avg tokens 17666.450 |tokens/s 59485.589 |walltime 517.564 |
Transformer | epoch 0 | step 1800 |avg loss 6.581 |avg tokens 17374.410 |tokens/s 58410.485 |walltime 547.309 |
Transformer | epoch 0 | step 1900 |avg loss 6.472 |avg tokens 17514.860 |tokens/s 58965.495 |walltime 577.013 |
Transformer | epoch 0 | step 2000 |avg loss 6.334 |avg tokens 17664.530 |tokens/s 59491.427 |walltime 606.705 |
Transformer | epoch 0 | step 2100 |avg loss 6.327 |avg tokens 17503.740 |tokens/s 58946.633 |walltime 636.399 |
Transformer | epoch 0 | step 2200 |avg loss 6.164 |avg tokens 17382.150 |tokens/s 58526.071 |walltime 666.099 |
Transformer | epoch 0 | step 2300 |avg loss 6.150 |avg tokens 17473.690 |tokens/s 58942.487 |walltime 695.745 |
Transformer | epoch 0 | step 2400 |avg loss 6.079 |avg tokens 17396.820 |tokens/s 58750.505 |walltime 725.356 |
Transformer | epoch 0 | step 2500 |avg loss 5.980 |avg tokens 17344.480 |tokens/s 58661.442 |walltime 754.923 |
Transformer | epoch 0 | step 2600 |avg loss 6.000 |avg tokens 17435.460 |tokens/s 58989.782 |walltime 784.480 |
Transformer | epoch 0 | step 2700 |avg loss 5.910 |avg tokens 17521.910 |tokens/s 58950.777 |walltime 814.203 |
Transformer | epoch 0 | step 2800 |avg loss 5.866 |avg tokens 17536.230 |tokens/s 59178.036 |walltime 843.836 |
Transformer | epoch 0 | step 2900 |avg loss 5.818 |avg tokens 17360.850 |tokens/s 58564.002 |walltime 873.480 |
Transformer | epoch 0 | step 3000 |avg loss 5.804 |avg tokens 17359.100 |tokens/s 58640.693 |walltime 903.082 |
Transformer | epoch 0 | step 3100 |avg loss 5.674 |avg tokens 17476.600 |tokens/s 58804.789 |walltime 932.802 |
Transformer | epoch 0 | step 3200 |avg loss 5.673 |avg tokens 17587.910 |tokens/s 59124.773 |walltime 962.549 |
Transformer | epoch 0 | step 3300 |avg loss 5.647 |avg tokens 17710.590 |tokens/s 59681.138 |walltime 992.225 |
Transformer | epoch 0 | step 3400 |avg loss 5.652 |avg tokens 17472.580 |tokens/s 58694.773 |walltime 1021.993 |
Transformer | epoch 0 | step 3500 |avg loss 5.688 |avg tokens 17500.920 |tokens/s 58846.177 |walltime 1051.733 |
Transformer | epoch 0 | step 3600 |avg loss 5.676 |avg tokens 17515.390 |tokens/s 59366.683 |walltime 1081.237 |
Transformer | epoch 0 | step 3700 |avg loss 5.633 |avg tokens 17446.410 |tokens/s 58912.777 |walltime 1110.851 |
Transformer | epoch 0 | step 3800 |avg loss 5.633 |avg tokens 17440.840 |tokens/s 59018.771 |walltime 1140.402 |
Transformer | epoch 0 | step 3900 |avg loss 5.623 |avg tokens 17476.120 |tokens/s 58909.349 |walltime 1170.068 |
Transformer | epoch 0 | step 4000 |avg loss 5.507 |avg tokens 17506.980 |tokens/s 59062.623 |walltime 1199.710 |
Transformer | epoch 0 | step 4100 |avg loss 5.562 |avg tokens 17371.580 |tokens/s 58592.591 |walltime 1229.358 |
Transformer | epoch 0 | step 4200 |avg loss 5.492 |avg tokens 17595.390 |tokens/s 59442.076 |walltime 1258.959 |
Transformer | epoch 0 | step 4300 |avg loss 5.459 |avg tokens 17533.080 |tokens/s 59186.267 |walltime 1288.582 |
Transformer | epoch 0 | step 4400 |avg loss 5.457 |avg tokens 17349.410 |tokens/s 58570.831 |walltime 1318.204 |
Transformer | epoch 0 | step 4500 |avg loss 5.378 |avg tokens 17336.840 |tokens/s 58407.485 |walltime 1347.886 |
Transformer | epoch 0 | step 4600 |avg loss 5.423 |avg tokens 17489.200 |tokens/s 59206.191 |walltime 1377.426 |
Transformer | epoch 0 | step 4700 |avg loss 5.404 |avg tokens 17346.550 |tokens/s 58649.628 |walltime 1407.002 |
Transformer | epoch 0 | step 4800 |avg loss 5.289 |avg tokens 17608.100 |tokens/s 59461.373 |walltime 1436.615 |
Transformer | epoch 0 | step 4900 |avg loss 5.315 |avg tokens 17679.900 |tokens/s 59768.709 |walltime 1466.195 |
Transformer | epoch 0 | step 5000 |avg loss 5.303 |avg tokens 17567.980 |tokens/s 59377.819 |walltime 1495.782 |
Transformer | epoch 0 | step 5100 |avg loss 5.234 |avg tokens 17568.400 |tokens/s 59196.299 |walltime 1525.460 |
Transformer | epoch 0 | step 5200 |avg loss 5.275 |avg tokens 17380.480 |tokens/s 58698.943 |walltime 1555.070 |
Transformer | epoch 0 | step 5300 |avg loss 5.241 |avg tokens 17429.050 |tokens/s 58941.078 |walltime 1584.640 |
Transformer | epoch 0 | step 5400 |avg loss 5.212 |avg tokens 17554.390 |tokens/s 59368.391 |walltime 1614.209 |
Transformer | epoch 0 | step 5500 |avg loss 5.193 |avg tokens 17484.640 |tokens/s 59045.580 |walltime 1643.821 |
Transformer | epoch 0 | step 5600 |avg loss 5.164 |avg tokens 17322.310 |tokens/s 58504.354 |walltime 1673.430 |
Transformer | epoch 0 | step 5700 |avg loss 5.162 |avg tokens 17381.820 |tokens/s 58708.726 |walltime 1703.036 |
Transformer | epoch 0 | step 5800 |avg loss 5.151 |avg tokens 17398.550 |tokens/s 58718.441 |walltime 1732.667 |
Transformer | epoch 0 | step 5900 |avg loss 5.134 |avg tokens 17363.510 |tokens/s 58465.078 |walltime 1762.366 |
Transformer | epoch 0 | step 6000 |avg loss 5.096 |avg tokens 17548.860 |tokens/s 59424.797 |walltime 1791.897 |
Transformer | epoch 0 | step 6100 |avg loss 5.146 |avg tokens 17406.530 |tokens/s 58857.309 |walltime 1821.471 |
Transformer | epoch 0 | step 6200 |avg loss 5.127 |avg tokens 17337.680 |tokens/s 58539.633 |walltime 1851.088 |
Transformer | epoch 0 | step 6300 |avg loss 5.131 |avg tokens 17438.260 |tokens/s 58864.594 |walltime 1880.713 |
Transformer | epoch 0 | step 6400 |avg loss 5.076 |avg tokens 17529.390 |tokens/s 59231.898 |walltime 1910.307 |
Transformer | epoch 0 | step 6500 |avg loss 5.067 |avg tokens 17290.550 |tokens/s 58320.163 |walltime 1939.955 |
Transformer | epoch 0 | step 6600 |avg loss 4.953 |avg tokens 17479.460 |tokens/s 59025.563 |walltime 1969.568 |
Transformer | epoch 0 | step 6700 |avg loss 5.003 |avg tokens 17293.350 |tokens/s 58250.459 |walltime 1999.256 |
Transformer | epoch 0 | step 6800 |avg loss 5.028 |avg tokens 17475.630 |tokens/s 59098.252 |walltime 2028.826 |
Transformer | epoch 0 | step 6900 |avg loss 5.019 |avg tokens 17333.760 |tokens/s 58525.688 |walltime 2058.444 |
Transformer | epoch 0 | step 7000 |avg loss 4.978 |avg tokens 17392.020 |tokens/s 58629.602 |walltime 2088.108 |
Transformer | epoch 0 | step 7100 |avg loss 4.960 |avg tokens 17425.800 |tokens/s 58726.821 |walltime 2117.781 |
Transformer | epoch 0 | step 7200 |avg loss 4.975 |avg tokens 17368.430 |tokens/s 58835.242 |walltime 2147.301 |
Transformer | epoch 0 | step 7300 |avg loss 4.981 |avg tokens 17422.980 |tokens/s 58539.236 |walltime 2177.064 |
Transformer | epoch 0 | step 7400 |avg loss 4.977 |avg tokens 17337.590 |tokens/s 58714.972 |walltime 2206.592 |
Transformer | epoch 0 | step 7500 |avg loss 4.907 |avg tokens 17367.760 |tokens/s 58738.777 |walltime 2236.160 |
Transformer | epoch 0 | step 7600 |avg loss 4.972 |avg tokens 17369.950 |tokens/s 58701.502 |walltime 2265.751 |
Transformer | epoch 0 | step 7700 |avg loss 4.987 |avg tokens 17324.320 |tokens/s 58599.797 |walltime 2295.314 |
Transformer | epoch 0 | step 7800 |avg loss 4.935 |avg tokens 17251.270 |tokens/s 58307.792 |walltime 2324.901 |
Transformer | epoch 0 | step 7900 |avg loss 4.965 |avg tokens 17536.950 |tokens/s 59269.541 |walltime 2354.489 |
Transformer | epoch 0 | step 8000 |avg loss 4.908 |avg tokens 17489.800 |tokens/s 59207.516 |walltime 2384.029 |
Transformer | epoch 0 | step 8100 |avg loss 4.877 |avg tokens 17488.820 |tokens/s 58787.049 |walltime 2413.779 |
Epoch time: 2416.720618247986
Transformer | epoch 0 | step 8149 |avg loss 4.908 |avg tokens 17464.980 |tokens/s 58073.970 |walltime 2428.515 |
Validation loss on subset valid: 4.489606722553098
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [129].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [129].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [129], which does not match the required output shape [151].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [129], which does not match the required output shape [151].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [151], which does not match the required output shape [106].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [151], which does not match the required output shape [106].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [133].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [133].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [106], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [106], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [133], which does not match the required output shape [143].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [133], which does not match the required output shape [143].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [143], which does not match the required output shape [120].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [143], which does not match the required output shape [120].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [131].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [131].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [92, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [92, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [131], which does not match the required output shape [156].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [131], which does not match the required output shape [156].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [92, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [94].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [94].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [92, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [156], which does not match the required output shape [111].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [156], which does not match the required output shape [111].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [111], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [111], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [94], which does not match the required output shape [143].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [94], which does not match the required output shape [143].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [134].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [134].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [143], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [143], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [134], which does not match the required output shape [141].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [134], which does not match the required output shape [141].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [141], which does not match the required output shape [105].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [141], which does not match the required output shape [105].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [64].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [64].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [111].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [111].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [111], which does not match the required output shape [130].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [111], which does not match the required output shape [130].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [117].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [117].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [109].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [109].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [47, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [107].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [107].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [47, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [117], which does not match the required output shape [96].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [117], which does not match the required output shape [96].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [109], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [109], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [100, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [47, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [47, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [100, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [96], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [96], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [107], which does not match the required output shape [124].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [107], which does not match the required output shape [124].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [100, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [100, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [124], which does not match the required output shape [119].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [124], which does not match the required output shape [119].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [119], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [119], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [90].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [90].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [94, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [94, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [94, 8], which does not match the required output shape [66, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [94, 8], which does not match the required output shape [66, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [66, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [66, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [106].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [106].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [106], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [106], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [85].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [85].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [85], which does not match the required output shape [124].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [85], which does not match the required output shape [124].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [79, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [79, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [124], which does not match the required output shape [81].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [124], which does not match the required output shape [81].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [79, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [79, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [81], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [81], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [70, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [70, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [81].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [81].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [70, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [70, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [81], which does not match the required output shape [85].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [81], which does not match the required output shape [85].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [85], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [85], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [80].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [80].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [80], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [80], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [106, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [106, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [106, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [106, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [75, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [75, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [75, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [75, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [105, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [105, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [105, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [105, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [77, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [77, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [77, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [77, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [70, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [70, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [70, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [70, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [79, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [79, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [79, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [79, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [56, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [56, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [33, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [33, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [33, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [33, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [79, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [79, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [79, 8], which does not match the required output shape [64, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [79, 8], which does not match the required output shape [64, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [64, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [64, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [50].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [50].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [106, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [106, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [106, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [106, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [80, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [80, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [80, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [80, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [52, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [52, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [52, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [52, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [83, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [83, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [83, 8], which does not match the required output shape [77, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [83, 8], which does not match the required output shape [77, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [77, 8], which does not match the required output shape [73, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [77, 8], which does not match the required output shape [73, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [73, 8], which does not match the required output shape [66, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [73, 8], which does not match the required output shape [66, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [66, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [66, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
Traceback (most recent call last):
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 430, in <module>
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    raise EOFError("Source and reference streams have different lengths!")
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
EOFError  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
: Source and reference streams have different lengths!
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '/data/', '--arch', 'transformer_wmt_en_de_big_t2t', '--share-all-embeddings', '--optimizer', 'adam', '--adam-betas', '0.9', '0.997', '--adam-eps', '1e-9', '--clip-norm', '0.0', '--lr-scheduler', 'inverse_sqrt', '--warmup-init-lr', '0.0', '--warmup-updates', '4000', '--lr', '0.000846', '--min-lr', '0.0', '--dropout', '0.1', '--weight-decay', '0.0', '--criterion', 'label_smoothed_cross_entropy', '--label-smoothing', '0.1', '--max-tokens', '2560', '--seed', '1', '--max-epoch', '1', '--no-save', '--fuse-layer-norm', '--log-interval', '100', '--distributed-init-method', 'env://', '--save-dir', '/workspace/checkpoint']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 6305
Killing subprocess 6306
Killing subprocess 6307
Killing subprocess 6308
Killing subprocess 6309
Killing subprocess 6310
Killing subprocess 6311
Killing subprocess 6312
