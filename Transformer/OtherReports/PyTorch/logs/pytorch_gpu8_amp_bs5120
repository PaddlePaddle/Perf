| distributed init (rank 3): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 3
| distributed init (rank 7): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 7
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 0
| distributed init (rank 1): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 1
| distributed init (rank 6): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 6
| distributed init (rank 4): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 4
| distributed init (rank 2): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 2
| distributed init (rank 5): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 5
| distributed init done!
| initialized host 5b14333bb733 as rank 0 and device id 0
| distributed init done!
Namespace(adam_betas=[0.9, 0.997], adam_eps=1e-09, amp=True, arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, beam=4, bpe_codes=None, buffer_size=64, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', data='/data/', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, device_id=0, distributed_backend='nccl', distributed_init_method='env://', distributed_port=-1, distributed_rank=0, distributed_world_size=8, do_sanity_check=False, dropout=0.1, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, file=None, fp16=False, fuse_dropout_add=False, fuse_layer_norm=True, fuse_relu_dropout=False, gen_subset='test', label_smoothing=0.1, left_pad_source=True, left_pad_target=False, lenpen=1, local_rank=0, log_interval=100, lr=[0.000846], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=1, max_len_a=0, max_len_b=200, max_positions=(1024, 1024), max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=5120, max_update=0, min_len=1, min_lr=0.0, momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_save=True, no_token_positional_embeddings=False, num_shards=1, online_eval=False, optimizer='adam', pad_sequence=1, path=None, prefix_size=0, print_alignment=False, quiet=False, raw_text=False, relu_dropout=0.1, remove_bpe=None, replace_unk=None, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='/workspace/checkpoint', save_interval=1, save_predictions=False, seed=1, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, source_lang=None, stat_file='run_log.json', target_bleu=0.0, target_lang=None, test_cased_bleu=False, train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], valid_subset='valid', validate_interval=1, warmup_init_lr=0.0, warmup_updates=4000, weight_decay=0.0)
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
filename test.en-de.de.bin
args.data /data/
args.source_lang en
args.target_lang de
| [en] dictionary: 33712 types
| [de] dictionary: 33712 types
| /data/ train 4575637 examples
| Sentences are being padded to multiples of: 1
| /data/ valid 3000 examples
| Sentences are being padded to multiples of: 1
| /data/ test 3003 examples
| Sentences are being padded to multiples of: 1
| num. model params: 210808832
| model transformer_wmt_en_de_big_t2t, criterion LabelSmoothedCrossEntropyCriterion
| training on 8 GPUs
| max tokens per GPU = 5120 and max sentences per GPU = None
Transformer | epoch 0 | step 100 |avg loss 13.824 |avg tokens 36353.610 |tokens/s 203920.610 |walltime 29.962 |
Transformer | epoch 0 | step 200 |avg loss 11.717 |avg tokens 35786.590 |tokens/s 201958.126 |walltime 47.682 |
Transformer | epoch 0 | step 300 |avg loss 11.110 |avg tokens 36262.110 |tokens/s 204306.108 |walltime 65.431 |
Transformer | epoch 0 | step 400 |avg loss 10.612 |avg tokens 36412.460 |tokens/s 203854.782 |walltime 83.293 |
Transformer | epoch 0 | step 500 |avg loss 10.073 |avg tokens 35965.510 |tokens/s 201837.215 |walltime 101.112 |
Transformer | epoch 0 | step 600 |avg loss 9.561 |avg tokens 36495.790 |tokens/s 206083.400 |walltime 118.821 |
Transformer | epoch 0 | step 700 |avg loss 9.196 |avg tokens 36266.870 |tokens/s 204397.902 |walltime 136.564 |
Transformer | epoch 0 | step 800 |avg loss 8.763 |avg tokens 36163.800 |tokens/s 201654.981 |walltime 154.498 |
Transformer | epoch 0 | step 900 |avg loss 8.454 |avg tokens 36097.570 |tokens/s 203215.094 |walltime 172.261 |
Transformer | epoch 0 | step 1000 |avg loss 8.052 |avg tokens 36422.970 |tokens/s 204880.969 |walltime 190.039 |
Transformer | epoch 0 | step 1100 |avg loss 7.812 |avg tokens 36349.340 |tokens/s 203892.442 |walltime 207.867 |
Transformer | epoch 0 | step 1200 |avg loss 7.427 |avg tokens 35992.260 |tokens/s 201484.420 |walltime 225.730 |
Transformer | epoch 0 | step 1300 |avg loss 7.144 |avg tokens 36245.200 |tokens/s 203650.382 |walltime 243.528 |
Transformer | epoch 0 | step 1400 |avg loss 6.843 |avg tokens 36101.440 |tokens/s 203267.000 |walltime 261.288 |
Transformer | epoch 0 | step 1500 |avg loss 6.637 |avg tokens 36097.960 |tokens/s 203504.919 |walltime 279.027 |
Transformer | epoch 0 | step 1600 |avg loss 6.440 |avg tokens 35857.810 |tokens/s 202003.648 |walltime 296.778 |
Transformer | epoch 0 | step 1700 |avg loss 6.259 |avg tokens 35886.470 |tokens/s 200159.736 |walltime 314.707 |
Transformer | epoch 0 | step 1800 |avg loss 6.063 |avg tokens 36472.800 |tokens/s 204640.409 |walltime 332.529 |
Transformer | epoch 0 | step 1900 |avg loss 6.082 |avg tokens 36059.150 |tokens/s 203574.797 |walltime 350.242 |
Transformer | epoch 0 | step 2000 |avg loss 5.977 |avg tokens 36203.190 |tokens/s 203562.255 |walltime 368.027 |
Transformer | epoch 0 | step 2100 |avg loss 5.833 |avg tokens 36194.740 |tokens/s 202106.703 |walltime 385.936 |
Transformer | epoch 0 | step 2200 |avg loss 5.755 |avg tokens 36001.400 |tokens/s 203182.067 |walltime 403.655 |
Transformer | epoch 0 | step 2300 |avg loss 5.735 |avg tokens 36061.920 |tokens/s 203297.202 |walltime 421.393 |
Transformer | epoch 0 | step 2400 |avg loss 5.653 |avg tokens 36140.300 |tokens/s 202204.104 |walltime 439.266 |
Transformer | epoch 0 | step 2500 |avg loss 5.616 |avg tokens 36324.380 |tokens/s 204582.818 |walltime 457.022 |
Transformer | epoch 0 | step 2600 |avg loss 5.599 |avg tokens 36176.370 |tokens/s 204382.408 |walltime 474.722 |
Transformer | epoch 0 | step 2700 |avg loss 5.528 |avg tokens 35999.920 |tokens/s 202490.487 |walltime 492.501 |
Transformer | epoch 0 | step 2800 |avg loss 5.565 |avg tokens 36263.430 |tokens/s 201596.136 |walltime 510.489 |
Transformer | epoch 0 | step 2900 |avg loss 5.443 |avg tokens 35973.760 |tokens/s 203318.525 |walltime 528.182 |
Transformer | epoch 0 | step 3000 |avg loss 5.424 |avg tokens 35927.070 |tokens/s 200861.950 |walltime 546.069 |
Transformer | epoch 0 | step 3100 |avg loss 5.361 |avg tokens 36114.570 |tokens/s 203551.602 |walltime 563.811 |
Transformer | epoch 0 | step 3200 |avg loss 5.394 |avg tokens 35998.340 |tokens/s 203743.494 |walltime 581.479 |
Transformer | epoch 0 | step 3300 |avg loss 5.294 |avg tokens 36113.130 |tokens/s 202427.984 |walltime 599.319 |
Transformer | epoch 0 | step 3400 |avg loss 5.281 |avg tokens 35947.060 |tokens/s 202164.338 |walltime 617.100 |
Transformer | epoch 0 | step 3500 |avg loss 5.285 |avg tokens 36689.520 |tokens/s 206928.198 |walltime 634.831 |
Transformer | epoch 0 | step 3600 |avg loss 5.365 |avg tokens 35624.780 |tokens/s 199153.124 |walltime 652.719 |
Transformer | epoch 0 | step 3700 |avg loss 5.265 |avg tokens 36514.170 |tokens/s 205858.589 |walltime 670.457 |
Transformer | epoch 0 | step 3800 |avg loss 5.278 |avg tokens 36249.430 |tokens/s 204379.030 |walltime 688.193 |
Transformer | epoch 0 | step 3900 |avg loss 5.215 |avg tokens 36099.800 |tokens/s 203454.359 |walltime 705.936 |
Epoch time: 700.5794098377228
Transformer | epoch 0 | step 3935 |avg loss 5.094 |avg tokens 36188.571 |tokens/s 196715.091 |walltime 712.375 |
Validation loss on subset valid: 4.776280646074398
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [127].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [127].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [127], which does not match the required output shape [156].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [127], which does not match the required output shape [156].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [156], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [156], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [150].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [150].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [123].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [123].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [95, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [130].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [130].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [95, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [123], which does not match the required output shape [158].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [123], which does not match the required output shape [158].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [99].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [99].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [95, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [95, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [158], which does not match the required output shape [105].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [158], which does not match the required output shape [105].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [99], which does not match the required output shape [138].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [99], which does not match the required output shape [138].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [83, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [83, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [138], which does not match the required output shape [108].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [138], which does not match the required output shape [108].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [83, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [162].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [162].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [83, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [108], which does not match the required output shape [79].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [108], which does not match the required output shape [79].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [96].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [96].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [108].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [108].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [79], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [79], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [96], which does not match the required output shape [120].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [96], which does not match the required output shape [120].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [162], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [162], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [108], which does not match the required output shape [109].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [108], which does not match the required output shape [109].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [56, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [56, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [109], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [109], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [40, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [40, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [40, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [75, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [40, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [75, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [115].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [115].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [75, 8], which does not match the required output shape [47, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [75, 8], which does not match the required output shape [47, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [115], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [115], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [47, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [47, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [50].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [50].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [111].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [111].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [103].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [103].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [111], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [111], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [103], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [103], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [120].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [120].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [85, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [85, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [99].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [120], which does not match the required output shape [99].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [85, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [126].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [85, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [99], which does not match the required output shape [90].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [99], which does not match the required output shape [90].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [40, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [40, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [126], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [40, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [40, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [96, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [96, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [96, 8], which does not match the required output shape [80, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [96, 8], which does not match the required output shape [80, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [82].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [82].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [80, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [83].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [83].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [80, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [82], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [82], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [83], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [83], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [70].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [70], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [67].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [79].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [67], which does not match the required output shape [79].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [79], which does not match the required output shape [90].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [79], which does not match the required output shape [90].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [85, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [90], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [85, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [85, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [85, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [117, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [108, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [117, 8], which does not match the required output shape [108, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [108, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [108, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [64].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [64].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [52, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [52, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [52, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [80].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [80].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [92, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [52, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [92, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [80], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [80], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [92, 8], which does not match the required output shape [75, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [92, 8], which does not match the required output shape [75, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [75, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [75, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [104, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [104, 8], which does not match the required output shape [86, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [86, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [62].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [62], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [105, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [95, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [105, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [105, 8], which does not match the required output shape [96, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [95, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [95, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [105, 8], which does not match the required output shape [96, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [96, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [95, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [96, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [28].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [28], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [50, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [50, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [40, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [40, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [40, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [40, 8], which does not match the required output shape [37, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [37, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [63, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [63, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [63, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [63, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "train.py", line 430, in <module>
    main(ARGS)
  File "train.py", line 128, in main
    valid_bleu = score(args, trainer, datasets[valid_subsets[0]], src_dict, tgt_dict, 'valid.raw.de')
  File "train.py", line 305, in score
    sacrebleu_score = sacrebleu.corpus_bleu(predictions, refs, lowercase=not args.test_cased_bleu).score
  File "/opt/conda/lib/python3.8/site-packages/sacrebleu.py", line 1031, in corpus_bleu
    raise EOFError("Source and reference streams have different lengths!")
EOFError: Source and reference streams have different lengths!
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 340, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'train.py', '--local_rank=7', '/data/', '--arch', 'transformer_wmt_en_de_big_t2t', '--share-all-embeddings', '--optimizer', 'adam', '--adam-betas', '0.9', '0.997', '--adam-eps', '1e-9', '--clip-norm', '0.0', '--lr-scheduler', 'inverse_sqrt', '--warmup-init-lr', '0.0', '--warmup-updates', '4000', '--lr', '0.000846', '--min-lr', '0.0', '--dropout', '0.1', '--weight-decay', '0.0', '--criterion', 'label_smoothed_cross_entropy', '--label-smoothing', '0.1', '--max-tokens', '5120', '--seed', '1', '--max-epoch', '1', '--no-save', '--fuse-layer-norm', '--log-interval', '100', '--distributed-init-method', 'env://', '--save-dir', '/workspace/checkpoint', '--amp']' returned non-zero exit status 1.
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Killing subprocess 8520
Killing subprocess 8521
Killing subprocess 8522
Killing subprocess 8523
Killing subprocess 8524
Killing subprocess 8525
Killing subprocess 8526
Killing subprocess 8527
