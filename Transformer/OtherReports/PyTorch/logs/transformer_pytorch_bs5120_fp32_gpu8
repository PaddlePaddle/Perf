| distributed init (rank 5): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 5
| distributed init (rank 6): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 6
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 0
| distributed init (rank 1): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 1
| distributed init (rank 7): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 7
| distributed init (rank 4): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 4
| distributed init (rank 3): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 3
| distributed init (rank 2): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 8421, WORLD_SIZE: 8, RANK: 2
| distributed init done!
| initialized host 70bfc6a3004d as rank 0 and device id 0
Namespace(adam_betas=[0.9, 0.997], adam_eps=1e-09, amp=False, arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, beam=4, bpe_codes=None, buffer_size=64, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', data='/data/wmt14_en_de_joined_dict', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, device_id=0, distributed_backend='nccl', distributed_init_method='env://', distributed_port=-1, distributed_rank=0, distributed_world_size=8, do_sanity_check=False, dropout=0.1, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, file=None, fp16=False, fuse_dropout_add=False, fuse_layer_norm=True, fuse_relu_dropout=False, gen_subset='test', label_smoothing=0.1, left_pad_source=True, left_pad_target=False, lenpen=1, local_rank=0, log_interval=10, lr=[0.000846], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=1, max_len_a=0, max_len_b=200, max_positions=(1024, 1024), max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=5120, max_update=0, min_len=1, min_lr=0.0, momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=True, no_save=False, no_token_positional_embeddings=False, num_shards=1, online_eval=False, optimizer='adam', pad_sequence=1, path=None, prefix_size=0, print_alignment=False, quiet=False, raw_text=False, relu_dropout=0.1, remove_bpe=None, replace_unk=None, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='/workspace/checkpoint', save_interval=1, save_predictions=False, seed=1, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, source_lang=None, stat_file='run_log.json', target_bleu=0.0, target_lang=None, test_cased_bleu=False, train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], valid_subset='valid', validate_interval=1, warmup_init_lr=0.0, warmup_updates=4000, weight_decay=0.0)
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| [en] dictionary: 33712 types
| [de] dictionary: 33712 types
| /data/wmt14_en_de_joined_dict train 4575637 examples
| Sentences are being padded to multiples of: 1
| /data/wmt14_en_de_joined_dict valid 3000 examples
| Sentences are being padded to multiples of: 1
| /data/wmt14_en_de_joined_dict test 3003 examples
| Sentences are being padded to multiples of: 1
| num. model params: 210808832
| NOTICE: your device may support faster training with --amp
| model transformer_wmt_en_de_big_t2t, criterion LabelSmoothedCrossEntropyCriterion
| training on 8 GPUs
| max tokens per GPU = 5120 and max sentences per GPU = None
Transformer | epoch 0 | step 10 |avg loss 16.006 |avg tokens 37260.500 |tokens/s 67014.414 |walltime 17.911 |
Transformer | epoch 0 | step 20 |avg loss 15.347 |avg tokens 36015.800 |tokens/s 65991.534 |walltime 23.369 |
Transformer | epoch 0 | step 30 |avg loss 14.564 |avg tokens 35667.400 |tokens/s 64107.446 |walltime 28.933 |
Transformer | epoch 0 | step 40 |avg loss 13.979 |avg tokens 36759.500 |tokens/s 66199.365 |walltime 34.486 |
Transformer | epoch 0 | step 50 |avg loss 13.587 |avg tokens 36580.300 |tokens/s 66424.837 |walltime 39.993 |
Transformer | epoch 0 | step 60 |avg loss 13.271 |avg tokens 35806.900 |tokens/s 64406.962 |walltime 45.552 |
Transformer | epoch 0 | step 70 |avg loss 13.062 |avg tokens 36997.900 |tokens/s 66434.678 |walltime 51.121 |
Transformer | epoch 0 | step 80 |avg loss 12.757 |avg tokens 35974.800 |tokens/s 64555.980 |walltime 56.694 |
Transformer | epoch 0 | step 90 |avg loss 12.497 |avg tokens 36153.000 |tokens/s 64915.496 |walltime 62.263 |
Transformer | epoch 0 | step 100 |avg loss 12.418 |avg tokens 36320.000 |tokens/s 65367.946 |walltime 67.819 |
Transformer | epoch 0 | step 110 |avg loss 12.190 |avg tokens 36752.600 |tokens/s 66728.671 |walltime 73.327 |
Transformer | epoch 0 | step 120 |avg loss 12.108 |avg tokens 35843.200 |tokens/s 64890.494 |walltime 78.851 |
Transformer | epoch 0 | step 130 |avg loss 11.902 |avg tokens 35890.000 |tokens/s 64728.344 |walltime 84.395 |
Transformer | epoch 0 | step 140 |avg loss 11.787 |avg tokens 35159.600 |tokens/s 63840.932 |walltime 89.903 |
Transformer | epoch 0 | step 150 |avg loss 11.691 |avg tokens 34679.900 |tokens/s 62351.270 |walltime 95.465 |
Transformer | epoch 0 | step 160 |avg loss 11.566 |avg tokens 35658.500 |tokens/s 63897.783 |walltime 101.045 |
Transformer | epoch 0 | step 170 |avg loss 11.549 |avg tokens 36158.500 |tokens/s 65548.868 |walltime 106.562 |
Transformer | epoch 0 | step 180 |avg loss 11.530 |avg tokens 36027.300 |tokens/s 64900.778 |walltime 112.113 |
Transformer | epoch 0 | step 190 |avg loss 11.503 |avg tokens 36359.600 |tokens/s 65091.920 |walltime 117.699 |
Transformer | epoch 0 | step 200 |avg loss 11.432 |avg tokens 35336.700 |tokens/s 63864.118 |walltime 123.232 |
Transformer | epoch 0 | step 210 |avg loss 11.370 |avg tokens 35638.000 |tokens/s 64396.205 |walltime 128.766 |
Transformer | epoch 0 | step 220 |avg loss 11.295 |avg tokens 35752.600 |tokens/s 63826.394 |walltime 134.367 |
Transformer | epoch 0 | step 230 |avg loss 11.335 |avg tokens 35616.600 |tokens/s 63965.841 |walltime 139.936 |
Transformer | epoch 0 | step 240 |avg loss 11.236 |avg tokens 37160.800 |tokens/s 66235.788 |walltime 145.546 |
Transformer | epoch 0 | step 250 |avg loss 11.164 |avg tokens 36574.400 |tokens/s 65395.577 |walltime 151.139 |
Transformer | epoch 0 | step 260 |avg loss 11.105 |avg tokens 37304.500 |tokens/s 66782.017 |walltime 156.725 |
Transformer | epoch 0 | step 270 |avg loss 11.180 |avg tokens 36251.300 |tokens/s 64773.335 |walltime 162.321 |
Transformer | epoch 0 | step 280 |avg loss 10.993 |avg tokens 36784.900 |tokens/s 65785.056 |walltime 167.913 |
Transformer | epoch 0 | step 290 |avg loss 10.927 |avg tokens 35906.000 |tokens/s 64215.701 |walltime 173.505 |
Transformer | epoch 0 | step 300 |avg loss 10.967 |avg tokens 35632.000 |tokens/s 63912.225 |walltime 179.080 |
Transformer | epoch 0 | step 310 |avg loss 10.911 |avg tokens 36827.200 |tokens/s 65164.726 |walltime 184.731 |
Transformer | epoch 0 | step 320 |avg loss 10.821 |avg tokens 36037.000 |tokens/s 64472.123 |walltime 190.321 |
Transformer | epoch 0 | step 330 |avg loss 10.910 |avg tokens 37260.400 |tokens/s 66445.873 |walltime 195.928 |
Transformer | epoch 0 | step 340 |avg loss 10.769 |avg tokens 37661.600 |tokens/s 67148.080 |walltime 201.537 |
Transformer | epoch 0 | step 350 |avg loss 10.677 |avg tokens 35479.900 |tokens/s 63399.924 |walltime 207.133 |
Transformer | epoch 0 | step 360 |avg loss 10.717 |avg tokens 36252.800 |tokens/s 64800.261 |walltime 212.728 |
Transformer | epoch 0 | step 370 |avg loss 10.604 |avg tokens 37179.600 |tokens/s 66187.597 |walltime 218.345 |
Transformer | epoch 0 | step 380 |avg loss 10.564 |avg tokens 36363.400 |tokens/s 64927.028 |walltime 223.946 |
Transformer | epoch 0 | step 390 |avg loss 10.335 |avg tokens 36309.000 |tokens/s 64783.883 |walltime 229.550 |
Transformer | epoch 0 | step 400 |avg loss 10.457 |avg tokens 34753.700 |tokens/s 62308.234 |walltime 235.128 |
Transformer | epoch 0 | step 410 |avg loss 10.396 |avg tokens 36775.600 |tokens/s 65871.706 |walltime 240.711 |
Transformer | epoch 0 | step 420 |avg loss 10.344 |avg tokens 35915.700 |tokens/s 64354.372 |walltime 246.292 |
Transformer | epoch 0 | step 430 |avg loss 10.344 |avg tokens 35944.700 |tokens/s 63693.724 |walltime 251.935 |
Transformer | epoch 0 | step 440 |avg loss 10.187 |avg tokens 36582.300 |tokens/s 65837.937 |walltime 257.492 |
Transformer | epoch 0 | step 450 |avg loss 10.106 |avg tokens 36208.800 |tokens/s 64665.144 |walltime 263.091 |
Transformer | epoch 0 | step 460 |avg loss 10.057 |avg tokens 36136.600 |tokens/s 64155.306 |walltime 268.724 |
Transformer | epoch 0 | step 470 |avg loss 10.104 |avg tokens 34348.100 |tokens/s 61103.655 |walltime 274.345 |
Transformer | epoch 0 | step 480 |avg loss 9.980 |avg tokens 36000.100 |tokens/s 64298.402 |walltime 279.944 |
Transformer | epoch 0 | step 490 |avg loss 9.919 |avg tokens 36753.900 |tokens/s 65794.288 |walltime 285.530 |
Transformer | epoch 0 | step 500 |avg loss 9.869 |avg tokens 34989.300 |tokens/s 62684.755 |walltime 291.112 |
Transformer | epoch 0 | step 510 |avg loss 9.818 |avg tokens 35927.000 |tokens/s 63941.017 |walltime 296.731 |
Transformer | epoch 0 | step 520 |avg loss 9.817 |avg tokens 36312.900 |tokens/s 64479.893 |walltime 302.362 |
Transformer | epoch 0 | step 530 |avg loss 9.735 |avg tokens 37115.700 |tokens/s 65709.568 |walltime 308.011 |
Transformer | epoch 0 | step 540 |avg loss 9.686 |avg tokens 36796.200 |tokens/s 65733.209 |walltime 313.609 |
Transformer | epoch 0 | step 550 |avg loss 9.536 |avg tokens 38234.700 |tokens/s 67710.187 |walltime 319.256 |
Transformer | epoch 0 | step 560 |avg loss 9.564 |avg tokens 36017.800 |tokens/s 64325.454 |walltime 324.855 |
Transformer | epoch 0 | step 570 |avg loss 9.505 |avg tokens 37394.000 |tokens/s 66885.986 |walltime 330.446 |
Transformer | epoch 0 | step 580 |avg loss 9.578 |avg tokens 36319.700 |tokens/s 64878.910 |walltime 336.044 |
Transformer | epoch 0 | step 590 |avg loss 9.493 |avg tokens 34987.000 |tokens/s 62384.777 |walltime 341.652 |
Transformer | epoch 0 | step 600 |avg loss 9.355 |avg tokens 35852.900 |tokens/s 63728.840 |walltime 347.278 |
Transformer | epoch 0 | step 610 |avg loss 9.400 |avg tokens 36964.700 |tokens/s 66276.804 |walltime 352.855 |
Transformer | epoch 0 | step 620 |avg loss 9.469 |avg tokens 35593.900 |tokens/s 63635.727 |walltime 358.448 |
Transformer | epoch 0 | step 630 |avg loss 9.260 |avg tokens 35754.400 |tokens/s 63494.933 |walltime 364.080 |
Transformer | epoch 0 | step 640 |avg loss 9.363 |avg tokens 35317.700 |tokens/s 63475.283 |walltime 369.644 |
Transformer | epoch 0 | step 650 |avg loss 9.264 |avg tokens 37097.500 |tokens/s 65844.311 |walltime 375.278 |
Transformer | epoch 0 | step 660 |avg loss 9.262 |avg tokens 36527.300 |tokens/s 64944.318 |walltime 380.902 |
Transformer | epoch 0 | step 670 |avg loss 9.194 |avg tokens 36386.200 |tokens/s 64947.279 |walltime 386.505 |
Transformer | epoch 0 | step 680 |avg loss 9.093 |avg tokens 36059.300 |tokens/s 64280.751 |walltime 392.114 |
Transformer | epoch 0 | step 690 |avg loss 9.051 |avg tokens 36752.300 |tokens/s 65936.432 |walltime 397.688 |
Transformer | epoch 0 | step 700 |avg loss 9.005 |avg tokens 36215.400 |tokens/s 64895.372 |walltime 403.269 |
Transformer | epoch 0 | step 710 |avg loss 8.964 |avg tokens 36495.700 |tokens/s 65025.628 |walltime 408.881 |
Transformer | epoch 0 | step 720 |avg loss 8.977 |avg tokens 37266.500 |tokens/s 66337.035 |walltime 414.499 |
Transformer | epoch 0 | step 730 |avg loss 8.903 |avg tokens 35855.800 |tokens/s 64281.207 |walltime 420.077 |
Transformer | epoch 0 | step 740 |avg loss 8.803 |avg tokens 36153.600 |tokens/s 64348.846 |walltime 425.695 |
Transformer | epoch 0 | step 750 |avg loss 8.835 |avg tokens 35404.000 |tokens/s 62761.924 |walltime 431.336 |
Transformer | epoch 0 | step 760 |avg loss 8.635 |avg tokens 35811.000 |tokens/s 63715.217 |walltime 436.957 |
Transformer | epoch 0 | step 770 |avg loss 8.778 |avg tokens 34865.400 |tokens/s 62200.545 |walltime 442.562 |
Transformer | epoch 0 | step 780 |avg loss 8.739 |avg tokens 35609.800 |tokens/s 62731.838 |walltime 448.239 |
Transformer | epoch 0 | step 790 |avg loss 8.720 |avg tokens 37581.700 |tokens/s 67113.300 |walltime 453.838 |
Transformer | epoch 0 | step 800 |avg loss 8.654 |avg tokens 36594.500 |tokens/s 65465.384 |walltime 459.428 |
Transformer | epoch 0 | step 810 |avg loss 8.580 |avg tokens 35854.800 |tokens/s 64213.500 |walltime 465.012 |
Transformer | epoch 0 | step 820 |avg loss 8.674 |avg tokens 36356.700 |tokens/s 64867.296 |walltime 470.617 |
Transformer | epoch 0 | step 830 |avg loss 8.551 |avg tokens 35969.400 |tokens/s 63676.946 |walltime 476.265 |
Transformer | epoch 0 | step 840 |avg loss 8.478 |avg tokens 36199.600 |tokens/s 63979.593 |walltime 481.923 |
Transformer | epoch 0 | step 850 |avg loss 8.545 |avg tokens 36108.100 |tokens/s 64033.959 |walltime 487.562 |
Transformer | epoch 0 | step 860 |avg loss 8.396 |avg tokens 37240.800 |tokens/s 66314.486 |walltime 493.178 |
Transformer | epoch 0 | step 870 |avg loss 8.423 |avg tokens 35402.500 |tokens/s 63480.694 |walltime 498.755 |
Transformer | epoch 0 | step 880 |avg loss 8.329 |avg tokens 36533.800 |tokens/s 65411.182 |walltime 504.340 |
Transformer | epoch 0 | step 890 |avg loss 8.516 |avg tokens 36251.800 |tokens/s 65277.007 |walltime 509.894 |
Transformer | epoch 0 | step 900 |avg loss 8.400 |avg tokens 35058.200 |tokens/s 63468.868 |walltime 515.418 |
Transformer | epoch 0 | step 910 |avg loss 8.276 |avg tokens 36559.100 |tokens/s 65197.205 |walltime 521.025 |
Transformer | epoch 0 | step 920 |avg loss 8.171 |avg tokens 36726.100 |tokens/s 65783.091 |walltime 526.608 |
Transformer | epoch 0 | step 930 |avg loss 8.054 |avg tokens 36889.500 |tokens/s 65540.142 |walltime 532.236 |
Transformer | epoch 0 | step 940 |avg loss 8.133 |avg tokens 36701.000 |tokens/s 65470.888 |walltime 537.842 |
Transformer | epoch 0 | step 950 |avg loss 8.056 |avg tokens 36234.100 |tokens/s 64149.643 |walltime 543.491 |
Transformer | epoch 0 | step 960 |avg loss 8.148 |avg tokens 35903.900 |tokens/s 63773.640 |walltime 549.120 |
Transformer | epoch 0 | step 970 |avg loss 8.120 |avg tokens 36004.500 |tokens/s 63991.938 |walltime 554.747 |
Transformer | epoch 0 | step 980 |avg loss 7.945 |avg tokens 37538.500 |tokens/s 66426.115 |walltime 560.398 |
Transformer | epoch 0 | step 990 |avg loss 8.080 |avg tokens 35128.800 |tokens/s 63049.362 |walltime 565.970 |
Transformer | epoch 0 | step 1000 |avg loss 7.847 |avg tokens 36544.200 |tokens/s 65291.373 |walltime 571.567 |
Transformer | epoch 0 | step 1010 |avg loss 7.750 |avg tokens 37413.200 |tokens/s 65938.057 |walltime 577.241 |
Transformer | epoch 0 | step 1020 |avg loss 7.884 |avg tokens 36832.000 |tokens/s 65449.583 |walltime 582.868 |
Transformer | epoch 0 | step 1030 |avg loss 7.896 |avg tokens 36775.200 |tokens/s 65108.990 |walltime 588.517 |
Transformer | epoch 0 | step 1040 |avg loss 8.022 |avg tokens 36508.000 |tokens/s 65079.374 |walltime 594.126 |
Transformer | epoch 0 | step 1050 |avg loss 7.800 |avg tokens 35987.200 |tokens/s 63614.860 |walltime 599.783 |
Transformer | epoch 0 | step 1060 |avg loss 7.819 |avg tokens 36100.000 |tokens/s 64453.335 |walltime 605.384 |
Transformer | epoch 0 | step 1070 |avg loss 7.806 |avg tokens 36058.600 |tokens/s 64518.670 |walltime 610.973 |
Transformer | epoch 0 | step 1080 |avg loss 7.831 |avg tokens 36278.200 |tokens/s 65326.356 |walltime 616.527 |
Transformer | epoch 0 | step 1090 |avg loss 7.859 |avg tokens 35212.000 |tokens/s 62395.032 |walltime 622.170 |
Transformer | epoch 0 | step 1100 |avg loss 7.768 |avg tokens 36329.000 |tokens/s 64608.497 |walltime 627.793 |
Transformer | epoch 0 | step 1110 |avg loss 7.437 |avg tokens 36461.200 |tokens/s 65003.620 |walltime 633.402 |
Transformer | epoch 0 | step 1120 |avg loss 7.705 |avg tokens 35964.400 |tokens/s 63962.654 |walltime 639.025 |
Transformer | epoch 0 | step 1130 |avg loss 7.640 |avg tokens 35509.400 |tokens/s 63773.885 |walltime 644.593 |
Transformer | epoch 0 | step 1140 |avg loss 7.502 |avg tokens 36292.400 |tokens/s 65141.482 |walltime 650.164 |
Transformer | epoch 0 | step 1150 |avg loss 7.633 |avg tokens 36251.700 |tokens/s 64759.564 |walltime 655.762 |
Transformer | epoch 0 | step 1160 |avg loss 7.492 |avg tokens 36813.100 |tokens/s 65281.843 |walltime 661.401 |
Transformer | epoch 0 | step 1170 |avg loss 7.386 |avg tokens 34779.400 |tokens/s 62361.800 |walltime 666.978 |
Transformer | epoch 0 | step 1180 |avg loss 7.381 |avg tokens 35989.900 |tokens/s 63907.859 |walltime 672.610 |
Transformer | epoch 0 | step 1190 |avg loss 7.289 |avg tokens 35973.000 |tokens/s 63862.339 |walltime 678.243 |
Transformer | epoch 0 | step 1200 |avg loss 7.161 |avg tokens 35888.100 |tokens/s 63594.780 |walltime 683.886 |
Transformer | epoch 0 | step 1210 |avg loss 7.132 |avg tokens 36610.900 |tokens/s 65267.243 |walltime 689.495 |
Transformer | epoch 0 | step 1220 |avg loss 7.386 |avg tokens 36055.500 |tokens/s 65132.765 |walltime 695.031 |
Transformer | epoch 0 | step 1230 |avg loss 7.289 |avg tokens 36480.700 |tokens/s 64679.975 |walltime 700.671 |
Transformer | epoch 0 | step 1240 |avg loss 7.305 |avg tokens 36605.000 |tokens/s 65370.211 |walltime 706.271 |
Transformer | epoch 0 | step 1250 |avg loss 7.096 |avg tokens 36907.900 |tokens/s 65675.065 |walltime 711.890 |
Transformer | epoch 0 | step 1260 |avg loss 7.060 |avg tokens 37134.300 |tokens/s 66222.879 |walltime 717.498 |
Transformer | epoch 0 | step 1270 |avg loss 7.356 |avg tokens 34626.000 |tokens/s 62350.622 |walltime 723.051 |
Transformer | epoch 0 | step 1280 |avg loss 7.167 |avg tokens 35757.700 |tokens/s 63479.496 |walltime 728.684 |
Transformer | epoch 0 | step 1290 |avg loss 6.958 |avg tokens 36523.100 |tokens/s 64664.210 |walltime 734.332 |
Transformer | epoch 0 | step 1300 |avg loss 7.075 |avg tokens 35750.900 |tokens/s 64419.443 |walltime 739.882 |
Transformer | epoch 0 | step 1310 |avg loss 7.016 |avg tokens 36725.500 |tokens/s 65492.733 |walltime 745.490 |
Transformer | epoch 0 | step 1320 |avg loss 6.978 |avg tokens 35968.400 |tokens/s 64096.608 |walltime 751.101 |
Transformer | epoch 0 | step 1330 |avg loss 7.031 |avg tokens 36382.000 |tokens/s 64931.453 |walltime 756.705 |
Transformer | epoch 0 | step 1340 |avg loss 6.907 |avg tokens 35955.100 |tokens/s 64710.390 |walltime 762.261 |
Transformer | epoch 0 | step 1350 |avg loss 6.639 |avg tokens 36287.100 |tokens/s 64045.263 |walltime 767.927 |
Transformer | epoch 0 | step 1360 |avg loss 6.819 |avg tokens 35899.600 |tokens/s 64624.333 |walltime 773.482 |
Transformer | epoch 0 | step 1370 |avg loss 6.893 |avg tokens 35787.000 |tokens/s 64094.511 |walltime 779.065 |
Transformer | epoch 0 | step 1380 |avg loss 6.784 |avg tokens 35517.800 |tokens/s 62936.593 |walltime 784.709 |
Transformer | epoch 0 | step 1390 |avg loss 6.970 |avg tokens 35749.300 |tokens/s 63486.882 |walltime 790.340 |
Transformer | epoch 0 | step 1400 |avg loss 6.679 |avg tokens 36742.600 |tokens/s 65447.786 |walltime 795.954 |
Transformer | epoch 0 | step 1410 |avg loss 6.627 |avg tokens 36381.900 |tokens/s 64900.401 |walltime 801.560 |
Transformer | epoch 0 | step 1420 |avg loss 6.579 |avg tokens 36782.500 |tokens/s 65150.210 |walltime 807.205 |
Transformer | epoch 0 | step 1430 |avg loss 6.638 |avg tokens 36470.400 |tokens/s 65272.871 |walltime 812.793 |
Transformer | epoch 0 | step 1440 |avg loss 6.786 |avg tokens 36225.200 |tokens/s 64101.661 |walltime 818.444 |
Transformer | epoch 0 | step 1450 |avg loss 7.017 |avg tokens 34957.800 |tokens/s 63768.043 |walltime 823.926 |
Transformer | epoch 0 | step 1460 |avg loss 6.645 |avg tokens 36867.500 |tokens/s 65474.580 |walltime 829.557 |
Transformer | epoch 0 | step 1470 |avg loss 6.639 |avg tokens 35118.700 |tokens/s 62865.284 |walltime 835.143 |
Transformer | epoch 0 | step 1480 |avg loss 6.407 |avg tokens 36624.600 |tokens/s 65112.100 |walltime 840.768 |
Transformer | epoch 0 | step 1490 |avg loss 6.773 |avg tokens 36014.000 |tokens/s 64720.044 |walltime 846.333 |
Transformer | epoch 0 | step 1500 |avg loss 6.555 |avg tokens 35537.000 |tokens/s 63485.034 |walltime 851.930 |
Transformer | epoch 0 | step 1510 |avg loss 6.639 |avg tokens 34541.800 |tokens/s 61498.763 |walltime 857.547 |
Transformer | epoch 0 | step 1520 |avg loss 6.653 |avg tokens 36400.500 |tokens/s 65391.515 |walltime 863.113 |
Transformer | epoch 0 | step 1530 |avg loss 6.793 |avg tokens 34325.700 |tokens/s 61273.621 |walltime 868.716 |
Transformer | epoch 0 | step 1540 |avg loss 6.517 |avg tokens 36439.500 |tokens/s 65612.249 |walltime 874.269 |
Transformer | epoch 0 | step 1550 |avg loss 6.341 |avg tokens 35970.100 |tokens/s 64614.265 |walltime 879.836 |
Transformer | epoch 0 | step 1560 |avg loss 6.293 |avg tokens 36157.400 |tokens/s 64201.158 |walltime 885.468 |
Transformer | epoch 0 | step 1570 |avg loss 6.209 |avg tokens 34335.400 |tokens/s 61726.271 |walltime 891.031 |
Transformer | epoch 0 | step 1580 |avg loss 6.328 |avg tokens 37072.000 |tokens/s 65970.826 |walltime 896.650 |
Transformer | epoch 0 | step 1590 |avg loss 6.459 |avg tokens 35875.500 |tokens/s 63843.479 |walltime 902.269 |
Transformer | epoch 0 | step 1600 |avg loss 6.441 |avg tokens 37460.200 |tokens/s 66840.288 |walltime 907.874 |
Transformer | epoch 0 | step 1610 |avg loss 6.271 |avg tokens 35985.400 |tokens/s 64249.296 |walltime 913.475 |
Transformer | epoch 0 | step 1620 |avg loss 6.288 |avg tokens 36848.000 |tokens/s 65806.748 |walltime 919.074 |
Transformer | epoch 0 | step 1630 |avg loss 6.164 |avg tokens 36044.800 |tokens/s 64028.133 |walltime 924.704 |
Transformer | epoch 0 | step 1640 |avg loss 6.414 |avg tokens 35081.300 |tokens/s 63215.690 |walltime 930.253 |
Transformer | epoch 0 | step 1650 |avg loss 6.309 |avg tokens 34979.500 |tokens/s 63076.697 |walltime 935.799 |
Transformer | epoch 0 | step 1660 |avg loss 6.174 |avg tokens 37309.600 |tokens/s 66756.760 |walltime 941.388 |
Transformer | epoch 0 | step 1670 |avg loss 6.222 |avg tokens 35985.700 |tokens/s 64007.492 |walltime 947.010 |
Transformer | epoch 0 | step 1680 |avg loss 6.288 |avg tokens 35969.400 |tokens/s 64091.119 |walltime 952.622 |
Transformer | epoch 0 | step 1690 |avg loss 6.293 |avg tokens 36207.600 |tokens/s 64933.449 |walltime 958.198 |
Transformer | epoch 0 | step 1700 |avg loss 6.358 |avg tokens 34453.400 |tokens/s 62238.863 |walltime 963.734 |
Transformer | epoch 0 | step 1710 |avg loss 6.150 |avg tokens 36328.300 |tokens/s 64282.082 |walltime 969.385 |
Transformer | epoch 0 | step 1720 |avg loss 6.309 |avg tokens 36816.700 |tokens/s 65564.905 |walltime 975.000 |
Transformer | epoch 0 | step 1730 |avg loss 6.162 |avg tokens 36628.200 |tokens/s 65574.474 |walltime 980.586 |
Transformer | epoch 0 | step 1740 |avg loss 5.943 |avg tokens 36708.600 |tokens/s 65211.708 |walltime 986.215 |
Transformer | epoch 0 | step 1750 |avg loss 5.926 |avg tokens 36145.100 |tokens/s 64344.492 |walltime 991.833 |
Transformer | epoch 0 | step 1760 |avg loss 6.004 |avg tokens 37601.200 |tokens/s 67036.797 |walltime 997.442 |
Transformer | epoch 0 | step 1770 |avg loss 6.233 |avg tokens 35597.600 |tokens/s 63302.983 |walltime 1003.065 |
Transformer | epoch 0 | step 1780 |avg loss 6.185 |avg tokens 35243.500 |tokens/s 63301.567 |walltime 1008.633 |
Transformer | epoch 0 | step 1790 |avg loss 5.793 |avg tokens 37180.100 |tokens/s 65979.244 |walltime 1014.268 |
Transformer | epoch 0 | step 1800 |avg loss 6.098 |avg tokens 36478.700 |tokens/s 65418.833 |walltime 1019.844 |
Transformer | epoch 0 | step 1810 |avg loss 6.202 |avg tokens 35449.500 |tokens/s 63475.225 |walltime 1025.429 |
Transformer | epoch 0 | step 1820 |avg loss 6.296 |avg tokens 35443.800 |tokens/s 64096.321 |walltime 1030.959 |
Transformer | epoch 0 | step 1830 |avg loss 6.165 |avg tokens 36242.500 |tokens/s 64225.354 |walltime 1036.602 |
Transformer | epoch 0 | step 1840 |avg loss 6.251 |avg tokens 35210.100 |tokens/s 63303.395 |walltime 1042.164 |
Transformer | epoch 0 | step 1850 |avg loss 6.199 |avg tokens 36155.600 |tokens/s 64651.155 |walltime 1047.756 |
Transformer | epoch 0 | step 1860 |avg loss 5.811 |avg tokens 36528.100 |tokens/s 64466.302 |walltime 1053.422 |
Transformer | epoch 0 | step 1870 |avg loss 6.136 |avg tokens 36188.500 |tokens/s 64818.557 |walltime 1059.005 |
Transformer | epoch 0 | step 1880 |avg loss 5.845 |avg tokens 36613.000 |tokens/s 65024.557 |walltime 1064.636 |
Transformer | epoch 0 | step 1890 |avg loss 6.110 |avg tokens 36386.900 |tokens/s 65814.850 |walltime 1070.165 |
Transformer | epoch 0 | step 1900 |avg loss 5.951 |avg tokens 36373.500 |tokens/s 64824.811 |walltime 1075.776 |
Transformer | epoch 0 | step 1910 |avg loss 6.077 |avg tokens 34338.400 |tokens/s 61771.818 |walltime 1081.335 |
Transformer | epoch 0 | step 1920 |avg loss 5.991 |avg tokens 37309.500 |tokens/s 66885.112 |walltime 1086.913 |
Transformer | epoch 0 | step 1930 |avg loss 6.062 |avg tokens 35257.700 |tokens/s 62717.596 |walltime 1092.535 |
Transformer | epoch 0 | step 1940 |avg loss 6.028 |avg tokens 35889.100 |tokens/s 64799.662 |walltime 1098.073 |
Transformer | epoch 0 | step 1950 |avg loss 6.072 |avg tokens 35845.800 |tokens/s 64572.672 |walltime 1103.624 |
Transformer | epoch 0 | step 1960 |avg loss 5.783 |avg tokens 36824.700 |tokens/s 65748.143 |walltime 1109.225 |
Transformer | epoch 0 | step 1970 |avg loss 5.881 |avg tokens 36589.200 |tokens/s 65460.429 |walltime 1114.815 |
Transformer | epoch 0 | step 1980 |avg loss 5.981 |avg tokens 36948.500 |tokens/s 65587.442 |walltime 1120.448 |
Transformer | epoch 0 | step 1990 |avg loss 5.974 |avg tokens 36124.500 |tokens/s 64474.625 |walltime 1126.051 |
Transformer | epoch 0 | step 2000 |avg loss 6.056 |avg tokens 36904.500 |tokens/s 66566.216 |walltime 1131.595 |
Transformer | epoch 0 | step 2010 |avg loss 6.125 |avg tokens 35646.600 |tokens/s 64097.605 |walltime 1137.156 |
Transformer | epoch 0 | step 2020 |avg loss 5.847 |avg tokens 35978.100 |tokens/s 64844.816 |walltime 1142.705 |
Transformer | epoch 0 | step 2030 |avg loss 6.012 |avg tokens 35163.200 |tokens/s 62362.084 |walltime 1148.343 |
Transformer | epoch 0 | step 2040 |avg loss 6.069 |avg tokens 34762.500 |tokens/s 61523.352 |walltime 1153.994 |
Transformer | epoch 0 | step 2050 |avg loss 5.782 |avg tokens 36210.400 |tokens/s 64858.830 |walltime 1159.576 |
Transformer | epoch 0 | step 2060 |avg loss 5.715 |avg tokens 36908.700 |tokens/s 65510.136 |walltime 1165.211 |
Transformer | epoch 0 | step 2070 |avg loss 5.761 |avg tokens 37251.900 |tokens/s 66600.501 |walltime 1170.804 |
Transformer | epoch 0 | step 2080 |avg loss 5.714 |avg tokens 36926.600 |tokens/s 65425.367 |walltime 1176.448 |
Transformer | epoch 0 | step 2090 |avg loss 5.706 |avg tokens 36638.200 |tokens/s 65469.284 |walltime 1182.044 |
Transformer | epoch 0 | step 2100 |avg loss 5.668 |avg tokens 36461.200 |tokens/s 65246.802 |walltime 1187.632 |
Transformer | epoch 0 | step 2110 |avg loss 6.028 |avg tokens 36364.600 |tokens/s 65133.078 |walltime 1193.216 |
Transformer | epoch 0 | step 2120 |avg loss 5.812 |avg tokens 37365.500 |tokens/s 67234.251 |walltime 1198.773 |
Transformer | epoch 0 | step 2130 |avg loss 5.782 |avg tokens 35340.600 |tokens/s 62941.136 |walltime 1204.388 |
Transformer | epoch 0 | step 2140 |avg loss 5.715 |avg tokens 36714.600 |tokens/s 65077.883 |walltime 1210.030 |
Transformer | epoch 0 | step 2150 |avg loss 5.735 |avg tokens 35683.600 |tokens/s 63507.673 |walltime 1215.648 |
Transformer | epoch 0 | step 2160 |avg loss 5.703 |avg tokens 35089.100 |tokens/s 62371.446 |walltime 1221.274 |
Transformer | epoch 0 | step 2170 |avg loss 5.680 |avg tokens 37099.500 |tokens/s 66464.228 |walltime 1226.856 |
Transformer | epoch 0 | step 2180 |avg loss 5.683 |avg tokens 35348.600 |tokens/s 63498.337 |walltime 1232.423 |
Transformer | epoch 0 | step 2190 |avg loss 5.890 |avg tokens 35154.700 |tokens/s 63527.768 |walltime 1237.957 |
Transformer | epoch 0 | step 2200 |avg loss 5.645 |avg tokens 35853.200 |tokens/s 63904.984 |walltime 1243.567 |
Transformer | epoch 0 | step 2210 |avg loss 6.036 |avg tokens 34603.600 |tokens/s 62624.350 |walltime 1249.093 |
Transformer | epoch 0 | step 2220 |avg loss 5.693 |avg tokens 36320.100 |tokens/s 64866.356 |walltime 1254.692 |
Transformer | epoch 0 | step 2230 |avg loss 5.821 |avg tokens 36732.700 |tokens/s 65284.177 |walltime 1260.318 |
Transformer | epoch 0 | step 2240 |avg loss 5.698 |avg tokens 36086.000 |tokens/s 64414.838 |walltime 1265.921 |
Transformer | epoch 0 | step 2250 |avg loss 5.685 |avg tokens 36498.300 |tokens/s 64523.128 |walltime 1271.577 |
Transformer | epoch 0 | step 2260 |avg loss 5.601 |avg tokens 35749.800 |tokens/s 63590.123 |walltime 1277.199 |
Transformer | epoch 0 | step 2270 |avg loss 5.783 |avg tokens 36731.900 |tokens/s 65475.194 |walltime 1282.809 |
Transformer | epoch 0 | step 2280 |avg loss 5.579 |avg tokens 36302.000 |tokens/s 65109.176 |walltime 1288.385 |
Transformer | epoch 0 | step 2290 |avg loss 5.841 |avg tokens 34970.800 |tokens/s 62260.357 |walltime 1294.002 |
Transformer | epoch 0 | step 2300 |avg loss 5.712 |avg tokens 36624.000 |tokens/s 65186.575 |walltime 1299.620 |
Transformer | epoch 0 | step 2310 |avg loss 5.673 |avg tokens 36060.100 |tokens/s 64213.024 |walltime 1305.236 |
Transformer | epoch 0 | step 2320 |avg loss 5.802 |avg tokens 36106.500 |tokens/s 65126.331 |walltime 1310.780 |
Transformer | epoch 0 | step 2330 |avg loss 5.788 |avg tokens 36499.400 |tokens/s 65895.234 |walltime 1316.319 |
Transformer | epoch 0 | step 2340 |avg loss 5.587 |avg tokens 37031.900 |tokens/s 66158.586 |walltime 1321.916 |
Transformer | epoch 0 | step 2350 |avg loss 5.636 |avg tokens 36089.900 |tokens/s 64555.474 |walltime 1327.507 |
Transformer | epoch 0 | step 2360 |avg loss 5.650 |avg tokens 35841.700 |tokens/s 64554.721 |walltime 1333.059 |
Transformer | epoch 0 | step 2370 |avg loss 5.394 |avg tokens 36672.700 |tokens/s 66057.261 |walltime 1338.611 |
Transformer | epoch 0 | step 2380 |avg loss 5.724 |avg tokens 35737.600 |tokens/s 64158.416 |walltime 1344.181 |
Transformer | epoch 0 | step 2390 |avg loss 5.733 |avg tokens 35261.300 |tokens/s 63620.796 |walltime 1349.723 |
Transformer | epoch 0 | step 2400 |avg loss 5.627 |avg tokens 36101.900 |tokens/s 63982.442 |walltime 1355.366 |
Transformer | epoch 0 | step 2410 |avg loss 5.791 |avg tokens 35920.400 |tokens/s 64387.717 |walltime 1360.944 |
Transformer | epoch 0 | step 2420 |avg loss 5.651 |avg tokens 36319.900 |tokens/s 65185.383 |walltime 1366.516 |
Transformer | epoch 0 | step 2430 |avg loss 5.492 |avg tokens 37617.200 |tokens/s 67506.456 |walltime 1372.089 |
Transformer | epoch 0 | step 2440 |avg loss 5.346 |avg tokens 37647.000 |tokens/s 66390.976 |walltime 1377.759 |
Transformer | epoch 0 | step 2450 |avg loss 5.772 |avg tokens 35288.900 |tokens/s 63359.853 |walltime 1383.329 |
Transformer | epoch 0 | step 2460 |avg loss 5.623 |avg tokens 36066.600 |tokens/s 64367.078 |walltime 1388.932 |
Transformer | epoch 0 | step 2470 |avg loss 5.579 |avg tokens 36849.600 |tokens/s 66582.506 |walltime 1394.466 |
Transformer | epoch 0 | step 2480 |avg loss 5.679 |avg tokens 36310.400 |tokens/s 64791.777 |walltime 1400.071 |
Transformer | epoch 0 | step 2490 |avg loss 5.573 |avg tokens 36158.600 |tokens/s 64571.992 |walltime 1405.670 |
Transformer | epoch 0 | step 2500 |avg loss 5.717 |avg tokens 35065.200 |tokens/s 63224.570 |walltime 1411.216 |
Transformer | epoch 0 | step 2510 |avg loss 5.608 |avg tokens 35549.500 |tokens/s 63193.824 |walltime 1416.842 |
Transformer | epoch 0 | step 2520 |avg loss 5.744 |avg tokens 36217.900 |tokens/s 64530.265 |walltime 1422.454 |
Transformer | epoch 0 | step 2530 |avg loss 5.532 |avg tokens 36406.900 |tokens/s 64673.507 |walltime 1428.084 |
Transformer | epoch 0 | step 2540 |avg loss 5.692 |avg tokens 35902.600 |tokens/s 64806.746 |walltime 1433.624 |
Transformer | epoch 0 | step 2550 |avg loss 5.455 |avg tokens 36505.700 |tokens/s 64840.500 |walltime 1439.254 |
Transformer | epoch 0 | step 2560 |avg loss 5.703 |avg tokens 36685.600 |tokens/s 65332.080 |walltime 1444.869 |
Transformer | epoch 0 | step 2570 |avg loss 5.641 |avg tokens 35980.000 |tokens/s 64246.125 |walltime 1450.469 |
Transformer | epoch 0 | step 2580 |avg loss 5.425 |avg tokens 36310.400 |tokens/s 65232.891 |walltime 1456.036 |
Transformer | epoch 0 | step 2590 |avg loss 5.610 |avg tokens 36645.500 |tokens/s 65598.306 |walltime 1461.622 |
Transformer | epoch 0 | step 2600 |avg loss 5.669 |avg tokens 35559.600 |tokens/s 63927.428 |walltime 1467.185 |
Transformer | epoch 0 | step 2610 |avg loss 5.694 |avg tokens 36333.900 |tokens/s 65036.632 |walltime 1472.771 |
Transformer | epoch 0 | step 2620 |avg loss 5.513 |avg tokens 35528.800 |tokens/s 63018.397 |walltime 1478.409 |
Transformer | epoch 0 | step 2630 |avg loss 5.442 |avg tokens 35787.100 |tokens/s 64189.225 |walltime 1483.984 |
Transformer | epoch 0 | step 2640 |avg loss 5.556 |avg tokens 34729.600 |tokens/s 62452.590 |walltime 1489.545 |
Transformer | epoch 0 | step 2650 |avg loss 5.516 |avg tokens 36029.100 |tokens/s 65009.792 |walltime 1495.087 |
Transformer | epoch 0 | step 2660 |avg loss 5.467 |avg tokens 37110.000 |tokens/s 66336.307 |walltime 1500.682 |
Transformer | epoch 0 | step 2670 |avg loss 5.590 |avg tokens 36545.500 |tokens/s 65711.788 |walltime 1506.243 |
Transformer | epoch 0 | step 2680 |avg loss 5.434 |avg tokens 36464.400 |tokens/s 64876.081 |walltime 1511.864 |
Transformer | epoch 0 | step 2690 |avg loss 5.513 |avg tokens 35750.600 |tokens/s 64068.487 |walltime 1517.444 |
Transformer | epoch 0 | step 2700 |avg loss 5.646 |avg tokens 35720.200 |tokens/s 63468.620 |walltime 1523.072 |
Transformer | epoch 0 | step 2710 |avg loss 5.687 |avg tokens 36326.000 |tokens/s 64813.674 |walltime 1528.676 |
Transformer | epoch 0 | step 2720 |avg loss 5.487 |avg tokens 36119.800 |tokens/s 64400.305 |walltime 1534.285 |
Transformer | epoch 0 | step 2730 |avg loss 5.511 |avg tokens 35842.800 |tokens/s 63295.621 |walltime 1539.948 |
Transformer | epoch 0 | step 2740 |avg loss 5.522 |avg tokens 37440.900 |tokens/s 66361.845 |walltime 1545.590 |
Transformer | epoch 0 | step 2750 |avg loss 5.766 |avg tokens 34907.400 |tokens/s 62218.078 |walltime 1551.200 |
Transformer | epoch 0 | step 2760 |avg loss 5.583 |avg tokens 35823.000 |tokens/s 64365.531 |walltime 1556.766 |
Transformer | epoch 0 | step 2770 |avg loss 5.671 |avg tokens 35410.200 |tokens/s 63170.442 |walltime 1562.371 |
Transformer | epoch 0 | step 2780 |avg loss 5.554 |avg tokens 36572.000 |tokens/s 65871.144 |walltime 1567.923 |
Transformer | epoch 0 | step 2790 |avg loss 5.428 |avg tokens 36850.800 |tokens/s 66093.376 |walltime 1573.499 |
Transformer | epoch 0 | step 2800 |avg loss 5.514 |avg tokens 37341.400 |tokens/s 67061.418 |walltime 1579.067 |
Transformer | epoch 0 | step 2810 |avg loss 5.523 |avg tokens 34741.900 |tokens/s 62592.851 |walltime 1584.618 |
Transformer | epoch 0 | step 2820 |avg loss 5.460 |avg tokens 36183.000 |tokens/s 64974.746 |walltime 1590.186 |
Transformer | epoch 0 | step 2830 |avg loss 5.663 |avg tokens 36044.000 |tokens/s 64219.171 |walltime 1595.799 |
Transformer | epoch 0 | step 2840 |avg loss 5.410 |avg tokens 36000.000 |tokens/s 64558.618 |walltime 1601.375 |
Transformer | epoch 0 | step 2850 |avg loss 5.435 |avg tokens 35787.300 |tokens/s 63912.784 |walltime 1606.975 |
Transformer | epoch 0 | step 2860 |avg loss 5.325 |avg tokens 37031.000 |tokens/s 66215.643 |walltime 1612.567 |
Transformer | epoch 0 | step 2870 |avg loss 5.440 |avg tokens 36597.000 |tokens/s 66142.466 |walltime 1618.100 |
Transformer | epoch 0 | step 2880 |avg loss 5.598 |avg tokens 34244.300 |tokens/s 61538.765 |walltime 1623.665 |
Transformer | epoch 0 | step 2890 |avg loss 5.200 |avg tokens 36816.100 |tokens/s 66148.303 |walltime 1629.231 |
Transformer | epoch 0 | step 2900 |avg loss 5.445 |avg tokens 36293.000 |tokens/s 64364.611 |walltime 1634.869 |
Transformer | epoch 0 | step 2910 |avg loss 5.482 |avg tokens 34771.000 |tokens/s 62527.306 |walltime 1640.430 |
Transformer | epoch 0 | step 2920 |avg loss 5.256 |avg tokens 37295.800 |tokens/s 66467.332 |walltime 1646.042 |
Transformer | epoch 0 | step 2930 |avg loss 5.483 |avg tokens 36186.400 |tokens/s 65008.422 |walltime 1651.608 |
Transformer | epoch 0 | step 2940 |avg loss 5.307 |avg tokens 35704.600 |tokens/s 64071.186 |walltime 1657.181 |
Transformer | epoch 0 | step 2950 |avg loss 5.511 |avg tokens 36359.300 |tokens/s 64847.164 |walltime 1662.788 |
Transformer | epoch 0 | step 2960 |avg loss 5.323 |avg tokens 36479.500 |tokens/s 64631.102 |walltime 1668.432 |
Transformer | epoch 0 | step 2970 |avg loss 5.371 |avg tokens 36470.200 |tokens/s 64992.063 |walltime 1674.043 |
Transformer | epoch 0 | step 2980 |avg loss 5.545 |avg tokens 35176.700 |tokens/s 63196.663 |walltime 1679.610 |
Transformer | epoch 0 | step 2990 |avg loss 5.434 |avg tokens 36282.900 |tokens/s 65047.627 |walltime 1685.187 |
Transformer | epoch 0 | step 3000 |avg loss 5.616 |avg tokens 34544.300 |tokens/s 61899.422 |walltime 1690.768 |
Transformer | epoch 0 | step 3010 |avg loss 5.290 |avg tokens 36338.200 |tokens/s 64913.992 |walltime 1696.366 |
Transformer | epoch 0 | step 3020 |avg loss 5.337 |avg tokens 36339.500 |tokens/s 64029.331 |walltime 1702.041 |
Transformer | epoch 0 | step 3030 |avg loss 5.383 |avg tokens 36326.500 |tokens/s 65230.453 |walltime 1707.610 |
Transformer | epoch 0 | step 3040 |avg loss 5.497 |avg tokens 35450.200 |tokens/s 62855.120 |walltime 1713.250 |
Transformer | epoch 0 | step 3050 |avg loss 5.344 |avg tokens 36082.900 |tokens/s 65041.773 |walltime 1718.798 |
Transformer | epoch 0 | step 3060 |avg loss 5.394 |avg tokens 35955.500 |tokens/s 64039.256 |walltime 1724.413 |
Transformer | epoch 0 | step 3070 |avg loss 5.470 |avg tokens 36254.500 |tokens/s 64962.098 |walltime 1729.994 |
Transformer | epoch 0 | step 3080 |avg loss 5.349 |avg tokens 36440.500 |tokens/s 65423.832 |walltime 1735.563 |
Transformer | epoch 0 | step 3090 |avg loss 5.356 |avg tokens 35200.400 |tokens/s 63535.356 |walltime 1741.104 |
Transformer | epoch 0 | step 3100 |avg loss 5.231 |avg tokens 36757.500 |tokens/s 65164.186 |walltime 1746.745 |
Transformer | epoch 0 | step 3110 |avg loss 5.393 |avg tokens 36362.400 |tokens/s 65240.564 |walltime 1752.318 |
Transformer | epoch 0 | step 3120 |avg loss 5.154 |avg tokens 36796.800 |tokens/s 65697.396 |walltime 1757.919 |
Transformer | epoch 0 | step 3130 |avg loss 5.374 |avg tokens 36962.500 |tokens/s 65801.152 |walltime 1763.536 |
Transformer | epoch 0 | step 3140 |avg loss 5.532 |avg tokens 34783.100 |tokens/s 62939.795 |walltime 1769.063 |
Transformer | epoch 0 | step 3150 |avg loss 5.647 |avg tokens 36153.400 |tokens/s 65244.615 |walltime 1774.604 |
Transformer | epoch 0 | step 3160 |avg loss 5.290 |avg tokens 36298.500 |tokens/s 64588.359 |walltime 1780.224 |
Transformer | epoch 0 | step 3170 |avg loss 5.355 |avg tokens 36006.700 |tokens/s 64640.982 |walltime 1785.794 |
Transformer | epoch 0 | step 3180 |avg loss 5.517 |avg tokens 36032.600 |tokens/s 64711.783 |walltime 1791.362 |
Transformer | epoch 0 | step 3190 |avg loss 5.367 |avg tokens 34962.800 |tokens/s 62666.444 |walltime 1796.942 |
Transformer | epoch 0 | step 3200 |avg loss 5.296 |avg tokens 35624.600 |tokens/s 64115.978 |walltime 1802.498 |
Transformer | epoch 0 | step 3210 |avg loss 5.283 |avg tokens 35404.400 |tokens/s 63072.367 |walltime 1808.111 |
Transformer | epoch 0 | step 3220 |avg loss 5.341 |avg tokens 36848.500 |tokens/s 65596.774 |walltime 1813.729 |
Transformer | epoch 0 | step 3230 |avg loss 5.220 |avg tokens 36252.700 |tokens/s 64616.514 |walltime 1819.339 |
Transformer | epoch 0 | step 3240 |avg loss 5.272 |avg tokens 36454.000 |tokens/s 65587.845 |walltime 1824.897 |
Transformer | epoch 0 | step 3250 |avg loss 5.119 |avg tokens 36692.900 |tokens/s 64963.443 |walltime 1830.545 |
Transformer | epoch 0 | step 3260 |avg loss 5.300 |avg tokens 36668.900 |tokens/s 65546.415 |walltime 1836.140 |
Transformer | epoch 0 | step 3270 |avg loss 5.306 |avg tokens 34839.800 |tokens/s 62569.277 |walltime 1841.708 |
Transformer | epoch 0 | step 3280 |avg loss 5.401 |avg tokens 36908.400 |tokens/s 66227.252 |walltime 1847.281 |
Transformer | epoch 0 | step 3290 |avg loss 5.330 |avg tokens 35133.000 |tokens/s 63511.723 |walltime 1852.813 |
Transformer | epoch 0 | step 3300 |avg loss 5.386 |avg tokens 35928.700 |tokens/s 64470.667 |walltime 1858.386 |
Transformer | epoch 0 | step 3310 |avg loss 5.402 |avg tokens 35760.800 |tokens/s 64251.317 |walltime 1863.951 |
Transformer | epoch 0 | step 3320 |avg loss 5.222 |avg tokens 36564.300 |tokens/s 64951.169 |walltime 1869.581 |
Transformer | epoch 0 | step 3330 |avg loss 5.328 |avg tokens 35827.800 |tokens/s 63908.800 |walltime 1875.187 |
Transformer | epoch 0 | step 3340 |avg loss 5.099 |avg tokens 36544.700 |tokens/s 65044.792 |walltime 1880.805 |
Transformer | epoch 0 | step 3350 |avg loss 5.293 |avg tokens 35752.700 |tokens/s 64050.718 |walltime 1886.387 |
Transformer | epoch 0 | step 3360 |avg loss 5.281 |avg tokens 36316.000 |tokens/s 65254.559 |walltime 1891.952 |
Transformer | epoch 0 | step 3370 |avg loss 5.384 |avg tokens 35782.100 |tokens/s 64248.675 |walltime 1897.522 |
Transformer | epoch 0 | step 3380 |avg loss 5.281 |avg tokens 36758.900 |tokens/s 64391.712 |walltime 1903.230 |
Transformer | epoch 0 | step 3390 |avg loss 5.142 |avg tokens 35394.800 |tokens/s 63534.966 |walltime 1908.801 |
Transformer | epoch 0 | step 3400 |avg loss 5.394 |avg tokens 34768.500 |tokens/s 62156.767 |walltime 1914.395 |
Transformer | epoch 0 | step 3410 |avg loss 5.367 |avg tokens 36088.600 |tokens/s 64712.100 |walltime 1919.972 |
Transformer | epoch 0 | step 3420 |avg loss 5.385 |avg tokens 36991.600 |tokens/s 66054.121 |walltime 1925.572 |
Transformer | epoch 0 | step 3430 |avg loss 5.224 |avg tokens 37379.600 |tokens/s 66513.726 |walltime 1931.192 |
Transformer | epoch 0 | step 3440 |avg loss 5.186 |avg tokens 36281.800 |tokens/s 65250.395 |walltime 1936.752 |
Transformer | epoch 0 | step 3450 |avg loss 5.264 |avg tokens 35690.000 |tokens/s 62888.896 |walltime 1942.427 |
Transformer | epoch 0 | step 3460 |avg loss 5.140 |avg tokens 37807.400 |tokens/s 67173.873 |walltime 1948.056 |
Transformer | epoch 0 | step 3470 |avg loss 5.360 |avg tokens 36970.600 |tokens/s 66370.007 |walltime 1953.626 |
Transformer | epoch 0 | step 3480 |avg loss 5.284 |avg tokens 35909.300 |tokens/s 64389.772 |walltime 1959.203 |
Transformer | epoch 0 | step 3490 |avg loss 5.428 |avg tokens 37198.800 |tokens/s 66512.801 |walltime 1964.796 |
Transformer | epoch 0 | step 3500 |avg loss 5.301 |avg tokens 36577.500 |tokens/s 65577.070 |walltime 1970.373 |
Transformer | epoch 0 | step 3510 |avg loss 5.426 |avg tokens 34677.800 |tokens/s 62532.109 |walltime 1975.919 |
Transformer | epoch 0 | step 3520 |avg loss 5.389 |avg tokens 36402.000 |tokens/s 65024.527 |walltime 1981.517 |
Transformer | epoch 0 | step 3530 |avg loss 5.558 |avg tokens 35747.100 |tokens/s 63978.465 |walltime 1987.105 |
Transformer | epoch 0 | step 3540 |avg loss 5.248 |avg tokens 35163.900 |tokens/s 62836.575 |walltime 1992.701 |
Transformer | epoch 0 | step 3550 |avg loss 5.336 |avg tokens 34664.300 |tokens/s 62534.051 |walltime 1998.244 |
Transformer | epoch 0 | step 3560 |avg loss 5.457 |avg tokens 35242.700 |tokens/s 64010.611 |walltime 2003.750 |
Transformer | epoch 0 | step 3570 |avg loss 5.193 |avg tokens 36701.600 |tokens/s 65238.344 |walltime 2009.376 |
Transformer | epoch 0 | step 3580 |avg loss 5.483 |avg tokens 35129.600 |tokens/s 63689.521 |walltime 2014.891 |
Transformer | epoch 0 | step 3590 |avg loss 5.287 |avg tokens 36498.600 |tokens/s 64950.795 |walltime 2020.511 |
Transformer | epoch 0 | step 3600 |avg loss 5.310 |avg tokens 36020.200 |tokens/s 64731.802 |walltime 2026.075 |
Transformer | epoch 0 | step 3610 |avg loss 5.302 |avg tokens 36411.200 |tokens/s 64936.553 |walltime 2031.682 |
Transformer | epoch 0 | step 3620 |avg loss 5.234 |avg tokens 37351.500 |tokens/s 66541.003 |walltime 2037.296 |
Transformer | epoch 0 | step 3630 |avg loss 5.295 |avg tokens 37042.600 |tokens/s 66070.348 |walltime 2042.902 |
Transformer | epoch 0 | step 3640 |avg loss 5.173 |avg tokens 36087.100 |tokens/s 64207.600 |walltime 2048.523 |
Transformer | epoch 0 | step 3650 |avg loss 5.481 |avg tokens 35986.500 |tokens/s 65004.090 |walltime 2054.059 |
Transformer | epoch 0 | step 3660 |avg loss 5.359 |avg tokens 36119.300 |tokens/s 64601.200 |walltime 2059.650 |
Transformer | epoch 0 | step 3670 |avg loss 5.219 |avg tokens 36178.600 |tokens/s 64896.625 |walltime 2065.225 |
Transformer | epoch 0 | step 3680 |avg loss 5.165 |avg tokens 36419.300 |tokens/s 65298.687 |walltime 2070.802 |
Transformer | epoch 0 | step 3690 |avg loss 5.154 |avg tokens 37402.000 |tokens/s 67118.910 |walltime 2076.374 |
Transformer | epoch 0 | step 3700 |avg loss 5.287 |avg tokens 36143.600 |tokens/s 65320.052 |walltime 2081.908 |
Transformer | epoch 0 | step 3710 |avg loss 5.473 |avg tokens 34846.100 |tokens/s 62987.226 |walltime 2087.440 |
Transformer | epoch 0 | step 3720 |avg loss 5.282 |avg tokens 36431.500 |tokens/s 65729.330 |walltime 2092.983 |
Transformer | epoch 0 | step 3730 |avg loss 5.264 |avg tokens 36829.800 |tokens/s 65875.420 |walltime 2098.574 |
Transformer | epoch 0 | step 3740 |avg loss 5.290 |avg tokens 36621.000 |tokens/s 66082.725 |walltime 2104.115 |
Transformer | epoch 0 | step 3750 |avg loss 5.245 |avg tokens 35978.800 |tokens/s 64214.545 |walltime 2109.718 |
Transformer | epoch 0 | step 3760 |avg loss 5.427 |avg tokens 35774.800 |tokens/s 64601.138 |walltime 2115.256 |
Transformer | epoch 0 | step 3770 |avg loss 5.179 |avg tokens 36711.800 |tokens/s 65730.813 |walltime 2120.841 |
Transformer | epoch 0 | step 3780 |avg loss 5.133 |avg tokens 36118.300 |tokens/s 64676.179 |walltime 2126.426 |
Transformer | epoch 0 | step 3790 |avg loss 5.181 |avg tokens 36115.400 |tokens/s 64395.717 |walltime 2132.034 |
Transformer | epoch 0 | step 3800 |avg loss 5.344 |avg tokens 37066.800 |tokens/s 63988.581 |walltime 2137.827 |
Transformer | epoch 0 | step 3810 |avg loss 5.323 |avg tokens 36092.700 |tokens/s 64803.603 |walltime 2143.396 |
Transformer | epoch 0 | step 3820 |avg loss 5.248 |avg tokens 36613.100 |tokens/s 66671.624 |walltime 2148.888 |
Transformer | epoch 0 | step 3830 |avg loss 5.368 |avg tokens 34870.700 |tokens/s 62228.880 |walltime 2154.491 |
Transformer | epoch 0 | step 3840 |avg loss 5.315 |avg tokens 35333.100 |tokens/s 63374.949 |walltime 2160.067 |
Transformer | epoch 0 | step 3850 |avg loss 5.121 |avg tokens 35828.900 |tokens/s 63536.658 |walltime 2165.706 |
Transformer | epoch 0 | step 3860 |avg loss 4.963 |avg tokens 36581.500 |tokens/s 65291.618 |walltime 2171.309 |
Transformer | epoch 0 | step 3870 |avg loss 5.129 |avg tokens 36795.500 |tokens/s 65277.563 |walltime 2176.945 |
Transformer | epoch 0 | step 3880 |avg loss 5.287 |avg tokens 36599.100 |tokens/s 65138.380 |walltime 2182.564 |
Transformer | epoch 0 | step 3890 |avg loss 5.304 |avg tokens 36567.200 |tokens/s 66124.207 |walltime 2188.094 |
Transformer | epoch 0 | step 3900 |avg loss 5.070 |avg tokens 35716.200 |tokens/s 64167.968 |walltime 2193.660 |
Transformer | epoch 0 | step 3910 |avg loss 5.078 |avg tokens 36426.200 |tokens/s 65250.020 |walltime 2199.243 |
Transformer | epoch 0 | step 3920 |avg loss 5.175 |avg tokens 36005.800 |tokens/s 64655.190 |walltime 2204.812 |
Transformer | epoch 0 | step 3930 |avg loss 5.092 |avg tokens 35078.800 |tokens/s 62638.118 |walltime 2210.412 |
Epoch time: 2202.4057261943817
Transformer | epoch 0 | step 3935 |avg loss 4.956 |avg tokens 38298.400 |tokens/s 56566.016 |walltime 2213.797 |
Validation loss on subset valid: 4.781688668926569
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [38].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [38], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [82].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [82].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [119].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [119].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [82], which does not match the required output shape [150].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [82], which does not match the required output shape [150].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [92, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [83, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [92, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [119], which does not match the required output shape [149].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [119], which does not match the required output shape [149].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [83, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [92, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [161].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [161].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [92, 8], which does not match the required output shape [60, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [149], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [149], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [83, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [83, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [161], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [161], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [60, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [18, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [18, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [150].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [150].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [82].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [82].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [69, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [130].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [150], which does not match the required output shape [130].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [83].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [83].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [82], which does not match the required output shape [133].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [82], which does not match the required output shape [133].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [69, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [130], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [83], which does not match the required output shape [148].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [83], which does not match the required output shape [148].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [90, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [133], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [133], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [56, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [90, 8], which does not match the required output shape [56, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [148], which does not match the required output shape [136].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [148], which does not match the required output shape [136].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [58].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [58].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [136], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [136], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [58], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [58], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [116].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [116], which does not match the required output shape [93].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [61, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [93], which does not match the required output shape [112].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [87].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [33, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [61, 8], which does not match the required output shape [33, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [112], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [112], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [33, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [88, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [87], which does not match the required output shape [128].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [33, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [63, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [77].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [100, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [88, 8], which does not match the required output shape [63, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [128], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [63, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [100, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [106].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [77], which does not match the required output shape [106].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [63, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [100, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [23, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [100, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [106], which does not match the required output shape [102].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [106], which does not match the required output shape [102].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [23, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [102], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [102], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [29].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [84].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [96, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [29], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [96, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [108].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [84], which does not match the required output shape [108].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [96, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [122].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [122].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [96, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [108], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [108], which does not match the required output shape [89].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [93, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [93, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [112, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [89], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [122], which does not match the required output shape [105].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [122], which does not match the required output shape [105].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [93, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [93, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [112, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [105], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [24, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [46, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [24, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [75].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [46, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [75], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [59].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [59], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [30, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [30, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [115, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [115, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [96].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [96].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [92].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [96], which does not match the required output shape [99].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [96], which does not match the required output shape [99].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [68, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [63, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [68, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [92], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [63, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [99], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [68, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [99], which does not match the required output shape [91].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [63, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [68, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [46].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [63, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [91], which does not match the required output shape [51].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [46], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [51], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [118, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [118, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [114, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [69].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [114, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [69], which does not match the required output shape [86].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [89, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [68, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [86], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [89, 8], which does not match the required output shape [68, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [68, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [68, 8], which does not match the required output shape [58, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [66].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [58, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [66], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [26, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [26, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [29, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [29, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [108, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [108, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [79].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [79].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [108, 8], which does not match the required output shape [93, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [108, 8], which does not match the required output shape [93, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [79], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [79], which does not match the required output shape [88].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [93, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [93, 8], which does not match the required output shape [72, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [88], which does not match the required output shape [68].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [72, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [68], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [57].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [57], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [94, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [94, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [95].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [95].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [94, 8], which does not match the required output shape [70, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [94, 8], which does not match the required output shape [70, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [95], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [95], which does not match the required output shape [65].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [70, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [70, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [65], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [45, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [45, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [20].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [43].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [20], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [43], which does not match the required output shape [78].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [102, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [74].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [78], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [102, 8], which does not match the required output shape [84, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [101, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [54].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [74], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [84, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [54], which does not match the required output shape [73].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [101, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [54, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [73], which does not match the required output shape [52].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [67, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [54, 8], which does not match the required output shape [39, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [52], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [67, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [39, 8], which does not match the required output shape [32, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [36, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [32, 8], which does not match the required output shape [20, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [35].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [20, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [36, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [35], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [16].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [16], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [126, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [39].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [128, 8], which does not match the required output shape [127, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [39], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [113, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [44].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [113, 8], which does not match the required output shape [98, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [127, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [44], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [98, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [53].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [80, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [80, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [53], which does not match the required output shape [56].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [80, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [121, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [80, 8], which does not match the required output shape [65, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [56], which does not match the required output shape [49].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [56, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [121, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [65, 8], which does not match the required output shape [57, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [50].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [50].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [49], which does not match the required output shape [45].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [57, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [45], which does not match the required output shape [48].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [110, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [58].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [50], which does not match the required output shape [58].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [48], which does not match the required output shape [33].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [33], which does not match the required output shape [22].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [110, 8], which does not match the required output shape [97, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [58], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [58], which does not match the required output shape [63].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [22], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [97, 8], which does not match the required output shape [82, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [63], which does not match the required output shape [71].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [68, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [82, 8], which does not match the required output shape [68, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [71], which does not match the required output shape [72].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [68, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [68, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [72], which does not match the required output shape [55].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [34, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [55], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [34, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [126, 8], which does not match the required output shape [125, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [124, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [124, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [14].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [120, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [14], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [120, 8], which does not match the required output shape [116, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [25], which does not match the required output shape [24].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [116, 8], which does not match the required output shape [109, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [40].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [109, 8], which does not match the required output shape [103, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [40], which does not match the required output shape [47].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [95, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [103, 8], which does not match the required output shape [95, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [47], which does not match the required output shape [41].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [95, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [95, 8], which does not match the required output shape [87, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [41], which does not match the required output shape [61].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [87, 8], which does not match the required output shape [74, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [61], which does not match the required output shape [76].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [74, 8], which does not match the required output shape [59, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [76], which does not match the required output shape [60].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [59, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [60], which does not match the required output shape [36].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [36], which does not match the required output shape [25].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [24], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [53, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [52, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [53, 8], which does not match the required output shape [52, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [52, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [52, 8], which does not match the required output shape [51, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [51, 8], which does not match the required output shape [48, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [125, 8], which does not match the required output shape [123, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [48, 8], which does not match the required output shape [44, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [44, 8], which does not match the required output shape [42, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [12].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [123, 8], which does not match the required output shape [122, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [42, 8], which does not match the required output shape [41, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [12], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [41, 8], which does not match the required output shape [35, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [122, 8], which does not match the required output shape [119, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [35, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [28, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [17], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [119, 8], which does not match the required output shape [111, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [28, 8], which does not match the required output shape [27, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [17].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [27, 8], which does not match the required output shape [21, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [21, 8], which does not match the required output shape [19, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [111, 8], which does not match the required output shape [107, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [37].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [19, 8], which does not match the required output shape [17, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [107, 8], which does not match the required output shape [99, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [37], which does not match the required output shape [31].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [17, 8], which does not match the required output shape [15, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [15, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [13, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [99, 8], which does not match the required output shape [91, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [31], which does not match the required output shape [34].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [13, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [91, 8], which does not match the required output shape [81, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [34], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [81, 8], which does not match the required output shape [76, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [23].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [11, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [76, 8], which does not match the required output shape [71, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [23], which does not match the required output shape [42].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [71, 8], which does not match the required output shape [62, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [42], which does not match the required output shape [18].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [11, 8], which does not match the required output shape [10, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [62, 8], which does not match the required output shape [55, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [18], which does not match the required output shape [30].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [10, 8], which does not match the required output shape [8, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [55, 8], which does not match the required output shape [49, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [30], which does not match the required output shape [27].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [49, 8], which does not match the required output shape [43, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [27], which does not match the required output shape [26].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [43, 8], which does not match the required output shape [38, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [26], which does not match the required output shape [32].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [38, 8], which does not match the required output shape [31, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [32], which does not match the required output shape [19].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [31, 8], which does not match the required output shape [25, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [19], which does not match the required output shape [21].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [25, 8], which does not match the required output shape [22, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [21], which does not match the required output shape [15].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [22, 8], which does not match the required output shape [16, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [15], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [16, 8], which does not match the required output shape [14, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [14, 8], which does not match the required output shape [12, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [12, 8], which does not match the required output shape [9, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [9, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [13].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [13], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:458: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.add(
/workspace/translation/fairseq/sequence_generator.py:379: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.div(cand_indices, self.vocab_size, out=cand_beams, rounding_mode='trunc')
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:411: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
/workspace/translation/fairseq/sequence_generator.py:405: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  ../aten/src/ATen/native/Resize.cpp:16.)
  torch.masked_select(
| Translated 3000 sentences (7431 tokens) in 2.5s (1192.70 sentences/s, 23634.63 tokens/s)
| Eval completed in: 8.73s | UNCASED BLEU 9.82
| done training in 2226.2 seconds
Transformer | epoch 0 | step () |avg loss 4.782 |walltime 2237.830 |
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
