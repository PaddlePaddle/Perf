| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 2
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 6
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 7
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 1
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 3
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 0
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 5
| distributed init done!
| distributed init (rank 0): env://
| distributed env init. MASTER_ADDR: 127.0.0.1, MASTER_PORT: 29500, WORLD_SIZE: 8, RANK: 4
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| distributed init done!
| initialized host df6665c7a5b6 as rank 0 and device id 0
Namespace(adam_betas='(0.9, 0.997)', adam_eps=1e-09, adaptive_softmax_cutoff=None, amp=False, amp_level='O1', arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, beam=4, bpe_codes=None, buffer_size=64, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', data='./data/wmt14_en_de_joined_dict', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_learned_pos=False, decoder_normalize_before=True, device_id=0, distributed_backend='nccl', distributed_init_method='env://', distributed_port=-1, distributed_rank=0, distributed_world_size=8, do_sanity_check=False, dropout=0.1, enable_parallel_backward_allred_opt=False, enable_parallel_backward_allred_opt_correctness_check=False, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, fp16=False, fuse_dropout_add=False, fuse_layer_norm=True, fuse_relu_dropout=False, gen_subset='test', keep_interval_updates=-1, label_smoothing=0.1, left_pad_source=True, left_pad_target=False, lenpen=1, local_rank=0, log_interval=100, lr=[0.0006], lr_scheduler='inverse_sqrt', lr_shrink=0.1, max_epoch=0, max_len_a=0, max_len_b=200, max_positions=(1024, 1024), max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=2560, max_update=0, min_len=1, min_loss_scale=0.0001, min_lr=0.0, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_save=False, no_token_positional_embeddings=False, num_shards=1, online_eval=False, optimizer='adam', pad_sequence=1, parallel_backward_allred_opt_threshold=0, path=None, prefix_size=0, print_alignment=False, profile=False, profiler_file=None, profiler_steps=100, quiet=False, raw_text=False, relu_dropout=0.1, remove_bpe=None, replace_unk=None, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='./checkpoints/', save_interval=1, save_interval_updates=0, save_predictions=False, score_reference=False, seed=1, sentence_avg=False, sentencepiece=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, stat_file='run_log.json', target_bleu=0.0, target_lang=None, test_cased_bleu=False, train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], valid_subset='valid', validate_interval=1, warmup_init_lr=0.0, warmup_updates=4000, weight_decay=0.0)
| [en] dictionary: 33712 types
| [de] dictionary: 33712 types
| ./data/wmt14_en_de_joined_dict train 4575637 examples
| Sentences are being padded to multiples of: 1
| ./data/wmt14_en_de_joined_dict valid 3000 examples
| Sentences are being padded to multiples of: 1
| ./data/wmt14_en_de_joined_dict test 3003 examples
| Sentences are being padded to multiples of: 1
| num. model params: 210808832
| NOTICE: your device may support faster training with --amp
| model transformer_wmt_en_de_big_t2t, criterion LabelSmoothedCrossEntropyCriterion
| training on 8 GPUs
| max tokens per GPU = 2560 and max sentences per GPU = None
Transformer | epoch 0 | step 100 |avg loss 13.982 |avg tokens 17622.930 |tokens/s 58337.172 |walltime 42.988 |
Transformer | epoch 0 | step 200 |avg loss 11.978 |avg tokens 17595.390 |tokens/s 58492.775 |walltime 73.070 |
Transformer | epoch 0 | step 300 |avg loss 11.362 |avg tokens 17486.850 |tokens/s 57593.523 |walltime 103.432 |
Transformer | epoch 0 | step 400 |avg loss 11.027 |avg tokens 17498.210 |tokens/s 56979.993 |walltime 134.142 |
Transformer | epoch 0 | step 500 |avg loss 10.607 |avg tokens 17637.670 |tokens/s 57578.057 |walltime 164.774 |
Transformer | epoch 0 | step 600 |avg loss 10.147 |avg tokens 17460.160 |tokens/s 57276.745 |walltime 195.258 |
Transformer | epoch 0 | step 700 |avg loss 9.775 |avg tokens 17342.970 |tokens/s 57037.395 |walltime 225.664 |
Transformer | epoch 0 | step 800 |avg loss 9.433 |avg tokens 17466.050 |tokens/s 57595.650 |walltime 255.990 |
Transformer | epoch 0 | step 900 |avg loss 9.180 |avg tokens 17505.330 |tokens/s 57322.148 |walltime 286.528 |
Transformer | epoch 0 | step 1000 |avg loss 8.946 |avg tokens 17462.590 |tokens/s 57186.533 |walltime 317.064 |
Transformer | epoch 0 | step 1100 |avg loss 8.633 |avg tokens 17572.500 |tokens/s 57428.394 |walltime 347.663 |
Transformer | epoch 0 | step 1200 |avg loss 8.386 |avg tokens 17553.430 |tokens/s 57411.241 |walltime 378.238 |
Transformer | epoch 0 | step 1300 |avg loss 8.134 |avg tokens 17355.130 |tokens/s 57099.352 |walltime 408.633 |
Transformer | epoch 0 | step 1400 |avg loss 7.921 |avg tokens 17295.400 |tokens/s 56937.422 |walltime 439.009 |
Transformer | epoch 0 | step 1500 |avg loss 7.701 |avg tokens 17517.340 |tokens/s 57540.988 |walltime 469.452 |
Transformer | epoch 0 | step 1600 |avg loss 7.372 |avg tokens 17487.490 |tokens/s 57440.375 |walltime 499.897 |
Transformer | epoch 0 | step 1700 |avg loss 7.176 |avg tokens 17666.450 |tokens/s 58047.966 |walltime 530.331 |
Transformer | epoch 0 | step 1800 |avg loss 6.988 |avg tokens 17374.410 |tokens/s 57003.511 |walltime 560.811 |
Transformer | epoch 0 | step 1900 |avg loss 6.820 |avg tokens 17514.860 |tokens/s 57500.782 |walltime 591.271 |
Transformer | epoch 0 | step 2000 |avg loss 6.650 |avg tokens 17664.530 |tokens/s 57941.578 |walltime 621.758 |
Transformer | epoch 0 | step 2100 |avg loss 6.598 |avg tokens 17503.740 |tokens/s 57563.898 |walltime 652.165 |
Transformer | epoch 0 | step 2200 |avg loss 6.399 |avg tokens 17382.150 |tokens/s 56923.772 |walltime 682.701 |
Transformer | epoch 0 | step 2300 |avg loss 6.361 |avg tokens 17473.690 |tokens/s 57482.559 |walltime 713.099 |
Transformer | epoch 0 | step 2400 |avg loss 6.266 |avg tokens 17396.820 |tokens/s 57226.830 |walltime 743.499 |
Transformer | epoch 0 | step 2500 |avg loss 6.150 |avg tokens 17344.480 |tokens/s 57107.466 |walltime 773.871 |
Transformer | epoch 0 | step 2600 |avg loss 6.147 |avg tokens 17435.460 |tokens/s 57356.655 |walltime 804.269 |
Transformer | epoch 0 | step 2700 |avg loss 6.044 |avg tokens 17521.910 |tokens/s 57579.742 |walltime 834.700 |
Transformer | epoch 0 | step 2800 |avg loss 5.989 |avg tokens 17536.230 |tokens/s 56985.876 |walltime 865.473 |
Transformer | epoch 0 | step 2900 |avg loss 5.929 |avg tokens 17360.850 |tokens/s 57135.526 |walltime 895.858 |
Transformer | epoch 0 | step 3000 |avg loss 5.903 |avg tokens 17359.100 |tokens/s 57049.419 |walltime 926.286 |
Transformer | epoch 0 | step 3100 |avg loss 5.758 |avg tokens 17476.600 |tokens/s 57322.104 |walltime 956.775 |
Transformer | epoch 0 | step 3200 |avg loss 5.750 |avg tokens 17587.910 |tokens/s 57631.357 |walltime 987.293 |
Transformer | epoch 0 | step 3300 |avg loss 5.714 |avg tokens 17710.590 |tokens/s 58120.218 |walltime 1017.765 |
Transformer | epoch 0 | step 3400 |avg loss 5.714 |avg tokens 17472.580 |tokens/s 57272.255 |walltime 1048.273 |
Transformer | epoch 0 | step 3500 |avg loss 5.760 |avg tokens 17500.920 |tokens/s 57563.441 |walltime 1078.676 |
Transformer | epoch 0 | step 3600 |avg loss 5.731 |avg tokens 17515.390 |tokens/s 57875.747 |walltime 1108.940 |
Transformer | epoch 0 | step 3700 |avg loss 5.675 |avg tokens 17446.410 |tokens/s 57526.332 |walltime 1139.267 |
Transformer | epoch 0 | step 3800 |avg loss 5.676 |avg tokens 17440.840 |tokens/s 57446.091 |walltime 1169.628 |
Transformer | epoch 0 | step 3900 |avg loss 5.657 |avg tokens 17476.120 |tokens/s 57510.808 |walltime 1200.015 |
Transformer | epoch 0 | step 4000 |avg loss 5.535 |avg tokens 17506.980 |tokens/s 57461.297 |walltime 1230.483 |
Transformer | epoch 0 | step 4100 |avg loss 5.588 |avg tokens 17371.580 |tokens/s 57169.058 |walltime 1260.869 |
Transformer | epoch 0 | step 4200 |avg loss 5.519 |avg tokens 17595.390 |tokens/s 57813.040 |walltime 1291.304 |
Transformer | epoch 0 | step 4300 |avg loss 5.489 |avg tokens 17533.080 |tokens/s 57760.620 |walltime 1321.659 |
Transformer | epoch 0 | step 4400 |avg loss 5.486 |avg tokens 17349.410 |tokens/s 57141.663 |walltime 1352.021 |
Transformer | epoch 0 | step 4500 |avg loss 5.410 |avg tokens 17336.840 |tokens/s 57050.161 |walltime 1382.410 |
Transformer | epoch 0 | step 4600 |avg loss 5.459 |avg tokens 17489.200 |tokens/s 57543.969 |walltime 1412.802 |
Transformer | epoch 0 | step 4700 |avg loss 5.434 |avg tokens 17346.550 |tokens/s 57079.361 |walltime 1443.193 |
Transformer | epoch 0 | step 4800 |avg loss 5.322 |avg tokens 17608.100 |tokens/s 57974.794 |walltime 1473.565 |
Transformer | epoch 0 | step 4900 |avg loss 5.351 |avg tokens 17679.900 |tokens/s 58233.263 |walltime 1503.925 |
Transformer | epoch 0 | step 5000 |avg loss 5.341 |avg tokens 17567.980 |tokens/s 57849.611 |walltime 1534.294 |
Transformer | epoch 0 | step 5100 |avg loss 5.270 |avg tokens 17568.400 |tokens/s 57781.591 |walltime 1564.698 |
Transformer | epoch 0 | step 5200 |avg loss 5.307 |avg tokens 17380.480 |tokens/s 57102.530 |walltime 1595.136 |
Transformer | epoch 0 | step 5300 |avg loss 5.278 |avg tokens 17429.050 |tokens/s 57328.830 |walltime 1625.538 |
Transformer | epoch 0 | step 5400 |avg loss 5.239 |avg tokens 17554.390 |tokens/s 57904.504 |walltime 1655.854 |
Transformer | epoch 0 | step 5500 |avg loss 5.219 |avg tokens 17484.640 |tokens/s 57420.896 |walltime 1686.304 |
Transformer | epoch 0 | step 5600 |avg loss 5.195 |avg tokens 17322.310 |tokens/s 57107.634 |walltime 1716.637 |
Transformer | epoch 0 | step 5700 |avg loss 5.195 |avg tokens 17381.820 |tokens/s 57236.436 |walltime 1747.005 |
Transformer | epoch 0 | step 5800 |avg loss 5.180 |avg tokens 17398.550 |tokens/s 57249.828 |walltime 1777.396 |
Transformer | epoch 0 | step 5900 |avg loss 5.167 |avg tokens 17363.510 |tokens/s 57188.076 |walltime 1807.758 |
Transformer | epoch 0 | step 6000 |avg loss 5.127 |avg tokens 17548.860 |tokens/s 57816.160 |walltime 1838.111 |
Transformer | epoch 0 | step 6100 |avg loss 5.177 |avg tokens 17406.530 |tokens/s 57258.748 |walltime 1868.510 |
Transformer | epoch 0 | step 6200 |avg loss 5.158 |avg tokens 17337.680 |tokens/s 57099.511 |walltime 1898.874 |
Transformer | epoch 0 | step 6300 |avg loss 5.160 |avg tokens 17438.260 |tokens/s 57517.864 |walltime 1929.192 |
Transformer | epoch 0 | step 6400 |avg loss 5.104 |avg tokens 17529.390 |tokens/s 57575.655 |walltime 1959.638 |
Transformer | epoch 0 | step 6500 |avg loss 5.097 |avg tokens 17290.550 |tokens/s 56767.686 |walltime 1990.097 |
Transformer | epoch 0 | step 6600 |avg loss 4.979 |avg tokens 17479.460 |tokens/s 57464.061 |walltime 2020.515 |
Transformer | epoch 0 | step 6700 |avg loss 5.031 |avg tokens 17293.350 |tokens/s 57014.534 |walltime 2050.846 |
Transformer | epoch 0 | step 6800 |avg loss 5.054 |avg tokens 17475.630 |tokens/s 57460.698 |walltime 2081.259 |
Transformer | epoch 0 | step 6900 |avg loss 5.044 |avg tokens 17333.760 |tokens/s 57104.649 |walltime 2111.614 |
Transformer | epoch 0 | step 7000 |avg loss 5.003 |avg tokens 17392.020 |tokens/s 57243.977 |walltime 2141.996 |
Transformer | epoch 0 | step 7100 |avg loss 4.983 |avg tokens 17425.800 |tokens/s 57318.040 |walltime 2172.398 |
Transformer | epoch 0 | step 7200 |avg loss 4.999 |avg tokens 17368.430 |tokens/s 57337.529 |walltime 2202.690 |
Transformer | epoch 0 | step 7300 |avg loss 5.005 |avg tokens 17422.980 |tokens/s 57291.099 |walltime 2233.101 |
Transformer | epoch 0 | step 7400 |avg loss 5.003 |avg tokens 17337.590 |tokens/s 57368.973 |walltime 2263.322 |
Transformer | epoch 0 | step 7500 |avg loss 4.931 |avg tokens 17367.760 |tokens/s 57028.231 |walltime 2293.777 |
Transformer | epoch 0 | step 7600 |avg loss 4.999 |avg tokens 17369.950 |tokens/s 57371.347 |walltime 2324.053 |
Transformer | epoch 0 | step 7700 |avg loss 5.008 |avg tokens 17324.320 |tokens/s 57125.307 |walltime 2354.380 |
Transformer | epoch 0 | step 7800 |avg loss 4.960 |avg tokens 17251.270 |tokens/s 56761.529 |walltime 2384.773 |
Transformer | epoch 0 | step 7900 |avg loss 4.987 |avg tokens 17536.950 |tokens/s 57802.507 |walltime 2415.112 |
Transformer | epoch 0 | step 8000 |avg loss 4.931 |avg tokens 17489.800 |tokens/s 57588.900 |walltime 2445.482 |
Transformer | epoch 0 | step 8100 |avg loss 4.901 |avg tokens 17488.820 |tokens/s 57399.000 |walltime 2475.951 |
Epoch time: 2479.0312118530273
Transformer | epoch 0 | step 8149 |avg loss 4.931 |avg tokens 17464.980 |tokens/s 56005.840 |walltime 2491.231 |
Validation loss on subset valid: 4.512662489144385
